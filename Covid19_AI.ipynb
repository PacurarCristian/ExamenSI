{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.  Country        Date  Confirmed  Death  newConfirmed  newDeath\n",
       "0    1  Romania  2019-12-31          0      0             0         0\n",
       "1    2  Romania  2020-01-01          0      0             0         0\n",
       "2    3  Romania  2020-01-02          0      0             0         0\n",
       "3    4  Romania  2020-01-03          0      0             0         0\n",
       "4    5  Romania  2020-01-04          0      0             0         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#importam datasetul nostru\n",
    "input_file = \"Dataset.csv\"\n",
    "\n",
    "#citim din csv si punem in data\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>10635</td>\n",
       "      <td>601</td>\n",
       "      <td>218</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>11036</td>\n",
       "      <td>619</td>\n",
       "      <td>401</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>11339</td>\n",
       "      <td>641</td>\n",
       "      <td>303</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11616</td>\n",
       "      <td>663</td>\n",
       "      <td>277</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>11978</td>\n",
       "      <td>693</td>\n",
       "      <td>362</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country        Date  Confirmed  Death  newConfirmed  newDeath\n",
       "0    Romania  2019-12-31          0      0             0         0\n",
       "1    Romania  2020-01-01          0      0             0         0\n",
       "2    Romania  2020-01-02          0      0             0         0\n",
       "3    Romania  2020-01-03          0      0             0         0\n",
       "4    Romania  2020-01-04          0      0             0         0\n",
       "..       ...         ...        ...    ...           ...       ...\n",
       "116  Romania  2020-04-25      10635    601           218        34\n",
       "117  Romania  2020-04-26      11036    619           401        18\n",
       "118  Romania  2020-04-27      11339    641           303        22\n",
       "119  Romania  2020-04-28      11616    663           277        22\n",
       "120  Romania  2020-04-29      11978    693           362        30\n",
       "\n",
       "[121 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stergem coloana cu numarul deoarece nu avem nevoie de ele in prelucrarea datelor\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#folosim un label encoder pentru coloanele country si date pentru a le putea transforma in valori numerice\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(data['Date'])\n",
    "data.loc[:, 'Date'] = le.transform(data['Date'])\n",
    "\n",
    "le.fit(data['Country'])\n",
    "data.loc[:, 'Country'] = le.transform(data['Country'])\n",
    "\n",
    "#punem in y doar Country si Date\n",
    "y = data.drop(data.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "\n",
    "#In X_final punem restul coloanelor\n",
    "X_final = data.drop(data.columns[1], axis=1)\n",
    "X_final = X_final.drop(X_final.columns[0], axis=1)\n",
    "\n",
    "y_train, y_test, X_train, X_test = train_test_split(X_final, y, test_size=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Date\n",
       "24         0    24\n",
       "103        0   103\n",
       "93         0    93\n",
       "67         0    67\n",
       "92         0    92\n",
       "..       ...   ...\n",
       "91         0    91\n",
       "109        0   109\n",
       "29         0    29\n",
       "13         0    13\n",
       "23         0    23\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train contine datele de train pentru input\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6300</td>\n",
       "      <td>316</td>\n",
       "      <td>310</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2738</td>\n",
       "      <td>115</td>\n",
       "      <td>278</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2460</td>\n",
       "      <td>92</td>\n",
       "      <td>215</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2245</td>\n",
       "      <td>82</td>\n",
       "      <td>136</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>8418</td>\n",
       "      <td>421</td>\n",
       "      <td>351</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Confirmed  Death  newConfirmed  newDeath\n",
       "24           0      0             0         0\n",
       "103       6300    316           310        25\n",
       "93        2738    115           278        23\n",
       "67           9      0             0         0\n",
       "92        2460     92           215        10\n",
       "..         ...    ...           ...       ...\n",
       "91        2245     82           136        17\n",
       "109       8418    421           351        10\n",
       "29           0      0             0         0\n",
       "13           0      0             0         0\n",
       "23           0      0             0         0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train contine datele de train pentru rezultatul inputului\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Date\n",
       "42         0    42\n",
       "41         0    41\n",
       "120        0   120\n",
       "104        0   104\n",
       "44         0    44\n",
       "65         0    65\n",
       "100        0   100\n",
       "80         0    80\n",
       "61         0    61\n",
       "57         0    57\n",
       "114        0   114\n",
       "111        0   111\n",
       "96         0    96\n",
       "59         0    59\n",
       "18         0    18\n",
       "69         0    69\n",
       "101        0   101\n",
       "50         0    50\n",
       "60         0    60\n",
       "106        0   106\n",
       "56         0    56"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test contine datele de input pentru test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11978</td>\n",
       "      <td>693</td>\n",
       "      <td>362</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6633</td>\n",
       "      <td>331</td>\n",
       "      <td>333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5202</td>\n",
       "      <td>248</td>\n",
       "      <td>441</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10096</td>\n",
       "      <td>545</td>\n",
       "      <td>386</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8936</td>\n",
       "      <td>478</td>\n",
       "      <td>190</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3864</td>\n",
       "      <td>151</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5467</td>\n",
       "      <td>270</td>\n",
       "      <td>265</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7216</td>\n",
       "      <td>372</td>\n",
       "      <td>337</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Confirmed  Death  newConfirmed  newDeath\n",
       "42           0      0             0         0\n",
       "41           0      0             0         0\n",
       "120      11978    693           362        30\n",
       "104       6633    331           333        15\n",
       "44           0      0             0         0\n",
       "65           6      0             2         0\n",
       "100       5202    248           441        28\n",
       "80         308      0            31         0\n",
       "61           3      0             0         0\n",
       "57           1      0             1         0\n",
       "114      10096    545           386        21\n",
       "111       8936    478           190        27\n",
       "96        3864    151           251         5\n",
       "59           3      0             2         0\n",
       "18           0      0             0         0\n",
       "69          15      0             0         0\n",
       "101       5467    270           265        22\n",
       "50           0      0             0         0\n",
       "60           3      0             0         0\n",
       "106       7216    372           337        21\n",
       "56           0      0             0         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test contine datele rezultate in urma inputului de test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1629562.58131070\n",
      "Iteration 2, loss = 1627091.64381731\n",
      "Iteration 3, loss = 1624746.44726566\n",
      "Iteration 4, loss = 1622467.12566039\n",
      "Iteration 5, loss = 1620293.71059235\n",
      "Iteration 6, loss = 1618206.18970531\n",
      "Iteration 7, loss = 1616158.12425028\n",
      "Iteration 8, loss = 1614203.74674996\n",
      "Iteration 9, loss = 1612371.19920041\n",
      "Iteration 10, loss = 1610520.11010393\n",
      "Iteration 11, loss = 1608698.84635024\n",
      "Iteration 12, loss = 1606851.62171183\n",
      "Iteration 13, loss = 1604978.90241679\n",
      "Iteration 14, loss = 1603062.65483693\n",
      "Iteration 15, loss = 1601116.97117584\n",
      "Iteration 16, loss = 1599122.52354803\n",
      "Iteration 17, loss = 1597088.39384224\n",
      "Iteration 18, loss = 1595072.56372661\n",
      "Iteration 19, loss = 1593034.42270442\n",
      "Iteration 20, loss = 1590935.26651745\n",
      "Iteration 21, loss = 1588773.09775785\n",
      "Iteration 22, loss = 1586554.90362232\n",
      "Iteration 23, loss = 1584249.10001885\n",
      "Iteration 24, loss = 1581881.82228096\n",
      "Iteration 25, loss = 1579440.64973472\n",
      "Iteration 26, loss = 1576922.77422349\n",
      "Iteration 27, loss = 1574325.37159240\n",
      "Iteration 28, loss = 1571645.61808686\n",
      "Iteration 29, loss = 1568880.56541600\n",
      "Iteration 30, loss = 1565973.21856830\n",
      "Iteration 31, loss = 1562958.46101180\n",
      "Iteration 32, loss = 1559832.71480528\n",
      "Iteration 33, loss = 1556598.37392309\n",
      "Iteration 34, loss = 1553254.18118233\n",
      "Iteration 35, loss = 1549840.46627854\n",
      "Iteration 36, loss = 1546238.71573484\n",
      "Iteration 37, loss = 1542551.17086318\n",
      "Iteration 38, loss = 1538754.39791020\n",
      "Iteration 39, loss = 1534850.95186319\n",
      "Iteration 40, loss = 1530807.02595050\n",
      "Iteration 41, loss = 1526648.23437153\n",
      "Iteration 42, loss = 1522368.28930020\n",
      "Iteration 43, loss = 1517962.80080491\n",
      "Iteration 44, loss = 1513430.10616110\n",
      "Iteration 45, loss = 1508774.46759529\n",
      "Iteration 46, loss = 1503977.43659328\n",
      "Iteration 47, loss = 1499053.71830002\n",
      "Iteration 48, loss = 1493997.56759435\n",
      "Iteration 49, loss = 1488807.50785482\n",
      "Iteration 50, loss = 1483482.72343469\n",
      "Iteration 51, loss = 1478022.56170012\n",
      "Iteration 52, loss = 1472426.53427457\n",
      "Iteration 53, loss = 1466694.29461367\n",
      "Iteration 54, loss = 1460825.60486709\n",
      "Iteration 55, loss = 1454820.27121846\n",
      "Iteration 56, loss = 1448678.70660165\n",
      "Iteration 57, loss = 1442400.18892747\n",
      "Iteration 58, loss = 1435988.97424557\n",
      "Iteration 59, loss = 1429437.25264686\n",
      "Iteration 60, loss = 1422752.77818529\n",
      "Iteration 61, loss = 1415934.17962324\n",
      "Iteration 62, loss = 1408981.01371549\n",
      "Iteration 63, loss = 1401894.43577337\n",
      "Iteration 64, loss = 1394675.16789900\n",
      "Iteration 65, loss = 1387321.73052430\n",
      "Iteration 66, loss = 1379844.23081415\n",
      "Iteration 67, loss = 1372218.50502298\n",
      "Iteration 68, loss = 1364468.34463809\n",
      "Iteration 69, loss = 1356584.97381079\n",
      "Iteration 70, loss = 1348569.80343994\n",
      "Iteration 71, loss = 1340426.88276341\n",
      "Iteration 72, loss = 1332142.89944079\n",
      "Iteration 73, loss = 1323739.85114513\n",
      "Iteration 74, loss = 1315195.58094979\n",
      "Iteration 75, loss = 1306529.47833128\n",
      "Iteration 76, loss = 1297730.86003157\n",
      "Iteration 77, loss = 1288807.96852505\n",
      "Iteration 78, loss = 1279758.78024977\n",
      "Iteration 79, loss = 1270586.69166986\n",
      "Iteration 80, loss = 1261295.16616341\n",
      "Iteration 81, loss = 1251901.33981155\n",
      "Iteration 82, loss = 1242366.97464210\n",
      "Iteration 83, loss = 1232748.01848303\n",
      "Iteration 84, loss = 1223016.15314392\n",
      "Iteration 85, loss = 1213180.24482376\n",
      "Iteration 86, loss = 1203259.22189799\n",
      "Iteration 87, loss = 1193248.39451983\n",
      "Iteration 88, loss = 1183153.78899881\n",
      "Iteration 89, loss = 1173006.89587274\n",
      "Iteration 90, loss = 1162755.37210702\n",
      "Iteration 91, loss = 1152467.56542953\n",
      "Iteration 92, loss = 1142122.07266883\n",
      "Iteration 93, loss = 1131756.41529811\n",
      "Iteration 94, loss = 1121315.01572518\n",
      "Iteration 95, loss = 1110878.65280139\n",
      "Iteration 96, loss = 1100404.32062938\n",
      "Iteration 97, loss = 1089940.35098393\n",
      "Iteration 98, loss = 1079479.20913946\n",
      "Iteration 99, loss = 1069028.87131452\n",
      "Iteration 100, loss = 1058597.53839074\n",
      "Iteration 101, loss = 1048206.14387589\n",
      "Iteration 102, loss = 1037878.45865121\n",
      "Iteration 103, loss = 1027578.96457072\n",
      "Iteration 104, loss = 1017333.18759565\n",
      "Iteration 105, loss = 1007214.72155009\n",
      "Iteration 106, loss = 997177.86862411\n",
      "Iteration 107, loss = 987195.30051037\n",
      "Iteration 108, loss = 977341.02421750\n",
      "Iteration 109, loss = 967649.65990380\n",
      "Iteration 110, loss = 958020.07626261\n",
      "Iteration 111, loss = 948607.14932121\n",
      "Iteration 112, loss = 939289.32016556\n",
      "Iteration 113, loss = 930136.53769168\n",
      "Iteration 114, loss = 921165.74706612\n",
      "Iteration 115, loss = 912368.78837170\n",
      "Iteration 116, loss = 903757.25246637\n",
      "Iteration 117, loss = 895357.37200740\n",
      "Iteration 118, loss = 887138.78737233\n",
      "Iteration 119, loss = 879180.17855449\n",
      "Iteration 120, loss = 871401.94727332\n",
      "Iteration 121, loss = 863813.02990720\n",
      "Iteration 122, loss = 856531.24130223\n",
      "Iteration 123, loss = 849470.94034367\n",
      "Iteration 124, loss = 842661.39921193\n",
      "Iteration 125, loss = 836088.16275709\n",
      "Iteration 126, loss = 829764.78690750\n",
      "Iteration 127, loss = 823702.92969432\n",
      "Iteration 128, loss = 817889.43805414\n",
      "Iteration 129, loss = 812387.69651335\n",
      "Iteration 130, loss = 807146.95547703\n",
      "Iteration 131, loss = 802180.64886842\n",
      "Iteration 132, loss = 797400.99964510\n",
      "Iteration 133, loss = 792891.48843853\n",
      "Iteration 134, loss = 788671.70286723\n",
      "Iteration 135, loss = 784757.99698993\n",
      "Iteration 136, loss = 781080.41155433\n",
      "Iteration 137, loss = 777594.90096734\n",
      "Iteration 138, loss = 774405.51287160\n",
      "Iteration 139, loss = 771458.78201934\n",
      "Iteration 140, loss = 768734.89949669\n",
      "Iteration 141, loss = 766214.24149908\n",
      "Iteration 142, loss = 763871.25623631\n",
      "Iteration 143, loss = 761732.02701197\n",
      "Iteration 144, loss = 759824.83882392\n",
      "Iteration 145, loss = 758039.69879731\n",
      "Iteration 146, loss = 756386.27509315\n",
      "Iteration 147, loss = 755011.89084785\n",
      "Iteration 148, loss = 753740.45364113\n",
      "Iteration 149, loss = 752609.79049599\n",
      "Iteration 150, loss = 751603.47552742\n",
      "Iteration 151, loss = 750692.24998061\n",
      "Iteration 152, loss = 749948.98879219\n",
      "Iteration 153, loss = 749281.42606276\n",
      "Iteration 154, loss = 748702.82636714\n",
      "Iteration 155, loss = 748198.37650831\n",
      "Iteration 156, loss = 747784.99808584\n",
      "Iteration 157, loss = 747397.16078430\n",
      "Iteration 158, loss = 747063.73595665\n",
      "Iteration 159, loss = 746793.64160498\n",
      "Iteration 160, loss = 746560.48643717\n",
      "Iteration 161, loss = 746366.94746213\n",
      "Iteration 162, loss = 746205.70653522\n",
      "Iteration 163, loss = 746057.14571883\n",
      "Iteration 164, loss = 745933.51308797\n",
      "Iteration 165, loss = 745815.79927231\n",
      "Iteration 166, loss = 745711.64218531\n",
      "Iteration 167, loss = 745607.61435568\n",
      "Iteration 168, loss = 745504.27178894\n",
      "Iteration 169, loss = 745387.43720726\n",
      "Iteration 170, loss = 745268.69732794\n",
      "Iteration 171, loss = 745160.51847672\n",
      "Iteration 172, loss = 745038.60004513\n",
      "Iteration 173, loss = 744907.21899677\n",
      "Iteration 174, loss = 744767.05874999\n",
      "Iteration 175, loss = 744602.08764641\n",
      "Iteration 176, loss = 744465.90410312\n",
      "Iteration 177, loss = 744290.11608181\n",
      "Iteration 178, loss = 744134.84530542\n",
      "Iteration 179, loss = 743999.28112053\n",
      "Iteration 180, loss = 743862.81138520\n",
      "Iteration 181, loss = 743725.25393398\n",
      "Iteration 182, loss = 743585.10929561\n",
      "Iteration 183, loss = 743428.74260676\n",
      "Iteration 184, loss = 743276.30309529\n",
      "Iteration 185, loss = 743091.15084954\n",
      "Iteration 186, loss = 742942.76275443\n",
      "Iteration 187, loss = 742810.33607260\n",
      "Iteration 188, loss = 742677.06691070\n",
      "Iteration 189, loss = 742539.61160208\n",
      "Iteration 190, loss = 742389.44000391\n",
      "Iteration 191, loss = 742229.10211496\n",
      "Iteration 192, loss = 742083.89947599\n",
      "Iteration 193, loss = 741931.62369501\n",
      "Iteration 194, loss = 741794.85077239\n",
      "Iteration 195, loss = 741653.96892902\n",
      "Iteration 196, loss = 741508.94129809\n",
      "Iteration 197, loss = 741356.96801930\n",
      "Iteration 198, loss = 741195.31224651\n",
      "Iteration 199, loss = 740998.36890727\n",
      "Iteration 200, loss = 740836.19738339\n",
      "Iteration 201, loss = 740678.23828115\n",
      "Iteration 202, loss = 740515.57937634\n",
      "Iteration 203, loss = 740343.79095165\n",
      "Iteration 204, loss = 740154.73106877\n",
      "Iteration 205, loss = 739893.99707406\n",
      "Iteration 206, loss = 739729.78618163\n",
      "Iteration 207, loss = 739568.97133413\n",
      "Iteration 208, loss = 739406.64980753\n",
      "Iteration 209, loss = 739242.94595645\n",
      "Iteration 210, loss = 739077.35212989\n",
      "Iteration 211, loss = 738907.22932399\n",
      "Iteration 212, loss = 738721.21752632\n",
      "Iteration 213, loss = 738554.53167494\n",
      "Iteration 214, loss = 738386.91516138\n",
      "Iteration 215, loss = 738218.31673427\n",
      "Iteration 216, loss = 738048.64411631\n",
      "Iteration 217, loss = 737877.80183962\n",
      "Iteration 218, loss = 737705.69202996\n",
      "Iteration 219, loss = 737532.24783993\n",
      "Iteration 220, loss = 737357.44757744\n",
      "Iteration 221, loss = 737181.30312513\n",
      "Iteration 222, loss = 737003.89891669\n",
      "Iteration 223, loss = 736825.35004903\n",
      "Iteration 224, loss = 736645.76519104\n",
      "Iteration 225, loss = 736465.22374612\n",
      "Iteration 226, loss = 736283.77196173\n",
      "Iteration 227, loss = 736101.43654268\n",
      "Iteration 228, loss = 735918.19089130\n",
      "Iteration 229, loss = 735733.96313250\n",
      "Iteration 230, loss = 735548.69288356\n",
      "Iteration 231, loss = 735362.33397499\n",
      "Iteration 232, loss = 735174.77886254\n",
      "Iteration 233, loss = 734985.76523021\n",
      "Iteration 234, loss = 734793.42380595\n",
      "Iteration 235, loss = 734590.38958506\n",
      "Iteration 236, loss = 734398.24553578\n",
      "Iteration 237, loss = 734204.96578270\n",
      "Iteration 238, loss = 734010.42569253\n",
      "Iteration 239, loss = 733814.57439611\n",
      "Iteration 240, loss = 733617.48335064\n",
      "Iteration 241, loss = 733419.27919465\n",
      "Iteration 242, loss = 733220.00882358\n",
      "Iteration 243, loss = 733019.70130075\n",
      "Iteration 244, loss = 732818.36500482\n",
      "Iteration 245, loss = 732615.90312438\n",
      "Iteration 246, loss = 732412.42763017\n",
      "Iteration 247, loss = 732207.52477608\n",
      "Iteration 248, loss = 732001.37775515\n",
      "Iteration 249, loss = 731793.96973530\n",
      "Iteration 250, loss = 731585.04291305\n",
      "Iteration 251, loss = 731373.82874776\n",
      "Iteration 252, loss = 731154.47320098\n",
      "Iteration 253, loss = 730934.04341214\n",
      "Iteration 254, loss = 730720.17743703\n",
      "Iteration 255, loss = 730504.92187993\n",
      "Iteration 256, loss = 730288.25168926\n",
      "Iteration 257, loss = 730070.16455300\n",
      "Iteration 258, loss = 729850.59839419\n",
      "Iteration 259, loss = 729629.47433534\n",
      "Iteration 260, loss = 729406.70276989\n",
      "Iteration 261, loss = 729182.13745659\n",
      "Iteration 262, loss = 728955.65265450\n",
      "Iteration 263, loss = 728726.97487472\n",
      "Iteration 264, loss = 728495.74749608\n",
      "Iteration 265, loss = 728261.77169207\n",
      "Iteration 266, loss = 728024.84904145\n",
      "Iteration 267, loss = 727782.51890947\n",
      "Iteration 268, loss = 727531.71954946\n",
      "Iteration 269, loss = 727269.21655539\n",
      "Iteration 270, loss = 726968.98754076\n",
      "Iteration 271, loss = 726598.68641883\n",
      "Iteration 272, loss = 726358.72845013\n",
      "Iteration 273, loss = 726116.21411574\n",
      "Iteration 274, loss = 725871.37940697\n",
      "Iteration 275, loss = 725624.98941839\n",
      "Iteration 276, loss = 725377.44053392\n",
      "Iteration 277, loss = 725128.40476714\n",
      "Iteration 278, loss = 724877.56279201\n",
      "Iteration 279, loss = 724625.14349014\n",
      "Iteration 280, loss = 724371.60101204\n",
      "Iteration 281, loss = 724117.03483052\n",
      "Iteration 282, loss = 723861.09809237\n",
      "Iteration 283, loss = 723603.49450330\n",
      "Iteration 284, loss = 723344.28820028\n",
      "Iteration 285, loss = 723083.73246107\n",
      "Iteration 286, loss = 722821.95793641\n",
      "Iteration 287, loss = 722558.88645824\n",
      "Iteration 288, loss = 722294.43811173\n",
      "Iteration 289, loss = 722028.68533354\n",
      "Iteration 290, loss = 721761.76330174\n",
      "Iteration 291, loss = 721493.67804556\n",
      "Iteration 292, loss = 721224.29671549\n",
      "Iteration 293, loss = 720953.53339851\n",
      "Iteration 294, loss = 720681.44961102\n",
      "Iteration 295, loss = 720408.14397937\n",
      "Iteration 296, loss = 720133.62201905\n",
      "Iteration 297, loss = 719857.82769562\n",
      "Iteration 298, loss = 719580.76203796\n",
      "Iteration 299, loss = 719302.49177215\n",
      "Iteration 300, loss = 719023.04290156\n",
      "Iteration 301, loss = 718742.36534066\n",
      "Iteration 302, loss = 718460.41013032\n",
      "Iteration 303, loss = 718177.19449757\n",
      "Iteration 304, loss = 717892.74912260\n",
      "Iteration 305, loss = 717606.99476927\n",
      "Iteration 306, loss = 717320.01391996\n",
      "Iteration 307, loss = 717031.73734327\n",
      "Iteration 308, loss = 716742.18930361\n",
      "Iteration 309, loss = 716451.36672209\n",
      "Iteration 310, loss = 716159.23096512\n",
      "Iteration 311, loss = 715865.75907015\n",
      "Iteration 312, loss = 715570.96473005\n",
      "Iteration 313, loss = 715274.85354556\n",
      "Iteration 314, loss = 714980.57886343\n",
      "Iteration 315, loss = 714680.01440461\n",
      "Iteration 316, loss = 714381.55933867\n",
      "Iteration 317, loss = 714079.82032401\n",
      "Iteration 318, loss = 713776.18449460\n",
      "Iteration 319, loss = 713472.56111521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 320, loss = 713168.08143520\n",
      "Iteration 321, loss = 712861.09618828\n",
      "Iteration 322, loss = 712552.36196271\n",
      "Iteration 323, loss = 712243.34947549\n",
      "Iteration 324, loss = 711933.48607693\n",
      "Iteration 325, loss = 711621.47113622\n",
      "Iteration 326, loss = 711308.13040809\n",
      "Iteration 327, loss = 710993.21074177\n",
      "Iteration 328, loss = 710677.27521057\n",
      "Iteration 329, loss = 710359.88060525\n",
      "Iteration 330, loss = 710041.42380698\n",
      "Iteration 331, loss = 709721.67852490\n",
      "Iteration 332, loss = 709400.25021527\n",
      "Iteration 333, loss = 709077.45271713\n",
      "Iteration 334, loss = 708753.41333368\n",
      "Iteration 335, loss = 708427.87901191\n",
      "Iteration 336, loss = 708101.71187301\n",
      "Iteration 337, loss = 707773.79286627\n",
      "Iteration 338, loss = 707444.72385574\n",
      "Iteration 339, loss = 707113.49517166\n",
      "Iteration 340, loss = 706781.31913502\n",
      "Iteration 341, loss = 706448.26712387\n",
      "Iteration 342, loss = 706113.32563909\n",
      "Iteration 343, loss = 705776.55776790\n",
      "Iteration 344, loss = 705438.86646661\n",
      "Iteration 345, loss = 705100.02172456\n",
      "Iteration 346, loss = 704759.30095526\n",
      "Iteration 347, loss = 704417.09880598\n",
      "Iteration 348, loss = 704073.69369610\n",
      "Iteration 349, loss = 703728.76845685\n",
      "Iteration 350, loss = 703382.88857257\n",
      "Iteration 351, loss = 703034.56514676\n",
      "Iteration 352, loss = 702686.02218651\n",
      "Iteration 353, loss = 702333.79830631\n",
      "Iteration 354, loss = 701977.74920800\n",
      "Iteration 355, loss = 701623.09775038\n",
      "Iteration 356, loss = 701266.60300884\n",
      "Iteration 357, loss = 700908.05579753\n",
      "Iteration 358, loss = 700548.26551436\n",
      "Iteration 359, loss = 700186.93412095\n",
      "Iteration 360, loss = 699823.65470869\n",
      "Iteration 361, loss = 699459.02007785\n",
      "Iteration 362, loss = 699093.07534070\n",
      "Iteration 363, loss = 698725.21271684\n",
      "Iteration 364, loss = 698355.56232044\n",
      "Iteration 365, loss = 697984.51971129\n",
      "Iteration 366, loss = 697611.81085819\n",
      "Iteration 367, loss = 697237.28592998\n",
      "Iteration 368, loss = 696861.13915381\n",
      "Iteration 369, loss = 696483.28883604\n",
      "Iteration 370, loss = 696103.23034030\n",
      "Iteration 371, loss = 695720.83045126\n",
      "Iteration 372, loss = 695335.74560515\n",
      "Iteration 373, loss = 694945.70273435\n",
      "Iteration 374, loss = 694541.84776530\n",
      "Iteration 375, loss = 694149.87882116\n",
      "Iteration 376, loss = 693761.08942667\n",
      "Iteration 377, loss = 693370.50931193\n",
      "Iteration 378, loss = 692978.21788983\n",
      "Iteration 379, loss = 692584.30960645\n",
      "Iteration 380, loss = 692188.78019075\n",
      "Iteration 381, loss = 691791.57665302\n",
      "Iteration 382, loss = 691392.66992563\n",
      "Iteration 383, loss = 690992.03319497\n",
      "Iteration 384, loss = 690589.68393324\n",
      "Iteration 385, loss = 690185.55888426\n",
      "Iteration 386, loss = 689779.46433072\n",
      "Iteration 387, loss = 689371.07385069\n",
      "Iteration 388, loss = 688959.58776586\n",
      "Iteration 389, loss = 688543.02470531\n",
      "Iteration 390, loss = 688107.34476115\n",
      "Iteration 391, loss = 687667.81601669\n",
      "Iteration 392, loss = 687251.34174968\n",
      "Iteration 393, loss = 686832.81797658\n",
      "Iteration 394, loss = 686448.42577785\n",
      "Iteration 395, loss = 685991.63464619\n",
      "Iteration 396, loss = 685569.39187508\n",
      "Iteration 397, loss = 685144.14504252\n",
      "Iteration 398, loss = 684716.49723160\n",
      "Iteration 399, loss = 684287.49670764\n",
      "Iteration 400, loss = 683857.63225808\n",
      "Iteration 401, loss = 683426.81970565\n",
      "Iteration 402, loss = 682994.16717926\n",
      "Iteration 403, loss = 682559.10187546\n",
      "Iteration 404, loss = 682122.36065792\n",
      "Iteration 405, loss = 681684.68622964\n",
      "Iteration 406, loss = 681245.84247714\n",
      "Iteration 407, loss = 680805.25432038\n",
      "Iteration 408, loss = 680362.76938442\n",
      "Iteration 409, loss = 679918.62866228\n",
      "Iteration 410, loss = 679473.25665692\n",
      "Iteration 411, loss = 679026.75089563\n",
      "Iteration 412, loss = 678578.71995838\n",
      "Iteration 413, loss = 678128.92154537\n",
      "Iteration 414, loss = 677677.60550196\n",
      "Iteration 415, loss = 677225.06351856\n",
      "Iteration 416, loss = 676771.27713277\n",
      "Iteration 417, loss = 676316.04443620\n",
      "Iteration 418, loss = 675859.25553714\n",
      "Iteration 419, loss = 675401.03004250\n",
      "Iteration 420, loss = 674941.47366848\n",
      "Iteration 421, loss = 674480.57479463\n",
      "Iteration 422, loss = 674018.22324054\n",
      "Iteration 423, loss = 673554.33863348\n",
      "Iteration 424, loss = 673088.98487718\n",
      "Iteration 425, loss = 672622.29054407\n",
      "Iteration 426, loss = 672154.25571758\n",
      "Iteration 427, loss = 671684.75316083\n",
      "Iteration 428, loss = 671213.83428697\n",
      "Iteration 429, loss = 670741.53161866\n",
      "Iteration 430, loss = 670267.97531872\n",
      "Iteration 431, loss = 669794.91811547\n",
      "Iteration 432, loss = 669325.32422256\n",
      "Iteration 433, loss = 668856.75481399\n",
      "Iteration 434, loss = 668376.53707909\n",
      "Iteration 435, loss = 667890.81923239\n",
      "Iteration 436, loss = 667410.90954845\n",
      "Iteration 437, loss = 666933.59237907\n",
      "Iteration 438, loss = 666450.42439937\n",
      "Iteration 439, loss = 665968.12305468\n",
      "Iteration 440, loss = 665487.72382616\n",
      "Iteration 441, loss = 665002.02840735\n",
      "Iteration 442, loss = 664551.23802211\n",
      "Iteration 443, loss = 664040.00928381\n",
      "Iteration 444, loss = 663556.44933279\n",
      "Iteration 445, loss = 663055.03194502\n",
      "Iteration 446, loss = 662572.66302028\n",
      "Iteration 447, loss = 662084.55743274\n",
      "Iteration 448, loss = 661584.28535005\n",
      "Iteration 449, loss = 661098.84096189\n",
      "Iteration 450, loss = 660608.18238133\n",
      "Iteration 451, loss = 660107.59010049\n",
      "Iteration 452, loss = 659617.27182594\n",
      "Iteration 453, loss = 659123.17334515\n",
      "Iteration 454, loss = 658622.58669921\n",
      "Iteration 455, loss = 658129.38735299\n",
      "Iteration 456, loss = 657631.98675643\n",
      "Iteration 457, loss = 657130.11271840\n",
      "Iteration 458, loss = 656633.88265729\n",
      "Iteration 459, loss = 656133.84487493\n",
      "Iteration 460, loss = 655631.03288846\n",
      "Iteration 461, loss = 655132.03902496\n",
      "Iteration 462, loss = 654629.25826223\n",
      "Iteration 463, loss = 654125.19880949\n",
      "Iteration 464, loss = 653623.58812156\n",
      "Iteration 465, loss = 653118.45428073\n",
      "Iteration 466, loss = 652613.08017523\n",
      "Iteration 467, loss = 652108.83784273\n",
      "Iteration 468, loss = 651601.51679883\n",
      "Iteration 469, loss = 651094.39878373\n",
      "Iteration 470, loss = 650587.27623241\n",
      "Iteration 471, loss = 650077.82343995\n",
      "Iteration 472, loss = 649568.94179807\n",
      "Iteration 473, loss = 649059.13428984\n",
      "Iteration 474, loss = 648547.69097047\n",
      "Iteration 475, loss = 648036.76586954\n",
      "Iteration 476, loss = 647524.60730322\n",
      "Iteration 477, loss = 647011.58874691\n",
      "Iteration 478, loss = 646498.62418138\n",
      "Iteration 479, loss = 645984.35113012\n",
      "Iteration 480, loss = 645474.12250122\n",
      "Iteration 481, loss = 644957.52674960\n",
      "Iteration 482, loss = 644442.73485450\n",
      "Iteration 483, loss = 643925.61182101\n",
      "Iteration 484, loss = 643411.70034280\n",
      "Iteration 485, loss = 642894.03582219\n",
      "Iteration 486, loss = 642377.37490497\n",
      "Iteration 487, loss = 641861.36866029\n",
      "Iteration 488, loss = 641358.25953122\n",
      "Iteration 489, loss = 640840.37465571\n",
      "Iteration 490, loss = 640314.66353192\n",
      "Iteration 491, loss = 639791.78540588\n",
      "Iteration 492, loss = 639282.98418369\n",
      "Iteration 493, loss = 638752.34614629\n",
      "Iteration 494, loss = 638238.86142407\n",
      "Iteration 495, loss = 637720.73793556\n",
      "Iteration 496, loss = 637194.20906049\n",
      "Iteration 497, loss = 636681.39588630\n",
      "Iteration 498, loss = 636156.34940754\n",
      "Iteration 499, loss = 635636.65821025\n",
      "Iteration 500, loss = 635119.72993659\n",
      "Iteration 501, loss = 634594.16198332\n",
      "Iteration 502, loss = 634077.47833190\n",
      "Iteration 503, loss = 633555.29105707\n",
      "Iteration 504, loss = 633033.66175685\n",
      "Iteration 505, loss = 632515.77239264\n",
      "Iteration 506, loss = 631991.83108448\n",
      "Iteration 507, loss = 631472.87047708\n",
      "Iteration 508, loss = 630951.20319236\n",
      "Iteration 509, loss = 630429.14321949\n",
      "Iteration 510, loss = 629909.35200531\n",
      "Iteration 511, loss = 629385.81880358\n",
      "Iteration 512, loss = 628865.27200300\n",
      "Iteration 513, loss = 628342.87318827\n",
      "Iteration 514, loss = 627820.59031700\n",
      "Iteration 515, loss = 627299.51021009\n",
      "Iteration 516, loss = 626776.29768853\n",
      "Iteration 517, loss = 626255.13267631\n",
      "Iteration 518, loss = 625732.85270638\n",
      "Iteration 519, loss = 625211.25544535\n",
      "Iteration 520, loss = 624690.09743730\n",
      "Iteration 521, loss = 624168.32795194\n",
      "Iteration 522, loss = 623647.84615113\n",
      "Iteration 523, loss = 623126.24981625\n",
      "Iteration 524, loss = 622605.42912252\n",
      "Iteration 525, loss = 622084.43112596\n",
      "Iteration 526, loss = 621563.48265892\n",
      "Iteration 527, loss = 621042.92853777\n",
      "Iteration 528, loss = 620521.79851042\n",
      "Iteration 529, loss = 620001.30411591\n",
      "Iteration 530, loss = 619480.47094392\n",
      "Iteration 531, loss = 618960.26134716\n",
      "Iteration 532, loss = 618439.80885650\n",
      "Iteration 533, loss = 617919.61546492\n",
      "Iteration 534, loss = 617399.98177066\n",
      "Iteration 535, loss = 616880.59828592\n",
      "Iteration 536, loss = 616361.81137635\n",
      "Iteration 537, loss = 615842.88371824\n",
      "Iteration 538, loss = 615324.24017094\n",
      "Iteration 539, loss = 614805.62210078\n",
      "Iteration 540, loss = 614287.39991599\n",
      "Iteration 541, loss = 613769.40931584\n",
      "Iteration 542, loss = 613251.75635336\n",
      "Iteration 543, loss = 612734.31291705\n",
      "Iteration 544, loss = 612217.14967781\n",
      "Iteration 545, loss = 611700.46028679\n",
      "Iteration 546, loss = 611183.93521558\n",
      "Iteration 547, loss = 610667.78957238\n",
      "Iteration 548, loss = 610151.96466053\n",
      "Iteration 549, loss = 609636.59006691\n",
      "Iteration 550, loss = 609121.44667106\n",
      "Iteration 551, loss = 608606.88747593\n",
      "Iteration 552, loss = 608092.53132175\n",
      "Iteration 553, loss = 607578.54331895\n",
      "Iteration 554, loss = 607065.08144842\n",
      "Iteration 555, loss = 606552.08875127\n",
      "Iteration 556, loss = 606039.27097461\n",
      "Iteration 557, loss = 605528.01324605\n",
      "Iteration 558, loss = 605024.95466395\n",
      "Iteration 559, loss = 604516.37989635\n",
      "Iteration 560, loss = 604002.99160744\n",
      "Iteration 561, loss = 603498.39550398\n",
      "Iteration 562, loss = 602984.11112661\n",
      "Iteration 563, loss = 602481.94921282\n",
      "Iteration 564, loss = 601968.01354584\n",
      "Iteration 565, loss = 601466.88322921\n",
      "Iteration 566, loss = 600954.26106745\n",
      "Iteration 567, loss = 600454.02739020\n",
      "Iteration 568, loss = 599944.55829663\n",
      "Iteration 569, loss = 599438.96363615\n",
      "Iteration 570, loss = 598935.92601924\n",
      "Iteration 571, loss = 598432.42042613\n",
      "Iteration 572, loss = 597929.93632489\n",
      "Iteration 573, loss = 597427.22509762\n",
      "Iteration 574, loss = 596925.27707908\n",
      "Iteration 575, loss = 596424.07893355\n",
      "Iteration 576, loss = 595929.54041589\n",
      "Iteration 577, loss = 595424.08176395\n",
      "Iteration 578, loss = 594932.60709050\n",
      "Iteration 579, loss = 594435.16790802\n",
      "Iteration 580, loss = 593934.05799980\n",
      "Iteration 581, loss = 593440.36067814\n",
      "Iteration 582, loss = 592940.10923456\n",
      "Iteration 583, loss = 592447.21468342\n",
      "Iteration 584, loss = 591947.83606652\n",
      "Iteration 585, loss = 591455.70202097\n",
      "Iteration 586, loss = 590956.82147355\n",
      "Iteration 587, loss = 590465.14118483\n",
      "Iteration 588, loss = 589967.14522108\n",
      "Iteration 589, loss = 589475.93393342\n",
      "Iteration 590, loss = 588978.58558179\n",
      "Iteration 591, loss = 588487.75312798\n",
      "Iteration 592, loss = 587991.43560016\n",
      "Iteration 593, loss = 587501.52647374\n",
      "Iteration 594, loss = 587006.21500551\n",
      "Iteration 595, loss = 586516.29695633\n",
      "Iteration 596, loss = 586040.99919252\n",
      "Iteration 597, loss = 585586.17193097\n",
      "Iteration 598, loss = 585060.47420315\n",
      "Iteration 599, loss = 584564.46599203\n",
      "Iteration 600, loss = 584079.53241572\n",
      "Iteration 601, loss = 583596.47510015\n",
      "Iteration 602, loss = 583114.68108589\n",
      "Iteration 603, loss = 582631.96382655\n",
      "Iteration 604, loss = 582149.84170323\n",
      "Iteration 605, loss = 581667.58299801\n",
      "Iteration 606, loss = 581192.97956419\n",
      "Iteration 607, loss = 580717.18236416\n",
      "Iteration 608, loss = 580260.60287298\n",
      "Iteration 609, loss = 579757.53948397\n",
      "Iteration 610, loss = 579275.57265132\n",
      "Iteration 611, loss = 578801.54307698\n",
      "Iteration 612, loss = 578323.32477268\n",
      "Iteration 613, loss = 577865.27553057\n",
      "Iteration 614, loss = 577435.13123168\n",
      "Iteration 615, loss = 576942.47938614\n",
      "Iteration 616, loss = 576426.85047268\n",
      "Iteration 617, loss = 575963.42160989\n",
      "Iteration 618, loss = 575479.92539699\n",
      "Iteration 619, loss = 575018.19606772\n",
      "Iteration 620, loss = 574539.89691858\n",
      "Iteration 621, loss = 574077.91582161\n",
      "Iteration 622, loss = 573599.41067269\n",
      "Iteration 623, loss = 573137.42682861\n",
      "Iteration 624, loss = 572680.18336190\n",
      "Iteration 625, loss = 572238.72576444\n",
      "Iteration 626, loss = 571729.32790913\n",
      "Iteration 627, loss = 571296.96308274\n",
      "Iteration 628, loss = 570799.39404316\n",
      "Iteration 629, loss = 570355.06354288\n",
      "Iteration 630, loss = 569869.80417354\n",
      "Iteration 631, loss = 569421.82739747\n",
      "Iteration 632, loss = 568990.10490785\n",
      "Iteration 633, loss = 568477.23247003\n",
      "Iteration 634, loss = 568063.83306542\n",
      "Iteration 635, loss = 567545.72451494\n",
      "Iteration 636, loss = 567121.36847592\n",
      "Iteration 637, loss = 566622.20624915\n",
      "Iteration 638, loss = 566209.49309930\n",
      "Iteration 639, loss = 565745.53907991\n",
      "Iteration 640, loss = 565252.84704271\n",
      "Iteration 641, loss = 564818.86940588\n",
      "Iteration 642, loss = 564324.57565516\n",
      "Iteration 643, loss = 563890.82630773\n",
      "Iteration 644, loss = 563398.05980098\n",
      "Iteration 645, loss = 562963.18610710\n",
      "Iteration 646, loss = 562473.77540659\n",
      "Iteration 647, loss = 562035.82496789\n",
      "Iteration 648, loss = 561552.07615685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 649, loss = 561089.94258265\n",
      "Iteration 650, loss = 560627.63203511\n",
      "Iteration 651, loss = 560168.15296756\n",
      "Iteration 652, loss = 559710.96379270\n",
      "Iteration 653, loss = 559247.54746097\n",
      "Iteration 654, loss = 558790.32311771\n",
      "Iteration 655, loss = 558330.75644242\n",
      "Iteration 656, loss = 557872.81757042\n",
      "Iteration 657, loss = 557415.67022620\n",
      "Iteration 658, loss = 556972.31464498\n",
      "Iteration 659, loss = 556536.74988673\n",
      "Iteration 660, loss = 556103.53891547\n",
      "Iteration 661, loss = 555614.30932295\n",
      "Iteration 662, loss = 555162.58381396\n",
      "Iteration 663, loss = 554739.00001695\n",
      "Iteration 664, loss = 554308.35079671\n",
      "Iteration 665, loss = 553894.36788692\n",
      "Iteration 666, loss = 553428.69663413\n",
      "Iteration 667, loss = 553009.21250454\n",
      "Iteration 668, loss = 552540.79315485\n",
      "Iteration 669, loss = 552191.43884693\n",
      "Iteration 670, loss = 551785.93670651\n",
      "Iteration 671, loss = 551293.71212574\n",
      "Iteration 672, loss = 550943.82263483\n",
      "Iteration 673, loss = 550463.16087218\n",
      "Iteration 674, loss = 550114.48265878\n",
      "Iteration 675, loss = 549648.84547572\n",
      "Iteration 676, loss = 549318.79116588\n",
      "Iteration 677, loss = 548856.55915829\n",
      "Iteration 678, loss = 548498.69925620\n",
      "Iteration 679, loss = 548069.89437925\n",
      "Iteration 680, loss = 547709.77467922\n",
      "Iteration 681, loss = 547293.61944063\n",
      "Iteration 682, loss = 546934.43586854\n",
      "Iteration 683, loss = 546533.75761010\n",
      "Iteration 684, loss = 546175.54826219\n",
      "Iteration 685, loss = 545788.98196691\n",
      "Iteration 686, loss = 545438.41660921\n",
      "Iteration 687, loss = 545055.89399003\n",
      "Iteration 688, loss = 544713.71611108\n",
      "Iteration 689, loss = 544347.96964633\n",
      "Iteration 690, loss = 544010.39545453\n",
      "Iteration 691, loss = 543658.57302791\n",
      "Iteration 692, loss = 543328.88136997\n",
      "Iteration 693, loss = 543001.73932255\n",
      "Iteration 694, loss = 542660.16289606\n",
      "Iteration 695, loss = 542347.08007059\n",
      "Iteration 696, loss = 542010.04102899\n",
      "Iteration 697, loss = 541702.39449703\n",
      "Iteration 698, loss = 541372.42920748\n",
      "Iteration 699, loss = 541068.99405448\n",
      "Iteration 700, loss = 540745.73389965\n",
      "Iteration 701, loss = 540446.53834800\n",
      "Iteration 702, loss = 540129.52147932\n",
      "Iteration 703, loss = 539823.78479895\n",
      "Iteration 704, loss = 539520.70872888\n",
      "Iteration 705, loss = 539219.72612600\n",
      "Iteration 706, loss = 538920.59098630\n",
      "Iteration 707, loss = 538623.19112088\n",
      "Iteration 708, loss = 538327.01357134\n",
      "Iteration 709, loss = 538031.97329154\n",
      "Iteration 710, loss = 537738.79124502\n",
      "Iteration 711, loss = 537447.45435942\n",
      "Iteration 712, loss = 537157.79068548\n",
      "Iteration 713, loss = 536869.19373986\n",
      "Iteration 714, loss = 536582.12180906\n",
      "Iteration 715, loss = 536296.65117905\n",
      "Iteration 716, loss = 536012.84364212\n",
      "Iteration 717, loss = 535730.58290045\n",
      "Iteration 718, loss = 535449.96596636\n",
      "Iteration 719, loss = 535170.82297880\n",
      "Iteration 720, loss = 534893.63870663\n",
      "Iteration 721, loss = 534618.23217351\n",
      "Iteration 722, loss = 534344.65743571\n",
      "Iteration 723, loss = 534072.99477420\n",
      "Iteration 724, loss = 533803.01901754\n",
      "Iteration 725, loss = 533534.45936633\n",
      "Iteration 726, loss = 533267.51596630\n",
      "Iteration 727, loss = 533002.26024242\n",
      "Iteration 728, loss = 532738.74407077\n",
      "Iteration 729, loss = 532476.78718404\n",
      "Iteration 730, loss = 532216.28029958\n",
      "Iteration 731, loss = 531957.59356726\n",
      "Iteration 732, loss = 531700.90737327\n",
      "Iteration 733, loss = 531442.22660014\n",
      "Iteration 734, loss = 531186.93287158\n",
      "Iteration 735, loss = 530931.81326320\n",
      "Iteration 736, loss = 530677.76880364\n",
      "Iteration 737, loss = 530427.76793598\n",
      "Iteration 738, loss = 530175.29690327\n",
      "Iteration 739, loss = 529927.07202984\n",
      "Iteration 740, loss = 529683.63924972\n",
      "Iteration 741, loss = 529435.72189170\n",
      "Iteration 742, loss = 529183.88464232\n",
      "Iteration 743, loss = 528941.16675434\n",
      "Iteration 744, loss = 528695.02899031\n",
      "Iteration 745, loss = 528450.72912597\n",
      "Iteration 746, loss = 528209.77273627\n",
      "Iteration 747, loss = 527964.11439631\n",
      "Iteration 748, loss = 527724.57884208\n",
      "Iteration 749, loss = 527480.01881570\n",
      "Iteration 750, loss = 527240.61211400\n",
      "Iteration 751, loss = 527011.88438534\n",
      "Iteration 752, loss = 526753.76746680\n",
      "Iteration 753, loss = 526520.29119746\n",
      "Iteration 754, loss = 526271.71805824\n",
      "Iteration 755, loss = 526024.37805721\n",
      "Iteration 756, loss = 525784.97117015\n",
      "Iteration 757, loss = 525531.89898382\n",
      "Iteration 758, loss = 525296.29361267\n",
      "Iteration 759, loss = 525052.65892627\n",
      "Iteration 760, loss = 524826.72814841\n",
      "Iteration 761, loss = 524626.82189354\n",
      "Iteration 762, loss = 524430.25049587\n",
      "Iteration 763, loss = 524230.70699236\n",
      "Iteration 764, loss = 523995.31158395\n",
      "Iteration 765, loss = 523760.09056303\n",
      "Iteration 766, loss = 523529.61566522\n",
      "Iteration 767, loss = 523307.98955369\n",
      "Iteration 768, loss = 523101.82991180\n",
      "Iteration 769, loss = 522894.88668951\n",
      "Iteration 770, loss = 522690.67190125\n",
      "Iteration 771, loss = 522486.56690824\n",
      "Iteration 772, loss = 522283.04429694\n",
      "Iteration 773, loss = 522073.01037076\n",
      "Iteration 774, loss = 521860.18516290\n",
      "Iteration 775, loss = 521649.35552972\n",
      "Iteration 776, loss = 521439.32356864\n",
      "Iteration 777, loss = 521225.17914988\n",
      "Iteration 778, loss = 521018.67467429\n",
      "Iteration 779, loss = 520810.87405036\n",
      "Iteration 780, loss = 520609.49582682\n",
      "Iteration 781, loss = 520408.38103361\n",
      "Iteration 782, loss = 520211.58966421\n",
      "Iteration 783, loss = 520010.22024990\n",
      "Iteration 784, loss = 519810.29545084\n",
      "Iteration 785, loss = 519609.33898847\n",
      "Iteration 786, loss = 519409.64283819\n",
      "Iteration 787, loss = 519207.61939113\n",
      "Iteration 788, loss = 519011.00608058\n",
      "Iteration 789, loss = 518819.23315529\n",
      "Iteration 790, loss = 518635.38619547\n",
      "Iteration 791, loss = 518427.00881981\n",
      "Iteration 792, loss = 518240.11253578\n",
      "Iteration 793, loss = 518046.68970616\n",
      "Iteration 794, loss = 517844.12122986\n",
      "Iteration 795, loss = 517658.53496021\n",
      "Iteration 796, loss = 517459.98665318\n",
      "Iteration 797, loss = 517265.68694638\n",
      "Iteration 798, loss = 517079.69292289\n",
      "Iteration 799, loss = 516882.69816018\n",
      "Iteration 800, loss = 516694.80587530\n",
      "Iteration 801, loss = 516525.62030847\n",
      "Iteration 802, loss = 516414.51407866\n",
      "Iteration 803, loss = 516189.86070499\n",
      "Iteration 804, loss = 515941.43381407\n",
      "Iteration 805, loss = 515762.92311145\n",
      "Iteration 806, loss = 515594.77413308\n",
      "Iteration 807, loss = 515484.43098648\n",
      "Iteration 808, loss = 515220.17231603\n",
      "Iteration 809, loss = 515034.55670039\n",
      "Iteration 810, loss = 514886.49395924\n",
      "Iteration 811, loss = 514620.55483130\n",
      "Iteration 812, loss = 514514.12517387\n",
      "Iteration 813, loss = 514313.89772773\n",
      "Iteration 814, loss = 514056.82267772\n",
      "Iteration 815, loss = 514038.61712926\n",
      "Iteration 816, loss = 513911.10466932\n",
      "Iteration 817, loss = 513494.31170471\n",
      "Iteration 818, loss = 513731.65526128\n",
      "Iteration 819, loss = 513773.48422274\n",
      "Iteration 820, loss = 513004.38835913\n",
      "Iteration 821, loss = 513675.77143448\n",
      "Iteration 822, loss = 512632.12881893\n",
      "Iteration 823, loss = 512858.56091245\n",
      "Iteration 824, loss = 512194.65970955\n",
      "Iteration 825, loss = 512420.97941632\n",
      "Iteration 826, loss = 511793.97656605\n",
      "Iteration 827, loss = 511953.16739910\n",
      "Iteration 828, loss = 511420.32829465\n",
      "Iteration 829, loss = 511499.83858238\n",
      "Iteration 830, loss = 511002.45878309\n",
      "Iteration 831, loss = 511000.72505140\n",
      "Iteration 832, loss = 510635.43844291\n",
      "Iteration 833, loss = 510540.61156596\n",
      "Iteration 834, loss = 510312.54639410\n",
      "Iteration 835, loss = 510139.15945521\n",
      "Iteration 836, loss = 510025.18465878\n",
      "Iteration 837, loss = 509787.99806378\n",
      "Iteration 838, loss = 509707.17152566\n",
      "Iteration 839, loss = 509405.85616539\n",
      "Iteration 840, loss = 509305.59932188\n",
      "Iteration 841, loss = 509026.10452370\n",
      "Iteration 842, loss = 508996.41810614\n",
      "Iteration 843, loss = 508708.66758312\n",
      "Iteration 844, loss = 508609.88605775\n",
      "Iteration 845, loss = 508347.51526423\n",
      "Iteration 846, loss = 508264.01217531\n",
      "Iteration 847, loss = 508008.20976224\n",
      "Iteration 848, loss = 507885.90474373\n",
      "Iteration 849, loss = 507674.58329631\n",
      "Iteration 850, loss = 507499.66700306\n",
      "Iteration 851, loss = 507330.24975350\n",
      "Iteration 852, loss = 507123.91361975\n",
      "Iteration 853, loss = 506977.98142092\n",
      "Iteration 854, loss = 506761.91891531\n",
      "Iteration 855, loss = 506618.61614663\n",
      "Iteration 856, loss = 506416.54998040\n",
      "Iteration 857, loss = 506255.20644565\n",
      "Iteration 858, loss = 506068.98120870\n",
      "Iteration 859, loss = 505889.51404268\n",
      "Iteration 860, loss = 505705.41462160\n",
      "Iteration 861, loss = 505525.71437107\n",
      "Iteration 862, loss = 505347.95695381\n",
      "Iteration 863, loss = 505164.80803280\n",
      "Iteration 864, loss = 504982.80992936\n",
      "Iteration 865, loss = 504805.16736988\n",
      "Iteration 866, loss = 504628.58618956\n",
      "Iteration 867, loss = 504448.06608885\n",
      "Iteration 868, loss = 504270.29040664\n",
      "Iteration 869, loss = 504091.19531302\n",
      "Iteration 870, loss = 503913.68562474\n",
      "Iteration 871, loss = 503735.46593701\n",
      "Iteration 872, loss = 503565.21672348\n",
      "Iteration 873, loss = 503376.33082510\n",
      "Iteration 874, loss = 503195.99333773\n",
      "Iteration 875, loss = 503018.62927924\n",
      "Iteration 876, loss = 502834.75823998\n",
      "Iteration 877, loss = 502654.42909634\n",
      "Iteration 878, loss = 502484.35330004\n",
      "Iteration 879, loss = 502293.40004533\n",
      "Iteration 880, loss = 502110.67341838\n",
      "Iteration 881, loss = 501929.45586516\n",
      "Iteration 882, loss = 501745.75356197\n",
      "Iteration 883, loss = 501562.75371828\n",
      "Iteration 884, loss = 501378.28074699\n",
      "Iteration 885, loss = 501193.61140713\n",
      "Iteration 886, loss = 501009.03413448\n",
      "Iteration 887, loss = 500825.61389255\n",
      "Iteration 888, loss = 500644.03830471\n",
      "Iteration 889, loss = 500456.78260717\n",
      "Iteration 890, loss = 500304.90068160\n",
      "Iteration 891, loss = 500153.38276885\n",
      "Iteration 892, loss = 499918.24379199\n",
      "Iteration 893, loss = 499771.60296132\n",
      "Iteration 894, loss = 499547.00708816\n",
      "Iteration 895, loss = 499381.93236734\n",
      "Iteration 896, loss = 499180.04782143\n",
      "Iteration 897, loss = 499099.98441824\n",
      "Iteration 898, loss = 498867.09581548\n",
      "Iteration 899, loss = 498645.72521230\n",
      "Iteration 900, loss = 498516.37365472\n",
      "Iteration 901, loss = 498252.55519880\n",
      "Iteration 902, loss = 498096.37955698\n",
      "Iteration 903, loss = 497902.46567186\n",
      "Iteration 904, loss = 497687.94139930\n",
      "Iteration 905, loss = 497509.42377945\n",
      "Iteration 906, loss = 497322.91366261\n",
      "Iteration 907, loss = 497142.89499999\n",
      "Iteration 908, loss = 496943.15285611\n",
      "Iteration 909, loss = 496769.81114413\n",
      "Iteration 910, loss = 496567.81461425\n",
      "Iteration 911, loss = 496386.53965756\n",
      "Iteration 912, loss = 496199.70809249\n",
      "Iteration 913, loss = 496009.17703575\n",
      "Iteration 914, loss = 495831.98809094\n",
      "Iteration 915, loss = 495628.78710238\n",
      "Iteration 916, loss = 495447.42988414\n",
      "Iteration 917, loss = 495251.57671003\n",
      "Iteration 918, loss = 495053.89432722\n",
      "Iteration 919, loss = 494860.25834917\n",
      "Iteration 920, loss = 494665.26950632\n",
      "Iteration 921, loss = 494468.71945190\n",
      "Iteration 922, loss = 494278.65318376\n",
      "Iteration 923, loss = 494104.28376597\n",
      "Iteration 924, loss = 493892.33945796\n",
      "Iteration 925, loss = 493678.68751381\n",
      "Iteration 926, loss = 493498.18616098\n",
      "Iteration 927, loss = 493281.43937658\n",
      "Iteration 928, loss = 493092.26128506\n",
      "Iteration 929, loss = 492901.29672344\n",
      "Iteration 930, loss = 492693.09190801\n",
      "Iteration 931, loss = 492483.11494106\n",
      "Iteration 932, loss = 492287.78148331\n",
      "Iteration 933, loss = 492088.63522051\n",
      "Iteration 934, loss = 491902.46937959\n",
      "Iteration 935, loss = 491683.97665046\n",
      "Iteration 936, loss = 491487.29441307\n",
      "Iteration 937, loss = 491295.35707150\n",
      "Iteration 938, loss = 491105.67594323\n",
      "Iteration 939, loss = 490887.19549006\n",
      "Iteration 940, loss = 490695.82494063\n",
      "Iteration 941, loss = 490480.26441019\n",
      "Iteration 942, loss = 490264.31451760\n",
      "Iteration 943, loss = 490057.35269386\n",
      "Iteration 944, loss = 489848.28152454\n",
      "Iteration 945, loss = 489643.19571826\n",
      "Iteration 946, loss = 489437.77139331\n",
      "Iteration 947, loss = 489216.16372853\n",
      "Iteration 948, loss = 489011.01702107\n",
      "Iteration 949, loss = 488797.83404186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 950, loss = 488599.64637427\n",
      "Iteration 951, loss = 488415.44440399\n",
      "Iteration 952, loss = 488162.91717632\n",
      "Iteration 953, loss = 487966.46083083\n",
      "Iteration 954, loss = 487740.77238631\n",
      "Iteration 955, loss = 487524.68925523\n",
      "Iteration 956, loss = 487336.52022300\n",
      "Iteration 957, loss = 487162.74452237\n",
      "Iteration 958, loss = 486936.18343197\n",
      "Iteration 959, loss = 486696.81356525\n",
      "Iteration 960, loss = 486472.04441896\n",
      "Iteration 961, loss = 486261.19871685\n",
      "Iteration 962, loss = 486027.38850703\n",
      "Iteration 963, loss = 485809.20018558\n",
      "Iteration 964, loss = 485585.00265938\n",
      "Iteration 965, loss = 485378.02357121\n",
      "Iteration 966, loss = 485169.56031960\n",
      "Iteration 967, loss = 484931.80767943\n",
      "Iteration 968, loss = 484705.65621112\n",
      "Iteration 969, loss = 484478.66682822\n",
      "Iteration 970, loss = 484257.96742989\n",
      "Iteration 971, loss = 484027.99125360\n",
      "Iteration 972, loss = 483811.93400900\n",
      "Iteration 973, loss = 483570.05646206\n",
      "Iteration 974, loss = 483337.40671244\n",
      "Iteration 975, loss = 483106.74763968\n",
      "Iteration 976, loss = 482881.82823272\n",
      "Iteration 977, loss = 482655.29962077\n",
      "Iteration 978, loss = 482402.16877810\n",
      "Iteration 979, loss = 482178.23170736\n",
      "Iteration 980, loss = 481948.24441005\n",
      "Iteration 981, loss = 481706.26907873\n",
      "Iteration 982, loss = 481478.75339339\n",
      "Iteration 983, loss = 481223.10626115\n",
      "Iteration 984, loss = 481015.43770380\n",
      "Iteration 985, loss = 480841.72271184\n",
      "Iteration 986, loss = 480524.84291685\n",
      "Iteration 987, loss = 480452.37808475\n",
      "Iteration 988, loss = 480252.78776111\n",
      "Iteration 989, loss = 479906.61193825\n",
      "Iteration 990, loss = 479986.15452923\n",
      "Iteration 991, loss = 479733.34523684\n",
      "Iteration 992, loss = 479391.87560312\n",
      "Iteration 993, loss = 479178.66231385\n",
      "Iteration 994, loss = 478764.77264789\n",
      "Iteration 995, loss = 478601.49657125\n",
      "Iteration 996, loss = 478349.42238624\n",
      "Iteration 997, loss = 478074.83073795\n",
      "Iteration 998, loss = 477823.89364425\n",
      "Iteration 999, loss = 477586.16876815\n",
      "Iteration 1000, loss = 477353.51892063\n",
      "Iteration 1001, loss = 477063.38143052\n",
      "Iteration 1002, loss = 476860.19216761\n",
      "Iteration 1003, loss = 476606.46004825\n",
      "Iteration 1004, loss = 476370.53173649\n",
      "Iteration 1005, loss = 476099.87852410\n",
      "Iteration 1006, loss = 475816.40610322\n",
      "Iteration 1007, loss = 475542.68959387\n",
      "Iteration 1008, loss = 475306.60458305\n",
      "Iteration 1009, loss = 475067.40773596\n",
      "Iteration 1010, loss = 474822.16049793\n",
      "Iteration 1011, loss = 474543.42633726\n",
      "Iteration 1012, loss = 474266.16293425\n",
      "Iteration 1013, loss = 473995.52489454\n",
      "Iteration 1014, loss = 473767.04818149\n",
      "Iteration 1015, loss = 473523.68378297\n",
      "Iteration 1016, loss = 473259.23848040\n",
      "Iteration 1017, loss = 472976.80157966\n",
      "Iteration 1018, loss = 472726.76403081\n",
      "Iteration 1019, loss = 472458.38959845\n",
      "Iteration 1020, loss = 472175.39378160\n",
      "Iteration 1021, loss = 471902.52686541\n",
      "Iteration 1022, loss = 471631.78982571\n",
      "Iteration 1023, loss = 471361.77573941\n",
      "Iteration 1024, loss = 471102.06446288\n",
      "Iteration 1025, loss = 470829.53612426\n",
      "Iteration 1026, loss = 470534.34551191\n",
      "Iteration 1027, loss = 470254.77651495\n",
      "Iteration 1028, loss = 470018.60901688\n",
      "Iteration 1029, loss = 469738.34225260\n",
      "Iteration 1030, loss = 469418.09612290\n",
      "Iteration 1031, loss = 469262.61035448\n",
      "Iteration 1032, loss = 469046.07094099\n",
      "Iteration 1033, loss = 468620.09557506\n",
      "Iteration 1034, loss = 468566.01886756\n",
      "Iteration 1035, loss = 468049.17268404\n",
      "Iteration 1036, loss = 467849.43054266\n",
      "Iteration 1037, loss = 467532.65063787\n",
      "Iteration 1038, loss = 467157.62849082\n",
      "Iteration 1039, loss = 466876.51480364\n",
      "Iteration 1040, loss = 466541.08324460\n",
      "Iteration 1041, loss = 466394.15483669\n",
      "Iteration 1042, loss = 465988.87426039\n",
      "Iteration 1043, loss = 465649.35662405\n",
      "Iteration 1044, loss = 465468.54232555\n",
      "Iteration 1045, loss = 465010.04782520\n",
      "Iteration 1046, loss = 464700.21042355\n",
      "Iteration 1047, loss = 464356.77462781\n",
      "Iteration 1048, loss = 463988.89515212\n",
      "Iteration 1049, loss = 463659.20120947\n",
      "Iteration 1050, loss = 463307.58095284\n",
      "Iteration 1051, loss = 462990.67505630\n",
      "Iteration 1052, loss = 462602.11615016\n",
      "Iteration 1053, loss = 462256.37608619\n",
      "Iteration 1054, loss = 461933.67519129\n",
      "Iteration 1055, loss = 461560.16628141\n",
      "Iteration 1056, loss = 461232.33715056\n",
      "Iteration 1057, loss = 460904.29760191\n",
      "Iteration 1058, loss = 460594.83221814\n",
      "Iteration 1059, loss = 460286.24365132\n",
      "Iteration 1060, loss = 459901.92727660\n",
      "Iteration 1061, loss = 459553.40534794\n",
      "Iteration 1062, loss = 459180.21232158\n",
      "Iteration 1063, loss = 458839.88430295\n",
      "Iteration 1064, loss = 458484.99930869\n",
      "Iteration 1065, loss = 458096.98036570\n",
      "Iteration 1066, loss = 457781.98683192\n",
      "Iteration 1067, loss = 457460.13918935\n",
      "Iteration 1068, loss = 457053.39713892\n",
      "Iteration 1069, loss = 456742.95618228\n",
      "Iteration 1070, loss = 456355.65953144\n",
      "Iteration 1071, loss = 455953.28357542\n",
      "Iteration 1072, loss = 455646.39774607\n",
      "Iteration 1073, loss = 455263.03682034\n",
      "Iteration 1074, loss = 454865.46213084\n",
      "Iteration 1075, loss = 454549.38061372\n",
      "Iteration 1076, loss = 454083.71226390\n",
      "Iteration 1077, loss = 453711.93806327\n",
      "Iteration 1078, loss = 453348.35707631\n",
      "Iteration 1079, loss = 452956.62184144\n",
      "Iteration 1080, loss = 452595.84023278\n",
      "Iteration 1081, loss = 452225.20508156\n",
      "Iteration 1082, loss = 451877.45363550\n",
      "Iteration 1083, loss = 451516.81556626\n",
      "Iteration 1084, loss = 451123.63892045\n",
      "Iteration 1085, loss = 450798.92051523\n",
      "Iteration 1086, loss = 450451.07779359\n",
      "Iteration 1087, loss = 450104.76765930\n",
      "Iteration 1088, loss = 449807.04006547\n",
      "Iteration 1089, loss = 449480.64600577\n",
      "Iteration 1090, loss = 449153.26921652\n",
      "Iteration 1091, loss = 448873.03408301\n",
      "Iteration 1092, loss = 448555.41359149\n",
      "Iteration 1093, loss = 448266.57637237\n",
      "Iteration 1094, loss = 447995.95652438\n",
      "Iteration 1095, loss = 447666.60115373\n",
      "Iteration 1096, loss = 447373.65080263\n",
      "Iteration 1097, loss = 447089.78872022\n",
      "Iteration 1098, loss = 446771.15093287\n",
      "Iteration 1099, loss = 446490.80652050\n",
      "Iteration 1100, loss = 446178.92369458\n",
      "Iteration 1101, loss = 445866.34015133\n",
      "Iteration 1102, loss = 445573.08731404\n",
      "Iteration 1103, loss = 445265.99044582\n",
      "Iteration 1104, loss = 444962.76254175\n",
      "Iteration 1105, loss = 444653.34349360\n",
      "Iteration 1106, loss = 444341.27594411\n",
      "Iteration 1107, loss = 444026.95061626\n",
      "Iteration 1108, loss = 443712.55623823\n",
      "Iteration 1109, loss = 443394.06171528\n",
      "Iteration 1110, loss = 443076.33476113\n",
      "Iteration 1111, loss = 442760.32846249\n",
      "Iteration 1112, loss = 442439.89055701\n",
      "Iteration 1113, loss = 442120.25354783\n",
      "Iteration 1114, loss = 441794.92060195\n",
      "Iteration 1115, loss = 441453.22364149\n",
      "Iteration 1116, loss = 441131.99862711\n",
      "Iteration 1117, loss = 440814.49171249\n",
      "Iteration 1118, loss = 440490.81060804\n",
      "Iteration 1119, loss = 440154.71290480\n",
      "Iteration 1120, loss = 439841.20267447\n",
      "Iteration 1121, loss = 439494.06487064\n",
      "Iteration 1122, loss = 439165.68517272\n",
      "Iteration 1123, loss = 438828.29923706\n",
      "Iteration 1124, loss = 438484.93380460\n",
      "Iteration 1125, loss = 438144.89428437\n",
      "Iteration 1126, loss = 437804.54176986\n",
      "Iteration 1127, loss = 437466.94799418\n",
      "Iteration 1128, loss = 437120.27926369\n",
      "Iteration 1129, loss = 436773.78031793\n",
      "Iteration 1130, loss = 436426.47082384\n",
      "Iteration 1131, loss = 436065.08756626\n",
      "Iteration 1132, loss = 435718.72636257\n",
      "Iteration 1133, loss = 435345.25310528\n",
      "Iteration 1134, loss = 435006.65936651\n",
      "Iteration 1135, loss = 434683.52089007\n",
      "Iteration 1136, loss = 434282.75108489\n",
      "Iteration 1137, loss = 433997.84068618\n",
      "Iteration 1138, loss = 433596.36026649\n",
      "Iteration 1139, loss = 433253.58169446\n",
      "Iteration 1140, loss = 432947.00655703\n",
      "Iteration 1141, loss = 432583.15606765\n",
      "Iteration 1142, loss = 432258.30978679\n",
      "Iteration 1143, loss = 431924.53223207\n",
      "Iteration 1144, loss = 431509.16321235\n",
      "Iteration 1145, loss = 431153.62090037\n",
      "Iteration 1146, loss = 430802.08899810\n",
      "Iteration 1147, loss = 430442.45839008\n",
      "Iteration 1148, loss = 430136.99386264\n",
      "Iteration 1149, loss = 429734.22669653\n",
      "Iteration 1150, loss = 429422.49496385\n",
      "Iteration 1151, loss = 429062.88947891\n",
      "Iteration 1152, loss = 428669.77174283\n",
      "Iteration 1153, loss = 428368.99115589\n",
      "Iteration 1154, loss = 427943.66089984\n",
      "Iteration 1155, loss = 427581.70520819\n",
      "Iteration 1156, loss = 427217.51226794\n",
      "Iteration 1157, loss = 426831.68246216\n",
      "Iteration 1158, loss = 426489.83951831\n",
      "Iteration 1159, loss = 426120.77978465\n",
      "Iteration 1160, loss = 425785.77726190\n",
      "Iteration 1161, loss = 425433.09731840\n",
      "Iteration 1162, loss = 425107.30844363\n",
      "Iteration 1163, loss = 424735.13749207\n",
      "Iteration 1164, loss = 424343.80424768\n",
      "Iteration 1165, loss = 423966.04995972\n",
      "Iteration 1166, loss = 423615.39280428\n",
      "Iteration 1167, loss = 423242.76438453\n",
      "Iteration 1168, loss = 422875.94097878\n",
      "Iteration 1169, loss = 422505.99433029\n",
      "Iteration 1170, loss = 422141.41217563\n",
      "Iteration 1171, loss = 421779.06232107\n",
      "Iteration 1172, loss = 421407.62174636\n",
      "Iteration 1173, loss = 421026.00559268\n",
      "Iteration 1174, loss = 420642.34614752\n",
      "Iteration 1175, loss = 420266.61359064\n",
      "Iteration 1176, loss = 419879.62012724\n",
      "Iteration 1177, loss = 419497.66791179\n",
      "Iteration 1178, loss = 419118.77886447\n",
      "Iteration 1179, loss = 418742.18523077\n",
      "Iteration 1180, loss = 418314.10478685\n",
      "Iteration 1181, loss = 417942.47864245\n",
      "Iteration 1182, loss = 417543.12690643\n",
      "Iteration 1183, loss = 417118.16405433\n",
      "Iteration 1184, loss = 416746.83087756\n",
      "Iteration 1185, loss = 416340.59155791\n",
      "Iteration 1186, loss = 415892.74788625\n",
      "Iteration 1187, loss = 415549.63944274\n",
      "Iteration 1188, loss = 415138.71271512\n",
      "Iteration 1189, loss = 414707.35084705\n",
      "Iteration 1190, loss = 414385.63638488\n",
      "Iteration 1191, loss = 413951.69386538\n",
      "Iteration 1192, loss = 413588.13041216\n",
      "Iteration 1193, loss = 413206.59404893\n",
      "Iteration 1194, loss = 412766.66318558\n",
      "Iteration 1195, loss = 412381.60920967\n",
      "Iteration 1196, loss = 412029.52671281\n",
      "Iteration 1197, loss = 411672.80424485\n",
      "Iteration 1198, loss = 411276.45023525\n",
      "Iteration 1199, loss = 410861.44144136\n",
      "Iteration 1200, loss = 410484.22342984\n",
      "Iteration 1201, loss = 410113.90552353\n",
      "Iteration 1202, loss = 409709.72156291\n",
      "Iteration 1203, loss = 409311.61046249\n",
      "Iteration 1204, loss = 408913.47085082\n",
      "Iteration 1205, loss = 408534.92460463\n",
      "Iteration 1206, loss = 408135.38334799\n",
      "Iteration 1207, loss = 407741.07703058\n",
      "Iteration 1208, loss = 407335.96348985\n",
      "Iteration 1209, loss = 406939.04175840\n",
      "Iteration 1210, loss = 406536.37542345\n",
      "Iteration 1211, loss = 406124.63770643\n",
      "Iteration 1212, loss = 405725.23987410\n",
      "Iteration 1213, loss = 405311.42106708\n",
      "Iteration 1214, loss = 404900.28982336\n",
      "Iteration 1215, loss = 404492.84243988\n",
      "Iteration 1216, loss = 404078.23988932\n",
      "Iteration 1217, loss = 403664.40845348\n",
      "Iteration 1218, loss = 403244.99443121\n",
      "Iteration 1219, loss = 402834.05110094\n",
      "Iteration 1220, loss = 402433.00615963\n",
      "Iteration 1221, loss = 402027.29543028\n",
      "Iteration 1222, loss = 401596.60681552\n",
      "Iteration 1223, loss = 401143.91490071\n",
      "Iteration 1224, loss = 400734.82373153\n",
      "Iteration 1225, loss = 400313.84631426\n",
      "Iteration 1226, loss = 399849.80526232\n",
      "Iteration 1227, loss = 399458.31638242\n",
      "Iteration 1228, loss = 399097.06524857\n",
      "Iteration 1229, loss = 398537.56144581\n",
      "Iteration 1230, loss = 398330.78561925\n",
      "Iteration 1231, loss = 398024.90541697\n",
      "Iteration 1232, loss = 397318.02083356\n",
      "Iteration 1233, loss = 397261.22314759\n",
      "Iteration 1234, loss = 396515.63967862\n",
      "Iteration 1235, loss = 396195.84072966\n",
      "Iteration 1236, loss = 395556.02906400\n",
      "Iteration 1237, loss = 395286.78163004\n",
      "Iteration 1238, loss = 394645.46626368\n",
      "Iteration 1239, loss = 394347.94288782\n",
      "Iteration 1240, loss = 393639.12031439\n",
      "Iteration 1241, loss = 393397.88724201\n",
      "Iteration 1242, loss = 392708.97467856\n",
      "Iteration 1243, loss = 392386.37909090\n",
      "Iteration 1244, loss = 391674.10699760\n",
      "Iteration 1245, loss = 391388.86062002\n",
      "Iteration 1246, loss = 391065.83650468\n",
      "Iteration 1247, loss = 390380.22731940\n",
      "Iteration 1248, loss = 390185.89022951\n",
      "Iteration 1249, loss = 389285.20493770\n",
      "Iteration 1250, loss = 389001.18586406\n",
      "Iteration 1251, loss = 388336.23788263\n",
      "Iteration 1252, loss = 388076.08678094\n",
      "Iteration 1253, loss = 387434.22929080\n",
      "Iteration 1254, loss = 387055.45643535\n",
      "Iteration 1255, loss = 386379.16832751\n",
      "Iteration 1256, loss = 386022.49566409\n",
      "Iteration 1257, loss = 385489.22777150\n",
      "Iteration 1258, loss = 385033.33533702\n",
      "Iteration 1259, loss = 384485.13319800\n",
      "Iteration 1260, loss = 383969.23274093\n",
      "Iteration 1261, loss = 383567.11603252\n",
      "Iteration 1262, loss = 383010.41150850\n",
      "Iteration 1263, loss = 382604.72086503\n",
      "Iteration 1264, loss = 381950.39770243\n",
      "Iteration 1265, loss = 381508.22136448\n",
      "Iteration 1266, loss = 380942.66181178\n",
      "Iteration 1267, loss = 380480.57890482\n",
      "Iteration 1268, loss = 379976.65095572\n",
      "Iteration 1269, loss = 379417.50639227\n",
      "Iteration 1270, loss = 378963.06424196\n",
      "Iteration 1271, loss = 378380.39126693\n",
      "Iteration 1272, loss = 377898.13142735\n",
      "Iteration 1273, loss = 377380.62902179\n",
      "Iteration 1274, loss = 376842.94681057\n",
      "Iteration 1275, loss = 376330.36012042\n",
      "Iteration 1276, loss = 375835.78714611\n",
      "Iteration 1277, loss = 375332.14896981\n",
      "Iteration 1278, loss = 374846.25173328\n",
      "Iteration 1279, loss = 374370.07092351\n",
      "Iteration 1280, loss = 373816.23335969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1281, loss = 373297.47987735\n",
      "Iteration 1282, loss = 372828.21637364\n",
      "Iteration 1283, loss = 372278.42520380\n",
      "Iteration 1284, loss = 371783.98789877\n",
      "Iteration 1285, loss = 371314.23809402\n",
      "Iteration 1286, loss = 370782.49616609\n",
      "Iteration 1287, loss = 370284.14825743\n",
      "Iteration 1288, loss = 369829.66529168\n",
      "Iteration 1289, loss = 369302.66480886\n",
      "Iteration 1290, loss = 368804.40483414\n",
      "Iteration 1291, loss = 368355.21893995\n",
      "Iteration 1292, loss = 367862.74558291\n",
      "Iteration 1293, loss = 367366.91933325\n",
      "Iteration 1294, loss = 366947.36688061\n",
      "Iteration 1295, loss = 366447.07045405\n",
      "Iteration 1296, loss = 365987.53985925\n",
      "Iteration 1297, loss = 365545.03883583\n",
      "Iteration 1298, loss = 365064.66846494\n",
      "Iteration 1299, loss = 364619.20080503\n",
      "Iteration 1300, loss = 364161.53108953\n",
      "Iteration 1301, loss = 363719.28421309\n",
      "Iteration 1302, loss = 363266.85036817\n",
      "Iteration 1303, loss = 362822.15069648\n",
      "Iteration 1304, loss = 362376.64246224\n",
      "Iteration 1305, loss = 361925.51484341\n",
      "Iteration 1306, loss = 361478.22967475\n",
      "Iteration 1307, loss = 361031.97274303\n",
      "Iteration 1308, loss = 360599.42505622\n",
      "Iteration 1309, loss = 360156.31542703\n",
      "Iteration 1310, loss = 359718.20018982\n",
      "Iteration 1311, loss = 359291.06411516\n",
      "Iteration 1312, loss = 358854.75820800\n",
      "Iteration 1313, loss = 358412.29464213\n",
      "Iteration 1314, loss = 357983.32155264\n",
      "Iteration 1315, loss = 357537.92328410\n",
      "Iteration 1316, loss = 357106.03036919\n",
      "Iteration 1317, loss = 356665.65226141\n",
      "Iteration 1318, loss = 356232.82289077\n",
      "Iteration 1319, loss = 355793.37230811\n",
      "Iteration 1320, loss = 355361.23268341\n",
      "Iteration 1321, loss = 354925.26522620\n",
      "Iteration 1322, loss = 354494.30902278\n",
      "Iteration 1323, loss = 354065.12830954\n",
      "Iteration 1324, loss = 353638.51296057\n",
      "Iteration 1325, loss = 353206.31260138\n",
      "Iteration 1326, loss = 352767.38471454\n",
      "Iteration 1327, loss = 352325.37625768\n",
      "Iteration 1328, loss = 351883.26890024\n",
      "Iteration 1329, loss = 351445.46078794\n",
      "Iteration 1330, loss = 351005.75095725\n",
      "Iteration 1331, loss = 350569.29282071\n",
      "Iteration 1332, loss = 350129.50545737\n",
      "Iteration 1333, loss = 349691.32022358\n",
      "Iteration 1334, loss = 349250.30280233\n",
      "Iteration 1335, loss = 348811.16609331\n",
      "Iteration 1336, loss = 348369.63784892\n",
      "Iteration 1337, loss = 347930.07725193\n",
      "Iteration 1338, loss = 347486.08245751\n",
      "Iteration 1339, loss = 347043.42389639\n",
      "Iteration 1340, loss = 346598.93579901\n",
      "Iteration 1341, loss = 346154.71829411\n",
      "Iteration 1342, loss = 345708.06445896\n",
      "Iteration 1343, loss = 345258.41429180\n",
      "Iteration 1344, loss = 344809.24766014\n",
      "Iteration 1345, loss = 344359.14862761\n",
      "Iteration 1346, loss = 343908.27483816\n",
      "Iteration 1347, loss = 343456.75503280\n",
      "Iteration 1348, loss = 343004.32178761\n",
      "Iteration 1349, loss = 342551.21219420\n",
      "Iteration 1350, loss = 342096.30461285\n",
      "Iteration 1351, loss = 341640.52388816\n",
      "Iteration 1352, loss = 341183.43620429\n",
      "Iteration 1353, loss = 340726.17352171\n",
      "Iteration 1354, loss = 340269.15181554\n",
      "Iteration 1355, loss = 339811.30177926\n",
      "Iteration 1356, loss = 339352.06704056\n",
      "Iteration 1357, loss = 338891.52477143\n",
      "Iteration 1358, loss = 338429.93303363\n",
      "Iteration 1359, loss = 337967.10597726\n",
      "Iteration 1360, loss = 337503.95577803\n",
      "Iteration 1361, loss = 337040.46727523\n",
      "Iteration 1362, loss = 336576.57884650\n",
      "Iteration 1363, loss = 336112.01770735\n",
      "Iteration 1364, loss = 335647.53530667\n",
      "Iteration 1365, loss = 335182.18392636\n",
      "Iteration 1366, loss = 334715.94006164\n",
      "Iteration 1367, loss = 334247.18315024\n",
      "Iteration 1368, loss = 333779.22589764\n",
      "Iteration 1369, loss = 333311.93753953\n",
      "Iteration 1370, loss = 332836.25507133\n",
      "Iteration 1371, loss = 332361.44442154\n",
      "Iteration 1372, loss = 331885.62546724\n",
      "Iteration 1373, loss = 331408.48128048\n",
      "Iteration 1374, loss = 330930.74537132\n",
      "Iteration 1375, loss = 330453.11517956\n",
      "Iteration 1376, loss = 329973.37309639\n",
      "Iteration 1377, loss = 329494.36707505\n",
      "Iteration 1378, loss = 329013.87080257\n",
      "Iteration 1379, loss = 328534.73704337\n",
      "Iteration 1380, loss = 328055.79048117\n",
      "Iteration 1381, loss = 327577.96650136\n",
      "Iteration 1382, loss = 327100.33880021\n",
      "Iteration 1383, loss = 326622.39375362\n",
      "Iteration 1384, loss = 326147.27839604\n",
      "Iteration 1385, loss = 325675.42084285\n",
      "Iteration 1386, loss = 325209.48854163\n",
      "Iteration 1387, loss = 324739.15493233\n",
      "Iteration 1388, loss = 324259.74231600\n",
      "Iteration 1389, loss = 323773.44351866\n",
      "Iteration 1390, loss = 323285.86544892\n",
      "Iteration 1391, loss = 322801.41287801\n",
      "Iteration 1392, loss = 322319.51254767\n",
      "Iteration 1393, loss = 321839.37185609\n",
      "Iteration 1394, loss = 321357.19570900\n",
      "Iteration 1395, loss = 320872.56644947\n",
      "Iteration 1396, loss = 320386.21178251\n",
      "Iteration 1397, loss = 319897.72494403\n",
      "Iteration 1398, loss = 319407.92473533\n",
      "Iteration 1399, loss = 318916.14813370\n",
      "Iteration 1400, loss = 318423.41100332\n",
      "Iteration 1401, loss = 317928.98657367\n",
      "Iteration 1402, loss = 317433.78504998\n",
      "Iteration 1403, loss = 316935.88643041\n",
      "Iteration 1404, loss = 316438.45315084\n",
      "Iteration 1405, loss = 315937.28622334\n",
      "Iteration 1406, loss = 315434.67253548\n",
      "Iteration 1407, loss = 314932.02702691\n",
      "Iteration 1408, loss = 314427.64288312\n",
      "Iteration 1409, loss = 313922.73294022\n",
      "Iteration 1410, loss = 313416.31062773\n",
      "Iteration 1411, loss = 312908.13239101\n",
      "Iteration 1412, loss = 312398.60167210\n",
      "Iteration 1413, loss = 311888.03152326\n",
      "Iteration 1414, loss = 311375.13161443\n",
      "Iteration 1415, loss = 310861.69406602\n",
      "Iteration 1416, loss = 310343.14135586\n",
      "Iteration 1417, loss = 309825.49715364\n",
      "Iteration 1418, loss = 309304.99899373\n",
      "Iteration 1419, loss = 308784.86417863\n",
      "Iteration 1420, loss = 308263.43643243\n",
      "Iteration 1421, loss = 307743.24226214\n",
      "Iteration 1422, loss = 307224.48324132\n",
      "Iteration 1423, loss = 306703.03465695\n",
      "Iteration 1424, loss = 306183.99573017\n",
      "Iteration 1425, loss = 305668.95164800\n",
      "Iteration 1426, loss = 305154.68051864\n",
      "Iteration 1427, loss = 304636.28849816\n",
      "Iteration 1428, loss = 304110.01242079\n",
      "Iteration 1429, loss = 303578.52517937\n",
      "Iteration 1430, loss = 303045.38608428\n",
      "Iteration 1431, loss = 302519.54799359\n",
      "Iteration 1432, loss = 301991.99189462\n",
      "Iteration 1433, loss = 301463.95267946\n",
      "Iteration 1434, loss = 300940.40773009\n",
      "Iteration 1435, loss = 300409.14157117\n",
      "Iteration 1436, loss = 299878.35910331\n",
      "Iteration 1437, loss = 299350.59480117\n",
      "Iteration 1438, loss = 298819.56393368\n",
      "Iteration 1439, loss = 298292.12716231\n",
      "Iteration 1440, loss = 297774.56347608\n",
      "Iteration 1441, loss = 297258.56092894\n",
      "Iteration 1442, loss = 296721.37640694\n",
      "Iteration 1443, loss = 296184.89302445\n",
      "Iteration 1444, loss = 295643.00722053\n",
      "Iteration 1445, loss = 295099.15383633\n",
      "Iteration 1446, loss = 294569.38813247\n",
      "Iteration 1447, loss = 294032.61626033\n",
      "Iteration 1448, loss = 293491.53077681\n",
      "Iteration 1449, loss = 292960.65795326\n",
      "Iteration 1450, loss = 292418.99197977\n",
      "Iteration 1451, loss = 291878.36447648\n",
      "Iteration 1452, loss = 291339.10168209\n",
      "Iteration 1453, loss = 290790.38490052\n",
      "Iteration 1454, loss = 290247.19367313\n",
      "Iteration 1455, loss = 289697.30640065\n",
      "Iteration 1456, loss = 289146.45164772\n",
      "Iteration 1457, loss = 288597.31134085\n",
      "Iteration 1458, loss = 288040.40812418\n",
      "Iteration 1459, loss = 287486.32107937\n",
      "Iteration 1460, loss = 286932.53503265\n",
      "Iteration 1461, loss = 286375.25369457\n",
      "Iteration 1462, loss = 285817.47133661\n",
      "Iteration 1463, loss = 285257.77372699\n",
      "Iteration 1464, loss = 284696.45185453\n",
      "Iteration 1465, loss = 284135.82885265\n",
      "Iteration 1466, loss = 283572.33784788\n",
      "Iteration 1467, loss = 283004.52638797\n",
      "Iteration 1468, loss = 282436.83534000\n",
      "Iteration 1469, loss = 281873.77963573\n",
      "Iteration 1470, loss = 281311.89149517\n",
      "Iteration 1471, loss = 280748.55728174\n",
      "Iteration 1472, loss = 280189.93486099\n",
      "Iteration 1473, loss = 279637.35119325\n",
      "Iteration 1474, loss = 279093.30477031\n",
      "Iteration 1475, loss = 278557.48249141\n",
      "Iteration 1476, loss = 278012.15496271\n",
      "Iteration 1477, loss = 277449.81581879\n",
      "Iteration 1478, loss = 276878.46730406\n",
      "Iteration 1479, loss = 276306.56828029\n",
      "Iteration 1480, loss = 275741.62158533\n",
      "Iteration 1481, loss = 275180.56044147\n",
      "Iteration 1482, loss = 274618.33725586\n",
      "Iteration 1483, loss = 274059.35020262\n",
      "Iteration 1484, loss = 273503.90537390\n",
      "Iteration 1485, loss = 272945.87041246\n",
      "Iteration 1486, loss = 272385.43189581\n",
      "Iteration 1487, loss = 271830.28795562\n",
      "Iteration 1488, loss = 271283.51235766\n",
      "Iteration 1489, loss = 270744.08767218\n",
      "Iteration 1490, loss = 270199.96908908\n",
      "Iteration 1491, loss = 269640.42065665\n",
      "Iteration 1492, loss = 269077.46864095\n",
      "Iteration 1493, loss = 268525.96855976\n",
      "Iteration 1494, loss = 267987.36251260\n",
      "Iteration 1495, loss = 267439.20691740\n",
      "Iteration 1496, loss = 266877.53811099\n",
      "Iteration 1497, loss = 266317.73397633\n",
      "Iteration 1498, loss = 265763.30692985\n",
      "Iteration 1499, loss = 265211.35169080\n",
      "Iteration 1500, loss = 264661.87645168\n",
      "Iteration 1501, loss = 264107.84914425\n",
      "Iteration 1502, loss = 263550.47822899\n",
      "Iteration 1503, loss = 262993.09203306\n",
      "Iteration 1504, loss = 262433.75820944\n",
      "Iteration 1505, loss = 261868.09900010\n",
      "Iteration 1506, loss = 261301.96624820\n",
      "Iteration 1507, loss = 260736.71561049\n",
      "Iteration 1508, loss = 260169.79608121\n",
      "Iteration 1509, loss = 259602.37077877\n",
      "Iteration 1510, loss = 259036.20294918\n",
      "Iteration 1511, loss = 258471.02376926\n",
      "Iteration 1512, loss = 257905.14681677\n",
      "Iteration 1513, loss = 257342.39804362\n",
      "Iteration 1514, loss = 256779.56728917\n",
      "Iteration 1515, loss = 256213.91483743\n",
      "Iteration 1516, loss = 255646.71676000\n",
      "Iteration 1517, loss = 255072.51591882\n",
      "Iteration 1518, loss = 254525.13236523\n",
      "Iteration 1519, loss = 253969.84277158\n",
      "Iteration 1520, loss = 253397.72068589\n",
      "Iteration 1521, loss = 252822.40559155\n",
      "Iteration 1522, loss = 252253.13157784\n",
      "Iteration 1523, loss = 251685.17254952\n",
      "Iteration 1524, loss = 251113.06465384\n",
      "Iteration 1525, loss = 250539.17428505\n",
      "Iteration 1526, loss = 249963.28522810\n",
      "Iteration 1527, loss = 249384.91126952\n",
      "Iteration 1528, loss = 248805.03514516\n",
      "Iteration 1529, loss = 248225.74085678\n",
      "Iteration 1530, loss = 247648.17637045\n",
      "Iteration 1531, loss = 247077.61280429\n",
      "Iteration 1532, loss = 246481.62851321\n",
      "Iteration 1533, loss = 245895.16827981\n",
      "Iteration 1534, loss = 245309.22679865\n",
      "Iteration 1535, loss = 244721.46783339\n",
      "Iteration 1536, loss = 244130.81075523\n",
      "Iteration 1537, loss = 243538.46221353\n",
      "Iteration 1538, loss = 242947.04954103\n",
      "Iteration 1539, loss = 242354.47270660\n",
      "Iteration 1540, loss = 241761.29180127\n",
      "Iteration 1541, loss = 241167.52236999\n",
      "Iteration 1542, loss = 240559.71345637\n",
      "Iteration 1543, loss = 239955.24491067\n",
      "Iteration 1544, loss = 239358.24680813\n",
      "Iteration 1545, loss = 238758.27751934\n",
      "Iteration 1546, loss = 238152.61005094\n",
      "Iteration 1547, loss = 237541.44605495\n",
      "Iteration 1548, loss = 236935.67626737\n",
      "Iteration 1549, loss = 236336.08742448\n",
      "Iteration 1550, loss = 235734.78895572\n",
      "Iteration 1551, loss = 235134.24614289\n",
      "Iteration 1552, loss = 234535.20011294\n",
      "Iteration 1553, loss = 233942.62081596\n",
      "Iteration 1554, loss = 233355.67837885\n",
      "Iteration 1555, loss = 232774.62455482\n",
      "Iteration 1556, loss = 232210.58412871\n",
      "Iteration 1557, loss = 231628.74761976\n",
      "Iteration 1558, loss = 231019.93626913\n",
      "Iteration 1559, loss = 230405.84671191\n",
      "Iteration 1560, loss = 229801.22742626\n",
      "Iteration 1561, loss = 229204.92662737\n",
      "Iteration 1562, loss = 228609.11043670\n",
      "Iteration 1563, loss = 228012.63114963\n",
      "Iteration 1564, loss = 227415.83517730\n",
      "Iteration 1565, loss = 226815.06546855\n",
      "Iteration 1566, loss = 226211.06035450\n",
      "Iteration 1567, loss = 225605.10077535\n",
      "Iteration 1568, loss = 224998.15899480\n",
      "Iteration 1569, loss = 224389.86069360\n",
      "Iteration 1570, loss = 223778.02429844\n",
      "Iteration 1571, loss = 223164.97309879\n",
      "Iteration 1572, loss = 222552.41811220\n",
      "Iteration 1573, loss = 221939.89366232\n",
      "Iteration 1574, loss = 221328.21068170\n",
      "Iteration 1575, loss = 220717.37171404\n",
      "Iteration 1576, loss = 220108.42098263\n",
      "Iteration 1577, loss = 219507.21474725\n",
      "Iteration 1578, loss = 218907.77209055\n",
      "Iteration 1579, loss = 218295.14506608\n",
      "Iteration 1580, loss = 217669.58169626\n",
      "Iteration 1581, loss = 217047.78283971\n",
      "Iteration 1582, loss = 216431.51097444\n",
      "Iteration 1583, loss = 215817.36972406\n",
      "Iteration 1584, loss = 215203.04632365\n",
      "Iteration 1585, loss = 214589.31559718\n",
      "Iteration 1586, loss = 213976.95017973\n",
      "Iteration 1587, loss = 213365.75695236\n",
      "Iteration 1588, loss = 212754.40687834\n",
      "Iteration 1589, loss = 212144.43489451\n",
      "Iteration 1590, loss = 211539.61154505\n",
      "Iteration 1591, loss = 210940.32737546\n",
      "Iteration 1592, loss = 210351.11530229\n",
      "Iteration 1593, loss = 209762.97398346\n",
      "Iteration 1594, loss = 209152.45484470\n",
      "Iteration 1595, loss = 208527.25807238\n",
      "Iteration 1596, loss = 207907.86514937\n",
      "Iteration 1597, loss = 207297.29097794\n",
      "Iteration 1598, loss = 206690.72947988\n",
      "Iteration 1599, loss = 206085.93337088\n",
      "Iteration 1600, loss = 205481.62201014\n",
      "Iteration 1601, loss = 204879.06913778\n",
      "Iteration 1602, loss = 204276.16020857\n",
      "Iteration 1603, loss = 203672.46059809\n",
      "Iteration 1604, loss = 203069.25713571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1605, loss = 202467.23977126\n",
      "Iteration 1606, loss = 201866.46733285\n",
      "Iteration 1607, loss = 201268.15646800\n",
      "Iteration 1608, loss = 200674.63030546\n",
      "Iteration 1609, loss = 200079.03479506\n",
      "Iteration 1610, loss = 199474.24871064\n",
      "Iteration 1611, loss = 198875.70023824\n",
      "Iteration 1612, loss = 198283.57947956\n",
      "Iteration 1613, loss = 197696.57999677\n",
      "Iteration 1614, loss = 197103.30191995\n",
      "Iteration 1615, loss = 196505.20425569\n",
      "Iteration 1616, loss = 195906.99126697\n",
      "Iteration 1617, loss = 195311.43520335\n",
      "Iteration 1618, loss = 194717.21613921\n",
      "Iteration 1619, loss = 194127.47099146\n",
      "Iteration 1620, loss = 193539.07211186\n",
      "Iteration 1621, loss = 192953.06275864\n",
      "Iteration 1622, loss = 192373.25328515\n",
      "Iteration 1623, loss = 191799.29256130\n",
      "Iteration 1624, loss = 191224.46470492\n",
      "Iteration 1625, loss = 190669.94445356\n",
      "Iteration 1626, loss = 190091.08735421\n",
      "Iteration 1627, loss = 189514.97874083\n",
      "Iteration 1628, loss = 188908.45226762\n",
      "Iteration 1629, loss = 188302.78171532\n",
      "Iteration 1630, loss = 187722.21489400\n",
      "Iteration 1631, loss = 187166.79976730\n",
      "Iteration 1632, loss = 186617.85196670\n",
      "Iteration 1633, loss = 186048.81764289\n",
      "Iteration 1634, loss = 185464.05801042\n",
      "Iteration 1635, loss = 184876.38476709\n",
      "Iteration 1636, loss = 184305.40939110\n",
      "Iteration 1637, loss = 183756.86468076\n",
      "Iteration 1638, loss = 183212.60939252\n",
      "Iteration 1639, loss = 182666.63279229\n",
      "Iteration 1640, loss = 182098.65978225\n",
      "Iteration 1641, loss = 181532.58025838\n",
      "Iteration 1642, loss = 180968.50606301\n",
      "Iteration 1643, loss = 180417.59459010\n",
      "Iteration 1644, loss = 179879.93977677\n",
      "Iteration 1645, loss = 179345.21361999\n",
      "Iteration 1646, loss = 178815.33911761\n",
      "Iteration 1647, loss = 178270.76187888\n",
      "Iteration 1648, loss = 177727.61755812\n",
      "Iteration 1649, loss = 177175.34758204\n",
      "Iteration 1650, loss = 176625.59569041\n",
      "Iteration 1651, loss = 176085.76025399\n",
      "Iteration 1652, loss = 175554.23760920\n",
      "Iteration 1653, loss = 175027.61592476\n",
      "Iteration 1654, loss = 174499.60316307\n",
      "Iteration 1655, loss = 173969.37296403\n",
      "Iteration 1656, loss = 173433.71846754\n",
      "Iteration 1657, loss = 172900.57565366\n",
      "Iteration 1658, loss = 172375.13069659\n",
      "Iteration 1659, loss = 171856.41447707\n",
      "Iteration 1660, loss = 171341.96780480\n",
      "Iteration 1661, loss = 170826.13071754\n",
      "Iteration 1662, loss = 170312.16479927\n",
      "Iteration 1663, loss = 169798.89558269\n",
      "Iteration 1664, loss = 169289.00350325\n",
      "Iteration 1665, loss = 168782.52784794\n",
      "Iteration 1666, loss = 168279.60542641\n",
      "Iteration 1667, loss = 167781.08470304\n",
      "Iteration 1668, loss = 167284.63254791\n",
      "Iteration 1669, loss = 166789.04562003\n",
      "Iteration 1670, loss = 166293.97180086\n",
      "Iteration 1671, loss = 165797.57734093\n",
      "Iteration 1672, loss = 165299.91844385\n",
      "Iteration 1673, loss = 164805.91234393\n",
      "Iteration 1674, loss = 164316.26834008\n",
      "Iteration 1675, loss = 163827.97000150\n",
      "Iteration 1676, loss = 163340.60289127\n",
      "Iteration 1677, loss = 162854.62042950\n",
      "Iteration 1678, loss = 162373.19484570\n",
      "Iteration 1679, loss = 161897.40693158\n",
      "Iteration 1680, loss = 161430.94687884\n",
      "Iteration 1681, loss = 160970.01695248\n",
      "Iteration 1682, loss = 160517.56827316\n",
      "Iteration 1683, loss = 160060.04270641\n",
      "Iteration 1684, loss = 159605.24894573\n",
      "Iteration 1685, loss = 159134.11773799\n",
      "Iteration 1686, loss = 158656.18768627\n",
      "Iteration 1687, loss = 158153.88467904\n",
      "Iteration 1688, loss = 157637.82508900\n",
      "Iteration 1689, loss = 157122.65358616\n",
      "Iteration 1690, loss = 156626.39256375\n",
      "Iteration 1691, loss = 156153.06016826\n",
      "Iteration 1692, loss = 155696.55570542\n",
      "Iteration 1693, loss = 155244.57843949\n",
      "Iteration 1694, loss = 154788.45355184\n",
      "Iteration 1695, loss = 154321.80702229\n",
      "Iteration 1696, loss = 153838.78101902\n",
      "Iteration 1697, loss = 153353.23781954\n",
      "Iteration 1698, loss = 152869.95457627\n",
      "Iteration 1699, loss = 152397.95473555\n",
      "Iteration 1700, loss = 151937.57064586\n",
      "Iteration 1701, loss = 151483.39964760\n",
      "Iteration 1702, loss = 151029.39473187\n",
      "Iteration 1703, loss = 150577.34166471\n",
      "Iteration 1704, loss = 150117.24876324\n",
      "Iteration 1705, loss = 149655.98781134\n",
      "Iteration 1706, loss = 149192.55301513\n",
      "Iteration 1707, loss = 148725.04469640\n",
      "Iteration 1708, loss = 148260.07393380\n",
      "Iteration 1709, loss = 147792.12097443\n",
      "Iteration 1710, loss = 147324.37362555\n",
      "Iteration 1711, loss = 146858.77677596\n",
      "Iteration 1712, loss = 146397.28516198\n",
      "Iteration 1713, loss = 145940.04191015\n",
      "Iteration 1714, loss = 145486.94993544\n",
      "Iteration 1715, loss = 145037.21065475\n",
      "Iteration 1716, loss = 144592.95905931\n",
      "Iteration 1717, loss = 144152.67957798\n",
      "Iteration 1718, loss = 143712.84179525\n",
      "Iteration 1719, loss = 143282.38026951\n",
      "Iteration 1720, loss = 142861.79855208\n",
      "Iteration 1721, loss = 142456.32958506\n",
      "Iteration 1722, loss = 142042.72666173\n",
      "Iteration 1723, loss = 141625.83417426\n",
      "Iteration 1724, loss = 141158.84382828\n",
      "Iteration 1725, loss = 140657.00077477\n",
      "Iteration 1726, loss = 140132.58996628\n",
      "Iteration 1727, loss = 139632.66180526\n",
      "Iteration 1728, loss = 139185.25425922\n",
      "Iteration 1729, loss = 138780.36350195\n",
      "Iteration 1730, loss = 138384.98628763\n",
      "Iteration 1731, loss = 137970.04148034\n",
      "Iteration 1732, loss = 137514.25426086\n",
      "Iteration 1733, loss = 137034.02911771\n",
      "Iteration 1734, loss = 136555.26565417\n",
      "Iteration 1735, loss = 136098.19142783\n",
      "Iteration 1736, loss = 135665.50713751\n",
      "Iteration 1737, loss = 135249.15882283\n",
      "Iteration 1738, loss = 134830.96531025\n",
      "Iteration 1739, loss = 134401.95401011\n",
      "Iteration 1740, loss = 133951.90305558\n",
      "Iteration 1741, loss = 133497.72862487\n",
      "Iteration 1742, loss = 133048.52586916\n",
      "Iteration 1743, loss = 132613.97804954\n",
      "Iteration 1744, loss = 132191.14365520\n",
      "Iteration 1745, loss = 131769.35489873\n",
      "Iteration 1746, loss = 131342.00547955\n",
      "Iteration 1747, loss = 130909.14035482\n",
      "Iteration 1748, loss = 130472.93592956\n",
      "Iteration 1749, loss = 130035.45114512\n",
      "Iteration 1750, loss = 129599.40536871\n",
      "Iteration 1751, loss = 129168.21277713\n",
      "Iteration 1752, loss = 128742.32019941\n",
      "Iteration 1753, loss = 128320.28621531\n",
      "Iteration 1754, loss = 127900.79558312\n",
      "Iteration 1755, loss = 127483.51217777\n",
      "Iteration 1756, loss = 127068.11863932\n",
      "Iteration 1757, loss = 126655.10692530\n",
      "Iteration 1758, loss = 126238.99173766\n",
      "Iteration 1759, loss = 125826.82960327\n",
      "Iteration 1760, loss = 125411.55904595\n",
      "Iteration 1761, loss = 125001.35827165\n",
      "Iteration 1762, loss = 124581.83214344\n",
      "Iteration 1763, loss = 124171.03127735\n",
      "Iteration 1764, loss = 123748.22745964\n",
      "Iteration 1765, loss = 123321.56506710\n",
      "Iteration 1766, loss = 122889.47658696\n",
      "Iteration 1767, loss = 122459.27805392\n",
      "Iteration 1768, loss = 122038.72924846\n",
      "Iteration 1769, loss = 121628.90106733\n",
      "Iteration 1770, loss = 121227.31794696\n",
      "Iteration 1771, loss = 120829.68180168\n",
      "Iteration 1772, loss = 120433.24816614\n",
      "Iteration 1773, loss = 120033.21161896\n",
      "Iteration 1774, loss = 119628.82847381\n",
      "Iteration 1775, loss = 119221.46534712\n",
      "Iteration 1776, loss = 118811.84804428\n",
      "Iteration 1777, loss = 118402.70311176\n",
      "Iteration 1778, loss = 117993.93426298\n",
      "Iteration 1779, loss = 117588.10216068\n",
      "Iteration 1780, loss = 117186.15051064\n",
      "Iteration 1781, loss = 116787.35875108\n",
      "Iteration 1782, loss = 116391.18311174\n",
      "Iteration 1783, loss = 115995.78961433\n",
      "Iteration 1784, loss = 115600.94459511\n",
      "Iteration 1785, loss = 115206.74880755\n",
      "Iteration 1786, loss = 114813.18177284\n",
      "Iteration 1787, loss = 114421.02439393\n",
      "Iteration 1788, loss = 114030.14152827\n",
      "Iteration 1789, loss = 113640.64785095\n",
      "Iteration 1790, loss = 113252.40190734\n",
      "Iteration 1791, loss = 112865.56289102\n",
      "Iteration 1792, loss = 112480.39958001\n",
      "Iteration 1793, loss = 112097.53472139\n",
      "Iteration 1794, loss = 111717.79084559\n",
      "Iteration 1795, loss = 111343.68620242\n",
      "Iteration 1796, loss = 110978.71147492\n",
      "Iteration 1797, loss = 110632.56994254\n",
      "Iteration 1798, loss = 110325.19509727\n",
      "Iteration 1799, loss = 110075.37721512\n",
      "Iteration 1800, loss = 109894.27175786\n",
      "Iteration 1801, loss = 109785.28495117\n",
      "Iteration 1802, loss = 109550.99619745\n",
      "Iteration 1803, loss = 109012.50621266\n",
      "Iteration 1804, loss = 108182.23547127\n",
      "Iteration 1805, loss = 107562.60018314\n",
      "Iteration 1806, loss = 107370.96779814\n",
      "Iteration 1807, loss = 107246.10631985\n",
      "Iteration 1808, loss = 106814.95663618\n",
      "Iteration 1809, loss = 106169.79166698\n",
      "Iteration 1810, loss = 105753.05818056\n",
      "Iteration 1811, loss = 105575.48240772\n",
      "Iteration 1812, loss = 105263.45819909\n",
      "Iteration 1813, loss = 104736.85113854\n",
      "Iteration 1814, loss = 104279.95568301\n",
      "Iteration 1815, loss = 104020.70952117\n",
      "Iteration 1816, loss = 103735.75627211\n",
      "Iteration 1817, loss = 103297.89570249\n",
      "Iteration 1818, loss = 102845.06857133\n",
      "Iteration 1819, loss = 102530.18918108\n",
      "Iteration 1820, loss = 102254.61560038\n",
      "Iteration 1821, loss = 101867.43068867\n",
      "Iteration 1822, loss = 101435.24599838\n",
      "Iteration 1823, loss = 101075.10639017\n",
      "Iteration 1824, loss = 100779.32236042\n",
      "Iteration 1825, loss = 100443.52231781\n",
      "Iteration 1826, loss = 100047.69832628\n",
      "Iteration 1827, loss = 99663.14289904\n",
      "Iteration 1828, loss = 99338.84158743\n",
      "Iteration 1829, loss = 99023.80650820\n",
      "Iteration 1830, loss = 98658.24718996\n",
      "Iteration 1831, loss = 98277.94236695\n",
      "Iteration 1832, loss = 97939.05144721\n",
      "Iteration 1833, loss = 97621.27659700\n",
      "Iteration 1834, loss = 97276.09754212\n",
      "Iteration 1835, loss = 96909.42049984\n",
      "Iteration 1836, loss = 96560.57295253\n",
      "Iteration 1837, loss = 96235.08561698\n",
      "Iteration 1838, loss = 95903.52370223\n",
      "Iteration 1839, loss = 95554.30472948\n",
      "Iteration 1840, loss = 95204.66953655\n",
      "Iteration 1841, loss = 94870.63501751\n",
      "Iteration 1842, loss = 94543.33476272\n",
      "Iteration 1843, loss = 94208.06349407\n",
      "Iteration 1844, loss = 93866.99404134\n",
      "Iteration 1845, loss = 93531.52642202\n",
      "Iteration 1846, loss = 93204.21637922\n",
      "Iteration 1847, loss = 92877.07587414\n",
      "Iteration 1848, loss = 92544.46078917\n",
      "Iteration 1849, loss = 92211.32196376\n",
      "Iteration 1850, loss = 91882.59697240\n",
      "Iteration 1851, loss = 91558.38910784\n",
      "Iteration 1852, loss = 91234.51389516\n",
      "Iteration 1853, loss = 90908.63097653\n",
      "Iteration 1854, loss = 90582.42850560\n",
      "Iteration 1855, loss = 90258.45695039\n",
      "Iteration 1856, loss = 89937.18641775\n",
      "Iteration 1857, loss = 89616.73824038\n",
      "Iteration 1858, loss = 89295.28072738\n",
      "Iteration 1859, loss = 88973.72266404\n",
      "Iteration 1860, loss = 88653.91276019\n",
      "Iteration 1861, loss = 88336.24544951\n",
      "Iteration 1862, loss = 88020.31207913\n",
      "Iteration 1863, loss = 87704.59569828\n",
      "Iteration 1864, loss = 87388.78614516\n",
      "Iteration 1865, loss = 87073.72578771\n",
      "Iteration 1866, loss = 86760.29880210\n",
      "Iteration 1867, loss = 86448.47910209\n",
      "Iteration 1868, loss = 86137.58349331\n",
      "Iteration 1869, loss = 85827.66809988\n",
      "Iteration 1870, loss = 85518.22712639\n",
      "Iteration 1871, loss = 85209.24557446\n",
      "Iteration 1872, loss = 84901.25759867\n",
      "Iteration 1873, loss = 84594.65997740\n",
      "Iteration 1874, loss = 84289.49059950\n",
      "Iteration 1875, loss = 83985.52066940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1876, loss = 83682.02149367\n",
      "Iteration 1877, loss = 83378.89661943\n",
      "Iteration 1878, loss = 83076.25164016\n",
      "Iteration 1879, loss = 82774.50969498\n",
      "Iteration 1880, loss = 82473.79687957\n",
      "Iteration 1881, loss = 82174.18061458\n",
      "Iteration 1882, loss = 81875.31216366\n",
      "Iteration 1883, loss = 81577.00315591\n",
      "Iteration 1884, loss = 81279.39414046\n",
      "Iteration 1885, loss = 80982.73470768\n",
      "Iteration 1886, loss = 80686.96528319\n",
      "Iteration 1887, loss = 80392.09361872\n",
      "Iteration 1888, loss = 80098.16521223\n",
      "Iteration 1889, loss = 79805.15544325\n",
      "Iteration 1890, loss = 79513.00857538\n",
      "Iteration 1891, loss = 79221.61196843\n",
      "Iteration 1892, loss = 78930.89101646\n",
      "Iteration 1893, loss = 78640.80790385\n",
      "Iteration 1894, loss = 78351.50736986\n",
      "Iteration 1895, loss = 78062.95943370\n",
      "Iteration 1896, loss = 77776.13226618\n",
      "Iteration 1897, loss = 77490.41684018\n",
      "Iteration 1898, loss = 77205.61646551\n",
      "Iteration 1899, loss = 76921.74103937\n",
      "Iteration 1900, loss = 76638.74313065\n",
      "Iteration 1901, loss = 76357.10170223\n",
      "Iteration 1902, loss = 76077.26470349\n",
      "Iteration 1903, loss = 75800.24267194\n",
      "Iteration 1904, loss = 75527.36525894\n",
      "Iteration 1905, loss = 75256.93830180\n",
      "Iteration 1906, loss = 74994.11477786\n",
      "Iteration 1907, loss = 74734.89898034\n",
      "Iteration 1908, loss = 74487.44275799\n",
      "Iteration 1909, loss = 74243.77053378\n",
      "Iteration 1910, loss = 74011.51656099\n",
      "Iteration 1911, loss = 73777.41942976\n",
      "Iteration 1912, loss = 73539.95575463\n",
      "Iteration 1913, loss = 73269.12820352\n",
      "Iteration 1914, loss = 72968.14086678\n",
      "Iteration 1915, loss = 72629.48367201\n",
      "Iteration 1916, loss = 72276.17392747\n",
      "Iteration 1917, loss = 71946.35260185\n",
      "Iteration 1918, loss = 71661.53827223\n",
      "Iteration 1919, loss = 71417.50009028\n",
      "Iteration 1920, loss = 71192.66935161\n",
      "Iteration 1921, loss = 70961.80871680\n",
      "Iteration 1922, loss = 70706.78886085\n",
      "Iteration 1923, loss = 70424.03350963\n",
      "Iteration 1924, loss = 70122.26049585\n",
      "Iteration 1925, loss = 69825.85285860\n",
      "Iteration 1926, loss = 69545.10949944\n",
      "Iteration 1927, loss = 69284.82066396\n",
      "Iteration 1928, loss = 69038.21929731\n",
      "Iteration 1929, loss = 68794.78550149\n",
      "Iteration 1930, loss = 68547.26615082\n",
      "Iteration 1931, loss = 68288.55699669\n",
      "Iteration 1932, loss = 68023.27426126\n",
      "Iteration 1933, loss = 67753.21900415\n",
      "Iteration 1934, loss = 67486.06076117\n",
      "Iteration 1935, loss = 67226.67220771\n",
      "Iteration 1936, loss = 66975.71027936\n",
      "Iteration 1937, loss = 66730.02887392\n",
      "Iteration 1938, loss = 66485.23384358\n",
      "Iteration 1939, loss = 66238.74064189\n",
      "Iteration 1940, loss = 65989.08072223\n",
      "Iteration 1941, loss = 65737.02455795\n",
      "Iteration 1942, loss = 65483.18301453\n",
      "Iteration 1943, loss = 65230.01283781\n",
      "Iteration 1944, loss = 64978.37941065\n",
      "Iteration 1945, loss = 64729.49784530\n",
      "Iteration 1946, loss = 64483.40612292\n",
      "Iteration 1947, loss = 64239.55504186\n",
      "Iteration 1948, loss = 63997.33148500\n",
      "Iteration 1949, loss = 63756.35423256\n",
      "Iteration 1950, loss = 63516.53274397\n",
      "Iteration 1951, loss = 63277.09690735\n",
      "Iteration 1952, loss = 63038.02512478\n",
      "Iteration 1953, loss = 62799.26269643\n",
      "Iteration 1954, loss = 62561.29179635\n",
      "Iteration 1955, loss = 62325.02437657\n",
      "Iteration 1956, loss = 62090.81249805\n",
      "Iteration 1957, loss = 61859.34515087\n",
      "Iteration 1958, loss = 61631.65079797\n",
      "Iteration 1959, loss = 61409.21613450\n",
      "Iteration 1960, loss = 61194.44841755\n",
      "Iteration 1961, loss = 60984.81474663\n",
      "Iteration 1962, loss = 60785.90343599\n",
      "Iteration 1963, loss = 60588.16757414\n",
      "Iteration 1964, loss = 60396.53163749\n",
      "Iteration 1965, loss = 60197.55685880\n",
      "Iteration 1966, loss = 59983.80292415\n",
      "Iteration 1967, loss = 59731.24840149\n",
      "Iteration 1968, loss = 59452.02972325\n",
      "Iteration 1969, loss = 59148.00204562\n",
      "Iteration 1970, loss = 58849.89955507\n",
      "Iteration 1971, loss = 58587.92115305\n",
      "Iteration 1972, loss = 58369.38123854\n",
      "Iteration 1973, loss = 58179.36231480\n",
      "Iteration 1974, loss = 57994.76826581\n",
      "Iteration 1975, loss = 57794.42669460\n",
      "Iteration 1976, loss = 57566.84034918\n",
      "Iteration 1977, loss = 57317.57396211\n",
      "Iteration 1978, loss = 57059.28926732\n",
      "Iteration 1979, loss = 56810.03373570\n",
      "Iteration 1980, loss = 56578.60284466\n",
      "Iteration 1981, loss = 56366.20222586\n",
      "Iteration 1982, loss = 56164.73970959\n",
      "Iteration 1983, loss = 55962.56698813\n",
      "Iteration 1984, loss = 55751.67755054\n",
      "Iteration 1985, loss = 55529.94262942\n",
      "Iteration 1986, loss = 55300.90166155\n",
      "Iteration 1987, loss = 55071.33356136\n",
      "Iteration 1988, loss = 54846.05222876\n",
      "Iteration 1989, loss = 54628.55729642\n",
      "Iteration 1990, loss = 54417.97525712\n",
      "Iteration 1991, loss = 54212.06537618\n",
      "Iteration 1992, loss = 54006.81804668\n",
      "Iteration 1993, loss = 53799.85969922\n",
      "Iteration 1994, loss = 53589.13602211\n",
      "Iteration 1995, loss = 53375.31519665\n",
      "Iteration 1996, loss = 53160.31068953\n",
      "Iteration 1997, loss = 52946.29446133\n",
      "Iteration 1998, loss = 52734.73227725\n",
      "Iteration 1999, loss = 52526.19911639\n",
      "Iteration 2000, loss = 52320.30245712\n",
      "Iteration 2001, loss = 52116.39683184\n",
      "Iteration 2002, loss = 51913.86730754\n",
      "Iteration 2003, loss = 51711.97331863\n",
      "Iteration 2004, loss = 51510.37205146\n",
      "Iteration 2005, loss = 51308.73813179\n",
      "Iteration 2006, loss = 51107.29167836\n",
      "Iteration 2007, loss = 50905.96698513\n",
      "Iteration 2008, loss = 50705.22322956\n",
      "Iteration 2009, loss = 50505.07034335\n",
      "Iteration 2010, loss = 50306.13711537\n",
      "Iteration 2011, loss = 50109.19804677\n",
      "Iteration 2012, loss = 49914.69961987\n",
      "Iteration 2013, loss = 49723.50716406\n",
      "Iteration 2014, loss = 49536.68514980\n",
      "Iteration 2015, loss = 49354.36928217\n",
      "Iteration 2016, loss = 49180.14426575\n",
      "Iteration 2017, loss = 49012.71730690\n",
      "Iteration 2018, loss = 48856.92715790\n",
      "Iteration 2019, loss = 48706.12397710\n",
      "Iteration 2020, loss = 48563.49311757\n",
      "Iteration 2021, loss = 48410.03066855\n",
      "Iteration 2022, loss = 48238.69976301\n",
      "Iteration 2023, loss = 48018.24389946\n",
      "Iteration 2024, loss = 47759.22765475\n",
      "Iteration 2025, loss = 47476.33985987\n",
      "Iteration 2026, loss = 47212.55669461\n",
      "Iteration 2027, loss = 46991.10042362\n",
      "Iteration 2028, loss = 46813.49924328\n",
      "Iteration 2029, loss = 46664.31192875\n",
      "Iteration 2030, loss = 46519.21458511\n",
      "Iteration 2031, loss = 46357.65101828\n",
      "Iteration 2032, loss = 46165.26002756\n",
      "Iteration 2033, loss = 45951.60444475\n",
      "Iteration 2034, loss = 45727.61973708\n",
      "Iteration 2035, loss = 45515.27023660\n",
      "Iteration 2036, loss = 45323.13621828\n",
      "Iteration 2037, loss = 45150.85803848\n",
      "Iteration 2038, loss = 44988.37148289\n",
      "Iteration 2039, loss = 44823.19574278\n",
      "Iteration 2040, loss = 44647.40900722\n",
      "Iteration 2041, loss = 44459.78793961\n",
      "Iteration 2042, loss = 44265.67816890\n",
      "Iteration 2043, loss = 44072.29512932\n",
      "Iteration 2044, loss = 43885.75351297\n",
      "Iteration 2045, loss = 43708.15175135\n",
      "Iteration 2046, loss = 43537.36082614\n",
      "Iteration 2047, loss = 43369.65972136\n",
      "Iteration 2048, loss = 43200.48175127\n",
      "Iteration 2049, loss = 43027.29917252\n",
      "Iteration 2050, loss = 42850.11264879\n",
      "Iteration 2051, loss = 42670.82397062\n",
      "Iteration 2052, loss = 42491.72481657\n",
      "Iteration 2053, loss = 42314.95838744\n",
      "Iteration 2054, loss = 42141.37933487\n",
      "Iteration 2055, loss = 41970.79878909\n",
      "Iteration 2056, loss = 41802.30931618\n",
      "Iteration 2057, loss = 41635.00869319\n",
      "Iteration 2058, loss = 41467.96624020\n",
      "Iteration 2059, loss = 41300.80459590\n",
      "Iteration 2060, loss = 41133.28040948\n",
      "Iteration 2061, loss = 40965.51253883\n",
      "Iteration 2062, loss = 40797.78641820\n",
      "Iteration 2063, loss = 40630.29060340\n",
      "Iteration 2064, loss = 40463.29650131\n",
      "Iteration 2065, loss = 40296.99655763\n",
      "Iteration 2066, loss = 40131.56561334\n",
      "Iteration 2067, loss = 39967.07913971\n",
      "Iteration 2068, loss = 39803.46186863\n",
      "Iteration 2069, loss = 39640.52342520\n",
      "Iteration 2070, loss = 39478.36912962\n",
      "Iteration 2071, loss = 39316.87065953\n",
      "Iteration 2072, loss = 39155.94556374\n",
      "Iteration 2073, loss = 38995.58145545\n",
      "Iteration 2074, loss = 38835.76449908\n",
      "Iteration 2075, loss = 38676.48884471\n",
      "Iteration 2076, loss = 38517.83621542\n",
      "Iteration 2077, loss = 38359.78878447\n",
      "Iteration 2078, loss = 38202.34085363\n",
      "Iteration 2079, loss = 38045.46711341\n",
      "Iteration 2080, loss = 37889.14708097\n",
      "Iteration 2081, loss = 37733.41223744\n",
      "Iteration 2082, loss = 37578.31414313\n",
      "Iteration 2083, loss = 37423.89600319\n",
      "Iteration 2084, loss = 37270.38461583\n",
      "Iteration 2085, loss = 37118.07506823\n",
      "Iteration 2086, loss = 36967.65149643\n",
      "Iteration 2087, loss = 36820.02836937\n",
      "Iteration 2088, loss = 36677.32789163\n",
      "Iteration 2089, loss = 36543.45155838\n",
      "Iteration 2090, loss = 36426.13799539\n",
      "Iteration 2091, loss = 36337.16912726\n",
      "Iteration 2092, loss = 36303.70890143\n",
      "Iteration 2093, loss = 36346.22072043\n",
      "Iteration 2094, loss = 36499.98895183\n",
      "Iteration 2095, loss = 36661.00514039\n",
      "Iteration 2096, loss = 36661.99784323\n",
      "Iteration 2097, loss = 36178.72284808\n",
      "Iteration 2098, loss = 35452.92948983\n",
      "Iteration 2099, loss = 35022.19195403\n",
      "Iteration 2100, loss = 35112.39325566\n",
      "Iteration 2101, loss = 35302.93695035\n",
      "Iteration 2102, loss = 35094.96696694\n",
      "Iteration 2103, loss = 34596.38973555\n",
      "Iteration 2104, loss = 34307.34920258\n",
      "Iteration 2105, loss = 34361.76336316\n",
      "Iteration 2106, loss = 34378.01703381\n",
      "Iteration 2107, loss = 34092.14684468\n",
      "Iteration 2108, loss = 33753.30376761\n",
      "Iteration 2109, loss = 33649.36033208\n",
      "Iteration 2110, loss = 33657.18802725\n",
      "Iteration 2111, loss = 33508.76125935\n",
      "Iteration 2112, loss = 33225.28075858\n",
      "Iteration 2113, loss = 33046.79587828\n",
      "Iteration 2114, loss = 33001.27929196\n",
      "Iteration 2115, loss = 32901.86443214\n",
      "Iteration 2116, loss = 32687.59877375\n",
      "Iteration 2117, loss = 32490.83185106\n",
      "Iteration 2118, loss = 32395.67641397\n",
      "Iteration 2119, loss = 32308.89350449\n",
      "Iteration 2120, loss = 32143.16967916\n",
      "Iteration 2121, loss = 31954.74622586\n",
      "Iteration 2122, loss = 31826.54258748\n",
      "Iteration 2123, loss = 31732.05048672\n",
      "Iteration 2124, loss = 31598.92963281\n",
      "Iteration 2125, loss = 31429.87007297\n",
      "Iteration 2126, loss = 31282.32418159\n",
      "Iteration 2127, loss = 31170.65743043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2128, loss = 31053.90002399\n",
      "Iteration 2129, loss = 30909.06109320\n",
      "Iteration 2130, loss = 30758.88082340\n",
      "Iteration 2131, loss = 30631.15642925\n",
      "Iteration 2132, loss = 30516.23948412\n",
      "Iteration 2133, loss = 30388.50404926\n",
      "Iteration 2134, loss = 30246.71633479\n",
      "Iteration 2135, loss = 30110.69316309\n",
      "Iteration 2136, loss = 29989.03983075\n",
      "Iteration 2137, loss = 29869.45209345\n",
      "Iteration 2138, loss = 29740.10571243\n",
      "Iteration 2139, loss = 29605.38782503\n",
      "Iteration 2140, loss = 29476.24155525\n",
      "Iteration 2141, loss = 29355.14948875\n",
      "Iteration 2142, loss = 29234.09509147\n",
      "Iteration 2143, loss = 29107.25095754\n",
      "Iteration 2144, loss = 28978.17591595\n",
      "Iteration 2145, loss = 28853.14226159\n",
      "Iteration 2146, loss = 28732.57346433\n",
      "Iteration 2147, loss = 28612.10889675\n",
      "Iteration 2148, loss = 28488.91701962\n",
      "Iteration 2149, loss = 28364.39395756\n",
      "Iteration 2150, loss = 28241.64178963\n",
      "Iteration 2151, loss = 28121.73013220\n",
      "Iteration 2152, loss = 28002.79368270\n",
      "Iteration 2153, loss = 27882.89759259\n",
      "Iteration 2154, loss = 27762.22564865\n",
      "Iteration 2155, loss = 27642.34289963\n",
      "Iteration 2156, loss = 27524.08876645\n",
      "Iteration 2157, loss = 27406.79642013\n",
      "Iteration 2158, loss = 27289.54012953\n",
      "Iteration 2159, loss = 27172.01717765\n",
      "Iteration 2160, loss = 27054.75087969\n",
      "Iteration 2161, loss = 26938.35072134\n",
      "Iteration 2162, loss = 26822.96665887\n",
      "Iteration 2163, loss = 26708.16447671\n",
      "Iteration 2164, loss = 26593.35499909\n",
      "Iteration 2165, loss = 26478.56594194\n",
      "Iteration 2166, loss = 26364.35514502\n",
      "Iteration 2167, loss = 26250.84049600\n",
      "Iteration 2168, loss = 26137.99243838\n",
      "Iteration 2169, loss = 26025.56316611\n",
      "Iteration 2170, loss = 25913.36011838\n",
      "Iteration 2171, loss = 25801.42322552\n",
      "Iteration 2172, loss = 25689.93017076\n",
      "Iteration 2173, loss = 25579.03376967\n",
      "Iteration 2174, loss = 25468.68185357\n",
      "Iteration 2175, loss = 25358.77321979\n",
      "Iteration 2176, loss = 25249.20308742\n",
      "Iteration 2177, loss = 25139.97340928\n",
      "Iteration 2178, loss = 25031.14560143\n",
      "Iteration 2179, loss = 24922.76797039\n",
      "Iteration 2180, loss = 24814.90120376\n",
      "Iteration 2181, loss = 24707.47367523\n",
      "Iteration 2182, loss = 24600.44458806\n",
      "Iteration 2183, loss = 24493.80436014\n",
      "Iteration 2184, loss = 24387.55003432\n",
      "Iteration 2185, loss = 24281.77231388\n",
      "Iteration 2186, loss = 24176.40768561\n",
      "Iteration 2187, loss = 24071.44348868\n",
      "Iteration 2188, loss = 23966.88031562\n",
      "Iteration 2189, loss = 23862.73336040\n",
      "Iteration 2190, loss = 23758.98459584\n",
      "Iteration 2191, loss = 23655.62331297\n",
      "Iteration 2192, loss = 23552.64583868\n",
      "Iteration 2193, loss = 23450.11859506\n",
      "Iteration 2194, loss = 23348.02837339\n",
      "Iteration 2195, loss = 23246.35853950\n",
      "Iteration 2196, loss = 23145.10073352\n",
      "Iteration 2197, loss = 23044.25135202\n",
      "Iteration 2198, loss = 22943.77491226\n",
      "Iteration 2199, loss = 22843.64283528\n",
      "Iteration 2200, loss = 22743.86632551\n",
      "Iteration 2201, loss = 22644.49784611\n",
      "Iteration 2202, loss = 22545.52915988\n",
      "Iteration 2203, loss = 22446.94691504\n",
      "Iteration 2204, loss = 22348.79598685\n",
      "Iteration 2205, loss = 22251.02307039\n",
      "Iteration 2206, loss = 22153.92329644\n",
      "Iteration 2207, loss = 22057.16398516\n",
      "Iteration 2208, loss = 21960.75460646\n",
      "Iteration 2209, loss = 21864.70962046\n",
      "Iteration 2210, loss = 21769.13494165\n",
      "Iteration 2211, loss = 21673.94670901\n",
      "Iteration 2212, loss = 21579.12582892\n",
      "Iteration 2213, loss = 21484.66548889\n",
      "Iteration 2214, loss = 21390.56298599\n",
      "Iteration 2215, loss = 21296.81409053\n",
      "Iteration 2216, loss = 21203.45919850\n",
      "Iteration 2217, loss = 21110.49359739\n",
      "Iteration 2218, loss = 21017.88792633\n",
      "Iteration 2219, loss = 20925.64431362\n",
      "Iteration 2220, loss = 20833.76763314\n",
      "Iteration 2221, loss = 20742.26090260\n",
      "Iteration 2222, loss = 20651.12421201\n",
      "Iteration 2223, loss = 20560.36319461\n",
      "Iteration 2224, loss = 20469.98285008\n",
      "Iteration 2225, loss = 20379.98592834\n",
      "Iteration 2226, loss = 20290.37977130\n",
      "Iteration 2227, loss = 20201.17378096\n",
      "Iteration 2228, loss = 20112.46591826\n",
      "Iteration 2229, loss = 20024.42055177\n",
      "Iteration 2230, loss = 19937.19093321\n",
      "Iteration 2231, loss = 19850.80813242\n",
      "Iteration 2232, loss = 19765.55972362\n",
      "Iteration 2233, loss = 19681.95746473\n",
      "Iteration 2234, loss = 19600.89812416\n",
      "Iteration 2235, loss = 19523.89811200\n",
      "Iteration 2236, loss = 19453.83584071\n",
      "Iteration 2237, loss = 19396.57828798\n",
      "Iteration 2238, loss = 19367.21261185\n",
      "Iteration 2239, loss = 19380.07349655\n",
      "Iteration 2240, loss = 19469.40057084\n",
      "Iteration 2241, loss = 19644.43063982\n",
      "Iteration 2242, loss = 19902.99273463\n",
      "Iteration 2243, loss = 20029.76006492\n",
      "Iteration 2244, loss = 19840.00919196\n",
      "Iteration 2245, loss = 19216.74039692\n",
      "Iteration 2246, loss = 18651.72543998\n",
      "Iteration 2247, loss = 18549.19593650\n",
      "Iteration 2248, loss = 18798.89327099\n",
      "Iteration 2249, loss = 18935.46410836\n",
      "Iteration 2250, loss = 18656.15277660\n",
      "Iteration 2251, loss = 18248.78126862\n",
      "Iteration 2252, loss = 18115.59472393\n",
      "Iteration 2253, loss = 18240.39764546\n",
      "Iteration 2254, loss = 18275.35505009\n",
      "Iteration 2255, loss = 18045.17072098\n",
      "Iteration 2256, loss = 17793.34435922\n",
      "Iteration 2257, loss = 17744.59542681\n",
      "Iteration 2258, loss = 17800.29152391\n",
      "Iteration 2259, loss = 17733.09873956\n",
      "Iteration 2260, loss = 17532.94654578\n",
      "Iteration 2261, loss = 17393.15917286\n",
      "Iteration 2262, loss = 17379.60774251\n",
      "Iteration 2263, loss = 17363.49145148\n",
      "Iteration 2264, loss = 17250.91606584\n",
      "Iteration 2265, loss = 17102.11263629\n",
      "Iteration 2266, loss = 17026.45627212\n",
      "Iteration 2267, loss = 17002.41431621\n",
      "Iteration 2268, loss = 16938.29049789\n",
      "Iteration 2269, loss = 16823.30044626\n",
      "Iteration 2270, loss = 16719.78665982\n",
      "Iteration 2271, loss = 16665.36197047\n",
      "Iteration 2272, loss = 16619.10845818\n",
      "Iteration 2273, loss = 16536.98737408\n",
      "Iteration 2274, loss = 16435.96218894\n",
      "Iteration 2275, loss = 16358.26449264\n",
      "Iteration 2276, loss = 16304.52052546\n",
      "Iteration 2277, loss = 16242.70391033\n",
      "Iteration 2278, loss = 16158.31433882\n",
      "Iteration 2279, loss = 16072.68677760\n",
      "Iteration 2280, loss = 16004.89722126\n",
      "Iteration 2281, loss = 15946.08558775\n",
      "Iteration 2282, loss = 15877.84358158\n",
      "Iteration 2283, loss = 15798.43930078\n",
      "Iteration 2284, loss = 15722.11031856\n",
      "Iteration 2285, loss = 15657.17780318\n",
      "Iteration 2286, loss = 15595.54877604\n",
      "Iteration 2287, loss = 15526.69372455\n",
      "Iteration 2288, loss = 15451.74516289\n",
      "Iteration 2289, loss = 15380.24620416\n",
      "Iteration 2290, loss = 15315.86438877\n",
      "Iteration 2291, loss = 15253.09690475\n",
      "Iteration 2292, loss = 15185.64434397\n",
      "Iteration 2293, loss = 15114.59456663\n",
      "Iteration 2294, loss = 15045.96293733\n",
      "Iteration 2295, loss = 14981.94619947\n",
      "Iteration 2296, loss = 14918.82915089\n",
      "Iteration 2297, loss = 14852.87359312\n",
      "Iteration 2298, loss = 14785.01048342\n",
      "Iteration 2299, loss = 14718.72235646\n",
      "Iteration 2300, loss = 14655.24122347\n",
      "Iteration 2301, loss = 14592.62227193\n",
      "Iteration 2302, loss = 14528.58626027\n",
      "Iteration 2303, loss = 14463.33896224\n",
      "Iteration 2304, loss = 14398.61810717\n",
      "Iteration 2305, loss = 14335.56817356\n",
      "Iteration 2306, loss = 14273.60566768\n",
      "Iteration 2307, loss = 14211.51182625\n",
      "Iteration 2308, loss = 14148.68361773\n",
      "Iteration 2309, loss = 14085.70216027\n",
      "Iteration 2310, loss = 14023.56733457\n",
      "Iteration 2311, loss = 13962.45689351\n",
      "Iteration 2312, loss = 13901.77717097\n",
      "Iteration 2313, loss = 13841.12905856\n",
      "Iteration 2314, loss = 13780.34638281\n",
      "Iteration 2315, loss = 13719.42751445\n",
      "Iteration 2316, loss = 13658.89007934\n",
      "Iteration 2317, loss = 13599.16001398\n",
      "Iteration 2318, loss = 13540.02105425\n",
      "Iteration 2319, loss = 13480.97018933\n",
      "Iteration 2320, loss = 13421.77321579\n",
      "Iteration 2321, loss = 13362.63515156\n",
      "Iteration 2322, loss = 13303.90535790\n",
      "Iteration 2323, loss = 13245.71617785\n",
      "Iteration 2324, loss = 13187.97723709\n",
      "Iteration 2325, loss = 13130.38423480\n",
      "Iteration 2326, loss = 13072.82480927\n",
      "Iteration 2327, loss = 13015.48521531\n",
      "Iteration 2328, loss = 12958.47005665\n",
      "Iteration 2329, loss = 12901.68537975\n",
      "Iteration 2330, loss = 12845.21833955\n",
      "Iteration 2331, loss = 12789.07602562\n",
      "Iteration 2332, loss = 12733.19281319\n",
      "Iteration 2333, loss = 12677.50019624\n",
      "Iteration 2334, loss = 12622.02665853\n",
      "Iteration 2335, loss = 12566.80146865\n",
      "Iteration 2336, loss = 12511.81749712\n",
      "Iteration 2337, loss = 12457.10412560\n",
      "Iteration 2338, loss = 12402.76298797\n",
      "Iteration 2339, loss = 12348.61491609\n",
      "Iteration 2340, loss = 12294.69861245\n",
      "Iteration 2341, loss = 12240.94891433\n",
      "Iteration 2342, loss = 12187.38827701\n",
      "Iteration 2343, loss = 12134.06163892\n",
      "Iteration 2344, loss = 12081.02483641\n",
      "Iteration 2345, loss = 12028.25521727\n",
      "Iteration 2346, loss = 11975.69119361\n",
      "Iteration 2347, loss = 11923.34210589\n",
      "Iteration 2348, loss = 11871.18261403\n",
      "Iteration 2349, loss = 11819.31670646\n",
      "Iteration 2350, loss = 11767.71221624\n",
      "Iteration 2351, loss = 11716.35558848\n",
      "Iteration 2352, loss = 11665.27593141\n",
      "Iteration 2353, loss = 11614.42888498\n",
      "Iteration 2354, loss = 11563.83357185\n",
      "Iteration 2355, loss = 11513.47464965\n",
      "Iteration 2356, loss = 11463.33087063\n",
      "Iteration 2357, loss = 11413.38754562\n",
      "Iteration 2358, loss = 11363.66500804\n",
      "Iteration 2359, loss = 11314.16646352\n",
      "Iteration 2360, loss = 11264.89665365\n",
      "Iteration 2361, loss = 11215.87252575\n",
      "Iteration 2362, loss = 11167.12749757\n",
      "Iteration 2363, loss = 11118.58994367\n",
      "Iteration 2364, loss = 11070.25659864\n",
      "Iteration 2365, loss = 11022.12914344\n",
      "Iteration 2366, loss = 10974.23596725\n",
      "Iteration 2367, loss = 10926.51745832\n",
      "Iteration 2368, loss = 10879.02863905\n",
      "Iteration 2369, loss = 10831.74650202\n",
      "Iteration 2370, loss = 10784.67245949\n",
      "Iteration 2371, loss = 10737.80742362\n",
      "Iteration 2372, loss = 10691.15182347\n",
      "Iteration 2373, loss = 10644.70442964\n",
      "Iteration 2374, loss = 10598.46341776\n",
      "Iteration 2375, loss = 10552.42641634\n",
      "Iteration 2376, loss = 10506.59141553\n",
      "Iteration 2377, loss = 10460.95311188\n",
      "Iteration 2378, loss = 10415.51324203\n",
      "Iteration 2379, loss = 10370.27095089\n",
      "Iteration 2380, loss = 10325.23666634\n",
      "Iteration 2381, loss = 10280.43283166\n",
      "Iteration 2382, loss = 10235.83930971\n",
      "Iteration 2383, loss = 10191.44318982\n",
      "Iteration 2384, loss = 10147.24772924\n",
      "Iteration 2385, loss = 10103.25847047\n",
      "Iteration 2386, loss = 10059.46276792\n",
      "Iteration 2387, loss = 10015.85931166\n",
      "Iteration 2388, loss = 9972.44693625\n",
      "Iteration 2389, loss = 9929.22485111\n",
      "Iteration 2390, loss = 9886.19238065\n",
      "Iteration 2391, loss = 9843.34848207\n",
      "Iteration 2392, loss = 9800.69226407\n",
      "Iteration 2393, loss = 9758.24380771\n",
      "Iteration 2394, loss = 9715.99993825\n",
      "Iteration 2395, loss = 9673.94131447\n",
      "Iteration 2396, loss = 9632.06649139\n",
      "Iteration 2397, loss = 9590.40562715\n",
      "Iteration 2398, loss = 9548.93312456\n",
      "Iteration 2399, loss = 9507.64915056\n",
      "Iteration 2400, loss = 9466.55572706\n",
      "Iteration 2401, loss = 9425.66971768\n",
      "Iteration 2402, loss = 9384.99152386\n",
      "Iteration 2403, loss = 9344.54473255\n",
      "Iteration 2404, loss = 9304.34161714\n",
      "Iteration 2405, loss = 9264.41239879\n",
      "Iteration 2406, loss = 9224.81409254\n",
      "Iteration 2407, loss = 9185.64458063\n",
      "Iteration 2408, loss = 9147.06520115\n",
      "Iteration 2409, loss = 9109.39478640\n",
      "Iteration 2410, loss = 9073.21601781\n",
      "Iteration 2411, loss = 9039.52479887\n",
      "Iteration 2412, loss = 9009.54310246\n",
      "Iteration 2413, loss = 8985.83998389\n",
      "Iteration 2414, loss = 8972.54520375\n",
      "Iteration 2415, loss = 8979.15685231\n",
      "Iteration 2416, loss = 9016.64748372\n",
      "Iteration 2417, loss = 9106.94376711\n",
      "Iteration 2418, loss = 9254.71905199\n",
      "Iteration 2419, loss = 9470.33259219\n",
      "Iteration 2420, loss = 9641.02461819\n",
      "Iteration 2421, loss = 9672.75870046\n",
      "Iteration 2422, loss = 9364.86687113\n",
      "Iteration 2423, loss = 8894.53876004\n",
      "Iteration 2424, loss = 8557.94675228\n",
      "Iteration 2425, loss = 8567.16127382\n",
      "Iteration 2426, loss = 8784.38164201\n",
      "Iteration 2427, loss = 8894.35458713\n",
      "Iteration 2428, loss = 8751.18294229\n",
      "Iteration 2429, loss = 8464.73174448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2430, loss = 8319.22066151\n",
      "Iteration 2431, loss = 8388.58461097\n",
      "Iteration 2432, loss = 8492.98093761\n",
      "Iteration 2433, loss = 8453.05752776\n",
      "Iteration 2434, loss = 8275.79699033\n",
      "Iteration 2435, loss = 8145.72438122\n",
      "Iteration 2436, loss = 8153.11906861\n",
      "Iteration 2437, loss = 8208.29988057\n",
      "Iteration 2438, loss = 8184.73070009\n",
      "Iteration 2439, loss = 8071.31213299\n",
      "Iteration 2440, loss = 7974.96682717\n",
      "Iteration 2441, loss = 7960.20900577\n",
      "Iteration 2442, loss = 7981.01392222\n",
      "Iteration 2443, loss = 7958.19251080\n",
      "Iteration 2444, loss = 7879.59801384\n",
      "Iteration 2445, loss = 7806.76313370\n",
      "Iteration 2446, loss = 7783.03824687\n",
      "Iteration 2447, loss = 7784.03090986\n",
      "Iteration 2448, loss = 7760.06113480\n",
      "Iteration 2449, loss = 7700.83243485\n",
      "Iteration 2450, loss = 7642.74593406\n",
      "Iteration 2451, loss = 7613.08433265\n",
      "Iteration 2452, loss = 7600.53654758\n",
      "Iteration 2453, loss = 7576.12931291\n",
      "Iteration 2454, loss = 7530.69158635\n",
      "Iteration 2455, loss = 7482.59786960\n",
      "Iteration 2456, loss = 7449.60374551\n",
      "Iteration 2457, loss = 7428.86544588\n",
      "Iteration 2458, loss = 7404.81083696\n",
      "Iteration 2459, loss = 7368.17642423\n",
      "Iteration 2460, loss = 7326.46028870\n",
      "Iteration 2461, loss = 7291.87747780\n",
      "Iteration 2462, loss = 7266.54389433\n",
      "Iteration 2463, loss = 7242.32851110\n",
      "Iteration 2464, loss = 7210.82999029\n",
      "Iteration 2465, loss = 7174.10921626\n",
      "Iteration 2466, loss = 7139.31677593\n",
      "Iteration 2467, loss = 7110.62545376\n",
      "Iteration 2468, loss = 7085.09027447\n",
      "Iteration 2469, loss = 7056.88119335\n",
      "Iteration 2470, loss = 7024.43285227\n",
      "Iteration 2471, loss = 6990.98086376\n",
      "Iteration 2472, loss = 6960.35300597\n",
      "Iteration 2473, loss = 6932.76251482\n",
      "Iteration 2474, loss = 6905.56975899\n",
      "Iteration 2475, loss = 6876.65021985\n",
      "Iteration 2476, loss = 6845.93669055\n",
      "Iteration 2477, loss = 6815.24877118\n",
      "Iteration 2478, loss = 6786.23622680\n",
      "Iteration 2479, loss = 6758.64899894\n",
      "Iteration 2480, loss = 6731.13732287\n",
      "Iteration 2481, loss = 6702.66942670\n",
      "Iteration 2482, loss = 6673.56531108\n",
      "Iteration 2483, loss = 6644.69042630\n",
      "Iteration 2484, loss = 6616.67923509\n",
      "Iteration 2485, loss = 6589.37914779\n",
      "Iteration 2486, loss = 6562.11972769\n",
      "Iteration 2487, loss = 6534.57273553\n",
      "Iteration 2488, loss = 6506.74876401\n",
      "Iteration 2489, loss = 6478.98391518\n",
      "Iteration 2490, loss = 6451.70535984\n",
      "Iteration 2491, loss = 6424.99999659\n",
      "Iteration 2492, loss = 6398.48541230\n",
      "Iteration 2493, loss = 6371.83675856\n",
      "Iteration 2494, loss = 6344.98448034\n",
      "Iteration 2495, loss = 6318.13540244\n",
      "Iteration 2496, loss = 6291.55652683\n",
      "Iteration 2497, loss = 6265.36028674\n",
      "Iteration 2498, loss = 6239.45187733\n",
      "Iteration 2499, loss = 6213.62031576\n",
      "Iteration 2500, loss = 6187.74261537\n",
      "Iteration 2501, loss = 6161.78975453\n",
      "Iteration 2502, loss = 6135.91075841\n",
      "Iteration 2503, loss = 6110.24393045\n",
      "Iteration 2504, loss = 6084.84402858\n",
      "Iteration 2505, loss = 6059.63873232\n",
      "Iteration 2506, loss = 6034.51138278\n",
      "Iteration 2507, loss = 6009.38877005\n",
      "Iteration 2508, loss = 5984.28882003\n",
      "Iteration 2509, loss = 5959.29038487\n",
      "Iteration 2510, loss = 5934.46247994\n",
      "Iteration 2511, loss = 5909.81990570\n",
      "Iteration 2512, loss = 5885.35163981\n",
      "Iteration 2513, loss = 5860.98282457\n",
      "Iteration 2514, loss = 5836.65048607\n",
      "Iteration 2515, loss = 5812.36692596\n",
      "Iteration 2516, loss = 5788.18467499\n",
      "Iteration 2517, loss = 5764.16613056\n",
      "Iteration 2518, loss = 5740.26462224\n",
      "Iteration 2519, loss = 5716.48813308\n",
      "Iteration 2520, loss = 5692.83099381\n",
      "Iteration 2521, loss = 5669.27788531\n",
      "Iteration 2522, loss = 5645.81023604\n",
      "Iteration 2523, loss = 5622.42482345\n",
      "Iteration 2524, loss = 5599.12902717\n",
      "Iteration 2525, loss = 5575.93014950\n",
      "Iteration 2526, loss = 5552.83429031\n",
      "Iteration 2527, loss = 5529.88647953\n",
      "Iteration 2528, loss = 5507.05698315\n",
      "Iteration 2529, loss = 5484.33111343\n",
      "Iteration 2530, loss = 5461.69938766\n",
      "Iteration 2531, loss = 5439.15178500\n",
      "Iteration 2532, loss = 5416.68556723\n",
      "Iteration 2533, loss = 5394.35103020\n",
      "Iteration 2534, loss = 5372.11123339\n",
      "Iteration 2535, loss = 5349.95894882\n",
      "Iteration 2536, loss = 5327.90164027\n",
      "Iteration 2537, loss = 5305.94311093\n",
      "Iteration 2538, loss = 5284.08361660\n",
      "Iteration 2539, loss = 5262.32862985\n",
      "Iteration 2540, loss = 5240.67668227\n",
      "Iteration 2541, loss = 5219.11858349\n",
      "Iteration 2542, loss = 5197.71070384\n",
      "Iteration 2543, loss = 5176.39680484\n",
      "Iteration 2544, loss = 5155.11779812\n",
      "Iteration 2545, loss = 5134.01021357\n",
      "Iteration 2546, loss = 5112.97831896\n",
      "Iteration 2547, loss = 5092.01685452\n",
      "Iteration 2548, loss = 5071.25478351\n",
      "Iteration 2549, loss = 5050.52435129\n",
      "Iteration 2550, loss = 5029.83376373\n",
      "Iteration 2551, loss = 5009.26961495\n",
      "Iteration 2552, loss = 4988.83442563\n",
      "Iteration 2553, loss = 4968.44919087\n",
      "Iteration 2554, loss = 4948.12819318\n",
      "Iteration 2555, loss = 4927.99067269\n",
      "Iteration 2556, loss = 4907.90131035\n",
      "Iteration 2557, loss = 4887.84649967\n",
      "Iteration 2558, loss = 4867.89104512\n",
      "Iteration 2559, loss = 4848.09052329\n",
      "Iteration 2560, loss = 4828.36073359\n",
      "Iteration 2561, loss = 4808.70340625\n",
      "Iteration 2562, loss = 4789.13183402\n",
      "Iteration 2563, loss = 4769.77764781\n",
      "Iteration 2564, loss = 4750.51548008\n",
      "Iteration 2565, loss = 4731.28453742\n",
      "Iteration 2566, loss = 4712.19487429\n",
      "Iteration 2567, loss = 4693.29698420\n",
      "Iteration 2568, loss = 4674.55633005\n",
      "Iteration 2569, loss = 4655.97577643\n",
      "Iteration 2570, loss = 4637.47557669\n",
      "Iteration 2571, loss = 4619.26821433\n",
      "Iteration 2572, loss = 4601.17807293\n",
      "Iteration 2573, loss = 4583.24861830\n",
      "Iteration 2574, loss = 4565.49559024\n",
      "Iteration 2575, loss = 4548.09185963\n",
      "Iteration 2576, loss = 4530.97064208\n",
      "Iteration 2577, loss = 4514.39435767\n",
      "Iteration 2578, loss = 4498.41254759\n",
      "Iteration 2579, loss = 4483.19202248\n",
      "Iteration 2580, loss = 4469.31002797\n",
      "Iteration 2581, loss = 4457.24485645\n",
      "Iteration 2582, loss = 4447.13433564\n",
      "Iteration 2583, loss = 4439.89430958\n",
      "Iteration 2584, loss = 4434.06084533\n",
      "Iteration 2585, loss = 4436.34172370\n",
      "Iteration 2586, loss = 4442.13715019\n",
      "Iteration 2587, loss = 4464.00390605\n",
      "Iteration 2588, loss = 4491.49474973\n",
      "Iteration 2589, loss = 4540.56615902\n",
      "Iteration 2590, loss = 4584.34855922\n",
      "Iteration 2591, loss = 4637.00178316\n",
      "Iteration 2592, loss = 4638.37687051\n",
      "Iteration 2593, loss = 4609.98139259\n",
      "Iteration 2594, loss = 4502.88209461\n",
      "Iteration 2595, loss = 4375.00701759\n",
      "Iteration 2596, loss = 4246.59430441\n",
      "Iteration 2597, loss = 4168.37452330\n",
      "Iteration 2598, loss = 4156.43293679\n",
      "Iteration 2599, loss = 4190.40775202\n",
      "Iteration 2600, loss = 4231.68491952\n",
      "Iteration 2601, loss = 4242.68382665\n",
      "Iteration 2602, loss = 4212.45971850\n",
      "Iteration 2603, loss = 4149.41803821\n",
      "Iteration 2604, loss = 4082.03602720\n",
      "Iteration 2605, loss = 4035.97234418\n",
      "Iteration 2606, loss = 4022.21264879\n",
      "Iteration 2607, loss = 4030.79443097\n",
      "Iteration 2608, loss = 4041.44208568\n",
      "Iteration 2609, loss = 4037.65243100\n",
      "Iteration 2610, loss = 4013.48522237\n",
      "Iteration 2611, loss = 3975.84640882\n",
      "Iteration 2612, loss = 3937.38029629\n",
      "Iteration 2613, loss = 3909.29528248\n",
      "Iteration 2614, loss = 3894.90208724\n",
      "Iteration 2615, loss = 3890.20768638\n",
      "Iteration 2616, loss = 3886.86684713\n",
      "Iteration 2617, loss = 3877.49667202\n",
      "Iteration 2618, loss = 3859.77680638\n",
      "Iteration 2619, loss = 3835.61904701\n",
      "Iteration 2620, loss = 3810.57619395\n",
      "Iteration 2621, loss = 3789.05246443\n",
      "Iteration 2622, loss = 3773.30156397\n",
      "Iteration 2623, loss = 3762.35910942\n",
      "Iteration 2624, loss = 3753.08675403\n",
      "Iteration 2625, loss = 3742.19437976\n",
      "Iteration 2626, loss = 3728.02804870\n",
      "Iteration 2627, loss = 3710.72098915\n",
      "Iteration 2628, loss = 3692.03335188\n",
      "Iteration 2629, loss = 3673.90407785\n",
      "Iteration 2630, loss = 3657.63701966\n",
      "Iteration 2631, loss = 3643.52648888\n",
      "Iteration 2632, loss = 3631.01336231\n",
      "Iteration 2633, loss = 3619.15823485\n",
      "Iteration 2634, loss = 3607.01181774\n",
      "Iteration 2635, loss = 3593.86316584\n",
      "Iteration 2636, loss = 3579.49869310\n",
      "Iteration 2637, loss = 3563.75610564\n",
      "Iteration 2638, loss = 3548.06252674\n",
      "Iteration 2639, loss = 3532.98574419\n",
      "Iteration 2640, loss = 3518.77978130\n",
      "Iteration 2641, loss = 3505.39180138\n",
      "Iteration 2642, loss = 3492.57682544\n",
      "Iteration 2643, loss = 3479.95345684\n",
      "Iteration 2644, loss = 3467.05143744\n",
      "Iteration 2645, loss = 3453.73960591\n",
      "Iteration 2646, loss = 3440.12777973\n",
      "Iteration 2647, loss = 3426.28909458\n",
      "Iteration 2648, loss = 3412.67310184\n",
      "Iteration 2649, loss = 3399.30823038\n",
      "Iteration 2650, loss = 3386.15156002\n",
      "Iteration 2651, loss = 3373.19877013\n",
      "Iteration 2652, loss = 3360.42384637\n",
      "Iteration 2653, loss = 3347.77590259\n",
      "Iteration 2654, loss = 3335.20416112\n",
      "Iteration 2655, loss = 3322.67620750\n",
      "Iteration 2656, loss = 3310.19981889\n",
      "Iteration 2657, loss = 3297.74962556\n",
      "Iteration 2658, loss = 3285.32186995\n",
      "Iteration 2659, loss = 3272.97338467\n",
      "Iteration 2660, loss = 3260.68550711\n",
      "Iteration 2661, loss = 3248.41229462\n",
      "Iteration 2662, loss = 3236.14747768\n",
      "Iteration 2663, loss = 3223.91034121\n",
      "Iteration 2664, loss = 3211.72280480\n",
      "Iteration 2665, loss = 3199.60156960\n",
      "Iteration 2666, loss = 3187.57856367\n",
      "Iteration 2667, loss = 3175.60681690\n",
      "Iteration 2668, loss = 3163.66409361\n",
      "Iteration 2669, loss = 3151.74673088\n",
      "Iteration 2670, loss = 3139.87726693\n",
      "Iteration 2671, loss = 3128.05707148\n",
      "Iteration 2672, loss = 3116.30865764\n",
      "Iteration 2673, loss = 3104.61616900\n",
      "Iteration 2674, loss = 3092.98344419\n",
      "Iteration 2675, loss = 3081.41389387\n",
      "Iteration 2676, loss = 3069.91675445\n",
      "Iteration 2677, loss = 3058.49828204\n",
      "Iteration 2678, loss = 3047.17201254\n",
      "Iteration 2679, loss = 3035.94506579\n",
      "Iteration 2680, loss = 3024.82631316\n",
      "Iteration 2681, loss = 3013.83647054\n",
      "Iteration 2682, loss = 3002.99916904\n",
      "Iteration 2683, loss = 2992.38038749\n",
      "Iteration 2684, loss = 2982.08642582\n",
      "Iteration 2685, loss = 2972.21804100\n",
      "Iteration 2686, loss = 2962.97715760\n",
      "Iteration 2687, loss = 2954.65197515\n",
      "Iteration 2688, loss = 2947.71428424\n",
      "Iteration 2689, loss = 2942.63080414\n",
      "Iteration 2690, loss = 2940.56340113\n",
      "Iteration 2691, loss = 2942.70873066\n",
      "Iteration 2692, loss = 2951.40470910\n",
      "Iteration 2693, loss = 2968.98637040\n",
      "Iteration 2694, loss = 3002.28873452\n",
      "Iteration 2695, loss = 3052.57915136\n",
      "Iteration 2696, loss = 3131.01010248\n",
      "Iteration 2697, loss = 3225.63473441\n",
      "Iteration 2698, loss = 3341.84605453\n",
      "Iteration 2699, loss = 3412.00847864\n",
      "Iteration 2700, loss = 3420.02444068\n",
      "Iteration 2701, loss = 3287.68055777\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#folosim MLP regressor pentru predictii\n",
    "#MLP Regressor pentru NN Multy Layer\n",
    "regr = MLPRegressor(solver='adam', hidden_layer_sizes=(200,100), max_iter=10000, verbose = 'true',activation='relu')\n",
    "\n",
    "#Antrenam modelul folosind setul de train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Facem predictii folosind setul de test\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-10,   5,   0,   0]),\n",
       " array([-11,   4,  -1,   0]),\n",
       " array([11512,   651,   400,    25]),\n",
       " array([6534,  336,  312,   19]),\n",
       " array([-7,  5,  0,  0]),\n",
       " array([35,  5, 19,  0]),\n",
       " array([5289,  257,  290,   17]),\n",
       " array([314, -22,  86,   0]),\n",
       " array([26,  5, 15,  0]),\n",
       " array([16,  5, 11,  0]),\n",
       " array([9645,  533,  367,   23]),\n",
       " array([8712,  474,  350,   22]),\n",
       " array([4045,  178,  268,   16]),\n",
       " array([21,  5, 13,  0]),\n",
       " array([-24,   0, -13,   0]),\n",
       " array([45,  5, 23,  0]),\n",
       " array([5600,  277,  295,   18]),\n",
       " array([2, 5, 5, 0]),\n",
       " array([23,  5, 14,  0]),\n",
       " array([7156,  375,  323,   20]),\n",
       " array([14,  5, 11,  0])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertim datele din float in int\n",
    "result_int = []\n",
    "for x in y_pred:\n",
    "    result_int.append(x.astype(int))\n",
    "\n",
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Folosim diferite scalere pentru a puteam face operatii de normalizare, standardizare si scalare\n",
    "std_scaler = StandardScaler() \n",
    "std_scaler2 = StandardScaler()\n",
    "minMaxScaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxScaler.fit(X_train)  \n",
    "X_train = minMaxScaler.transform(X_train)  \n",
    "\n",
    "#Normalizam si scalam setul de train\n",
    "std_scaler.fit(X_train)  \n",
    "X_train = std_scaler.transform(X_train) \n",
    "std_scaler2.fit(X_train)  \n",
    "X_train = std_scaler2.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizam si scalam setul de test\n",
    "minMaxScaler.fit(X_test) \n",
    "X_test = minMaxScaler.transform(X_test)  \n",
    "std_scaler.fit(X_test) \n",
    "X_test = std_scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalam si standardizam datele de test\n",
    "std_scaler2.fit(X_test) \n",
    "X_test = std_scaler2.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1629182.34781790\n",
      "Iteration 2, loss = 1629140.54172492\n",
      "Iteration 3, loss = 1629100.43913662\n",
      "Iteration 4, loss = 1629063.04530319\n",
      "Iteration 5, loss = 1629027.61051024\n",
      "Iteration 6, loss = 1628992.57344482\n",
      "Iteration 7, loss = 1628958.60501513\n",
      "Iteration 8, loss = 1628924.73022476\n",
      "Iteration 9, loss = 1628890.76451871\n",
      "Iteration 10, loss = 1628856.83331617\n",
      "Iteration 11, loss = 1628822.79809934\n",
      "Iteration 12, loss = 1628788.65935587\n",
      "Iteration 13, loss = 1628755.09967100\n",
      "Iteration 14, loss = 1628720.68760082\n",
      "Iteration 15, loss = 1628685.02576842\n",
      "Iteration 16, loss = 1628648.05195735\n",
      "Iteration 17, loss = 1628609.68811561\n",
      "Iteration 18, loss = 1628569.84957521\n",
      "Iteration 19, loss = 1628528.44927904\n",
      "Iteration 20, loss = 1628485.82883990\n",
      "Iteration 21, loss = 1628442.92059232\n",
      "Iteration 22, loss = 1628398.20160888\n",
      "Iteration 23, loss = 1628351.58933057\n",
      "Iteration 24, loss = 1628303.04838297\n",
      "Iteration 25, loss = 1628253.00711972\n",
      "Iteration 26, loss = 1628200.84137363\n",
      "Iteration 27, loss = 1628146.37827809\n",
      "Iteration 28, loss = 1628089.53050893\n",
      "Iteration 29, loss = 1628030.19793535\n",
      "Iteration 30, loss = 1627968.25077582\n",
      "Iteration 31, loss = 1627903.58019814\n",
      "Iteration 32, loss = 1627836.07198695\n",
      "Iteration 33, loss = 1627765.59642383\n",
      "Iteration 34, loss = 1627692.01074650\n",
      "Iteration 35, loss = 1627615.17116537\n",
      "Iteration 36, loss = 1627534.98922422\n",
      "Iteration 37, loss = 1627451.35827608\n",
      "Iteration 38, loss = 1627364.14449833\n",
      "Iteration 39, loss = 1627273.20556848\n",
      "Iteration 40, loss = 1627178.41079540\n",
      "Iteration 41, loss = 1627079.63259315\n",
      "Iteration 42, loss = 1626976.69666213\n",
      "Iteration 43, loss = 1626869.44271408\n",
      "Iteration 44, loss = 1626757.72695706\n",
      "Iteration 45, loss = 1626641.39845050\n",
      "Iteration 46, loss = 1626520.26349415\n",
      "Iteration 47, loss = 1626394.11069512\n",
      "Iteration 48, loss = 1626262.83136694\n",
      "Iteration 49, loss = 1626126.24625536\n",
      "Iteration 50, loss = 1625984.12102365\n",
      "Iteration 51, loss = 1625836.23256490\n",
      "Iteration 52, loss = 1625682.39937382\n",
      "Iteration 53, loss = 1625522.46113875\n",
      "Iteration 54, loss = 1625356.33427600\n",
      "Iteration 55, loss = 1625183.80298440\n",
      "Iteration 56, loss = 1625004.64103375\n",
      "Iteration 57, loss = 1624818.75192914\n",
      "Iteration 58, loss = 1624625.90735306\n",
      "Iteration 59, loss = 1624426.02242526\n",
      "Iteration 60, loss = 1624218.88032023\n",
      "Iteration 61, loss = 1624004.38424091\n",
      "Iteration 62, loss = 1623782.33904258\n",
      "Iteration 63, loss = 1623552.56925787\n",
      "Iteration 64, loss = 1623314.85373085\n",
      "Iteration 65, loss = 1623068.99352109\n",
      "Iteration 66, loss = 1622814.85202697\n",
      "Iteration 67, loss = 1622552.32863529\n",
      "Iteration 68, loss = 1622281.22009557\n",
      "Iteration 69, loss = 1622001.34544888\n",
      "Iteration 70, loss = 1621712.50677125\n",
      "Iteration 71, loss = 1621414.51268843\n",
      "Iteration 72, loss = 1621107.14233897\n",
      "Iteration 73, loss = 1620790.26364782\n",
      "Iteration 74, loss = 1620463.61761163\n",
      "Iteration 75, loss = 1620126.98941955\n",
      "Iteration 76, loss = 1619780.14480598\n",
      "Iteration 77, loss = 1619422.88339461\n",
      "Iteration 78, loss = 1619054.92223841\n",
      "Iteration 79, loss = 1618676.16923667\n",
      "Iteration 80, loss = 1618286.32958808\n",
      "Iteration 81, loss = 1617885.17322874\n",
      "Iteration 82, loss = 1617472.60022625\n",
      "Iteration 83, loss = 1617048.48749911\n",
      "Iteration 84, loss = 1616612.60958358\n",
      "Iteration 85, loss = 1616164.81569765\n",
      "Iteration 86, loss = 1615705.00200756\n",
      "Iteration 87, loss = 1615232.98323320\n",
      "Iteration 88, loss = 1614748.57687862\n",
      "Iteration 89, loss = 1614251.60210744\n",
      "Iteration 90, loss = 1613741.87535537\n",
      "Iteration 91, loss = 1613219.21654782\n",
      "Iteration 92, loss = 1612683.44694184\n",
      "Iteration 93, loss = 1612134.38287461\n",
      "Iteration 94, loss = 1611571.84106048\n",
      "Iteration 95, loss = 1610995.64313650\n",
      "Iteration 96, loss = 1610405.60701291\n",
      "Iteration 97, loss = 1609801.55489778\n",
      "Iteration 98, loss = 1609183.30627941\n",
      "Iteration 99, loss = 1608550.68500118\n",
      "Iteration 100, loss = 1607903.50933131\n",
      "Iteration 101, loss = 1607241.60823147\n",
      "Iteration 102, loss = 1606564.80714371\n",
      "Iteration 103, loss = 1605872.93530031\n",
      "Iteration 104, loss = 1605165.81370223\n",
      "Iteration 105, loss = 1604443.27115853\n",
      "Iteration 106, loss = 1603705.14637400\n",
      "Iteration 107, loss = 1602951.26524320\n",
      "Iteration 108, loss = 1602181.45721371\n",
      "Iteration 109, loss = 1601395.55417665\n",
      "Iteration 110, loss = 1600593.39761383\n",
      "Iteration 111, loss = 1599774.83018441\n",
      "Iteration 112, loss = 1598939.67562283\n",
      "Iteration 113, loss = 1598087.79318287\n",
      "Iteration 114, loss = 1597219.03251508\n",
      "Iteration 115, loss = 1596333.19676109\n",
      "Iteration 116, loss = 1595430.15530818\n",
      "Iteration 117, loss = 1594509.75757332\n",
      "Iteration 118, loss = 1593571.81443260\n",
      "Iteration 119, loss = 1592616.14293211\n",
      "Iteration 120, loss = 1591642.62490695\n",
      "Iteration 121, loss = 1590651.08464063\n",
      "Iteration 122, loss = 1589641.37346145\n",
      "Iteration 123, loss = 1588613.23890348\n",
      "Iteration 124, loss = 1587566.60819780\n",
      "Iteration 125, loss = 1586501.45700763\n",
      "Iteration 126, loss = 1585417.65767223\n",
      "Iteration 127, loss = 1584315.09098842\n",
      "Iteration 128, loss = 1583193.63877072\n",
      "Iteration 129, loss = 1582053.18006111\n",
      "Iteration 130, loss = 1580893.57514689\n",
      "Iteration 131, loss = 1579714.75804182\n",
      "Iteration 132, loss = 1578516.59956828\n",
      "Iteration 133, loss = 1577298.96810018\n",
      "Iteration 134, loss = 1576061.78043815\n",
      "Iteration 135, loss = 1574804.95914639\n",
      "Iteration 136, loss = 1573528.36537627\n",
      "Iteration 137, loss = 1572231.90408149\n",
      "Iteration 138, loss = 1570915.52166764\n",
      "Iteration 139, loss = 1569579.16903101\n",
      "Iteration 140, loss = 1568222.66024428\n",
      "Iteration 141, loss = 1566845.96167793\n",
      "Iteration 142, loss = 1565448.99770566\n",
      "Iteration 143, loss = 1564031.69525407\n",
      "Iteration 144, loss = 1562593.96178808\n",
      "Iteration 145, loss = 1561135.70679944\n",
      "Iteration 146, loss = 1559656.92291128\n",
      "Iteration 147, loss = 1558157.55403701\n",
      "Iteration 148, loss = 1556637.53459266\n",
      "Iteration 149, loss = 1555096.75845132\n",
      "Iteration 150, loss = 1553535.17109778\n",
      "Iteration 151, loss = 1551952.74871931\n",
      "Iteration 152, loss = 1550349.37358123\n",
      "Iteration 153, loss = 1548724.94420327\n",
      "Iteration 154, loss = 1547079.41538876\n",
      "Iteration 155, loss = 1545412.81004548\n",
      "Iteration 156, loss = 1543725.07504803\n",
      "Iteration 157, loss = 1542016.15525221\n",
      "Iteration 158, loss = 1540286.03538611\n",
      "Iteration 159, loss = 1538534.69181816\n",
      "Iteration 160, loss = 1536762.12804990\n",
      "Iteration 161, loss = 1534968.25726418\n",
      "Iteration 162, loss = 1533153.00787798\n",
      "Iteration 163, loss = 1531316.45269870\n",
      "Iteration 164, loss = 1529458.56285757\n",
      "Iteration 165, loss = 1527579.24066686\n",
      "Iteration 166, loss = 1525678.52682702\n",
      "Iteration 167, loss = 1523756.45275110\n",
      "Iteration 168, loss = 1521813.00817315\n",
      "Iteration 169, loss = 1519848.29253741\n",
      "Iteration 170, loss = 1517862.10984876\n",
      "Iteration 171, loss = 1515854.46525599\n",
      "Iteration 172, loss = 1513825.40857380\n",
      "Iteration 173, loss = 1511775.02108821\n",
      "Iteration 174, loss = 1509703.14124348\n",
      "Iteration 175, loss = 1507609.74590787\n",
      "Iteration 176, loss = 1505495.10862624\n",
      "Iteration 177, loss = 1503359.18195830\n",
      "Iteration 178, loss = 1501201.79485986\n",
      "Iteration 179, loss = 1499023.05866952\n",
      "Iteration 180, loss = 1496822.81404513\n",
      "Iteration 181, loss = 1494601.12215513\n",
      "Iteration 182, loss = 1492357.93740034\n",
      "Iteration 183, loss = 1490093.27504185\n",
      "Iteration 184, loss = 1487807.17509433\n",
      "Iteration 185, loss = 1485499.37924144\n",
      "Iteration 186, loss = 1483170.16526322\n",
      "Iteration 187, loss = 1480819.65226682\n",
      "Iteration 188, loss = 1478447.51400888\n",
      "Iteration 189, loss = 1476053.63630903\n",
      "Iteration 190, loss = 1473638.07939994\n",
      "Iteration 191, loss = 1471201.00502165\n",
      "Iteration 192, loss = 1468742.01967062\n",
      "Iteration 193, loss = 1466260.76053105\n",
      "Iteration 194, loss = 1463757.76722872\n",
      "Iteration 195, loss = 1461232.90219977\n",
      "Iteration 196, loss = 1458685.94719590\n",
      "Iteration 197, loss = 1456117.02586217\n",
      "Iteration 198, loss = 1453525.95116473\n",
      "Iteration 199, loss = 1450912.36230000\n",
      "Iteration 200, loss = 1448276.14514875\n",
      "Iteration 201, loss = 1445616.91401559\n",
      "Iteration 202, loss = 1442934.39910906\n",
      "Iteration 203, loss = 1440228.42253758\n",
      "Iteration 204, loss = 1437498.95806172\n",
      "Iteration 205, loss = 1434745.89951557\n",
      "Iteration 206, loss = 1431968.83771120\n",
      "Iteration 207, loss = 1429167.66644475\n",
      "Iteration 208, loss = 1426342.28363249\n",
      "Iteration 209, loss = 1423492.80812746\n",
      "Iteration 210, loss = 1420618.93042903\n",
      "Iteration 211, loss = 1417720.48524908\n",
      "Iteration 212, loss = 1414797.60189223\n",
      "Iteration 213, loss = 1411850.10839911\n",
      "Iteration 214, loss = 1408877.66321676\n",
      "Iteration 215, loss = 1405880.33340904\n",
      "Iteration 216, loss = 1402858.14016225\n",
      "Iteration 217, loss = 1399810.50708247\n",
      "Iteration 218, loss = 1396737.89736071\n",
      "Iteration 219, loss = 1393640.59139944\n",
      "Iteration 220, loss = 1390517.57511872\n",
      "Iteration 221, loss = 1387369.87465188\n",
      "Iteration 222, loss = 1384196.80414015\n",
      "Iteration 223, loss = 1380998.37010177\n",
      "Iteration 224, loss = 1377774.89099913\n",
      "Iteration 225, loss = 1374526.24870433\n",
      "Iteration 226, loss = 1371252.29593142\n",
      "Iteration 227, loss = 1367953.09510304\n",
      "Iteration 228, loss = 1364629.31255577\n",
      "Iteration 229, loss = 1361280.28749990\n",
      "Iteration 230, loss = 1357906.17352297\n",
      "Iteration 231, loss = 1354507.60932663\n",
      "Iteration 232, loss = 1351084.57678965\n",
      "Iteration 233, loss = 1347636.21001452\n",
      "Iteration 234, loss = 1344163.39508711\n",
      "Iteration 235, loss = 1340665.88332283\n",
      "Iteration 236, loss = 1337143.10682260\n",
      "Iteration 237, loss = 1333595.38741801\n",
      "Iteration 238, loss = 1330022.95407310\n",
      "Iteration 239, loss = 1326425.38188651\n",
      "Iteration 240, loss = 1322803.15032507\n",
      "Iteration 241, loss = 1319156.39513224\n",
      "Iteration 242, loss = 1315485.22142872\n",
      "Iteration 243, loss = 1311789.28282641\n",
      "Iteration 244, loss = 1308068.88174392\n",
      "Iteration 245, loss = 1304324.62416088\n",
      "Iteration 246, loss = 1300556.18267050\n",
      "Iteration 247, loss = 1296763.62041014\n",
      "Iteration 248, loss = 1292948.14783099\n",
      "Iteration 249, loss = 1289109.23351046\n",
      "Iteration 250, loss = 1285246.76068295\n",
      "Iteration 251, loss = 1281361.90159034\n",
      "Iteration 252, loss = 1277454.12151685\n",
      "Iteration 253, loss = 1273524.10837611\n",
      "Iteration 254, loss = 1269571.38208744\n",
      "Iteration 255, loss = 1265596.81283269\n",
      "Iteration 256, loss = 1261600.75021993\n",
      "Iteration 257, loss = 1257582.83281190\n",
      "Iteration 258, loss = 1253543.32984316\n",
      "Iteration 259, loss = 1249483.27257198\n",
      "Iteration 260, loss = 1245402.24640009\n",
      "Iteration 261, loss = 1241300.61092747\n",
      "Iteration 262, loss = 1237179.54638344\n",
      "Iteration 263, loss = 1233038.03338444\n",
      "Iteration 264, loss = 1228876.79222953\n",
      "Iteration 265, loss = 1224696.49787514\n",
      "Iteration 266, loss = 1220496.94502837\n",
      "Iteration 267, loss = 1216278.46262750\n",
      "Iteration 268, loss = 1212041.35685205\n",
      "Iteration 269, loss = 1207786.77381842\n",
      "Iteration 270, loss = 1203513.75558545\n",
      "Iteration 271, loss = 1199223.78434246\n",
      "Iteration 272, loss = 1194916.59035492\n",
      "Iteration 273, loss = 1190592.99358550\n",
      "Iteration 274, loss = 1186252.69930491\n",
      "Iteration 275, loss = 1181896.82787961\n",
      "Iteration 276, loss = 1177524.90693659\n",
      "Iteration 277, loss = 1173137.14342301\n",
      "Iteration 278, loss = 1168734.80057413\n",
      "Iteration 279, loss = 1164317.04034723\n",
      "Iteration 280, loss = 1159884.66925425\n",
      "Iteration 281, loss = 1155437.97029606\n",
      "Iteration 282, loss = 1150977.96735247\n",
      "Iteration 283, loss = 1146504.49806371\n",
      "Iteration 284, loss = 1142017.89095580\n",
      "Iteration 285, loss = 1137518.37840910\n",
      "Iteration 286, loss = 1133006.87777806\n",
      "Iteration 287, loss = 1128483.63087632\n",
      "Iteration 288, loss = 1123948.94966013\n",
      "Iteration 289, loss = 1119402.42978885\n",
      "Iteration 290, loss = 1114845.66411578\n",
      "Iteration 291, loss = 1110278.87849107\n",
      "Iteration 292, loss = 1105701.12173777\n",
      "Iteration 293, loss = 1101113.06409230\n",
      "Iteration 294, loss = 1096517.22260027\n",
      "Iteration 295, loss = 1091911.51566123\n",
      "Iteration 296, loss = 1087296.30671990\n",
      "Iteration 297, loss = 1082673.82733781\n",
      "Iteration 298, loss = 1078043.25559421\n",
      "Iteration 299, loss = 1073404.80114184\n",
      "Iteration 300, loss = 1068758.52897566\n",
      "Iteration 301, loss = 1064105.09330816\n",
      "Iteration 302, loss = 1059446.08747561\n",
      "Iteration 303, loss = 1054779.94096207\n",
      "Iteration 304, loss = 1050109.21186901\n",
      "Iteration 305, loss = 1045435.17295603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 306, loss = 1040756.03825872\n",
      "Iteration 307, loss = 1036070.96942539\n",
      "Iteration 308, loss = 1031381.84858961\n",
      "Iteration 309, loss = 1026690.12351587\n",
      "Iteration 310, loss = 1021993.41374983\n",
      "Iteration 311, loss = 1017294.23714613\n",
      "Iteration 312, loss = 1012592.33663566\n",
      "Iteration 313, loss = 1007886.74201246\n",
      "Iteration 314, loss = 1003178.23793704\n",
      "Iteration 315, loss = 998469.11357997\n",
      "Iteration 316, loss = 993755.55400012\n",
      "Iteration 317, loss = 989040.08765962\n",
      "Iteration 318, loss = 984323.62600821\n",
      "Iteration 319, loss = 979610.29490848\n",
      "Iteration 320, loss = 974896.52576920\n",
      "Iteration 321, loss = 970183.35960888\n",
      "Iteration 322, loss = 965473.02891276\n",
      "Iteration 323, loss = 960761.53802482\n",
      "Iteration 324, loss = 956054.19967165\n",
      "Iteration 325, loss = 951351.24240326\n",
      "Iteration 326, loss = 946651.56514410\n",
      "Iteration 327, loss = 941954.26504250\n",
      "Iteration 328, loss = 937261.17735914\n",
      "Iteration 329, loss = 932570.03893436\n",
      "Iteration 330, loss = 927884.01456448\n",
      "Iteration 331, loss = 923201.38150511\n",
      "Iteration 332, loss = 918524.64991205\n",
      "Iteration 333, loss = 913854.69948742\n",
      "Iteration 334, loss = 909191.26523597\n",
      "Iteration 335, loss = 904533.80324647\n",
      "Iteration 336, loss = 899885.72985762\n",
      "Iteration 337, loss = 895243.34611598\n",
      "Iteration 338, loss = 890609.45790779\n",
      "Iteration 339, loss = 885983.02613637\n",
      "Iteration 340, loss = 881362.57205967\n",
      "Iteration 341, loss = 876753.46277202\n",
      "Iteration 342, loss = 872152.85162681\n",
      "Iteration 343, loss = 867556.48585051\n",
      "Iteration 344, loss = 862973.97739686\n",
      "Iteration 345, loss = 858403.03061913\n",
      "Iteration 346, loss = 853843.09711031\n",
      "Iteration 347, loss = 849295.96156614\n",
      "Iteration 348, loss = 844758.38676971\n",
      "Iteration 349, loss = 840230.16137437\n",
      "Iteration 350, loss = 835716.39660549\n",
      "Iteration 351, loss = 831211.51170036\n",
      "Iteration 352, loss = 826718.14470940\n",
      "Iteration 353, loss = 822233.33245409\n",
      "Iteration 354, loss = 817762.10926390\n",
      "Iteration 355, loss = 813302.33186340\n",
      "Iteration 356, loss = 808851.41074359\n",
      "Iteration 357, loss = 804411.30927688\n",
      "Iteration 358, loss = 799980.75148385\n",
      "Iteration 359, loss = 795561.51736822\n",
      "Iteration 360, loss = 791159.50144856\n",
      "Iteration 361, loss = 786779.64695371\n",
      "Iteration 362, loss = 782415.28665276\n",
      "Iteration 363, loss = 778066.75610143\n",
      "Iteration 364, loss = 773734.45880815\n",
      "Iteration 365, loss = 769426.15020397\n",
      "Iteration 366, loss = 765132.61718683\n",
      "Iteration 367, loss = 760854.62175087\n",
      "Iteration 368, loss = 756592.95160899\n",
      "Iteration 369, loss = 752346.93869111\n",
      "Iteration 370, loss = 748118.07829487\n",
      "Iteration 371, loss = 743908.11939894\n",
      "Iteration 372, loss = 739715.08220768\n",
      "Iteration 373, loss = 735544.03406782\n",
      "Iteration 374, loss = 731394.50362093\n",
      "Iteration 375, loss = 727263.36567367\n",
      "Iteration 376, loss = 723151.95335502\n",
      "Iteration 377, loss = 719061.87422360\n",
      "Iteration 378, loss = 714993.95721572\n",
      "Iteration 379, loss = 710943.97182690\n",
      "Iteration 380, loss = 706916.33721915\n",
      "Iteration 381, loss = 702910.33055421\n",
      "Iteration 382, loss = 698927.20877130\n",
      "Iteration 383, loss = 694957.57519278\n",
      "Iteration 384, loss = 691017.01233397\n",
      "Iteration 385, loss = 687094.03508495\n",
      "Iteration 386, loss = 683186.38493771\n",
      "Iteration 387, loss = 679300.25645748\n",
      "Iteration 388, loss = 675436.77069128\n",
      "Iteration 389, loss = 671589.62536534\n",
      "Iteration 390, loss = 667759.55807866\n",
      "Iteration 391, loss = 663949.82712652\n",
      "Iteration 392, loss = 660160.43843590\n",
      "Iteration 393, loss = 656392.77572786\n",
      "Iteration 394, loss = 652660.23382791\n",
      "Iteration 395, loss = 648953.17720699\n",
      "Iteration 396, loss = 645269.12960860\n",
      "Iteration 397, loss = 641605.73845255\n",
      "Iteration 398, loss = 637963.70789135\n",
      "Iteration 399, loss = 634338.17303569\n",
      "Iteration 400, loss = 630739.62608900\n",
      "Iteration 401, loss = 627159.70250097\n",
      "Iteration 402, loss = 623595.62140621\n",
      "Iteration 403, loss = 620056.61995313\n",
      "Iteration 404, loss = 616547.84720831\n",
      "Iteration 405, loss = 613069.68279040\n",
      "Iteration 406, loss = 609615.57909998\n",
      "Iteration 407, loss = 606185.63765124\n",
      "Iteration 408, loss = 602776.13182099\n",
      "Iteration 409, loss = 599389.34727118\n",
      "Iteration 410, loss = 596026.47822653\n",
      "Iteration 411, loss = 592687.77704384\n",
      "Iteration 412, loss = 589372.64468263\n",
      "Iteration 413, loss = 586082.90385217\n",
      "Iteration 414, loss = 582819.87307469\n",
      "Iteration 415, loss = 579577.47470131\n",
      "Iteration 416, loss = 576364.64089351\n",
      "Iteration 417, loss = 573174.96018929\n",
      "Iteration 418, loss = 570008.64480605\n",
      "Iteration 419, loss = 566868.63815567\n",
      "Iteration 420, loss = 563751.49517342\n",
      "Iteration 421, loss = 560658.53421043\n",
      "Iteration 422, loss = 557587.33734902\n",
      "Iteration 423, loss = 554542.90073435\n",
      "Iteration 424, loss = 551525.66044406\n",
      "Iteration 425, loss = 548532.52066438\n",
      "Iteration 426, loss = 545568.77502969\n",
      "Iteration 427, loss = 542630.58191299\n",
      "Iteration 428, loss = 539715.83238466\n",
      "Iteration 429, loss = 536825.94166312\n",
      "Iteration 430, loss = 533956.26765300\n",
      "Iteration 431, loss = 531115.51427299\n",
      "Iteration 432, loss = 528296.61917506\n",
      "Iteration 433, loss = 525501.65788118\n",
      "Iteration 434, loss = 522732.26685414\n",
      "Iteration 435, loss = 519986.13366551\n",
      "Iteration 436, loss = 517263.99414274\n",
      "Iteration 437, loss = 514561.41958519\n",
      "Iteration 438, loss = 511884.35843811\n",
      "Iteration 439, loss = 509229.34759132\n",
      "Iteration 440, loss = 506595.10520296\n",
      "Iteration 441, loss = 503983.66370317\n",
      "Iteration 442, loss = 501395.77434194\n",
      "Iteration 443, loss = 498835.15729859\n",
      "Iteration 444, loss = 496296.44046636\n",
      "Iteration 445, loss = 493784.31032488\n",
      "Iteration 446, loss = 491298.07321678\n",
      "Iteration 447, loss = 488831.21119019\n",
      "Iteration 448, loss = 486381.87192059\n",
      "Iteration 449, loss = 483956.34287796\n",
      "Iteration 450, loss = 481557.18219086\n",
      "Iteration 451, loss = 479174.04975777\n",
      "Iteration 452, loss = 476812.87417925\n",
      "Iteration 453, loss = 474478.11045356\n",
      "Iteration 454, loss = 472160.73383199\n",
      "Iteration 455, loss = 469865.18953394\n",
      "Iteration 456, loss = 467587.63911259\n",
      "Iteration 457, loss = 465330.23859030\n",
      "Iteration 458, loss = 463096.50565214\n",
      "Iteration 459, loss = 460880.22807722\n",
      "Iteration 460, loss = 458683.53529210\n",
      "Iteration 461, loss = 456508.07206897\n",
      "Iteration 462, loss = 454356.10064952\n",
      "Iteration 463, loss = 452224.87749022\n",
      "Iteration 464, loss = 450114.00170636\n",
      "Iteration 465, loss = 448022.10057697\n",
      "Iteration 466, loss = 445950.64691400\n",
      "Iteration 467, loss = 443896.91030186\n",
      "Iteration 468, loss = 441861.49695478\n",
      "Iteration 469, loss = 439847.33135492\n",
      "Iteration 470, loss = 437849.44798474\n",
      "Iteration 471, loss = 435869.19740768\n",
      "Iteration 472, loss = 433911.37754572\n",
      "Iteration 473, loss = 431964.96916425\n",
      "Iteration 474, loss = 430038.09852279\n",
      "Iteration 475, loss = 428126.76907035\n",
      "Iteration 476, loss = 426233.22179689\n",
      "Iteration 477, loss = 424349.41169733\n",
      "Iteration 478, loss = 422482.44260680\n",
      "Iteration 479, loss = 420630.27420601\n",
      "Iteration 480, loss = 418786.52433675\n",
      "Iteration 481, loss = 416955.60595283\n",
      "Iteration 482, loss = 415136.58521237\n",
      "Iteration 483, loss = 413330.33775013\n",
      "Iteration 484, loss = 411534.64054678\n",
      "Iteration 485, loss = 409758.74828242\n",
      "Iteration 486, loss = 407996.32444705\n",
      "Iteration 487, loss = 406250.10386662\n",
      "Iteration 488, loss = 404518.96329483\n",
      "Iteration 489, loss = 402815.76828012\n",
      "Iteration 490, loss = 401132.56958805\n",
      "Iteration 491, loss = 399455.13526017\n",
      "Iteration 492, loss = 397785.64588521\n",
      "Iteration 493, loss = 396130.69864190\n",
      "Iteration 494, loss = 394492.95871252\n",
      "Iteration 495, loss = 392861.26325720\n",
      "Iteration 496, loss = 391240.28069781\n",
      "Iteration 497, loss = 389639.03614571\n",
      "Iteration 498, loss = 388048.08730635\n",
      "Iteration 499, loss = 386463.18451980\n",
      "Iteration 500, loss = 384893.40521619\n",
      "Iteration 501, loss = 383339.18525550\n",
      "Iteration 502, loss = 381798.81602625\n",
      "Iteration 503, loss = 380265.78156322\n",
      "Iteration 504, loss = 378746.88724651\n",
      "Iteration 505, loss = 377239.53556810\n",
      "Iteration 506, loss = 375742.68249633\n",
      "Iteration 507, loss = 374254.81157363\n",
      "Iteration 508, loss = 372783.28399740\n",
      "Iteration 509, loss = 371325.14154576\n",
      "Iteration 510, loss = 369876.05846327\n",
      "Iteration 511, loss = 368439.96940455\n",
      "Iteration 512, loss = 367013.54261693\n",
      "Iteration 513, loss = 365595.48004918\n",
      "Iteration 514, loss = 364188.65705778\n",
      "Iteration 515, loss = 362795.04543468\n",
      "Iteration 516, loss = 361405.56799231\n",
      "Iteration 517, loss = 360028.10538972\n",
      "Iteration 518, loss = 358667.27516835\n",
      "Iteration 519, loss = 357311.64238359\n",
      "Iteration 520, loss = 355963.22738610\n",
      "Iteration 521, loss = 354625.72625092\n",
      "Iteration 522, loss = 353303.54255764\n",
      "Iteration 523, loss = 351984.77997662\n",
      "Iteration 524, loss = 350671.53501197\n",
      "Iteration 525, loss = 349372.89053757\n",
      "Iteration 526, loss = 348081.21506958\n",
      "Iteration 527, loss = 346791.01667911\n",
      "Iteration 528, loss = 345513.37572459\n",
      "Iteration 529, loss = 344244.04071996\n",
      "Iteration 530, loss = 342975.27738978\n",
      "Iteration 531, loss = 341717.48068240\n",
      "Iteration 532, loss = 340466.98290161\n",
      "Iteration 533, loss = 339218.79882352\n",
      "Iteration 534, loss = 337977.25215694\n",
      "Iteration 535, loss = 336743.68811501\n",
      "Iteration 536, loss = 335511.27621499\n",
      "Iteration 537, loss = 334286.78651920\n",
      "Iteration 538, loss = 333064.91988082\n",
      "Iteration 539, loss = 331846.45200884\n",
      "Iteration 540, loss = 330634.30056479\n",
      "Iteration 541, loss = 329425.56473125\n",
      "Iteration 542, loss = 328218.54795843\n",
      "Iteration 543, loss = 327017.72203425\n",
      "Iteration 544, loss = 325822.24755149\n",
      "Iteration 545, loss = 324635.67769024\n",
      "Iteration 546, loss = 323468.26770689\n",
      "Iteration 547, loss = 322314.11941141\n",
      "Iteration 548, loss = 321171.25703338\n",
      "Iteration 549, loss = 320028.47769775\n",
      "Iteration 550, loss = 318887.49645882\n",
      "Iteration 551, loss = 317747.27161677\n",
      "Iteration 552, loss = 316609.81376868\n",
      "Iteration 553, loss = 315477.54940665\n",
      "Iteration 554, loss = 314348.20582933\n",
      "Iteration 555, loss = 313226.25982125\n",
      "Iteration 556, loss = 312114.69032842\n",
      "Iteration 557, loss = 311008.04586354\n",
      "Iteration 558, loss = 309906.10031542\n",
      "Iteration 559, loss = 308810.09595162\n",
      "Iteration 560, loss = 307726.22269294\n",
      "Iteration 561, loss = 306648.78517249\n",
      "Iteration 562, loss = 305574.25366016\n",
      "Iteration 563, loss = 304503.83303222\n",
      "Iteration 564, loss = 303440.97711325\n",
      "Iteration 565, loss = 302380.49900747\n",
      "Iteration 566, loss = 301329.28471756\n",
      "Iteration 567, loss = 300283.72414707\n",
      "Iteration 568, loss = 299238.96463770\n",
      "Iteration 569, loss = 298198.62020834\n",
      "Iteration 570, loss = 297165.48764067\n",
      "Iteration 571, loss = 296136.90951458\n",
      "Iteration 572, loss = 295112.20709878\n",
      "Iteration 573, loss = 294091.70615453\n",
      "Iteration 574, loss = 293078.42242772\n",
      "Iteration 575, loss = 292067.48814012\n",
      "Iteration 576, loss = 291060.96976852\n",
      "Iteration 577, loss = 290058.97724316\n",
      "Iteration 578, loss = 289062.21169753\n",
      "Iteration 579, loss = 288066.14566356\n",
      "Iteration 580, loss = 287075.50599710\n",
      "Iteration 581, loss = 286089.86705996\n",
      "Iteration 582, loss = 285102.09339927\n",
      "Iteration 583, loss = 284121.55330330\n",
      "Iteration 584, loss = 283145.72047000\n",
      "Iteration 585, loss = 282168.61422517\n",
      "Iteration 586, loss = 281197.62338312\n",
      "Iteration 587, loss = 280231.01858759\n",
      "Iteration 588, loss = 279268.92507724\n",
      "Iteration 589, loss = 278309.01635763\n",
      "Iteration 590, loss = 277352.69766086\n",
      "Iteration 591, loss = 276400.06018486\n",
      "Iteration 592, loss = 275449.23328129\n",
      "Iteration 593, loss = 274504.10226674\n",
      "Iteration 594, loss = 273565.14314166\n",
      "Iteration 595, loss = 272626.43458053\n",
      "Iteration 596, loss = 271691.35844240\n",
      "Iteration 597, loss = 270760.12488993\n",
      "Iteration 598, loss = 269833.90159806\n",
      "Iteration 599, loss = 268909.57891219\n",
      "Iteration 600, loss = 267987.93694665\n",
      "Iteration 601, loss = 267067.80140805\n",
      "Iteration 602, loss = 266151.44015312\n",
      "Iteration 603, loss = 265238.29491716\n",
      "Iteration 604, loss = 264328.68483853\n",
      "Iteration 605, loss = 263423.05797161\n",
      "Iteration 606, loss = 262519.13212467\n",
      "Iteration 607, loss = 261616.15810277\n",
      "Iteration 608, loss = 260719.83685170\n",
      "Iteration 609, loss = 259824.78245439\n",
      "Iteration 610, loss = 258933.11214060\n",
      "Iteration 611, loss = 258045.91979790\n",
      "Iteration 612, loss = 257160.71499756\n",
      "Iteration 613, loss = 256277.68060553\n",
      "Iteration 614, loss = 255396.36297713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 615, loss = 254519.14461291\n",
      "Iteration 616, loss = 253646.47665396\n",
      "Iteration 617, loss = 252773.22572530\n",
      "Iteration 618, loss = 251902.51510024\n",
      "Iteration 619, loss = 251037.78317008\n",
      "Iteration 620, loss = 250173.80942204\n",
      "Iteration 621, loss = 249310.70551519\n",
      "Iteration 622, loss = 248453.80882563\n",
      "Iteration 623, loss = 247602.19864970\n",
      "Iteration 624, loss = 246748.79267708\n",
      "Iteration 625, loss = 245898.75232964\n",
      "Iteration 626, loss = 245051.20168947\n",
      "Iteration 627, loss = 244208.27075871\n",
      "Iteration 628, loss = 243366.52798206\n",
      "Iteration 629, loss = 242525.54931447\n",
      "Iteration 630, loss = 241687.37959640\n",
      "Iteration 631, loss = 240856.82037142\n",
      "Iteration 632, loss = 240023.92026513\n",
      "Iteration 633, loss = 239189.81539326\n",
      "Iteration 634, loss = 238361.39140481\n",
      "Iteration 635, loss = 237539.27028142\n",
      "Iteration 636, loss = 236716.02896516\n",
      "Iteration 637, loss = 235893.47920023\n",
      "Iteration 638, loss = 235074.53401299\n",
      "Iteration 639, loss = 234258.95093529\n",
      "Iteration 640, loss = 233444.45798722\n",
      "Iteration 641, loss = 232633.70826306\n",
      "Iteration 642, loss = 231825.79081111\n",
      "Iteration 643, loss = 231019.54249926\n",
      "Iteration 644, loss = 230215.36509850\n",
      "Iteration 645, loss = 229414.88364086\n",
      "Iteration 646, loss = 228617.06141221\n",
      "Iteration 647, loss = 227820.21817950\n",
      "Iteration 648, loss = 227025.24495408\n",
      "Iteration 649, loss = 226233.49156418\n",
      "Iteration 650, loss = 225446.13357908\n",
      "Iteration 651, loss = 224656.72336982\n",
      "Iteration 652, loss = 223867.67729163\n",
      "Iteration 653, loss = 223086.37117965\n",
      "Iteration 654, loss = 222305.57760307\n",
      "Iteration 655, loss = 221526.38116115\n",
      "Iteration 656, loss = 220746.54919868\n",
      "Iteration 657, loss = 219968.12112617\n",
      "Iteration 658, loss = 219195.59202072\n",
      "Iteration 659, loss = 218425.70084675\n",
      "Iteration 660, loss = 217653.64176431\n",
      "Iteration 661, loss = 216884.73420618\n",
      "Iteration 662, loss = 216120.77491437\n",
      "Iteration 663, loss = 215358.38303914\n",
      "Iteration 664, loss = 214595.38424639\n",
      "Iteration 665, loss = 213835.73203942\n",
      "Iteration 666, loss = 213080.30803995\n",
      "Iteration 667, loss = 212324.54823778\n",
      "Iteration 668, loss = 211570.45019031\n",
      "Iteration 669, loss = 210820.05434045\n",
      "Iteration 670, loss = 210072.28081749\n",
      "Iteration 671, loss = 209326.65059098\n",
      "Iteration 672, loss = 208583.33269126\n",
      "Iteration 673, loss = 207841.31255053\n",
      "Iteration 674, loss = 207105.04261081\n",
      "Iteration 675, loss = 206370.45986069\n",
      "Iteration 676, loss = 205636.43334855\n",
      "Iteration 677, loss = 204906.21682270\n",
      "Iteration 678, loss = 204179.99027713\n",
      "Iteration 679, loss = 203453.74803305\n",
      "Iteration 680, loss = 202730.11020210\n",
      "Iteration 681, loss = 202009.50028868\n",
      "Iteration 682, loss = 201290.85125888\n",
      "Iteration 683, loss = 200573.18532050\n",
      "Iteration 684, loss = 199859.81561316\n",
      "Iteration 685, loss = 199147.83925259\n",
      "Iteration 686, loss = 198437.27294198\n",
      "Iteration 687, loss = 197729.32148070\n",
      "Iteration 688, loss = 197024.78544356\n",
      "Iteration 689, loss = 196321.69533515\n",
      "Iteration 690, loss = 195621.10905748\n",
      "Iteration 691, loss = 194921.77479732\n",
      "Iteration 692, loss = 194225.36766729\n",
      "Iteration 693, loss = 193531.10394162\n",
      "Iteration 694, loss = 192839.86194279\n",
      "Iteration 695, loss = 192149.91376813\n",
      "Iteration 696, loss = 191464.34119449\n",
      "Iteration 697, loss = 190782.09310036\n",
      "Iteration 698, loss = 190100.16836268\n",
      "Iteration 699, loss = 189420.29076696\n",
      "Iteration 700, loss = 188743.46292876\n",
      "Iteration 701, loss = 188069.37004173\n",
      "Iteration 702, loss = 187397.54264440\n",
      "Iteration 703, loss = 186728.37698119\n",
      "Iteration 704, loss = 186060.82202306\n",
      "Iteration 705, loss = 185396.24713506\n",
      "Iteration 706, loss = 184734.53846892\n",
      "Iteration 707, loss = 184073.57849185\n",
      "Iteration 708, loss = 183414.94935582\n",
      "Iteration 709, loss = 182758.21502920\n",
      "Iteration 710, loss = 182105.33295617\n",
      "Iteration 711, loss = 181453.37908457\n",
      "Iteration 712, loss = 180801.29208822\n",
      "Iteration 713, loss = 180152.97891393\n",
      "Iteration 714, loss = 179507.71108036\n",
      "Iteration 715, loss = 178863.19712690\n",
      "Iteration 716, loss = 178219.75310736\n",
      "Iteration 717, loss = 177578.37124543\n",
      "Iteration 718, loss = 176939.81050100\n",
      "Iteration 719, loss = 176303.29922964\n",
      "Iteration 720, loss = 175667.67320069\n",
      "Iteration 721, loss = 175032.63018621\n",
      "Iteration 722, loss = 174400.56088052\n",
      "Iteration 723, loss = 173771.52379414\n",
      "Iteration 724, loss = 173146.40516836\n",
      "Iteration 725, loss = 172519.99300488\n",
      "Iteration 726, loss = 171895.04028924\n",
      "Iteration 727, loss = 171274.76037156\n",
      "Iteration 728, loss = 170658.72375992\n",
      "Iteration 729, loss = 170043.45302488\n",
      "Iteration 730, loss = 169428.89384162\n",
      "Iteration 731, loss = 168817.96327359\n",
      "Iteration 732, loss = 168210.36863676\n",
      "Iteration 733, loss = 167604.32231152\n",
      "Iteration 734, loss = 167000.07559031\n",
      "Iteration 735, loss = 166398.12094359\n",
      "Iteration 736, loss = 165800.89623532\n",
      "Iteration 737, loss = 165202.41353415\n",
      "Iteration 738, loss = 164605.80886551\n",
      "Iteration 739, loss = 164012.72069468\n",
      "Iteration 740, loss = 163421.26306856\n",
      "Iteration 741, loss = 162832.07717826\n",
      "Iteration 742, loss = 162245.65727953\n",
      "Iteration 743, loss = 161661.49043270\n",
      "Iteration 744, loss = 161079.09773717\n",
      "Iteration 745, loss = 160496.95205045\n",
      "Iteration 746, loss = 159916.49503374\n",
      "Iteration 747, loss = 159339.44550382\n",
      "Iteration 748, loss = 158765.24635643\n",
      "Iteration 749, loss = 158192.17552238\n",
      "Iteration 750, loss = 157621.06158040\n",
      "Iteration 751, loss = 157052.07180585\n",
      "Iteration 752, loss = 156485.76991633\n",
      "Iteration 753, loss = 155921.37608899\n",
      "Iteration 754, loss = 155359.12458447\n",
      "Iteration 755, loss = 154799.80433727\n",
      "Iteration 756, loss = 154243.69601629\n",
      "Iteration 757, loss = 153689.54423180\n",
      "Iteration 758, loss = 153138.12881785\n",
      "Iteration 759, loss = 152587.74281694\n",
      "Iteration 760, loss = 152041.46818919\n",
      "Iteration 761, loss = 151498.09427523\n",
      "Iteration 762, loss = 150956.71351100\n",
      "Iteration 763, loss = 150415.94041401\n",
      "Iteration 764, loss = 149877.67497189\n",
      "Iteration 765, loss = 149341.42077405\n",
      "Iteration 766, loss = 148809.41706681\n",
      "Iteration 767, loss = 148278.61826792\n",
      "Iteration 768, loss = 147748.03798276\n",
      "Iteration 769, loss = 147220.91108385\n",
      "Iteration 770, loss = 146695.63983761\n",
      "Iteration 771, loss = 146173.15624617\n",
      "Iteration 772, loss = 145652.66430905\n",
      "Iteration 773, loss = 145133.75970569\n",
      "Iteration 774, loss = 144615.51654195\n",
      "Iteration 775, loss = 144101.29429148\n",
      "Iteration 776, loss = 143589.16842358\n",
      "Iteration 777, loss = 143079.59306798\n",
      "Iteration 778, loss = 142568.78450271\n",
      "Iteration 779, loss = 142060.41819232\n",
      "Iteration 780, loss = 141555.96974855\n",
      "Iteration 781, loss = 141053.16173755\n",
      "Iteration 782, loss = 140551.16268297\n",
      "Iteration 783, loss = 140051.93571033\n",
      "Iteration 784, loss = 139554.81879495\n",
      "Iteration 785, loss = 139062.52801694\n",
      "Iteration 786, loss = 138572.29620119\n",
      "Iteration 787, loss = 138083.43315894\n",
      "Iteration 788, loss = 137597.99594318\n",
      "Iteration 789, loss = 137115.30538892\n",
      "Iteration 790, loss = 136634.64795014\n",
      "Iteration 791, loss = 136154.24236278\n",
      "Iteration 792, loss = 135675.83643186\n",
      "Iteration 793, loss = 135201.37111373\n",
      "Iteration 794, loss = 134728.89641718\n",
      "Iteration 795, loss = 134257.61505225\n",
      "Iteration 796, loss = 133788.52091048\n",
      "Iteration 797, loss = 133321.46859998\n",
      "Iteration 798, loss = 132856.25108195\n",
      "Iteration 799, loss = 132393.40910326\n",
      "Iteration 800, loss = 131933.68816307\n",
      "Iteration 801, loss = 131473.71215281\n",
      "Iteration 802, loss = 131014.79479135\n",
      "Iteration 803, loss = 130559.25552445\n",
      "Iteration 804, loss = 130105.20198070\n",
      "Iteration 805, loss = 129653.86347420\n",
      "Iteration 806, loss = 129202.22846063\n",
      "Iteration 807, loss = 128752.55954543\n",
      "Iteration 808, loss = 128304.97599552\n",
      "Iteration 809, loss = 127858.71550129\n",
      "Iteration 810, loss = 127415.07976464\n",
      "Iteration 811, loss = 126973.34176901\n",
      "Iteration 812, loss = 126531.90703302\n",
      "Iteration 813, loss = 126094.53338807\n",
      "Iteration 814, loss = 125659.66374612\n",
      "Iteration 815, loss = 125228.95156227\n",
      "Iteration 816, loss = 124799.47015866\n",
      "Iteration 817, loss = 124371.51602947\n",
      "Iteration 818, loss = 123944.96741542\n",
      "Iteration 819, loss = 123519.82072607\n",
      "Iteration 820, loss = 123097.07013999\n",
      "Iteration 821, loss = 122674.79599489\n",
      "Iteration 822, loss = 122253.60906605\n",
      "Iteration 823, loss = 121834.99796667\n",
      "Iteration 824, loss = 121418.25630625\n",
      "Iteration 825, loss = 121002.35977367\n",
      "Iteration 826, loss = 120587.79795586\n",
      "Iteration 827, loss = 120175.41116047\n",
      "Iteration 828, loss = 119765.40711079\n",
      "Iteration 829, loss = 119356.61005476\n",
      "Iteration 830, loss = 118948.63931785\n",
      "Iteration 831, loss = 118541.59369252\n",
      "Iteration 832, loss = 118136.58711398\n",
      "Iteration 833, loss = 117733.84130470\n",
      "Iteration 834, loss = 117332.02115733\n",
      "Iteration 835, loss = 116930.04335059\n",
      "Iteration 836, loss = 116529.38421445\n",
      "Iteration 837, loss = 116130.61012808\n",
      "Iteration 838, loss = 115732.38262125\n",
      "Iteration 839, loss = 115336.52696392\n",
      "Iteration 840, loss = 114940.33627281\n",
      "Iteration 841, loss = 114546.00720451\n",
      "Iteration 842, loss = 114154.26376580\n",
      "Iteration 843, loss = 113764.42457908\n",
      "Iteration 844, loss = 113376.66000668\n",
      "Iteration 845, loss = 112990.16026381\n",
      "Iteration 846, loss = 112607.46219300\n",
      "Iteration 847, loss = 112225.84366714\n",
      "Iteration 848, loss = 111845.37627681\n",
      "Iteration 849, loss = 111465.87876668\n",
      "Iteration 850, loss = 111089.10295255\n",
      "Iteration 851, loss = 110714.04788437\n",
      "Iteration 852, loss = 110339.56338343\n",
      "Iteration 853, loss = 109966.61488234\n",
      "Iteration 854, loss = 109594.24674731\n",
      "Iteration 855, loss = 109224.18275904\n",
      "Iteration 856, loss = 108853.52159829\n",
      "Iteration 857, loss = 108485.29125185\n",
      "Iteration 858, loss = 108118.31315324\n",
      "Iteration 859, loss = 107752.88952183\n",
      "Iteration 860, loss = 107388.23497220\n",
      "Iteration 861, loss = 107025.13325777\n",
      "Iteration 862, loss = 106663.42455146\n",
      "Iteration 863, loss = 106301.88645023\n",
      "Iteration 864, loss = 105942.85257977\n",
      "Iteration 865, loss = 105583.75046262\n",
      "Iteration 866, loss = 105224.59088612\n",
      "Iteration 867, loss = 104866.86891366\n",
      "Iteration 868, loss = 104510.90086117\n",
      "Iteration 869, loss = 104155.89187711\n",
      "Iteration 870, loss = 103800.44516254\n",
      "Iteration 871, loss = 103446.06796217\n",
      "Iteration 872, loss = 103092.68060873\n",
      "Iteration 873, loss = 102740.53000092\n",
      "Iteration 874, loss = 102389.55881314\n",
      "Iteration 875, loss = 102041.36940166\n",
      "Iteration 876, loss = 101695.40095932\n",
      "Iteration 877, loss = 101351.18497623\n",
      "Iteration 878, loss = 101007.72968744\n",
      "Iteration 879, loss = 100665.49986212\n",
      "Iteration 880, loss = 100325.77925772\n",
      "Iteration 881, loss = 99987.30548446\n",
      "Iteration 882, loss = 99649.82600110\n",
      "Iteration 883, loss = 99312.53148015\n",
      "Iteration 884, loss = 98977.07152097\n",
      "Iteration 885, loss = 98643.78228752\n",
      "Iteration 886, loss = 98311.46438632\n",
      "Iteration 887, loss = 97980.46030300\n",
      "Iteration 888, loss = 97650.12306496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 889, loss = 97321.32209820\n",
      "Iteration 890, loss = 96993.45866633\n",
      "Iteration 891, loss = 96666.16855203\n",
      "Iteration 892, loss = 96338.85983510\n",
      "Iteration 893, loss = 96013.70969370\n",
      "Iteration 894, loss = 95690.44758861\n",
      "Iteration 895, loss = 95367.80189682\n",
      "Iteration 896, loss = 95046.46148570\n",
      "Iteration 897, loss = 94725.52486310\n",
      "Iteration 898, loss = 94405.87912073\n",
      "Iteration 899, loss = 94087.16549996\n",
      "Iteration 900, loss = 93768.48040944\n",
      "Iteration 901, loss = 93450.37334285\n",
      "Iteration 902, loss = 93133.58674799\n",
      "Iteration 903, loss = 92817.10049436\n",
      "Iteration 904, loss = 92500.22452725\n",
      "Iteration 905, loss = 92184.40956812\n",
      "Iteration 906, loss = 91869.62182308\n",
      "Iteration 907, loss = 91555.85537613\n",
      "Iteration 908, loss = 91242.91204853\n",
      "Iteration 909, loss = 90930.20273250\n",
      "Iteration 910, loss = 90616.97508850\n",
      "Iteration 911, loss = 90305.21464489\n",
      "Iteration 912, loss = 89994.52624135\n",
      "Iteration 913, loss = 89682.33249396\n",
      "Iteration 914, loss = 89371.59906995\n",
      "Iteration 915, loss = 89062.52909763\n",
      "Iteration 916, loss = 88754.33805023\n",
      "Iteration 917, loss = 88445.42711468\n",
      "Iteration 918, loss = 88137.17427935\n",
      "Iteration 919, loss = 87830.17422952\n",
      "Iteration 920, loss = 87524.16679367\n",
      "Iteration 921, loss = 87218.47760189\n",
      "Iteration 922, loss = 86913.51475400\n",
      "Iteration 923, loss = 86610.41207094\n",
      "Iteration 924, loss = 86307.82129681\n",
      "Iteration 925, loss = 86007.14358231\n",
      "Iteration 926, loss = 85709.90380017\n",
      "Iteration 927, loss = 85413.90305096\n",
      "Iteration 928, loss = 85122.65212631\n",
      "Iteration 929, loss = 84831.94565479\n",
      "Iteration 930, loss = 84540.43029320\n",
      "Iteration 931, loss = 84250.12093033\n",
      "Iteration 932, loss = 83961.17072040\n",
      "Iteration 933, loss = 83672.60827030\n",
      "Iteration 934, loss = 83385.80380830\n",
      "Iteration 935, loss = 83100.58718749\n",
      "Iteration 936, loss = 82816.78239801\n",
      "Iteration 937, loss = 82534.89831556\n",
      "Iteration 938, loss = 82253.06012489\n",
      "Iteration 939, loss = 81973.05628064\n",
      "Iteration 940, loss = 81693.48638128\n",
      "Iteration 941, loss = 81414.98331946\n",
      "Iteration 942, loss = 81138.11248120\n",
      "Iteration 943, loss = 80862.78592824\n",
      "Iteration 944, loss = 80587.46365773\n",
      "Iteration 945, loss = 80314.10224872\n",
      "Iteration 946, loss = 80041.99175069\n",
      "Iteration 947, loss = 79770.12357606\n",
      "Iteration 948, loss = 79499.48296664\n",
      "Iteration 949, loss = 79229.93376022\n",
      "Iteration 950, loss = 78961.17918278\n",
      "Iteration 951, loss = 78693.35909637\n",
      "Iteration 952, loss = 78427.11019960\n",
      "Iteration 953, loss = 78160.58882281\n",
      "Iteration 954, loss = 77895.65581527\n",
      "Iteration 955, loss = 77631.41022274\n",
      "Iteration 956, loss = 77368.01881250\n",
      "Iteration 957, loss = 77105.32346993\n",
      "Iteration 958, loss = 76843.60007356\n",
      "Iteration 959, loss = 76582.35868786\n",
      "Iteration 960, loss = 76322.11048900\n",
      "Iteration 961, loss = 76062.93486623\n",
      "Iteration 962, loss = 75804.23188485\n",
      "Iteration 963, loss = 75548.01213170\n",
      "Iteration 964, loss = 75294.18709748\n",
      "Iteration 965, loss = 75044.16762554\n",
      "Iteration 966, loss = 74794.40613927\n",
      "Iteration 967, loss = 74545.29777542\n",
      "Iteration 968, loss = 74296.51580177\n",
      "Iteration 969, loss = 74048.71738198\n",
      "Iteration 970, loss = 73802.47208120\n",
      "Iteration 971, loss = 73556.96981159\n",
      "Iteration 972, loss = 73311.47807928\n",
      "Iteration 973, loss = 73067.23363731\n",
      "Iteration 974, loss = 72824.16957839\n",
      "Iteration 975, loss = 72581.53379030\n",
      "Iteration 976, loss = 72340.69876770\n",
      "Iteration 977, loss = 72101.21732708\n",
      "Iteration 978, loss = 71862.89875610\n",
      "Iteration 979, loss = 71625.92681643\n",
      "Iteration 980, loss = 71390.26349148\n",
      "Iteration 981, loss = 71155.63815235\n",
      "Iteration 982, loss = 70922.24162808\n",
      "Iteration 983, loss = 70690.20792401\n",
      "Iteration 984, loss = 70458.04648504\n",
      "Iteration 985, loss = 70226.94638599\n",
      "Iteration 986, loss = 69997.96817138\n",
      "Iteration 987, loss = 69769.50880686\n",
      "Iteration 988, loss = 69541.36219356\n",
      "Iteration 989, loss = 69313.31223838\n",
      "Iteration 990, loss = 69087.14683385\n",
      "Iteration 991, loss = 68861.88573039\n",
      "Iteration 992, loss = 68637.19191568\n",
      "Iteration 993, loss = 68412.73468198\n",
      "Iteration 994, loss = 68187.84898031\n",
      "Iteration 995, loss = 67963.72780907\n",
      "Iteration 996, loss = 67739.81037654\n",
      "Iteration 997, loss = 67516.84991640\n",
      "Iteration 998, loss = 67294.66753967\n",
      "Iteration 999, loss = 67072.57799084\n",
      "Iteration 1000, loss = 66850.75535966\n",
      "Iteration 1001, loss = 66629.95688564\n",
      "Iteration 1002, loss = 66409.48515505\n",
      "Iteration 1003, loss = 66190.12319847\n",
      "Iteration 1004, loss = 65971.46071657\n",
      "Iteration 1005, loss = 65752.37613077\n",
      "Iteration 1006, loss = 65534.11002949\n",
      "Iteration 1007, loss = 65316.77265093\n",
      "Iteration 1008, loss = 65100.22971653\n",
      "Iteration 1009, loss = 64884.28238375\n",
      "Iteration 1010, loss = 64671.53505419\n",
      "Iteration 1011, loss = 64460.00736257\n",
      "Iteration 1012, loss = 64249.65033974\n",
      "Iteration 1013, loss = 64041.75876067\n",
      "Iteration 1014, loss = 63834.32984450\n",
      "Iteration 1015, loss = 63626.92592215\n",
      "Iteration 1016, loss = 63419.66925062\n",
      "Iteration 1017, loss = 63213.07461349\n",
      "Iteration 1018, loss = 63007.88945296\n",
      "Iteration 1019, loss = 62802.75481578\n",
      "Iteration 1020, loss = 62598.03647346\n",
      "Iteration 1021, loss = 62394.40692304\n",
      "Iteration 1022, loss = 62190.99431532\n",
      "Iteration 1023, loss = 61988.35987109\n",
      "Iteration 1024, loss = 61786.83857902\n",
      "Iteration 1025, loss = 61586.24497704\n",
      "Iteration 1026, loss = 61387.14504013\n",
      "Iteration 1027, loss = 61189.20734236\n",
      "Iteration 1028, loss = 60991.02190078\n",
      "Iteration 1029, loss = 60794.13859429\n",
      "Iteration 1030, loss = 60598.58614849\n",
      "Iteration 1031, loss = 60403.25588850\n",
      "Iteration 1032, loss = 60208.77639235\n",
      "Iteration 1033, loss = 60015.18681929\n",
      "Iteration 1034, loss = 59821.93048335\n",
      "Iteration 1035, loss = 59629.41618837\n",
      "Iteration 1036, loss = 59437.06970249\n",
      "Iteration 1037, loss = 59245.98085319\n",
      "Iteration 1038, loss = 59055.08292229\n",
      "Iteration 1039, loss = 58864.25840226\n",
      "Iteration 1040, loss = 58674.60209528\n",
      "Iteration 1041, loss = 58485.28115012\n",
      "Iteration 1042, loss = 58295.95000247\n",
      "Iteration 1043, loss = 58107.42748875\n",
      "Iteration 1044, loss = 57918.75788620\n",
      "Iteration 1045, loss = 57730.25485564\n",
      "Iteration 1046, loss = 57542.04615843\n",
      "Iteration 1047, loss = 57353.81881323\n",
      "Iteration 1048, loss = 57166.00590643\n",
      "Iteration 1049, loss = 56978.66411102\n",
      "Iteration 1050, loss = 56791.51806954\n",
      "Iteration 1051, loss = 56605.52042950\n",
      "Iteration 1052, loss = 56419.13500023\n",
      "Iteration 1053, loss = 56233.71143092\n",
      "Iteration 1054, loss = 56048.35843054\n",
      "Iteration 1055, loss = 55863.62782079\n",
      "Iteration 1056, loss = 55679.17878433\n",
      "Iteration 1057, loss = 55495.60309406\n",
      "Iteration 1058, loss = 55312.99230449\n",
      "Iteration 1059, loss = 55130.76868702\n",
      "Iteration 1060, loss = 54951.45528786\n",
      "Iteration 1061, loss = 54774.30956664\n",
      "Iteration 1062, loss = 54598.37184776\n",
      "Iteration 1063, loss = 54422.10404635\n",
      "Iteration 1064, loss = 54245.89465215\n",
      "Iteration 1065, loss = 54069.75268870\n",
      "Iteration 1066, loss = 53893.98865811\n",
      "Iteration 1067, loss = 53718.88734455\n",
      "Iteration 1068, loss = 53544.41473125\n",
      "Iteration 1069, loss = 53370.13260513\n",
      "Iteration 1070, loss = 53196.74852396\n",
      "Iteration 1071, loss = 53023.64254885\n",
      "Iteration 1072, loss = 52851.49884929\n",
      "Iteration 1073, loss = 52680.14586000\n",
      "Iteration 1074, loss = 52509.53537821\n",
      "Iteration 1075, loss = 52339.91416221\n",
      "Iteration 1076, loss = 52170.74021282\n",
      "Iteration 1077, loss = 52002.32102664\n",
      "Iteration 1078, loss = 51834.79333236\n",
      "Iteration 1079, loss = 51667.65245247\n",
      "Iteration 1080, loss = 51501.36805758\n",
      "Iteration 1081, loss = 51335.81464206\n",
      "Iteration 1082, loss = 51170.96151894\n",
      "Iteration 1083, loss = 51006.58527071\n",
      "Iteration 1084, loss = 50842.88761465\n",
      "Iteration 1085, loss = 50679.58856739\n",
      "Iteration 1086, loss = 50516.68277893\n",
      "Iteration 1087, loss = 50354.41252325\n",
      "Iteration 1088, loss = 50192.53846933\n",
      "Iteration 1089, loss = 50030.95310034\n",
      "Iteration 1090, loss = 49869.79964773\n",
      "Iteration 1091, loss = 49709.14156655\n",
      "Iteration 1092, loss = 49548.79820422\n",
      "Iteration 1093, loss = 49388.85416798\n",
      "Iteration 1094, loss = 49228.90784233\n",
      "Iteration 1095, loss = 49069.26253150\n",
      "Iteration 1096, loss = 48909.81087966\n",
      "Iteration 1097, loss = 48750.61433657\n",
      "Iteration 1098, loss = 48591.71037408\n",
      "Iteration 1099, loss = 48432.97429142\n",
      "Iteration 1100, loss = 48274.54600330\n",
      "Iteration 1101, loss = 48116.58204388\n",
      "Iteration 1102, loss = 47959.06135894\n",
      "Iteration 1103, loss = 47801.86658546\n",
      "Iteration 1104, loss = 47644.87531790\n",
      "Iteration 1105, loss = 47488.27392851\n",
      "Iteration 1106, loss = 47332.07284942\n",
      "Iteration 1107, loss = 47176.28153844\n",
      "Iteration 1108, loss = 47021.27242575\n",
      "Iteration 1109, loss = 46867.11077856\n",
      "Iteration 1110, loss = 46713.38807896\n",
      "Iteration 1111, loss = 46561.45877997\n",
      "Iteration 1112, loss = 46410.43426101\n",
      "Iteration 1113, loss = 46260.54306295\n",
      "Iteration 1114, loss = 46111.23292635\n",
      "Iteration 1115, loss = 45963.13301416\n",
      "Iteration 1116, loss = 45815.87879742\n",
      "Iteration 1117, loss = 45668.89337729\n",
      "Iteration 1118, loss = 45522.28058540\n",
      "Iteration 1119, loss = 45376.14641101\n",
      "Iteration 1120, loss = 45230.36792201\n",
      "Iteration 1121, loss = 45084.92839176\n",
      "Iteration 1122, loss = 44940.62787785\n",
      "Iteration 1123, loss = 44796.91344381\n",
      "Iteration 1124, loss = 44653.87122024\n",
      "Iteration 1125, loss = 44511.55306766\n",
      "Iteration 1126, loss = 44369.88905356\n",
      "Iteration 1127, loss = 44228.93806592\n",
      "Iteration 1128, loss = 44088.75809237\n",
      "Iteration 1129, loss = 43949.35201911\n",
      "Iteration 1130, loss = 43810.73599236\n",
      "Iteration 1131, loss = 43672.93695469\n",
      "Iteration 1132, loss = 43535.89635112\n",
      "Iteration 1133, loss = 43399.39883848\n",
      "Iteration 1134, loss = 43263.61873526\n",
      "Iteration 1135, loss = 43128.53604665\n",
      "Iteration 1136, loss = 42994.10252416\n",
      "Iteration 1137, loss = 42860.26189549\n",
      "Iteration 1138, loss = 42727.12082759\n",
      "Iteration 1139, loss = 42594.56918686\n",
      "Iteration 1140, loss = 42462.58974493\n",
      "Iteration 1141, loss = 42331.23954411\n",
      "Iteration 1142, loss = 42200.47559867\n",
      "Iteration 1143, loss = 42070.05326463\n",
      "Iteration 1144, loss = 41940.10042212\n",
      "Iteration 1145, loss = 41810.63987006\n",
      "Iteration 1146, loss = 41681.51546760\n",
      "Iteration 1147, loss = 41552.81807251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1148, loss = 41424.39384629\n",
      "Iteration 1149, loss = 41296.23631641\n",
      "Iteration 1150, loss = 41168.45876207\n",
      "Iteration 1151, loss = 41041.03096206\n",
      "Iteration 1152, loss = 40913.90900753\n",
      "Iteration 1153, loss = 40787.14342256\n",
      "Iteration 1154, loss = 40660.51949835\n",
      "Iteration 1155, loss = 40534.24057670\n",
      "Iteration 1156, loss = 40408.23025954\n",
      "Iteration 1157, loss = 40282.53425347\n",
      "Iteration 1158, loss = 40157.17481241\n",
      "Iteration 1159, loss = 40032.21359295\n",
      "Iteration 1160, loss = 39907.60786182\n",
      "Iteration 1161, loss = 39783.37516067\n",
      "Iteration 1162, loss = 39659.41844361\n",
      "Iteration 1163, loss = 39535.71771779\n",
      "Iteration 1164, loss = 39412.41225437\n",
      "Iteration 1165, loss = 39289.29455173\n",
      "Iteration 1166, loss = 39166.53465448\n",
      "Iteration 1167, loss = 39044.16227442\n",
      "Iteration 1168, loss = 38922.15374256\n",
      "Iteration 1169, loss = 38800.51232698\n",
      "Iteration 1170, loss = 38679.47214186\n",
      "Iteration 1171, loss = 38559.45708074\n",
      "Iteration 1172, loss = 38440.05829306\n",
      "Iteration 1173, loss = 38321.51536034\n",
      "Iteration 1174, loss = 38203.37767632\n",
      "Iteration 1175, loss = 38085.62407931\n",
      "Iteration 1176, loss = 37968.93605378\n",
      "Iteration 1177, loss = 37853.33143653\n",
      "Iteration 1178, loss = 37737.80331764\n",
      "Iteration 1179, loss = 37622.05256471\n",
      "Iteration 1180, loss = 37506.38116613\n",
      "Iteration 1181, loss = 37390.69574334\n",
      "Iteration 1182, loss = 37275.01988878\n",
      "Iteration 1183, loss = 37159.75372283\n",
      "Iteration 1184, loss = 37044.82555540\n",
      "Iteration 1185, loss = 36930.82480134\n",
      "Iteration 1186, loss = 36817.54764618\n",
      "Iteration 1187, loss = 36704.87660071\n",
      "Iteration 1188, loss = 36592.61296767\n",
      "Iteration 1189, loss = 36481.06483633\n",
      "Iteration 1190, loss = 36370.00561019\n",
      "Iteration 1191, loss = 36259.51658128\n",
      "Iteration 1192, loss = 36149.40532628\n",
      "Iteration 1193, loss = 36039.95379182\n",
      "Iteration 1194, loss = 35931.19203571\n",
      "Iteration 1195, loss = 35823.05920295\n",
      "Iteration 1196, loss = 35715.30199226\n",
      "Iteration 1197, loss = 35608.29594986\n",
      "Iteration 1198, loss = 35501.98002358\n",
      "Iteration 1199, loss = 35395.82393767\n",
      "Iteration 1200, loss = 35290.19143783\n",
      "Iteration 1201, loss = 35185.16894355\n",
      "Iteration 1202, loss = 35080.40050896\n",
      "Iteration 1203, loss = 34976.22888243\n",
      "Iteration 1204, loss = 34872.36365749\n",
      "Iteration 1205, loss = 34768.40243607\n",
      "Iteration 1206, loss = 34664.89886317\n",
      "Iteration 1207, loss = 34561.88307606\n",
      "Iteration 1208, loss = 34459.59114778\n",
      "Iteration 1209, loss = 34357.67250444\n",
      "Iteration 1210, loss = 34256.07398803\n",
      "Iteration 1211, loss = 34154.64095943\n",
      "Iteration 1212, loss = 34053.47426626\n",
      "Iteration 1213, loss = 33952.51449938\n",
      "Iteration 1214, loss = 33851.85443699\n",
      "Iteration 1215, loss = 33751.32268953\n",
      "Iteration 1216, loss = 33651.10591720\n",
      "Iteration 1217, loss = 33551.25447211\n",
      "Iteration 1218, loss = 33451.63212427\n",
      "Iteration 1219, loss = 33352.49514666\n",
      "Iteration 1220, loss = 33253.59041441\n",
      "Iteration 1221, loss = 33154.60970507\n",
      "Iteration 1222, loss = 33056.09315936\n",
      "Iteration 1223, loss = 32957.89697937\n",
      "Iteration 1224, loss = 32859.99219125\n",
      "Iteration 1225, loss = 32762.73013075\n",
      "Iteration 1226, loss = 32665.74932287\n",
      "Iteration 1227, loss = 32568.87660118\n",
      "Iteration 1228, loss = 32472.32888980\n",
      "Iteration 1229, loss = 32375.86221794\n",
      "Iteration 1230, loss = 32279.42074280\n",
      "Iteration 1231, loss = 32183.72105991\n",
      "Iteration 1232, loss = 32088.25459548\n",
      "Iteration 1233, loss = 31993.37121120\n",
      "Iteration 1234, loss = 31898.99914910\n",
      "Iteration 1235, loss = 31804.76855472\n",
      "Iteration 1236, loss = 31710.72401779\n",
      "Iteration 1237, loss = 31617.02517267\n",
      "Iteration 1238, loss = 31523.48265558\n",
      "Iteration 1239, loss = 31430.10335669\n",
      "Iteration 1240, loss = 31336.93811695\n",
      "Iteration 1241, loss = 31243.96250414\n",
      "Iteration 1242, loss = 31151.20187900\n",
      "Iteration 1243, loss = 31058.63962537\n",
      "Iteration 1244, loss = 30966.41675115\n",
      "Iteration 1245, loss = 30874.53399079\n",
      "Iteration 1246, loss = 30782.81953744\n",
      "Iteration 1247, loss = 30691.55988140\n",
      "Iteration 1248, loss = 30600.51597023\n",
      "Iteration 1249, loss = 30509.48949188\n",
      "Iteration 1250, loss = 30418.66862537\n",
      "Iteration 1251, loss = 30328.43822329\n",
      "Iteration 1252, loss = 30239.03713493\n",
      "Iteration 1253, loss = 30149.64718978\n",
      "Iteration 1254, loss = 30060.40675400\n",
      "Iteration 1255, loss = 29971.82016415\n",
      "Iteration 1256, loss = 29883.57038720\n",
      "Iteration 1257, loss = 29795.92877544\n",
      "Iteration 1258, loss = 29709.18202545\n",
      "Iteration 1259, loss = 29622.28864943\n",
      "Iteration 1260, loss = 29535.60204066\n",
      "Iteration 1261, loss = 29449.51213500\n",
      "Iteration 1262, loss = 29363.49612410\n",
      "Iteration 1263, loss = 29278.01413230\n",
      "Iteration 1264, loss = 29192.92610756\n",
      "Iteration 1265, loss = 29108.75943443\n",
      "Iteration 1266, loss = 29024.62657266\n",
      "Iteration 1267, loss = 28940.65440946\n",
      "Iteration 1268, loss = 28857.92265319\n",
      "Iteration 1269, loss = 28775.27544031\n",
      "Iteration 1270, loss = 28692.88349915\n",
      "Iteration 1271, loss = 28610.86064519\n",
      "Iteration 1272, loss = 28529.36591855\n",
      "Iteration 1273, loss = 28448.09327564\n",
      "Iteration 1274, loss = 28366.99601186\n",
      "Iteration 1275, loss = 28286.25934778\n",
      "Iteration 1276, loss = 28205.78912377\n",
      "Iteration 1277, loss = 28125.87660528\n",
      "Iteration 1278, loss = 28045.88249336\n",
      "Iteration 1279, loss = 27966.44422626\n",
      "Iteration 1280, loss = 27887.63736031\n",
      "Iteration 1281, loss = 27808.92566843\n",
      "Iteration 1282, loss = 27730.27558786\n",
      "Iteration 1283, loss = 27651.86109193\n",
      "Iteration 1284, loss = 27573.91167290\n",
      "Iteration 1285, loss = 27496.14036566\n",
      "Iteration 1286, loss = 27418.67516823\n",
      "Iteration 1287, loss = 27341.20350023\n",
      "Iteration 1288, loss = 27264.00031521\n",
      "Iteration 1289, loss = 27186.80774298\n",
      "Iteration 1290, loss = 27109.83484695\n",
      "Iteration 1291, loss = 27032.93107804\n",
      "Iteration 1292, loss = 26956.15592815\n",
      "Iteration 1293, loss = 26879.80672143\n",
      "Iteration 1294, loss = 26803.69911306\n",
      "Iteration 1295, loss = 26727.56804243\n",
      "Iteration 1296, loss = 26651.76405679\n",
      "Iteration 1297, loss = 26576.34284186\n",
      "Iteration 1298, loss = 26501.16102172\n",
      "Iteration 1299, loss = 26426.14788648\n",
      "Iteration 1300, loss = 26351.29931122\n",
      "Iteration 1301, loss = 26276.80923599\n",
      "Iteration 1302, loss = 26202.57396162\n",
      "Iteration 1303, loss = 26128.49689018\n",
      "Iteration 1304, loss = 26054.48036088\n",
      "Iteration 1305, loss = 25980.79288713\n",
      "Iteration 1306, loss = 25907.31419738\n",
      "Iteration 1307, loss = 25834.16246900\n",
      "Iteration 1308, loss = 25761.03607485\n",
      "Iteration 1309, loss = 25688.01828504\n",
      "Iteration 1310, loss = 25615.20974000\n",
      "Iteration 1311, loss = 25542.39797568\n",
      "Iteration 1312, loss = 25469.63746586\n",
      "Iteration 1313, loss = 25397.01480954\n",
      "Iteration 1314, loss = 25324.34810618\n",
      "Iteration 1315, loss = 25251.62997903\n",
      "Iteration 1316, loss = 25179.18133846\n",
      "Iteration 1317, loss = 25106.88235036\n",
      "Iteration 1318, loss = 25034.81469692\n",
      "Iteration 1319, loss = 24963.00114766\n",
      "Iteration 1320, loss = 24891.39885639\n",
      "Iteration 1321, loss = 24819.98337848\n",
      "Iteration 1322, loss = 24748.87418007\n",
      "Iteration 1323, loss = 24678.00733339\n",
      "Iteration 1324, loss = 24607.33406956\n",
      "Iteration 1325, loss = 24536.85087517\n",
      "Iteration 1326, loss = 24466.85448915\n",
      "Iteration 1327, loss = 24397.28228977\n",
      "Iteration 1328, loss = 24327.74073530\n",
      "Iteration 1329, loss = 24258.26905136\n",
      "Iteration 1330, loss = 24189.27838682\n",
      "Iteration 1331, loss = 24120.32256370\n",
      "Iteration 1332, loss = 24051.96013781\n",
      "Iteration 1333, loss = 23984.27693034\n",
      "Iteration 1334, loss = 23917.05510028\n",
      "Iteration 1335, loss = 23849.71162593\n",
      "Iteration 1336, loss = 23782.55258719\n",
      "Iteration 1337, loss = 23715.82337118\n",
      "Iteration 1338, loss = 23648.82309218\n",
      "Iteration 1339, loss = 23582.28876070\n",
      "Iteration 1340, loss = 23516.05290551\n",
      "Iteration 1341, loss = 23449.69958482\n",
      "Iteration 1342, loss = 23383.62118156\n",
      "Iteration 1343, loss = 23318.17438762\n",
      "Iteration 1344, loss = 23252.73058847\n",
      "Iteration 1345, loss = 23187.70830805\n",
      "Iteration 1346, loss = 23123.10237037\n",
      "Iteration 1347, loss = 23058.45769372\n",
      "Iteration 1348, loss = 22994.77691663\n",
      "Iteration 1349, loss = 22931.59613821\n",
      "Iteration 1350, loss = 22868.45288872\n",
      "Iteration 1351, loss = 22805.84966534\n",
      "Iteration 1352, loss = 22743.41361344\n",
      "Iteration 1353, loss = 22680.84245094\n",
      "Iteration 1354, loss = 22618.83347680\n",
      "Iteration 1355, loss = 22557.33992927\n",
      "Iteration 1356, loss = 22495.94134333\n",
      "Iteration 1357, loss = 22434.56470765\n",
      "Iteration 1358, loss = 22373.08633258\n",
      "Iteration 1359, loss = 22312.22508041\n",
      "Iteration 1360, loss = 22251.69558226\n",
      "Iteration 1361, loss = 22191.22918154\n",
      "Iteration 1362, loss = 22130.98669235\n",
      "Iteration 1363, loss = 22071.24397092\n",
      "Iteration 1364, loss = 22011.53877006\n",
      "Iteration 1365, loss = 21952.36345627\n",
      "Iteration 1366, loss = 21893.29750888\n",
      "Iteration 1367, loss = 21834.38778432\n",
      "Iteration 1368, loss = 21775.61656763\n",
      "Iteration 1369, loss = 21717.20884797\n",
      "Iteration 1370, loss = 21659.00397568\n",
      "Iteration 1371, loss = 21601.18954048\n",
      "Iteration 1372, loss = 21543.44570029\n",
      "Iteration 1373, loss = 21485.90747789\n",
      "Iteration 1374, loss = 21428.84041299\n",
      "Iteration 1375, loss = 21371.81472702\n",
      "Iteration 1376, loss = 21314.86213865\n",
      "Iteration 1377, loss = 21258.30919835\n",
      "Iteration 1378, loss = 21201.88443156\n",
      "Iteration 1379, loss = 21145.26851801\n",
      "Iteration 1380, loss = 21088.76652159\n",
      "Iteration 1381, loss = 21032.45523457\n",
      "Iteration 1382, loss = 20976.00712305\n",
      "Iteration 1383, loss = 20919.69938537\n",
      "Iteration 1384, loss = 20863.58375309\n",
      "Iteration 1385, loss = 20807.82055280\n",
      "Iteration 1386, loss = 20752.16032220\n",
      "Iteration 1387, loss = 20696.41297509\n",
      "Iteration 1388, loss = 20640.64754121\n",
      "Iteration 1389, loss = 20585.26753999\n",
      "Iteration 1390, loss = 20530.12438072\n",
      "Iteration 1391, loss = 20475.07071316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1392, loss = 20420.37442738\n",
      "Iteration 1393, loss = 20365.46219102\n",
      "Iteration 1394, loss = 20310.67269866\n",
      "Iteration 1395, loss = 20256.31441109\n",
      "Iteration 1396, loss = 20202.32120155\n",
      "Iteration 1397, loss = 20148.34096373\n",
      "Iteration 1398, loss = 20094.54874742\n",
      "Iteration 1399, loss = 20040.93461960\n",
      "Iteration 1400, loss = 19987.52452598\n",
      "Iteration 1401, loss = 19934.08087742\n",
      "Iteration 1402, loss = 19881.00945854\n",
      "Iteration 1403, loss = 19828.10469232\n",
      "Iteration 1404, loss = 19775.21547137\n",
      "Iteration 1405, loss = 19722.23467821\n",
      "Iteration 1406, loss = 19669.31182683\n",
      "Iteration 1407, loss = 19616.50173979\n",
      "Iteration 1408, loss = 19564.03208878\n",
      "Iteration 1409, loss = 19511.61114507\n",
      "Iteration 1410, loss = 19459.46722829\n",
      "Iteration 1411, loss = 19407.37173096\n",
      "Iteration 1412, loss = 19355.20610457\n",
      "Iteration 1413, loss = 19303.18450756\n",
      "Iteration 1414, loss = 19251.48154448\n",
      "Iteration 1415, loss = 19199.96795451\n",
      "Iteration 1416, loss = 19148.61916267\n",
      "Iteration 1417, loss = 19097.20478175\n",
      "Iteration 1418, loss = 19045.77138406\n",
      "Iteration 1419, loss = 18994.82689494\n",
      "Iteration 1420, loss = 18944.14800126\n",
      "Iteration 1421, loss = 18893.59684514\n",
      "Iteration 1422, loss = 18843.27659802\n",
      "Iteration 1423, loss = 18792.93443633\n",
      "Iteration 1424, loss = 18742.96509009\n",
      "Iteration 1425, loss = 18693.22600401\n",
      "Iteration 1426, loss = 18643.58430864\n",
      "Iteration 1427, loss = 18593.99900914\n",
      "Iteration 1428, loss = 18544.77983950\n",
      "Iteration 1429, loss = 18495.35810265\n",
      "Iteration 1430, loss = 18446.43487488\n",
      "Iteration 1431, loss = 18397.55394985\n",
      "Iteration 1432, loss = 18349.08224888\n",
      "Iteration 1433, loss = 18300.84775485\n",
      "Iteration 1434, loss = 18252.60518719\n",
      "Iteration 1435, loss = 18204.13717281\n",
      "Iteration 1436, loss = 18155.91453982\n",
      "Iteration 1437, loss = 18107.79547401\n",
      "Iteration 1438, loss = 18059.78348815\n",
      "Iteration 1439, loss = 18011.77746203\n",
      "Iteration 1440, loss = 17963.94474971\n",
      "Iteration 1441, loss = 17916.40398335\n",
      "Iteration 1442, loss = 17869.47125271\n",
      "Iteration 1443, loss = 17822.66956940\n",
      "Iteration 1444, loss = 17776.11536857\n",
      "Iteration 1445, loss = 17729.64376643\n",
      "Iteration 1446, loss = 17683.22149884\n",
      "Iteration 1447, loss = 17637.31564789\n",
      "Iteration 1448, loss = 17591.54301301\n",
      "Iteration 1449, loss = 17545.91470657\n",
      "Iteration 1450, loss = 17500.36790874\n",
      "Iteration 1451, loss = 17455.08092857\n",
      "Iteration 1452, loss = 17409.92122559\n",
      "Iteration 1453, loss = 17364.90763988\n",
      "Iteration 1454, loss = 17319.91261188\n",
      "Iteration 1455, loss = 17274.89493015\n",
      "Iteration 1456, loss = 17230.01530088\n",
      "Iteration 1457, loss = 17185.79096991\n",
      "Iteration 1458, loss = 17141.80047453\n",
      "Iteration 1459, loss = 17097.92736035\n",
      "Iteration 1460, loss = 17054.03414436\n",
      "Iteration 1461, loss = 17010.20003964\n",
      "Iteration 1462, loss = 16966.64865904\n",
      "Iteration 1463, loss = 16923.24338472\n",
      "Iteration 1464, loss = 16879.90956810\n",
      "Iteration 1465, loss = 16836.85119312\n",
      "Iteration 1466, loss = 16793.82280803\n",
      "Iteration 1467, loss = 16751.09153187\n",
      "Iteration 1468, loss = 16708.52748759\n",
      "Iteration 1469, loss = 16666.10919095\n",
      "Iteration 1470, loss = 16623.91316456\n",
      "Iteration 1471, loss = 16581.95616738\n",
      "Iteration 1472, loss = 16540.16512971\n",
      "Iteration 1473, loss = 16498.51296703\n",
      "Iteration 1474, loss = 16456.99959599\n",
      "Iteration 1475, loss = 16415.59749158\n",
      "Iteration 1476, loss = 16374.35052759\n",
      "Iteration 1477, loss = 16332.97512730\n",
      "Iteration 1478, loss = 16291.77426446\n",
      "Iteration 1479, loss = 16250.69840303\n",
      "Iteration 1480, loss = 16209.63737627\n",
      "Iteration 1481, loss = 16168.83475338\n",
      "Iteration 1482, loss = 16128.14595288\n",
      "Iteration 1483, loss = 16087.55565483\n",
      "Iteration 1484, loss = 16047.15713894\n",
      "Iteration 1485, loss = 16006.77117314\n",
      "Iteration 1486, loss = 15966.52848624\n",
      "Iteration 1487, loss = 15926.40085770\n",
      "Iteration 1488, loss = 15886.51108964\n",
      "Iteration 1489, loss = 15846.81858820\n",
      "Iteration 1490, loss = 15807.24516526\n",
      "Iteration 1491, loss = 15767.89676834\n",
      "Iteration 1492, loss = 15728.41020753\n",
      "Iteration 1493, loss = 15689.05463832\n",
      "Iteration 1494, loss = 15649.80497926\n",
      "Iteration 1495, loss = 15610.69492032\n",
      "Iteration 1496, loss = 15571.74853108\n",
      "Iteration 1497, loss = 15532.92627552\n",
      "Iteration 1498, loss = 15494.14440725\n",
      "Iteration 1499, loss = 15455.46306653\n",
      "Iteration 1500, loss = 15416.84461072\n",
      "Iteration 1501, loss = 15378.25549216\n",
      "Iteration 1502, loss = 15339.81968754\n",
      "Iteration 1503, loss = 15301.64002027\n",
      "Iteration 1504, loss = 15263.33015804\n",
      "Iteration 1505, loss = 15224.97605361\n",
      "Iteration 1506, loss = 15186.69754194\n",
      "Iteration 1507, loss = 15148.59595278\n",
      "Iteration 1508, loss = 15110.54202955\n",
      "Iteration 1509, loss = 15072.66072148\n",
      "Iteration 1510, loss = 15035.01376646\n",
      "Iteration 1511, loss = 14997.40972745\n",
      "Iteration 1512, loss = 14959.85458274\n",
      "Iteration 1513, loss = 14922.62568613\n",
      "Iteration 1514, loss = 14885.45904965\n",
      "Iteration 1515, loss = 14848.39880388\n",
      "Iteration 1516, loss = 14811.38716358\n",
      "Iteration 1517, loss = 14774.54702033\n",
      "Iteration 1518, loss = 14737.86170820\n",
      "Iteration 1519, loss = 14701.28745674\n",
      "Iteration 1520, loss = 14664.75955585\n",
      "Iteration 1521, loss = 14628.40876037\n",
      "Iteration 1522, loss = 14592.02305121\n",
      "Iteration 1523, loss = 14555.67361415\n",
      "Iteration 1524, loss = 14519.51398940\n",
      "Iteration 1525, loss = 14483.40017778\n",
      "Iteration 1526, loss = 14447.37496870\n",
      "Iteration 1527, loss = 14411.47046942\n",
      "Iteration 1528, loss = 14375.53829179\n",
      "Iteration 1529, loss = 14339.66546666\n",
      "Iteration 1530, loss = 14303.85247920\n",
      "Iteration 1531, loss = 14268.08775192\n",
      "Iteration 1532, loss = 14232.26592959\n",
      "Iteration 1533, loss = 14196.26190933\n",
      "Iteration 1534, loss = 14160.33089643\n",
      "Iteration 1535, loss = 14124.56609670\n",
      "Iteration 1536, loss = 14088.92182393\n",
      "Iteration 1537, loss = 14053.52598493\n",
      "Iteration 1538, loss = 14018.10688973\n",
      "Iteration 1539, loss = 13982.81524631\n",
      "Iteration 1540, loss = 13947.69473767\n",
      "Iteration 1541, loss = 13912.93974612\n",
      "Iteration 1542, loss = 13878.25714147\n",
      "Iteration 1543, loss = 13843.46904269\n",
      "Iteration 1544, loss = 13808.76406430\n",
      "Iteration 1545, loss = 13774.14315134\n",
      "Iteration 1546, loss = 13739.58396188\n",
      "Iteration 1547, loss = 13705.06122271\n",
      "Iteration 1548, loss = 13670.68168795\n",
      "Iteration 1549, loss = 13636.66101860\n",
      "Iteration 1550, loss = 13602.94043065\n",
      "Iteration 1551, loss = 13569.45392712\n",
      "Iteration 1552, loss = 13536.00502660\n",
      "Iteration 1553, loss = 13502.66956417\n",
      "Iteration 1554, loss = 13469.52807371\n",
      "Iteration 1555, loss = 13436.56109673\n",
      "Iteration 1556, loss = 13403.77009495\n",
      "Iteration 1557, loss = 13371.19900912\n",
      "Iteration 1558, loss = 13338.79125047\n",
      "Iteration 1559, loss = 13306.60827195\n",
      "Iteration 1560, loss = 13274.57148411\n",
      "Iteration 1561, loss = 13242.40022186\n",
      "Iteration 1562, loss = 13210.32713110\n",
      "Iteration 1563, loss = 13178.39386834\n",
      "Iteration 1564, loss = 13146.61060260\n",
      "Iteration 1565, loss = 13114.96724603\n",
      "Iteration 1566, loss = 13083.47975855\n",
      "Iteration 1567, loss = 13052.10831807\n",
      "Iteration 1568, loss = 13020.87978918\n",
      "Iteration 1569, loss = 12989.66215592\n",
      "Iteration 1570, loss = 12958.56322218\n",
      "Iteration 1571, loss = 12927.58397492\n",
      "Iteration 1572, loss = 12896.72347051\n",
      "Iteration 1573, loss = 12866.01452582\n",
      "Iteration 1574, loss = 12835.38037645\n",
      "Iteration 1575, loss = 12804.89214936\n",
      "Iteration 1576, loss = 12774.48707785\n",
      "Iteration 1577, loss = 12744.09940957\n",
      "Iteration 1578, loss = 12713.82371621\n",
      "Iteration 1579, loss = 12683.67007880\n",
      "Iteration 1580, loss = 12653.57028937\n",
      "Iteration 1581, loss = 12623.54251731\n",
      "Iteration 1582, loss = 12593.54800798\n",
      "Iteration 1583, loss = 12563.44906716\n",
      "Iteration 1584, loss = 12533.37165659\n",
      "Iteration 1585, loss = 12503.34981005\n",
      "Iteration 1586, loss = 12473.43540950\n",
      "Iteration 1587, loss = 12443.63664040\n",
      "Iteration 1588, loss = 12413.93328722\n",
      "Iteration 1589, loss = 12384.24443733\n",
      "Iteration 1590, loss = 12354.62500015\n",
      "Iteration 1591, loss = 12325.01843558\n",
      "Iteration 1592, loss = 12295.45935616\n",
      "Iteration 1593, loss = 12265.99536678\n",
      "Iteration 1594, loss = 12236.64990373\n",
      "Iteration 1595, loss = 12207.39309092\n",
      "Iteration 1596, loss = 12178.24687599\n",
      "Iteration 1597, loss = 12149.24882700\n",
      "Iteration 1598, loss = 12120.33240922\n",
      "Iteration 1599, loss = 12091.53805029\n",
      "Iteration 1600, loss = 12062.84968830\n",
      "Iteration 1601, loss = 12034.27372830\n",
      "Iteration 1602, loss = 12005.81334048\n",
      "Iteration 1603, loss = 11977.37700508\n",
      "Iteration 1604, loss = 11949.00494683\n",
      "Iteration 1605, loss = 11920.75068859\n",
      "Iteration 1606, loss = 11892.60603431\n",
      "Iteration 1607, loss = 11864.58656774\n",
      "Iteration 1608, loss = 11836.67761529\n",
      "Iteration 1609, loss = 11808.89535846\n",
      "Iteration 1610, loss = 11781.21689934\n",
      "Iteration 1611, loss = 11753.49241546\n",
      "Iteration 1612, loss = 11725.81083570\n",
      "Iteration 1613, loss = 11698.19846397\n",
      "Iteration 1614, loss = 11670.64936486\n",
      "Iteration 1615, loss = 11643.06129330\n",
      "Iteration 1616, loss = 11615.35044070\n",
      "Iteration 1617, loss = 11587.55244414\n",
      "Iteration 1618, loss = 11559.80104666\n",
      "Iteration 1619, loss = 11532.02678944\n",
      "Iteration 1620, loss = 11504.31360264\n",
      "Iteration 1621, loss = 11476.67452100\n",
      "Iteration 1622, loss = 11449.08097629\n",
      "Iteration 1623, loss = 11421.46929830\n",
      "Iteration 1624, loss = 11393.90555893\n",
      "Iteration 1625, loss = 11366.40298394\n",
      "Iteration 1626, loss = 11338.85339098\n",
      "Iteration 1627, loss = 11311.30720768\n",
      "Iteration 1628, loss = 11283.73528800\n",
      "Iteration 1629, loss = 11256.15566394\n",
      "Iteration 1630, loss = 11228.64211062\n",
      "Iteration 1631, loss = 11201.20399989\n",
      "Iteration 1632, loss = 11173.82626362\n",
      "Iteration 1633, loss = 11146.50051135\n",
      "Iteration 1634, loss = 11119.22307143\n",
      "Iteration 1635, loss = 11092.07333947\n",
      "Iteration 1636, loss = 11065.00406255\n",
      "Iteration 1637, loss = 11038.02599613\n",
      "Iteration 1638, loss = 11011.13801416\n",
      "Iteration 1639, loss = 10984.34413045\n",
      "Iteration 1640, loss = 10957.64789404\n",
      "Iteration 1641, loss = 10931.04039083\n",
      "Iteration 1642, loss = 10904.49167990\n",
      "Iteration 1643, loss = 10877.96188213\n",
      "Iteration 1644, loss = 10851.53884366\n",
      "Iteration 1645, loss = 10825.18343840\n",
      "Iteration 1646, loss = 10799.02653327\n",
      "Iteration 1647, loss = 10772.98369751\n",
      "Iteration 1648, loss = 10746.97855868\n",
      "Iteration 1649, loss = 10720.99833166\n",
      "Iteration 1650, loss = 10695.09325974\n",
      "Iteration 1651, loss = 10669.29932433\n",
      "Iteration 1652, loss = 10643.65762723\n",
      "Iteration 1653, loss = 10618.09160350\n",
      "Iteration 1654, loss = 10592.70559057\n",
      "Iteration 1655, loss = 10567.41978470\n",
      "Iteration 1656, loss = 10542.25220680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1657, loss = 10517.02850102\n",
      "Iteration 1658, loss = 10491.95747144\n",
      "Iteration 1659, loss = 10466.98443047\n",
      "Iteration 1660, loss = 10442.04887372\n",
      "Iteration 1661, loss = 10417.26751256\n",
      "Iteration 1662, loss = 10392.63106480\n",
      "Iteration 1663, loss = 10368.14779697\n",
      "Iteration 1664, loss = 10343.86945698\n",
      "Iteration 1665, loss = 10319.70190785\n",
      "Iteration 1666, loss = 10295.57477813\n",
      "Iteration 1667, loss = 10271.42522161\n",
      "Iteration 1668, loss = 10247.29034944\n",
      "Iteration 1669, loss = 10223.21503611\n",
      "Iteration 1670, loss = 10199.23175290\n",
      "Iteration 1671, loss = 10175.42571665\n",
      "Iteration 1672, loss = 10151.70628062\n",
      "Iteration 1673, loss = 10128.02390831\n",
      "Iteration 1674, loss = 10104.39910352\n",
      "Iteration 1675, loss = 10080.83524471\n",
      "Iteration 1676, loss = 10057.43940590\n",
      "Iteration 1677, loss = 10034.15322377\n",
      "Iteration 1678, loss = 10010.98794039\n",
      "Iteration 1679, loss = 9987.91234042\n",
      "Iteration 1680, loss = 9964.88659004\n",
      "Iteration 1681, loss = 9941.95138200\n",
      "Iteration 1682, loss = 9919.11716181\n",
      "Iteration 1683, loss = 9896.41247468\n",
      "Iteration 1684, loss = 9873.84430932\n",
      "Iteration 1685, loss = 9851.31607948\n",
      "Iteration 1686, loss = 9828.82439630\n",
      "Iteration 1687, loss = 9806.42151170\n",
      "Iteration 1688, loss = 9784.10028578\n",
      "Iteration 1689, loss = 9761.80866853\n",
      "Iteration 1690, loss = 9739.59925396\n",
      "Iteration 1691, loss = 9717.46882503\n",
      "Iteration 1692, loss = 9695.42111281\n",
      "Iteration 1693, loss = 9673.45492525\n",
      "Iteration 1694, loss = 9651.57046635\n",
      "Iteration 1695, loss = 9629.79482499\n",
      "Iteration 1696, loss = 9608.08781784\n",
      "Iteration 1697, loss = 9586.40052376\n",
      "Iteration 1698, loss = 9564.77768559\n",
      "Iteration 1699, loss = 9543.16840165\n",
      "Iteration 1700, loss = 9521.47775680\n",
      "Iteration 1701, loss = 9499.83739630\n",
      "Iteration 1702, loss = 9478.19209297\n",
      "Iteration 1703, loss = 9456.54274020\n",
      "Iteration 1704, loss = 9434.89642234\n",
      "Iteration 1705, loss = 9413.22696835\n",
      "Iteration 1706, loss = 9391.47583780\n",
      "Iteration 1707, loss = 9369.79232409\n",
      "Iteration 1708, loss = 9348.24116090\n",
      "Iteration 1709, loss = 9326.59729055\n",
      "Iteration 1710, loss = 9304.93302937\n",
      "Iteration 1711, loss = 9283.23685354\n",
      "Iteration 1712, loss = 9261.63933271\n",
      "Iteration 1713, loss = 9240.16348662\n",
      "Iteration 1714, loss = 9218.79011993\n",
      "Iteration 1715, loss = 9197.42228610\n",
      "Iteration 1716, loss = 9175.94708963\n",
      "Iteration 1717, loss = 9154.50736223\n",
      "Iteration 1718, loss = 9133.15920901\n",
      "Iteration 1719, loss = 9111.83637790\n",
      "Iteration 1720, loss = 9090.48688727\n",
      "Iteration 1721, loss = 9069.25004519\n",
      "Iteration 1722, loss = 9048.02722642\n",
      "Iteration 1723, loss = 9026.87909784\n",
      "Iteration 1724, loss = 9005.67509442\n",
      "Iteration 1725, loss = 8984.75671898\n",
      "Iteration 1726, loss = 8963.90487103\n",
      "Iteration 1727, loss = 8943.04668051\n",
      "Iteration 1728, loss = 8922.20170039\n",
      "Iteration 1729, loss = 8901.42840270\n",
      "Iteration 1730, loss = 8880.68587187\n",
      "Iteration 1731, loss = 8860.03135146\n",
      "Iteration 1732, loss = 8839.44330285\n",
      "Iteration 1733, loss = 8818.89233990\n",
      "Iteration 1734, loss = 8798.39248565\n",
      "Iteration 1735, loss = 8777.92515091\n",
      "Iteration 1736, loss = 8757.47055253\n",
      "Iteration 1737, loss = 8737.21895128\n",
      "Iteration 1738, loss = 8717.11615578\n",
      "Iteration 1739, loss = 8697.09549983\n",
      "Iteration 1740, loss = 8677.12272826\n",
      "Iteration 1741, loss = 8657.13421972\n",
      "Iteration 1742, loss = 8637.17563290\n",
      "Iteration 1743, loss = 8617.22283739\n",
      "Iteration 1744, loss = 8597.26906510\n",
      "Iteration 1745, loss = 8577.36700035\n",
      "Iteration 1746, loss = 8557.56496607\n",
      "Iteration 1747, loss = 8537.89360465\n",
      "Iteration 1748, loss = 8518.25182100\n",
      "Iteration 1749, loss = 8498.53585828\n",
      "Iteration 1750, loss = 8478.80284518\n",
      "Iteration 1751, loss = 8459.13778954\n",
      "Iteration 1752, loss = 8439.61515354\n",
      "Iteration 1753, loss = 8420.11488241\n",
      "Iteration 1754, loss = 8400.70979257\n",
      "Iteration 1755, loss = 8381.42362858\n",
      "Iteration 1756, loss = 8362.24175084\n",
      "Iteration 1757, loss = 8343.04824500\n",
      "Iteration 1758, loss = 8323.92663965\n",
      "Iteration 1759, loss = 8304.75810627\n",
      "Iteration 1760, loss = 8285.64718387\n",
      "Iteration 1761, loss = 8266.63955276\n",
      "Iteration 1762, loss = 8247.64072758\n",
      "Iteration 1763, loss = 8228.66940769\n",
      "Iteration 1764, loss = 8209.81091938\n",
      "Iteration 1765, loss = 8191.04778213\n",
      "Iteration 1766, loss = 8172.29318347\n",
      "Iteration 1767, loss = 8153.56507036\n",
      "Iteration 1768, loss = 8134.96161030\n",
      "Iteration 1769, loss = 8116.41318765\n",
      "Iteration 1770, loss = 8097.81141599\n",
      "Iteration 1771, loss = 8079.27662208\n",
      "Iteration 1772, loss = 8060.77069441\n",
      "Iteration 1773, loss = 8042.29696176\n",
      "Iteration 1774, loss = 8023.84492393\n",
      "Iteration 1775, loss = 8005.44619262\n",
      "Iteration 1776, loss = 7987.15232214\n",
      "Iteration 1777, loss = 7968.85207921\n",
      "Iteration 1778, loss = 7950.64181772\n",
      "Iteration 1779, loss = 7932.47852620\n",
      "Iteration 1780, loss = 7914.33487306\n",
      "Iteration 1781, loss = 7896.24347727\n",
      "Iteration 1782, loss = 7878.22193260\n",
      "Iteration 1783, loss = 7860.23624038\n",
      "Iteration 1784, loss = 7842.25571488\n",
      "Iteration 1785, loss = 7824.34242890\n",
      "Iteration 1786, loss = 7806.53999463\n",
      "Iteration 1787, loss = 7788.84478551\n",
      "Iteration 1788, loss = 7771.34242630\n",
      "Iteration 1789, loss = 7753.99861674\n",
      "Iteration 1790, loss = 7736.61056487\n",
      "Iteration 1791, loss = 7719.36359998\n",
      "Iteration 1792, loss = 7702.13538415\n",
      "Iteration 1793, loss = 7684.89351834\n",
      "Iteration 1794, loss = 7667.66046774\n",
      "Iteration 1795, loss = 7650.45094355\n",
      "Iteration 1796, loss = 7633.25477392\n",
      "Iteration 1797, loss = 7616.10519934\n",
      "Iteration 1798, loss = 7599.09070521\n",
      "Iteration 1799, loss = 7582.19508458\n",
      "Iteration 1800, loss = 7565.34804853\n",
      "Iteration 1801, loss = 7548.52810241\n",
      "Iteration 1802, loss = 7531.73771401\n",
      "Iteration 1803, loss = 7514.89378711\n",
      "Iteration 1804, loss = 7498.13511115\n",
      "Iteration 1805, loss = 7481.54932928\n",
      "Iteration 1806, loss = 7465.03891807\n",
      "Iteration 1807, loss = 7448.55778973\n",
      "Iteration 1808, loss = 7431.99496422\n",
      "Iteration 1809, loss = 7415.52415034\n",
      "Iteration 1810, loss = 7399.09904704\n",
      "Iteration 1811, loss = 7382.71188960\n",
      "Iteration 1812, loss = 7366.36182389\n",
      "Iteration 1813, loss = 7350.06567001\n",
      "Iteration 1814, loss = 7333.77936736\n",
      "Iteration 1815, loss = 7317.52151938\n",
      "Iteration 1816, loss = 7301.30671791\n",
      "Iteration 1817, loss = 7285.11988142\n",
      "Iteration 1818, loss = 7269.02771541\n",
      "Iteration 1819, loss = 7253.04085150\n",
      "Iteration 1820, loss = 7237.08005900\n",
      "Iteration 1821, loss = 7221.16053360\n",
      "Iteration 1822, loss = 7205.26262271\n",
      "Iteration 1823, loss = 7189.43765156\n",
      "Iteration 1824, loss = 7173.62493983\n",
      "Iteration 1825, loss = 7157.79678454\n",
      "Iteration 1826, loss = 7142.04178515\n",
      "Iteration 1827, loss = 7126.36737725\n",
      "Iteration 1828, loss = 7110.72258534\n",
      "Iteration 1829, loss = 7095.08263821\n",
      "Iteration 1830, loss = 7079.49231752\n",
      "Iteration 1831, loss = 7063.93547667\n",
      "Iteration 1832, loss = 7048.33695788\n",
      "Iteration 1833, loss = 7032.62219012\n",
      "Iteration 1834, loss = 7016.92300775\n",
      "Iteration 1835, loss = 7001.25352912\n",
      "Iteration 1836, loss = 6985.59364032\n",
      "Iteration 1837, loss = 6969.93590669\n",
      "Iteration 1838, loss = 6954.27260026\n",
      "Iteration 1839, loss = 6938.64159479\n",
      "Iteration 1840, loss = 6922.96062981\n",
      "Iteration 1841, loss = 6907.29878577\n",
      "Iteration 1842, loss = 6891.65691039\n",
      "Iteration 1843, loss = 6876.06156028\n",
      "Iteration 1844, loss = 6860.48753928\n",
      "Iteration 1845, loss = 6844.93920301\n",
      "Iteration 1846, loss = 6829.41549850\n",
      "Iteration 1847, loss = 6813.94230669\n",
      "Iteration 1848, loss = 6798.49622901\n",
      "Iteration 1849, loss = 6783.09974831\n",
      "Iteration 1850, loss = 6767.74839252\n",
      "Iteration 1851, loss = 6752.39957267\n",
      "Iteration 1852, loss = 6737.04661184\n",
      "Iteration 1853, loss = 6721.73689595\n",
      "Iteration 1854, loss = 6706.46343134\n",
      "Iteration 1855, loss = 6691.24649304\n",
      "Iteration 1856, loss = 6676.10393097\n",
      "Iteration 1857, loss = 6660.90339076\n",
      "Iteration 1858, loss = 6645.74945759\n",
      "Iteration 1859, loss = 6630.69279925\n",
      "Iteration 1860, loss = 6615.66126219\n",
      "Iteration 1861, loss = 6600.67597219\n",
      "Iteration 1862, loss = 6585.73556446\n",
      "Iteration 1863, loss = 6570.84227412\n",
      "Iteration 1864, loss = 6555.99674582\n",
      "Iteration 1865, loss = 6541.12381673\n",
      "Iteration 1866, loss = 6526.28823546\n",
      "Iteration 1867, loss = 6511.49272881\n",
      "Iteration 1868, loss = 6496.73694887\n",
      "Iteration 1869, loss = 6482.03219878\n",
      "Iteration 1870, loss = 6467.33527830\n",
      "Iteration 1871, loss = 6452.67935566\n",
      "Iteration 1872, loss = 6438.08582055\n",
      "Iteration 1873, loss = 6423.54123172\n",
      "Iteration 1874, loss = 6409.03284131\n",
      "Iteration 1875, loss = 6394.55554315\n",
      "Iteration 1876, loss = 6380.14195447\n",
      "Iteration 1877, loss = 6365.74887393\n",
      "Iteration 1878, loss = 6351.41903969\n",
      "Iteration 1879, loss = 6337.11189717\n",
      "Iteration 1880, loss = 6322.86108971\n",
      "Iteration 1881, loss = 6308.65057158\n",
      "Iteration 1882, loss = 6294.51216285\n",
      "Iteration 1883, loss = 6280.43396187\n",
      "Iteration 1884, loss = 6266.39501081\n",
      "Iteration 1885, loss = 6252.38782073\n",
      "Iteration 1886, loss = 6238.40817258\n",
      "Iteration 1887, loss = 6224.49962041\n",
      "Iteration 1888, loss = 6210.63082644\n",
      "Iteration 1889, loss = 6196.80666686\n",
      "Iteration 1890, loss = 6183.02288731\n",
      "Iteration 1891, loss = 6169.23442854\n",
      "Iteration 1892, loss = 6155.43444785\n",
      "Iteration 1893, loss = 6141.68734288\n",
      "Iteration 1894, loss = 6127.95479817\n",
      "Iteration 1895, loss = 6114.28339590\n",
      "Iteration 1896, loss = 6100.61918685\n",
      "Iteration 1897, loss = 6086.97008663\n",
      "Iteration 1898, loss = 6073.31330203\n",
      "Iteration 1899, loss = 6059.64463921\n",
      "Iteration 1900, loss = 6046.01451358\n",
      "Iteration 1901, loss = 6032.41062388\n",
      "Iteration 1902, loss = 6018.83627273\n",
      "Iteration 1903, loss = 6005.28320675\n",
      "Iteration 1904, loss = 5991.77348472\n",
      "Iteration 1905, loss = 5978.31985274\n",
      "Iteration 1906, loss = 5964.88923884\n",
      "Iteration 1907, loss = 5951.51997616\n",
      "Iteration 1908, loss = 5938.17279472\n",
      "Iteration 1909, loss = 5924.85858615\n",
      "Iteration 1910, loss = 5911.58180630\n",
      "Iteration 1911, loss = 5898.32259096\n",
      "Iteration 1912, loss = 5885.05663409\n",
      "Iteration 1913, loss = 5871.85035344\n",
      "Iteration 1914, loss = 5858.71586258\n",
      "Iteration 1915, loss = 5845.60119286\n",
      "Iteration 1916, loss = 5832.51302249\n",
      "Iteration 1917, loss = 5819.43369614\n",
      "Iteration 1918, loss = 5806.29964033\n",
      "Iteration 1919, loss = 5793.20963582\n",
      "Iteration 1920, loss = 5780.12194295\n",
      "Iteration 1921, loss = 5767.03849167\n",
      "Iteration 1922, loss = 5753.93638636\n",
      "Iteration 1923, loss = 5740.81526571\n",
      "Iteration 1924, loss = 5727.71025942\n",
      "Iteration 1925, loss = 5714.58054283\n",
      "Iteration 1926, loss = 5701.44431484\n",
      "Iteration 1927, loss = 5688.31868704\n",
      "Iteration 1928, loss = 5675.21377982\n",
      "Iteration 1929, loss = 5662.13189705\n",
      "Iteration 1930, loss = 5649.08164394\n",
      "Iteration 1931, loss = 5636.07370861\n",
      "Iteration 1932, loss = 5623.06194613\n",
      "Iteration 1933, loss = 5610.07728627\n",
      "Iteration 1934, loss = 5597.12414064\n",
      "Iteration 1935, loss = 5584.19222185\n",
      "Iteration 1936, loss = 5571.28558095\n",
      "Iteration 1937, loss = 5558.37162096\n",
      "Iteration 1938, loss = 5545.47653317\n",
      "Iteration 1939, loss = 5532.65897563\n",
      "Iteration 1940, loss = 5519.85205503\n",
      "Iteration 1941, loss = 5507.08369722\n",
      "Iteration 1942, loss = 5494.28837881\n",
      "Iteration 1943, loss = 5481.49969706\n",
      "Iteration 1944, loss = 5468.75687544\n",
      "Iteration 1945, loss = 5456.05823146\n",
      "Iteration 1946, loss = 5443.32764603\n",
      "Iteration 1947, loss = 5430.58106777\n",
      "Iteration 1948, loss = 5417.87100208\n",
      "Iteration 1949, loss = 5405.17213446\n",
      "Iteration 1950, loss = 5392.49570807\n",
      "Iteration 1951, loss = 5379.82488529\n",
      "Iteration 1952, loss = 5367.19678734\n",
      "Iteration 1953, loss = 5354.59925666\n",
      "Iteration 1954, loss = 5342.00490130\n",
      "Iteration 1955, loss = 5329.45120903\n",
      "Iteration 1956, loss = 5316.98045366\n",
      "Iteration 1957, loss = 5304.53868052\n",
      "Iteration 1958, loss = 5292.18995855\n",
      "Iteration 1959, loss = 5279.85374166\n",
      "Iteration 1960, loss = 5267.55828117\n",
      "Iteration 1961, loss = 5255.29444889\n",
      "Iteration 1962, loss = 5243.08557893\n",
      "Iteration 1963, loss = 5230.88090805\n",
      "Iteration 1964, loss = 5218.67605547\n",
      "Iteration 1965, loss = 5206.44536646\n",
      "Iteration 1966, loss = 5194.26240239\n",
      "Iteration 1967, loss = 5182.13127829\n",
      "Iteration 1968, loss = 5170.08376963\n",
      "Iteration 1969, loss = 5158.11194855\n",
      "Iteration 1970, loss = 5146.14421995\n",
      "Iteration 1971, loss = 5134.24961787\n",
      "Iteration 1972, loss = 5122.39336489\n",
      "Iteration 1973, loss = 5110.56121916\n",
      "Iteration 1974, loss = 5098.75841299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1975, loss = 5086.97041567\n",
      "Iteration 1976, loss = 5075.21941351\n",
      "Iteration 1977, loss = 5063.52249903\n",
      "Iteration 1978, loss = 5051.85248996\n",
      "Iteration 1979, loss = 5040.19294033\n",
      "Iteration 1980, loss = 5028.64102469\n",
      "Iteration 1981, loss = 5017.13619825\n",
      "Iteration 1982, loss = 5005.61292731\n",
      "Iteration 1983, loss = 4994.09393004\n",
      "Iteration 1984, loss = 4982.58561698\n",
      "Iteration 1985, loss = 4971.14444214\n",
      "Iteration 1986, loss = 4959.71497668\n",
      "Iteration 1987, loss = 4948.28203235\n",
      "Iteration 1988, loss = 4937.00567760\n",
      "Iteration 1989, loss = 4925.74015622\n",
      "Iteration 1990, loss = 4914.53627463\n",
      "Iteration 1991, loss = 4903.34943138\n",
      "Iteration 1992, loss = 4892.17499850\n",
      "Iteration 1993, loss = 4881.05096599\n",
      "Iteration 1994, loss = 4869.97115015\n",
      "Iteration 1995, loss = 4858.93189154\n",
      "Iteration 1996, loss = 4847.91562241\n",
      "Iteration 1997, loss = 4836.94829295\n",
      "Iteration 1998, loss = 4825.99809288\n",
      "Iteration 1999, loss = 4815.04847275\n",
      "Iteration 2000, loss = 4804.09524704\n",
      "Iteration 2001, loss = 4793.16521930\n",
      "Iteration 2002, loss = 4782.26851320\n",
      "Iteration 2003, loss = 4771.40139805\n",
      "Iteration 2004, loss = 4760.55693531\n",
      "Iteration 2005, loss = 4749.74478684\n",
      "Iteration 2006, loss = 4738.96672171\n",
      "Iteration 2007, loss = 4728.28698543\n",
      "Iteration 2008, loss = 4717.63236303\n",
      "Iteration 2009, loss = 4707.00930632\n",
      "Iteration 2010, loss = 4696.41574022\n",
      "Iteration 2011, loss = 4685.85554813\n",
      "Iteration 2012, loss = 4675.31709123\n",
      "Iteration 2013, loss = 4664.81376667\n",
      "Iteration 2014, loss = 4654.34065135\n",
      "Iteration 2015, loss = 4643.92539713\n",
      "Iteration 2016, loss = 4633.54127476\n",
      "Iteration 2017, loss = 4623.19623934\n",
      "Iteration 2018, loss = 4612.86453392\n",
      "Iteration 2019, loss = 4602.56669130\n",
      "Iteration 2020, loss = 4592.29229522\n",
      "Iteration 2021, loss = 4582.05886162\n",
      "Iteration 2022, loss = 4571.84748567\n",
      "Iteration 2023, loss = 4561.65796977\n",
      "Iteration 2024, loss = 4551.49316707\n",
      "Iteration 2025, loss = 4541.35929133\n",
      "Iteration 2026, loss = 4531.26700622\n",
      "Iteration 2027, loss = 4521.20577402\n",
      "Iteration 2028, loss = 4511.12642909\n",
      "Iteration 2029, loss = 4501.06956941\n",
      "Iteration 2030, loss = 4491.04025408\n",
      "Iteration 2031, loss = 4481.03585223\n",
      "Iteration 2032, loss = 4471.04447030\n",
      "Iteration 2033, loss = 4461.08628156\n",
      "Iteration 2034, loss = 4451.14742093\n",
      "Iteration 2035, loss = 4441.20456891\n",
      "Iteration 2036, loss = 4431.26969556\n",
      "Iteration 2037, loss = 4421.35643897\n",
      "Iteration 2038, loss = 4411.46089942\n",
      "Iteration 2039, loss = 4401.59344717\n",
      "Iteration 2040, loss = 4391.75400040\n",
      "Iteration 2041, loss = 4381.95154916\n",
      "Iteration 2042, loss = 4372.15356428\n",
      "Iteration 2043, loss = 4362.40201073\n",
      "Iteration 2044, loss = 4352.67874159\n",
      "Iteration 2045, loss = 4342.97361091\n",
      "Iteration 2046, loss = 4333.29594275\n",
      "Iteration 2047, loss = 4323.64551638\n",
      "Iteration 2048, loss = 4314.02071593\n",
      "Iteration 2049, loss = 4304.43044767\n",
      "Iteration 2050, loss = 4294.86067765\n",
      "Iteration 2051, loss = 4285.31894416\n",
      "Iteration 2052, loss = 4275.78467198\n",
      "Iteration 2053, loss = 4266.28770234\n",
      "Iteration 2054, loss = 4256.80400328\n",
      "Iteration 2055, loss = 4247.36369139\n",
      "Iteration 2056, loss = 4237.94680957\n",
      "Iteration 2057, loss = 4228.54485496\n",
      "Iteration 2058, loss = 4219.17503534\n",
      "Iteration 2059, loss = 4209.83780768\n",
      "Iteration 2060, loss = 4200.52928373\n",
      "Iteration 2061, loss = 4191.24704485\n",
      "Iteration 2062, loss = 4181.99039074\n",
      "Iteration 2063, loss = 4172.76379714\n",
      "Iteration 2064, loss = 4163.56170840\n",
      "Iteration 2065, loss = 4154.39403362\n",
      "Iteration 2066, loss = 4145.25226861\n",
      "Iteration 2067, loss = 4136.13767912\n",
      "Iteration 2068, loss = 4127.05072223\n",
      "Iteration 2069, loss = 4117.97795916\n",
      "Iteration 2070, loss = 4108.89786691\n",
      "Iteration 2071, loss = 4099.79218819\n",
      "Iteration 2072, loss = 4090.70671239\n",
      "Iteration 2073, loss = 4081.64088253\n",
      "Iteration 2074, loss = 4072.59635470\n",
      "Iteration 2075, loss = 4063.56945841\n",
      "Iteration 2076, loss = 4054.56252824\n",
      "Iteration 2077, loss = 4045.58182361\n",
      "Iteration 2078, loss = 4036.62270270\n",
      "Iteration 2079, loss = 4027.69243349\n",
      "Iteration 2080, loss = 4018.77716033\n",
      "Iteration 2081, loss = 4009.89397714\n",
      "Iteration 2082, loss = 4001.03797145\n",
      "Iteration 2083, loss = 3992.20297924\n",
      "Iteration 2084, loss = 3983.38352773\n",
      "Iteration 2085, loss = 3974.55220445\n",
      "Iteration 2086, loss = 3965.73728666\n",
      "Iteration 2087, loss = 3956.94444011\n",
      "Iteration 2088, loss = 3948.17354386\n",
      "Iteration 2089, loss = 3939.42437724\n",
      "Iteration 2090, loss = 3930.70060010\n",
      "Iteration 2091, loss = 3921.99652329\n",
      "Iteration 2092, loss = 3913.31631935\n",
      "Iteration 2093, loss = 3904.66084527\n",
      "Iteration 2094, loss = 3896.02928841\n",
      "Iteration 2095, loss = 3887.42529292\n",
      "Iteration 2096, loss = 3878.84594373\n",
      "Iteration 2097, loss = 3870.28777682\n",
      "Iteration 2098, loss = 3861.75805368\n",
      "Iteration 2099, loss = 3853.24849147\n",
      "Iteration 2100, loss = 3844.71487513\n",
      "Iteration 2101, loss = 3836.20176654\n",
      "Iteration 2102, loss = 3827.71314299\n",
      "Iteration 2103, loss = 3819.24398893\n",
      "Iteration 2104, loss = 3810.80250123\n",
      "Iteration 2105, loss = 3802.38186445\n",
      "Iteration 2106, loss = 3793.98309003\n",
      "Iteration 2107, loss = 3785.60455445\n",
      "Iteration 2108, loss = 3777.25639126\n",
      "Iteration 2109, loss = 3768.93144820\n",
      "Iteration 2110, loss = 3760.62900545\n",
      "Iteration 2111, loss = 3752.34833964\n",
      "Iteration 2112, loss = 3744.09095418\n",
      "Iteration 2113, loss = 3735.86620075\n",
      "Iteration 2114, loss = 3727.66604779\n",
      "Iteration 2115, loss = 3719.48591026\n",
      "Iteration 2116, loss = 3711.32999759\n",
      "Iteration 2117, loss = 3703.19951481\n",
      "Iteration 2118, loss = 3695.08997738\n",
      "Iteration 2119, loss = 3687.01318135\n",
      "Iteration 2120, loss = 3678.94751443\n",
      "Iteration 2121, loss = 3670.87313344\n",
      "Iteration 2122, loss = 3662.81967958\n",
      "Iteration 2123, loss = 3654.78547409\n",
      "Iteration 2124, loss = 3646.77127987\n",
      "Iteration 2125, loss = 3638.77742566\n",
      "Iteration 2126, loss = 3630.76733110\n",
      "Iteration 2127, loss = 3622.74497269\n",
      "Iteration 2128, loss = 3614.73856987\n",
      "Iteration 2129, loss = 3606.74694418\n",
      "Iteration 2130, loss = 3598.76656167\n",
      "Iteration 2131, loss = 3590.81050787\n",
      "Iteration 2132, loss = 3582.87391183\n",
      "Iteration 2133, loss = 3574.95365511\n",
      "Iteration 2134, loss = 3567.05218178\n",
      "Iteration 2135, loss = 3559.15206234\n",
      "Iteration 2136, loss = 3551.26443921\n",
      "Iteration 2137, loss = 3543.39493207\n",
      "Iteration 2138, loss = 3535.54126699\n",
      "Iteration 2139, loss = 3527.70829858\n",
      "Iteration 2140, loss = 3519.89651815\n",
      "Iteration 2141, loss = 3512.10456505\n",
      "Iteration 2142, loss = 3504.33443362\n",
      "Iteration 2143, loss = 3496.58444502\n",
      "Iteration 2144, loss = 3488.85752438\n",
      "Iteration 2145, loss = 3481.15250210\n",
      "Iteration 2146, loss = 3473.46941555\n",
      "Iteration 2147, loss = 3465.80960916\n",
      "Iteration 2148, loss = 3458.16953630\n",
      "Iteration 2149, loss = 3450.56310907\n",
      "Iteration 2150, loss = 3442.95996624\n",
      "Iteration 2151, loss = 3435.35583295\n",
      "Iteration 2152, loss = 3427.77255438\n",
      "Iteration 2153, loss = 3420.20675536\n",
      "Iteration 2154, loss = 3412.66213591\n",
      "Iteration 2155, loss = 3405.13817537\n",
      "Iteration 2156, loss = 3397.63861998\n",
      "Iteration 2157, loss = 3390.16668019\n",
      "Iteration 2158, loss = 3382.71617441\n",
      "Iteration 2159, loss = 3375.29036017\n",
      "Iteration 2160, loss = 3367.88290345\n",
      "Iteration 2161, loss = 3360.50616634\n",
      "Iteration 2162, loss = 3353.15288732\n",
      "Iteration 2163, loss = 3345.82072736\n",
      "Iteration 2164, loss = 3338.50631244\n",
      "Iteration 2165, loss = 3331.20548307\n",
      "Iteration 2166, loss = 3323.92203678\n",
      "Iteration 2167, loss = 3316.65877262\n",
      "Iteration 2168, loss = 3309.41975647\n",
      "Iteration 2169, loss = 3302.20954012\n",
      "Iteration 2170, loss = 3295.03354519\n",
      "Iteration 2171, loss = 3287.87426090\n",
      "Iteration 2172, loss = 3280.70978761\n",
      "Iteration 2173, loss = 3273.55474366\n",
      "Iteration 2174, loss = 3266.41324080\n",
      "Iteration 2175, loss = 3259.29320465\n",
      "Iteration 2176, loss = 3252.19929210\n",
      "Iteration 2177, loss = 3245.13348715\n",
      "Iteration 2178, loss = 3238.08549006\n",
      "Iteration 2179, loss = 3231.05628440\n",
      "Iteration 2180, loss = 3224.04257613\n",
      "Iteration 2181, loss = 3217.05138539\n",
      "Iteration 2182, loss = 3210.08128574\n",
      "Iteration 2183, loss = 3203.13918445\n",
      "Iteration 2184, loss = 3196.21780609\n",
      "Iteration 2185, loss = 3189.31668796\n",
      "Iteration 2186, loss = 3182.43563594\n",
      "Iteration 2187, loss = 3175.57399364\n",
      "Iteration 2188, loss = 3168.73450730\n",
      "Iteration 2189, loss = 3161.91810126\n",
      "Iteration 2190, loss = 3155.12041339\n",
      "Iteration 2191, loss = 3148.34617342\n",
      "Iteration 2192, loss = 3141.59078919\n",
      "Iteration 2193, loss = 3134.85507976\n",
      "Iteration 2194, loss = 3128.13739724\n",
      "Iteration 2195, loss = 3121.44752099\n",
      "Iteration 2196, loss = 3114.78092411\n",
      "Iteration 2197, loss = 3108.13032786\n",
      "Iteration 2198, loss = 3101.49863865\n",
      "Iteration 2199, loss = 3094.88110783\n",
      "Iteration 2200, loss = 3088.28972476\n",
      "Iteration 2201, loss = 3081.71813531\n",
      "Iteration 2202, loss = 3075.16734486\n",
      "Iteration 2203, loss = 3068.63695987\n",
      "Iteration 2204, loss = 3062.13205937\n",
      "Iteration 2205, loss = 3055.64924536\n",
      "Iteration 2206, loss = 3049.18368068\n",
      "Iteration 2207, loss = 3042.71579946\n",
      "Iteration 2208, loss = 3036.26557514\n",
      "Iteration 2209, loss = 3029.83542594\n",
      "Iteration 2210, loss = 3023.42093295\n",
      "Iteration 2211, loss = 3016.99929492\n",
      "Iteration 2212, loss = 3010.59290043\n",
      "Iteration 2213, loss = 3004.18158052\n",
      "Iteration 2214, loss = 2997.78628125\n",
      "Iteration 2215, loss = 2991.40757259\n",
      "Iteration 2216, loss = 2985.04311075\n",
      "Iteration 2217, loss = 2978.69682226\n",
      "Iteration 2218, loss = 2972.36538422\n",
      "Iteration 2219, loss = 2966.03490863\n",
      "Iteration 2220, loss = 2959.70128478\n",
      "Iteration 2221, loss = 2953.35748101\n",
      "Iteration 2222, loss = 2947.02843524\n",
      "Iteration 2223, loss = 2940.69723313\n",
      "Iteration 2224, loss = 2934.37305125\n",
      "Iteration 2225, loss = 2928.07224410\n",
      "Iteration 2226, loss = 2921.78314312\n",
      "Iteration 2227, loss = 2915.50670221\n",
      "Iteration 2228, loss = 2909.24394807\n",
      "Iteration 2229, loss = 2902.99424911\n",
      "Iteration 2230, loss = 2896.76032546\n",
      "Iteration 2231, loss = 2890.53915348\n",
      "Iteration 2232, loss = 2884.33544148\n",
      "Iteration 2233, loss = 2878.14249255\n",
      "Iteration 2234, loss = 2871.95939509\n",
      "Iteration 2235, loss = 2865.79500154\n",
      "Iteration 2236, loss = 2859.64614246\n",
      "Iteration 2237, loss = 2853.51192158\n",
      "Iteration 2238, loss = 2847.39341420\n",
      "Iteration 2239, loss = 2841.29608285\n",
      "Iteration 2240, loss = 2835.21284767\n",
      "Iteration 2241, loss = 2829.14701533\n",
      "Iteration 2242, loss = 2823.09686388\n",
      "Iteration 2243, loss = 2817.06801041\n",
      "Iteration 2244, loss = 2811.05565565\n",
      "Iteration 2245, loss = 2805.06125089\n",
      "Iteration 2246, loss = 2799.08212454\n",
      "Iteration 2247, loss = 2793.11793780\n",
      "Iteration 2248, loss = 2787.17129891\n",
      "Iteration 2249, loss = 2781.21823507\n",
      "Iteration 2250, loss = 2775.26089072\n",
      "Iteration 2251, loss = 2769.31413598\n",
      "Iteration 2252, loss = 2763.38255934\n",
      "Iteration 2253, loss = 2757.46887264\n",
      "Iteration 2254, loss = 2751.56619020\n",
      "Iteration 2255, loss = 2745.67840503\n",
      "Iteration 2256, loss = 2739.80590204\n",
      "Iteration 2257, loss = 2733.95021527\n",
      "Iteration 2258, loss = 2728.10933692\n",
      "Iteration 2259, loss = 2722.28533458\n",
      "Iteration 2260, loss = 2716.47694767\n",
      "Iteration 2261, loss = 2710.68486221\n",
      "Iteration 2262, loss = 2704.90994725\n",
      "Iteration 2263, loss = 2699.14957846\n",
      "Iteration 2264, loss = 2693.40584302\n",
      "Iteration 2265, loss = 2687.67846796\n",
      "Iteration 2266, loss = 2681.96690178\n",
      "Iteration 2267, loss = 2676.27187282\n",
      "Iteration 2268, loss = 2670.59483391\n",
      "Iteration 2269, loss = 2664.93347894\n",
      "Iteration 2270, loss = 2659.29109725\n",
      "Iteration 2271, loss = 2653.66443733\n",
      "Iteration 2272, loss = 2648.05305357\n",
      "Iteration 2273, loss = 2642.44388202\n",
      "Iteration 2274, loss = 2636.84588180\n",
      "Iteration 2275, loss = 2631.25515856\n",
      "Iteration 2276, loss = 2625.67369794\n",
      "Iteration 2277, loss = 2620.10510359\n",
      "Iteration 2278, loss = 2614.55278679\n",
      "Iteration 2279, loss = 2609.01316583\n",
      "Iteration 2280, loss = 2603.48271149\n",
      "Iteration 2281, loss = 2597.95505207\n",
      "Iteration 2282, loss = 2592.43673616\n",
      "Iteration 2283, loss = 2586.92817732\n",
      "Iteration 2284, loss = 2581.43247880\n",
      "Iteration 2285, loss = 2575.94960290\n",
      "Iteration 2286, loss = 2570.47914376\n",
      "Iteration 2287, loss = 2565.02305121\n",
      "Iteration 2288, loss = 2559.57821903\n",
      "Iteration 2289, loss = 2554.14857482\n",
      "Iteration 2290, loss = 2548.73076032\n",
      "Iteration 2291, loss = 2543.31878745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2292, loss = 2537.91432523\n",
      "Iteration 2293, loss = 2532.51989415\n",
      "Iteration 2294, loss = 2527.14232843\n",
      "Iteration 2295, loss = 2521.77921462\n",
      "Iteration 2296, loss = 2516.42593790\n",
      "Iteration 2297, loss = 2511.08551416\n",
      "Iteration 2298, loss = 2505.75193115\n",
      "Iteration 2299, loss = 2500.42906365\n",
      "Iteration 2300, loss = 2495.11949141\n",
      "Iteration 2301, loss = 2489.82253241\n",
      "Iteration 2302, loss = 2484.52805317\n",
      "Iteration 2303, loss = 2479.23444190\n",
      "Iteration 2304, loss = 2473.95096450\n",
      "Iteration 2305, loss = 2468.68011086\n",
      "Iteration 2306, loss = 2463.41995324\n",
      "Iteration 2307, loss = 2458.17334956\n",
      "Iteration 2308, loss = 2452.93805744\n",
      "Iteration 2309, loss = 2447.71485268\n",
      "Iteration 2310, loss = 2442.50300378\n",
      "Iteration 2311, loss = 2437.30205740\n",
      "Iteration 2312, loss = 2432.11585993\n",
      "Iteration 2313, loss = 2426.94310567\n",
      "Iteration 2314, loss = 2421.78466575\n",
      "Iteration 2315, loss = 2416.63712656\n",
      "Iteration 2316, loss = 2411.50519598\n",
      "Iteration 2317, loss = 2406.38640028\n",
      "Iteration 2318, loss = 2401.28145353\n",
      "Iteration 2319, loss = 2396.19136918\n",
      "Iteration 2320, loss = 2391.11326646\n",
      "Iteration 2321, loss = 2386.03129342\n",
      "Iteration 2322, loss = 2380.96037043\n",
      "Iteration 2323, loss = 2375.89881492\n",
      "Iteration 2324, loss = 2370.84836125\n",
      "Iteration 2325, loss = 2365.81011235\n",
      "Iteration 2326, loss = 2360.78128569\n",
      "Iteration 2327, loss = 2355.76790191\n",
      "Iteration 2328, loss = 2350.76564493\n",
      "Iteration 2329, loss = 2345.77335773\n",
      "Iteration 2330, loss = 2340.79545141\n",
      "Iteration 2331, loss = 2335.83028728\n",
      "Iteration 2332, loss = 2330.87618939\n",
      "Iteration 2333, loss = 2325.93411957\n",
      "Iteration 2334, loss = 2321.00749870\n",
      "Iteration 2335, loss = 2316.09324703\n",
      "Iteration 2336, loss = 2311.19056972\n",
      "Iteration 2337, loss = 2306.30217242\n",
      "Iteration 2338, loss = 2301.42969979\n",
      "Iteration 2339, loss = 2296.56766044\n",
      "Iteration 2340, loss = 2291.71587120\n",
      "Iteration 2341, loss = 2286.85692933\n",
      "Iteration 2342, loss = 2282.00978356\n",
      "Iteration 2343, loss = 2277.17338855\n",
      "Iteration 2344, loss = 2272.34967383\n",
      "Iteration 2345, loss = 2267.53760956\n",
      "Iteration 2346, loss = 2262.73901369\n",
      "Iteration 2347, loss = 2257.95543354\n",
      "Iteration 2348, loss = 2253.18273225\n",
      "Iteration 2349, loss = 2248.41423470\n",
      "Iteration 2350, loss = 2243.64723098\n",
      "Iteration 2351, loss = 2238.88786955\n",
      "Iteration 2352, loss = 2234.15424131\n",
      "Iteration 2353, loss = 2229.43961100\n",
      "Iteration 2354, loss = 2224.74305752\n",
      "Iteration 2355, loss = 2220.06542874\n",
      "Iteration 2356, loss = 2215.40908413\n",
      "Iteration 2357, loss = 2210.76639467\n",
      "Iteration 2358, loss = 2206.13241258\n",
      "Iteration 2359, loss = 2201.50662724\n",
      "Iteration 2360, loss = 2196.88941470\n",
      "Iteration 2361, loss = 2192.28844990\n",
      "Iteration 2362, loss = 2187.70489441\n",
      "Iteration 2363, loss = 2183.13725264\n",
      "Iteration 2364, loss = 2178.58296204\n",
      "Iteration 2365, loss = 2174.03970513\n",
      "Iteration 2366, loss = 2169.50687209\n",
      "Iteration 2367, loss = 2164.98901001\n",
      "Iteration 2368, loss = 2160.48165305\n",
      "Iteration 2369, loss = 2155.98718747\n",
      "Iteration 2370, loss = 2151.50796613\n",
      "Iteration 2371, loss = 2147.04198882\n",
      "Iteration 2372, loss = 2142.58873394\n",
      "Iteration 2373, loss = 2138.14463130\n",
      "Iteration 2374, loss = 2133.71541412\n",
      "Iteration 2375, loss = 2129.29889511\n",
      "Iteration 2376, loss = 2124.89417223\n",
      "Iteration 2377, loss = 2120.50274970\n",
      "Iteration 2378, loss = 2116.12526906\n",
      "Iteration 2379, loss = 2111.75911286\n",
      "Iteration 2380, loss = 2107.40473942\n",
      "Iteration 2381, loss = 2103.05992545\n",
      "Iteration 2382, loss = 2098.73155435\n",
      "Iteration 2383, loss = 2094.41475018\n",
      "Iteration 2384, loss = 2090.11130209\n",
      "Iteration 2385, loss = 2085.81881104\n",
      "Iteration 2386, loss = 2081.53896299\n",
      "Iteration 2387, loss = 2077.27065500\n",
      "Iteration 2388, loss = 2073.01353269\n",
      "Iteration 2389, loss = 2068.76958908\n",
      "Iteration 2390, loss = 2064.53655514\n",
      "Iteration 2391, loss = 2060.30428139\n",
      "Iteration 2392, loss = 2056.08235031\n",
      "Iteration 2393, loss = 2051.88611073\n",
      "Iteration 2394, loss = 2047.70286271\n",
      "Iteration 2395, loss = 2043.53150638\n",
      "Iteration 2396, loss = 2039.37182609\n",
      "Iteration 2397, loss = 2035.21954473\n",
      "Iteration 2398, loss = 2031.06638661\n",
      "Iteration 2399, loss = 2026.93020725\n",
      "Iteration 2400, loss = 2022.82268547\n",
      "Iteration 2401, loss = 2018.72845718\n",
      "Iteration 2402, loss = 2014.63713358\n",
      "Iteration 2403, loss = 2010.55390986\n",
      "Iteration 2404, loss = 2006.48081561\n",
      "Iteration 2405, loss = 2002.43202423\n",
      "Iteration 2406, loss = 1998.40082398\n",
      "Iteration 2407, loss = 1994.38041531\n",
      "Iteration 2408, loss = 1990.37324255\n",
      "Iteration 2409, loss = 1986.36915811\n",
      "Iteration 2410, loss = 1982.36094269\n",
      "Iteration 2411, loss = 1978.36447306\n",
      "Iteration 2412, loss = 1974.37734542\n",
      "Iteration 2413, loss = 1970.39221853\n",
      "Iteration 2414, loss = 1966.41692178\n",
      "Iteration 2415, loss = 1962.45040759\n",
      "Iteration 2416, loss = 1958.49077308\n",
      "Iteration 2417, loss = 1954.54211831\n",
      "Iteration 2418, loss = 1950.59882755\n",
      "Iteration 2419, loss = 1946.65934848\n",
      "Iteration 2420, loss = 1942.73046199\n",
      "Iteration 2421, loss = 1938.81063857\n",
      "Iteration 2422, loss = 1934.89945508\n",
      "Iteration 2423, loss = 1930.99693775\n",
      "Iteration 2424, loss = 1927.10477928\n",
      "Iteration 2425, loss = 1923.22285957\n",
      "Iteration 2426, loss = 1919.34990987\n",
      "Iteration 2427, loss = 1915.48891789\n",
      "Iteration 2428, loss = 1911.63764108\n",
      "Iteration 2429, loss = 1907.79571267\n",
      "Iteration 2430, loss = 1903.96580570\n",
      "Iteration 2431, loss = 1900.14538691\n",
      "Iteration 2432, loss = 1896.33405503\n",
      "Iteration 2433, loss = 1892.53556100\n",
      "Iteration 2434, loss = 1888.74668395\n",
      "Iteration 2435, loss = 1884.96362935\n",
      "Iteration 2436, loss = 1881.18944031\n",
      "Iteration 2437, loss = 1877.42654428\n",
      "Iteration 2438, loss = 1873.67286152\n",
      "Iteration 2439, loss = 1869.92924631\n",
      "Iteration 2440, loss = 1866.19536415\n",
      "Iteration 2441, loss = 1862.47386787\n",
      "Iteration 2442, loss = 1858.76118137\n",
      "Iteration 2443, loss = 1855.05931584\n",
      "Iteration 2444, loss = 1851.36583776\n",
      "Iteration 2445, loss = 1847.68367223\n",
      "Iteration 2446, loss = 1844.01242584\n",
      "Iteration 2447, loss = 1840.35213597\n",
      "Iteration 2448, loss = 1836.70225183\n",
      "Iteration 2449, loss = 1833.06096582\n",
      "Iteration 2450, loss = 1829.43085746\n",
      "Iteration 2451, loss = 1825.81260579\n",
      "Iteration 2452, loss = 1822.20340777\n",
      "Iteration 2453, loss = 1818.62022156\n",
      "Iteration 2454, loss = 1815.04649039\n",
      "Iteration 2455, loss = 1811.48286320\n",
      "Iteration 2456, loss = 1807.92992513\n",
      "Iteration 2457, loss = 1804.38758328\n",
      "Iteration 2458, loss = 1800.85533882\n",
      "Iteration 2459, loss = 1797.33304894\n",
      "Iteration 2460, loss = 1793.82124688\n",
      "Iteration 2461, loss = 1790.31529434\n",
      "Iteration 2462, loss = 1786.80963805\n",
      "Iteration 2463, loss = 1783.31403581\n",
      "Iteration 2464, loss = 1779.82746812\n",
      "Iteration 2465, loss = 1776.35134795\n",
      "Iteration 2466, loss = 1772.88340053\n",
      "Iteration 2467, loss = 1769.42595859\n",
      "Iteration 2468, loss = 1765.97741314\n",
      "Iteration 2469, loss = 1762.53760105\n",
      "Iteration 2470, loss = 1759.10642622\n",
      "Iteration 2471, loss = 1755.68549602\n",
      "Iteration 2472, loss = 1752.27785220\n",
      "Iteration 2473, loss = 1748.87363473\n",
      "Iteration 2474, loss = 1745.46849865\n",
      "Iteration 2475, loss = 1742.07137470\n",
      "Iteration 2476, loss = 1738.68256714\n",
      "Iteration 2477, loss = 1735.30092899\n",
      "Iteration 2478, loss = 1731.92919695\n",
      "Iteration 2479, loss = 1728.56954945\n",
      "Iteration 2480, loss = 1725.21680667\n",
      "Iteration 2481, loss = 1721.87078619\n",
      "Iteration 2482, loss = 1718.53471216\n",
      "Iteration 2483, loss = 1715.20984036\n",
      "Iteration 2484, loss = 1711.89370007\n",
      "Iteration 2485, loss = 1708.58616816\n",
      "Iteration 2486, loss = 1705.28700851\n",
      "Iteration 2487, loss = 1701.99419355\n",
      "Iteration 2488, loss = 1698.70550297\n",
      "Iteration 2489, loss = 1695.42672721\n",
      "Iteration 2490, loss = 1692.15914692\n",
      "Iteration 2491, loss = 1688.89603887\n",
      "Iteration 2492, loss = 1685.64189136\n",
      "Iteration 2493, loss = 1682.39911478\n",
      "Iteration 2494, loss = 1679.16399024\n",
      "Iteration 2495, loss = 1675.93145442\n",
      "Iteration 2496, loss = 1672.68342308\n",
      "Iteration 2497, loss = 1669.42623872\n",
      "Iteration 2498, loss = 1666.15769456\n",
      "Iteration 2499, loss = 1662.87862933\n",
      "Iteration 2500, loss = 1659.59078462\n",
      "Iteration 2501, loss = 1656.29630644\n",
      "Iteration 2502, loss = 1653.00149709\n",
      "Iteration 2503, loss = 1649.70918837\n",
      "Iteration 2504, loss = 1646.41831705\n",
      "Iteration 2505, loss = 1643.13216387\n",
      "Iteration 2506, loss = 1639.84850413\n",
      "Iteration 2507, loss = 1636.57042471\n",
      "Iteration 2508, loss = 1633.29722313\n",
      "Iteration 2509, loss = 1630.02746415\n",
      "Iteration 2510, loss = 1626.76336994\n",
      "Iteration 2511, loss = 1623.50298964\n",
      "Iteration 2512, loss = 1620.24655279\n",
      "Iteration 2513, loss = 1616.99471826\n",
      "Iteration 2514, loss = 1613.74910563\n",
      "Iteration 2515, loss = 1610.50935967\n",
      "Iteration 2516, loss = 1607.27556295\n",
      "Iteration 2517, loss = 1604.04973481\n",
      "Iteration 2518, loss = 1600.83112163\n",
      "Iteration 2519, loss = 1597.61960205\n",
      "Iteration 2520, loss = 1594.41342552\n",
      "Iteration 2521, loss = 1591.20500959\n",
      "Iteration 2522, loss = 1588.00321637\n",
      "Iteration 2523, loss = 1584.81034051\n",
      "Iteration 2524, loss = 1581.62728010\n",
      "Iteration 2525, loss = 1578.45329344\n",
      "Iteration 2526, loss = 1575.28782922\n",
      "Iteration 2527, loss = 1572.12772999\n",
      "Iteration 2528, loss = 1568.96193773\n",
      "Iteration 2529, loss = 1565.77543818\n",
      "Iteration 2530, loss = 1562.58877149\n",
      "Iteration 2531, loss = 1559.41212714\n",
      "Iteration 2532, loss = 1556.25143582\n",
      "Iteration 2533, loss = 1553.10921800\n",
      "Iteration 2534, loss = 1549.97641267\n",
      "Iteration 2535, loss = 1546.84454628\n",
      "Iteration 2536, loss = 1543.71259921\n",
      "Iteration 2537, loss = 1540.58474448\n",
      "Iteration 2538, loss = 1537.46750007\n",
      "Iteration 2539, loss = 1534.36411846\n",
      "Iteration 2540, loss = 1531.27320644\n",
      "Iteration 2541, loss = 1528.18972348\n",
      "Iteration 2542, loss = 1525.11374878\n",
      "Iteration 2543, loss = 1522.04603431\n",
      "Iteration 2544, loss = 1518.98696818\n",
      "Iteration 2545, loss = 1515.94045307\n",
      "Iteration 2546, loss = 1512.90377800\n",
      "Iteration 2547, loss = 1509.87544812\n",
      "Iteration 2548, loss = 1506.85245707\n",
      "Iteration 2549, loss = 1503.83627366\n",
      "Iteration 2550, loss = 1500.82949000\n",
      "Iteration 2551, loss = 1497.83286629\n",
      "Iteration 2552, loss = 1494.84684945\n",
      "Iteration 2553, loss = 1491.86925423\n",
      "Iteration 2554, loss = 1488.89925902\n",
      "Iteration 2555, loss = 1485.93753409\n",
      "Iteration 2556, loss = 1482.98331924\n",
      "Iteration 2557, loss = 1480.03882552\n",
      "Iteration 2558, loss = 1477.10365266\n",
      "Iteration 2559, loss = 1474.17718020\n",
      "Iteration 2560, loss = 1471.25933565\n",
      "Iteration 2561, loss = 1468.34746451\n",
      "Iteration 2562, loss = 1465.43733276\n",
      "Iteration 2563, loss = 1462.53547758\n",
      "Iteration 2564, loss = 1459.64243903\n",
      "Iteration 2565, loss = 1456.75657009\n",
      "Iteration 2566, loss = 1453.87936845\n",
      "Iteration 2567, loss = 1451.00941934\n",
      "Iteration 2568, loss = 1448.14629360\n",
      "Iteration 2569, loss = 1445.29331381\n",
      "Iteration 2570, loss = 1442.44821874\n",
      "Iteration 2571, loss = 1439.61163108\n",
      "Iteration 2572, loss = 1436.78316209\n",
      "Iteration 2573, loss = 1433.96208977\n",
      "Iteration 2574, loss = 1431.14990753\n",
      "Iteration 2575, loss = 1428.34528312\n",
      "Iteration 2576, loss = 1425.55642675\n",
      "Iteration 2577, loss = 1422.77874869\n",
      "Iteration 2578, loss = 1420.00788990\n",
      "Iteration 2579, loss = 1417.24484023\n",
      "Iteration 2580, loss = 1414.49081801\n",
      "Iteration 2581, loss = 1411.74630240\n",
      "Iteration 2582, loss = 1409.00948526\n",
      "Iteration 2583, loss = 1406.27951862\n",
      "Iteration 2584, loss = 1403.55804640\n",
      "Iteration 2585, loss = 1400.84502452\n",
      "Iteration 2586, loss = 1398.14005081\n",
      "Iteration 2587, loss = 1395.44384000\n",
      "Iteration 2588, loss = 1392.75630384\n",
      "Iteration 2589, loss = 1390.07063705\n",
      "Iteration 2590, loss = 1387.38764498\n",
      "Iteration 2591, loss = 1384.71144229\n",
      "Iteration 2592, loss = 1382.04395780\n",
      "Iteration 2593, loss = 1379.38284857\n",
      "Iteration 2594, loss = 1376.72909143\n",
      "Iteration 2595, loss = 1374.08273163\n",
      "Iteration 2596, loss = 1371.44473867\n",
      "Iteration 2597, loss = 1368.81398021\n",
      "Iteration 2598, loss = 1366.18999134\n",
      "Iteration 2599, loss = 1363.58160564\n",
      "Iteration 2600, loss = 1360.98968330\n",
      "Iteration 2601, loss = 1358.39558550\n",
      "Iteration 2602, loss = 1355.80056139\n",
      "Iteration 2603, loss = 1353.21293833\n",
      "Iteration 2604, loss = 1350.64504106\n",
      "Iteration 2605, loss = 1348.08239533\n",
      "Iteration 2606, loss = 1345.52537035\n",
      "Iteration 2607, loss = 1342.97433047\n",
      "Iteration 2608, loss = 1340.43041073\n",
      "Iteration 2609, loss = 1337.89388735\n",
      "Iteration 2610, loss = 1335.36402328\n",
      "Iteration 2611, loss = 1332.84167116\n",
      "Iteration 2612, loss = 1330.33033505\n",
      "Iteration 2613, loss = 1327.82649403\n",
      "Iteration 2614, loss = 1325.32570423\n",
      "Iteration 2615, loss = 1322.83556025\n",
      "Iteration 2616, loss = 1320.36283331\n",
      "Iteration 2617, loss = 1317.89697616\n",
      "Iteration 2618, loss = 1315.43792267\n",
      "Iteration 2619, loss = 1312.99299804\n",
      "Iteration 2620, loss = 1310.54982143\n",
      "Iteration 2621, loss = 1308.11435538\n",
      "Iteration 2622, loss = 1305.68973729\n",
      "Iteration 2623, loss = 1303.27221596\n",
      "Iteration 2624, loss = 1300.86170506\n",
      "Iteration 2625, loss = 1298.45816212\n",
      "Iteration 2626, loss = 1296.06114560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2627, loss = 1293.67100733\n",
      "Iteration 2628, loss = 1291.29612749\n",
      "Iteration 2629, loss = 1288.92940926\n",
      "Iteration 2630, loss = 1286.56819757\n",
      "Iteration 2631, loss = 1284.21934642\n",
      "Iteration 2632, loss = 1281.87782891\n",
      "Iteration 2633, loss = 1279.54364944\n",
      "Iteration 2634, loss = 1277.21661483\n",
      "Iteration 2635, loss = 1274.89667892\n",
      "Iteration 2636, loss = 1272.58420757\n",
      "Iteration 2637, loss = 1270.28833085\n",
      "Iteration 2638, loss = 1267.99282644\n",
      "Iteration 2639, loss = 1265.70116604\n",
      "Iteration 2640, loss = 1263.42306089\n",
      "Iteration 2641, loss = 1261.16074905\n",
      "Iteration 2642, loss = 1258.90751304\n",
      "Iteration 2643, loss = 1256.66111831\n",
      "Iteration 2644, loss = 1254.42196121\n",
      "Iteration 2645, loss = 1252.19014119\n",
      "Iteration 2646, loss = 1249.96767513\n",
      "Iteration 2647, loss = 1247.75110827\n",
      "Iteration 2648, loss = 1245.54277066\n",
      "Iteration 2649, loss = 1243.34397440\n",
      "Iteration 2650, loss = 1241.15154002\n",
      "Iteration 2651, loss = 1238.96603724\n",
      "Iteration 2652, loss = 1236.78652390\n",
      "Iteration 2653, loss = 1234.61448367\n",
      "Iteration 2654, loss = 1232.44841007\n",
      "Iteration 2655, loss = 1230.28725960\n",
      "Iteration 2656, loss = 1228.12057328\n",
      "Iteration 2657, loss = 1225.95844744\n",
      "Iteration 2658, loss = 1223.80218563\n",
      "Iteration 2659, loss = 1221.65156205\n",
      "Iteration 2660, loss = 1219.50699320\n",
      "Iteration 2661, loss = 1217.36721379\n",
      "Iteration 2662, loss = 1215.23233075\n",
      "Iteration 2663, loss = 1213.10337261\n",
      "Iteration 2664, loss = 1210.98268507\n",
      "Iteration 2665, loss = 1208.86417455\n",
      "Iteration 2666, loss = 1206.74209224\n",
      "Iteration 2667, loss = 1204.61923060\n",
      "Iteration 2668, loss = 1202.49153101\n",
      "Iteration 2669, loss = 1200.36560252\n",
      "Iteration 2670, loss = 1198.24248633\n",
      "Iteration 2671, loss = 1196.12190825\n",
      "Iteration 2672, loss = 1194.00403467\n",
      "Iteration 2673, loss = 1191.88737268\n",
      "Iteration 2674, loss = 1189.77203112\n",
      "Iteration 2675, loss = 1187.66170901\n",
      "Iteration 2676, loss = 1185.54851148\n",
      "Iteration 2677, loss = 1183.44287555\n",
      "Iteration 2678, loss = 1181.33607665\n",
      "Iteration 2679, loss = 1179.23661900\n",
      "Iteration 2680, loss = 1177.12828453\n",
      "Iteration 2681, loss = 1175.01965929\n",
      "Iteration 2682, loss = 1172.90946324\n",
      "Iteration 2683, loss = 1170.80146189\n",
      "Iteration 2684, loss = 1168.69393562\n",
      "Iteration 2685, loss = 1166.58774552\n",
      "Iteration 2686, loss = 1164.48781136\n",
      "Iteration 2687, loss = 1162.38511813\n",
      "Iteration 2688, loss = 1160.28828009\n",
      "Iteration 2689, loss = 1158.19537353\n",
      "Iteration 2690, loss = 1156.10161680\n",
      "Iteration 2691, loss = 1154.00337301\n",
      "Iteration 2692, loss = 1151.93086529\n",
      "Iteration 2693, loss = 1149.85220894\n",
      "Iteration 2694, loss = 1147.76785026\n",
      "Iteration 2695, loss = 1145.68354277\n",
      "Iteration 2696, loss = 1143.59370322\n",
      "Iteration 2697, loss = 1141.53153622\n",
      "Iteration 2698, loss = 1139.48725742\n",
      "Iteration 2699, loss = 1137.44556882\n",
      "Iteration 2700, loss = 1135.40559549\n",
      "Iteration 2701, loss = 1133.36906746\n",
      "Iteration 2702, loss = 1131.33662459\n",
      "Iteration 2703, loss = 1129.30929871\n",
      "Iteration 2704, loss = 1127.28751692\n",
      "Iteration 2705, loss = 1125.26890659\n",
      "Iteration 2706, loss = 1123.24847931\n",
      "Iteration 2707, loss = 1121.23133068\n",
      "Iteration 2708, loss = 1119.22238272\n",
      "Iteration 2709, loss = 1117.21053757\n",
      "Iteration 2710, loss = 1115.19868908\n",
      "Iteration 2711, loss = 1113.20601913\n",
      "Iteration 2712, loss = 1111.20957333\n",
      "Iteration 2713, loss = 1109.20865029\n",
      "Iteration 2714, loss = 1107.20853750\n",
      "Iteration 2715, loss = 1105.22315573\n",
      "Iteration 2716, loss = 1103.24089054\n",
      "Iteration 2717, loss = 1101.26731804\n",
      "Iteration 2718, loss = 1099.31172720\n",
      "Iteration 2719, loss = 1097.35892194\n",
      "Iteration 2720, loss = 1095.41318915\n",
      "Iteration 2721, loss = 1093.47277378\n",
      "Iteration 2722, loss = 1091.53727744\n",
      "Iteration 2723, loss = 1089.60703231\n",
      "Iteration 2724, loss = 1087.68862768\n",
      "Iteration 2725, loss = 1085.77718999\n",
      "Iteration 2726, loss = 1083.86273881\n",
      "Iteration 2727, loss = 1081.96084947\n",
      "Iteration 2728, loss = 1080.06794088\n",
      "Iteration 2729, loss = 1078.17851106\n",
      "Iteration 2730, loss = 1076.29050755\n",
      "Iteration 2731, loss = 1074.40426205\n",
      "Iteration 2732, loss = 1072.51674383\n",
      "Iteration 2733, loss = 1070.63055116\n",
      "Iteration 2734, loss = 1068.75140742\n",
      "Iteration 2735, loss = 1066.88606208\n",
      "Iteration 2736, loss = 1065.02943534\n",
      "Iteration 2737, loss = 1063.18346393\n",
      "Iteration 2738, loss = 1061.34441242\n",
      "Iteration 2739, loss = 1059.50625531\n",
      "Iteration 2740, loss = 1057.66880046\n",
      "Iteration 2741, loss = 1055.82801032\n",
      "Iteration 2742, loss = 1053.99276192\n",
      "Iteration 2743, loss = 1052.16487274\n",
      "Iteration 2744, loss = 1050.34380728\n",
      "Iteration 2745, loss = 1048.52777184\n",
      "Iteration 2746, loss = 1046.73891681\n",
      "Iteration 2747, loss = 1044.94869443\n",
      "Iteration 2748, loss = 1043.16158571\n",
      "Iteration 2749, loss = 1041.38548196\n",
      "Iteration 2750, loss = 1039.61762981\n",
      "Iteration 2751, loss = 1037.85545874\n",
      "Iteration 2752, loss = 1036.09931291\n",
      "Iteration 2753, loss = 1034.34915740\n",
      "Iteration 2754, loss = 1032.60705723\n",
      "Iteration 2755, loss = 1030.86256738\n",
      "Iteration 2756, loss = 1029.12616164\n",
      "Iteration 2757, loss = 1027.39607254\n",
      "Iteration 2758, loss = 1025.67281343\n",
      "Iteration 2759, loss = 1023.95451425\n",
      "Iteration 2760, loss = 1022.24728753\n",
      "Iteration 2761, loss = 1020.53972451\n",
      "Iteration 2762, loss = 1018.84065898\n",
      "Iteration 2763, loss = 1017.14482842\n",
      "Iteration 2764, loss = 1015.45302392\n",
      "Iteration 2765, loss = 1013.76807816\n",
      "Iteration 2766, loss = 1012.09081116\n",
      "Iteration 2767, loss = 1010.41331524\n",
      "Iteration 2768, loss = 1008.74268797\n",
      "Iteration 2769, loss = 1007.08110171\n",
      "Iteration 2770, loss = 1005.41795216\n",
      "Iteration 2771, loss = 1003.76426556\n",
      "Iteration 2772, loss = 1002.11769408\n",
      "Iteration 2773, loss = 1000.47324999\n",
      "Iteration 2774, loss = 998.83424739\n",
      "Iteration 2775, loss = 997.19971516\n",
      "Iteration 2776, loss = 995.56869962\n",
      "Iteration 2777, loss = 993.94130263\n",
      "Iteration 2778, loss = 992.32287451\n",
      "Iteration 2779, loss = 990.70187154\n",
      "Iteration 2780, loss = 989.09715189\n",
      "Iteration 2781, loss = 987.49329688\n",
      "Iteration 2782, loss = 985.88898905\n",
      "Iteration 2783, loss = 984.29150600\n",
      "Iteration 2784, loss = 982.69174273\n",
      "Iteration 2785, loss = 981.10595445\n",
      "Iteration 2786, loss = 979.52690449\n",
      "Iteration 2787, loss = 977.95357192\n",
      "Iteration 2788, loss = 976.38499530\n",
      "Iteration 2789, loss = 974.82080148\n",
      "Iteration 2790, loss = 973.26059149\n",
      "Iteration 2791, loss = 971.70725127\n",
      "Iteration 2792, loss = 970.15687746\n",
      "Iteration 2793, loss = 968.61298916\n",
      "Iteration 2794, loss = 967.07489798\n",
      "Iteration 2795, loss = 965.54049431\n",
      "Iteration 2796, loss = 964.00887567\n",
      "Iteration 2797, loss = 962.48670410\n",
      "Iteration 2798, loss = 960.96303038\n",
      "Iteration 2799, loss = 959.44343930\n",
      "Iteration 2800, loss = 957.93346997\n",
      "Iteration 2801, loss = 956.42926212\n",
      "Iteration 2802, loss = 954.93686972\n",
      "Iteration 2803, loss = 953.43797298\n",
      "Iteration 2804, loss = 951.93946440\n",
      "Iteration 2805, loss = 950.45070458\n",
      "Iteration 2806, loss = 948.96596953\n",
      "Iteration 2807, loss = 947.48656464\n",
      "Iteration 2808, loss = 946.00704168\n",
      "Iteration 2809, loss = 944.53052046\n",
      "Iteration 2810, loss = 943.05701657\n",
      "Iteration 2811, loss = 941.58433104\n",
      "Iteration 2812, loss = 940.11771807\n",
      "Iteration 2813, loss = 938.65033970\n",
      "Iteration 2814, loss = 937.18704209\n",
      "Iteration 2815, loss = 935.73594457\n",
      "Iteration 2816, loss = 934.28266074\n",
      "Iteration 2817, loss = 932.82966084\n",
      "Iteration 2818, loss = 931.38492747\n",
      "Iteration 2819, loss = 929.94331230\n",
      "Iteration 2820, loss = 928.50430232\n",
      "Iteration 2821, loss = 927.06873727\n",
      "Iteration 2822, loss = 925.63617388\n",
      "Iteration 2823, loss = 924.22352104\n",
      "Iteration 2824, loss = 922.80154616\n",
      "Iteration 2825, loss = 921.37458857\n",
      "Iteration 2826, loss = 919.96617037\n",
      "Iteration 2827, loss = 918.55975955\n",
      "Iteration 2828, loss = 917.16263632\n",
      "Iteration 2829, loss = 915.76961042\n",
      "Iteration 2830, loss = 914.37933065\n",
      "Iteration 2831, loss = 912.99729131\n",
      "Iteration 2832, loss = 911.61638885\n",
      "Iteration 2833, loss = 910.23754034\n",
      "Iteration 2834, loss = 908.86591896\n",
      "Iteration 2835, loss = 907.49377840\n",
      "Iteration 2836, loss = 906.12392082\n",
      "Iteration 2837, loss = 904.75628906\n",
      "Iteration 2838, loss = 903.40458896\n",
      "Iteration 2839, loss = 902.04836006\n",
      "Iteration 2840, loss = 900.69109011\n",
      "Iteration 2841, loss = 899.34160281\n",
      "Iteration 2842, loss = 898.00054808\n",
      "Iteration 2843, loss = 896.66176219\n",
      "Iteration 2844, loss = 895.32591908\n",
      "Iteration 2845, loss = 893.99254673\n",
      "Iteration 2846, loss = 892.66156299\n",
      "Iteration 2847, loss = 891.34230531\n",
      "Iteration 2848, loss = 890.02004369\n",
      "Iteration 2849, loss = 888.69641522\n",
      "Iteration 2850, loss = 887.38314061\n",
      "Iteration 2851, loss = 886.08092492\n",
      "Iteration 2852, loss = 884.77803771\n",
      "Iteration 2853, loss = 883.47165296\n",
      "Iteration 2854, loss = 882.17726487\n",
      "Iteration 2855, loss = 880.88625409\n",
      "Iteration 2856, loss = 879.59743481\n",
      "Iteration 2857, loss = 878.31072214\n",
      "Iteration 2858, loss = 877.02695748\n",
      "Iteration 2859, loss = 875.75118076\n",
      "Iteration 2860, loss = 874.48562509\n",
      "Iteration 2861, loss = 873.21896126\n",
      "Iteration 2862, loss = 871.95911391\n",
      "Iteration 2863, loss = 870.70445778\n",
      "Iteration 2864, loss = 869.45779980\n",
      "Iteration 2865, loss = 868.21689513\n",
      "Iteration 2866, loss = 866.97600412\n",
      "Iteration 2867, loss = 865.74245432\n",
      "Iteration 2868, loss = 864.51141191\n",
      "Iteration 2869, loss = 863.28364328\n",
      "Iteration 2870, loss = 862.06511677\n",
      "Iteration 2871, loss = 860.85136232\n",
      "Iteration 2872, loss = 859.63087364\n",
      "Iteration 2873, loss = 858.42442839\n",
      "Iteration 2874, loss = 857.22223819\n",
      "Iteration 2875, loss = 856.02209267\n",
      "Iteration 2876, loss = 854.82385171\n",
      "Iteration 2877, loss = 853.62956237\n",
      "Iteration 2878, loss = 852.43730910\n",
      "Iteration 2879, loss = 851.24683129\n",
      "Iteration 2880, loss = 850.05888578\n",
      "Iteration 2881, loss = 848.88082350\n",
      "Iteration 2882, loss = 847.70579719\n",
      "Iteration 2883, loss = 846.52921386\n",
      "Iteration 2884, loss = 845.36207163\n",
      "Iteration 2885, loss = 844.19714110\n",
      "Iteration 2886, loss = 843.03479049\n",
      "Iteration 2887, loss = 841.87869977\n",
      "Iteration 2888, loss = 840.72108635\n",
      "Iteration 2889, loss = 839.57420074\n",
      "Iteration 2890, loss = 838.42748045\n",
      "Iteration 2891, loss = 837.28458708\n",
      "Iteration 2892, loss = 836.14651510\n",
      "Iteration 2893, loss = 835.00971601\n",
      "Iteration 2894, loss = 833.87563396\n",
      "Iteration 2895, loss = 832.74480183\n",
      "Iteration 2896, loss = 831.62552079\n",
      "Iteration 2897, loss = 830.50474872\n",
      "Iteration 2898, loss = 829.39020689\n",
      "Iteration 2899, loss = 828.27773133\n",
      "Iteration 2900, loss = 827.17181416\n",
      "Iteration 2901, loss = 826.07554006\n",
      "Iteration 2902, loss = 824.98078342\n",
      "Iteration 2903, loss = 823.88357175\n",
      "Iteration 2904, loss = 822.77838130\n",
      "Iteration 2905, loss = 821.66621763\n",
      "Iteration 2906, loss = 820.55375498\n",
      "Iteration 2907, loss = 819.45851521\n",
      "Iteration 2908, loss = 818.37406389\n",
      "Iteration 2909, loss = 817.29588487\n",
      "Iteration 2910, loss = 816.22016366\n",
      "Iteration 2911, loss = 815.14461390\n",
      "Iteration 2912, loss = 814.06381994\n",
      "Iteration 2913, loss = 812.98462985\n",
      "Iteration 2914, loss = 811.91192177\n",
      "Iteration 2915, loss = 810.84900021\n",
      "Iteration 2916, loss = 809.79163659\n",
      "Iteration 2917, loss = 808.73888373\n",
      "Iteration 2918, loss = 807.68175951\n",
      "Iteration 2919, loss = 806.62138965\n",
      "Iteration 2920, loss = 805.56909059\n",
      "Iteration 2921, loss = 804.52900658\n",
      "Iteration 2922, loss = 803.48831683\n",
      "Iteration 2923, loss = 802.45245381\n",
      "Iteration 2924, loss = 801.41684597\n",
      "Iteration 2925, loss = 800.38128575\n",
      "Iteration 2926, loss = 799.34851443\n",
      "Iteration 2927, loss = 798.31942383\n",
      "Iteration 2928, loss = 797.30280175\n",
      "Iteration 2929, loss = 796.28378492\n",
      "Iteration 2930, loss = 795.26185311\n",
      "Iteration 2931, loss = 794.24144213\n",
      "Iteration 2932, loss = 793.23379677\n",
      "Iteration 2933, loss = 792.22920382\n",
      "Iteration 2934, loss = 791.22628833\n",
      "Iteration 2935, loss = 790.22360883\n",
      "Iteration 2936, loss = 789.22119446\n",
      "Iteration 2937, loss = 788.22257222\n",
      "Iteration 2938, loss = 787.23543494\n",
      "Iteration 2939, loss = 786.24774504\n",
      "Iteration 2940, loss = 785.25902406\n",
      "Iteration 2941, loss = 784.27735631\n",
      "Iteration 2942, loss = 783.29701222\n",
      "Iteration 2943, loss = 782.31796296\n",
      "Iteration 2944, loss = 781.34607257\n",
      "Iteration 2945, loss = 780.37983088\n",
      "Iteration 2946, loss = 779.40861571\n",
      "Iteration 2947, loss = 778.44455638\n",
      "Iteration 2948, loss = 777.48440045\n",
      "Iteration 2949, loss = 776.52577411\n",
      "Iteration 2950, loss = 775.57225489\n",
      "Iteration 2951, loss = 774.61694968\n",
      "Iteration 2952, loss = 773.66443980\n",
      "Iteration 2953, loss = 772.71859574\n",
      "Iteration 2954, loss = 771.77370653\n",
      "Iteration 2955, loss = 770.83045229\n",
      "Iteration 2956, loss = 769.89176675\n",
      "Iteration 2957, loss = 768.95740913\n",
      "Iteration 2958, loss = 768.02507202\n",
      "Iteration 2959, loss = 767.09518919\n",
      "Iteration 2960, loss = 766.16953392\n",
      "Iteration 2961, loss = 765.24440626\n",
      "Iteration 2962, loss = 764.32311242\n",
      "Iteration 2963, loss = 763.40465598\n",
      "Iteration 2964, loss = 762.48685675\n",
      "Iteration 2965, loss = 761.57057445\n",
      "Iteration 2966, loss = 760.65778163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2967, loss = 759.74581969\n",
      "Iteration 2968, loss = 758.83953827\n",
      "Iteration 2969, loss = 757.93280913\n",
      "Iteration 2970, loss = 757.03116392\n",
      "Iteration 2971, loss = 756.13321424\n",
      "Iteration 2972, loss = 755.23393464\n",
      "Iteration 2973, loss = 754.33991520\n",
      "Iteration 2974, loss = 753.44856303\n",
      "Iteration 2975, loss = 752.55810058\n",
      "Iteration 2976, loss = 751.67311127\n",
      "Iteration 2977, loss = 750.78978781\n",
      "Iteration 2978, loss = 749.90861184\n",
      "Iteration 2979, loss = 749.03146544\n",
      "Iteration 2980, loss = 748.15535695\n",
      "Iteration 2981, loss = 747.28208598\n",
      "Iteration 2982, loss = 746.40859950\n",
      "Iteration 2983, loss = 745.54225514\n",
      "Iteration 2984, loss = 744.67740111\n",
      "Iteration 2985, loss = 743.81246384\n",
      "Iteration 2986, loss = 742.95358763\n",
      "Iteration 2987, loss = 742.09565224\n",
      "Iteration 2988, loss = 741.23860810\n",
      "Iteration 2989, loss = 740.39218297\n",
      "Iteration 2990, loss = 739.54048956\n",
      "Iteration 2991, loss = 738.69216997\n",
      "Iteration 2992, loss = 737.85076072\n",
      "Iteration 2993, loss = 737.00976099\n",
      "Iteration 2994, loss = 736.16996079\n",
      "Iteration 2995, loss = 735.33274057\n",
      "Iteration 2996, loss = 734.50046690\n",
      "Iteration 2997, loss = 733.67198246\n",
      "Iteration 2998, loss = 732.84134310\n",
      "Iteration 2999, loss = 732.01405513\n",
      "Iteration 3000, loss = 731.19236372\n",
      "Iteration 3001, loss = 730.37150482\n",
      "Iteration 3002, loss = 729.55448688\n",
      "Iteration 3003, loss = 728.73546781\n",
      "Iteration 3004, loss = 727.92096881\n",
      "Iteration 3005, loss = 727.10977275\n",
      "Iteration 3006, loss = 726.29859352\n",
      "Iteration 3007, loss = 725.49311941\n",
      "Iteration 3008, loss = 724.68484815\n",
      "Iteration 3009, loss = 723.88294299\n",
      "Iteration 3010, loss = 723.08355428\n",
      "Iteration 3011, loss = 722.28287853\n",
      "Iteration 3012, loss = 721.48681150\n",
      "Iteration 3013, loss = 720.69368787\n",
      "Iteration 3014, loss = 719.90477066\n",
      "Iteration 3015, loss = 719.12272081\n",
      "Iteration 3016, loss = 718.33333096\n",
      "Iteration 3017, loss = 717.54287526\n",
      "Iteration 3018, loss = 716.76099442\n",
      "Iteration 3019, loss = 715.97990155\n",
      "Iteration 3020, loss = 715.19847965\n",
      "Iteration 3021, loss = 714.41961044\n",
      "Iteration 3022, loss = 713.64204647\n",
      "Iteration 3023, loss = 712.87013303\n",
      "Iteration 3024, loss = 712.10022565\n",
      "Iteration 3025, loss = 711.33396754\n",
      "Iteration 3026, loss = 710.56639210\n",
      "Iteration 3027, loss = 709.79954129\n",
      "Iteration 3028, loss = 709.03328434\n",
      "Iteration 3029, loss = 708.27217131\n",
      "Iteration 3030, loss = 707.51391213\n",
      "Iteration 3031, loss = 706.75648836\n",
      "Iteration 3032, loss = 705.99640604\n",
      "Iteration 3033, loss = 705.23874785\n",
      "Iteration 3034, loss = 704.47927136\n",
      "Iteration 3035, loss = 703.71775156\n",
      "Iteration 3036, loss = 702.95379629\n",
      "Iteration 3037, loss = 702.19034116\n",
      "Iteration 3038, loss = 701.42439933\n",
      "Iteration 3039, loss = 700.65957772\n",
      "Iteration 3040, loss = 699.89695839\n",
      "Iteration 3041, loss = 699.13813004\n",
      "Iteration 3042, loss = 698.37966566\n",
      "Iteration 3043, loss = 697.62233786\n",
      "Iteration 3044, loss = 696.86320966\n",
      "Iteration 3045, loss = 696.10711328\n",
      "Iteration 3046, loss = 695.35527620\n",
      "Iteration 3047, loss = 694.60324883\n",
      "Iteration 3048, loss = 693.84385215\n",
      "Iteration 3049, loss = 693.08549770\n",
      "Iteration 3050, loss = 692.32785266\n",
      "Iteration 3051, loss = 691.57244123\n",
      "Iteration 3052, loss = 690.81602510\n",
      "Iteration 3053, loss = 690.06312195\n",
      "Iteration 3054, loss = 689.31387549\n",
      "Iteration 3055, loss = 688.56205052\n",
      "Iteration 3056, loss = 687.81203441\n",
      "Iteration 3057, loss = 687.06391764\n",
      "Iteration 3058, loss = 686.31517650\n",
      "Iteration 3059, loss = 685.56865278\n",
      "Iteration 3060, loss = 684.82558095\n",
      "Iteration 3061, loss = 684.08238635\n",
      "Iteration 3062, loss = 683.34563251\n",
      "Iteration 3063, loss = 682.61081082\n",
      "Iteration 3064, loss = 681.88173889\n",
      "Iteration 3065, loss = 681.15019515\n",
      "Iteration 3066, loss = 680.42427597\n",
      "Iteration 3067, loss = 679.70197709\n",
      "Iteration 3068, loss = 678.98132764\n",
      "Iteration 3069, loss = 678.26095090\n",
      "Iteration 3070, loss = 677.54220810\n",
      "Iteration 3071, loss = 676.82782303\n",
      "Iteration 3072, loss = 676.12252393\n",
      "Iteration 3073, loss = 675.41515590\n",
      "Iteration 3074, loss = 674.70761800\n",
      "Iteration 3075, loss = 674.00523527\n",
      "Iteration 3076, loss = 673.30570262\n",
      "Iteration 3077, loss = 672.60721392\n",
      "Iteration 3078, loss = 671.91687760\n",
      "Iteration 3079, loss = 671.22347730\n",
      "Iteration 3080, loss = 670.52966467\n",
      "Iteration 3081, loss = 669.84150834\n",
      "Iteration 3082, loss = 669.15880306\n",
      "Iteration 3083, loss = 668.47507559\n",
      "Iteration 3084, loss = 667.79062457\n",
      "Iteration 3085, loss = 667.11056124\n",
      "Iteration 3086, loss = 666.43524624\n",
      "Iteration 3087, loss = 665.76221780\n",
      "Iteration 3088, loss = 665.08890458\n",
      "Iteration 3089, loss = 664.41806076\n",
      "Iteration 3090, loss = 663.75081758\n",
      "Iteration 3091, loss = 663.08530330\n",
      "Iteration 3092, loss = 662.42818058\n",
      "Iteration 3093, loss = 661.77063335\n",
      "Iteration 3094, loss = 661.10949211\n",
      "Iteration 3095, loss = 660.45040400\n",
      "Iteration 3096, loss = 659.79540583\n",
      "Iteration 3097, loss = 659.14637035\n",
      "Iteration 3098, loss = 658.50118052\n",
      "Iteration 3099, loss = 657.85547219\n",
      "Iteration 3100, loss = 657.21035373\n",
      "Iteration 3101, loss = 656.56638064\n",
      "Iteration 3102, loss = 655.92599450\n",
      "Iteration 3103, loss = 655.29132234\n",
      "Iteration 3104, loss = 654.65853306\n",
      "Iteration 3105, loss = 654.02396975\n",
      "Iteration 3106, loss = 653.39103532\n",
      "Iteration 3107, loss = 652.76220589\n",
      "Iteration 3108, loss = 652.13374397\n",
      "Iteration 3109, loss = 651.51041329\n",
      "Iteration 3110, loss = 650.88829984\n",
      "Iteration 3111, loss = 650.26703419\n",
      "Iteration 3112, loss = 649.65092198\n",
      "Iteration 3113, loss = 649.03322978\n",
      "Iteration 3114, loss = 648.41862287\n",
      "Iteration 3115, loss = 647.80907642\n",
      "Iteration 3116, loss = 647.20335829\n",
      "Iteration 3117, loss = 646.60726689\n",
      "Iteration 3118, loss = 646.01108666\n",
      "Iteration 3119, loss = 645.41296159\n",
      "Iteration 3120, loss = 644.81305420\n",
      "Iteration 3121, loss = 644.20603656\n",
      "Iteration 3122, loss = 643.59636671\n",
      "Iteration 3123, loss = 642.98411098\n",
      "Iteration 3124, loss = 642.37680674\n",
      "Iteration 3125, loss = 641.78159854\n",
      "Iteration 3126, loss = 641.19648143\n",
      "Iteration 3127, loss = 640.61438648\n",
      "Iteration 3128, loss = 640.02884727\n",
      "Iteration 3129, loss = 639.43793341\n",
      "Iteration 3130, loss = 638.84713106\n",
      "Iteration 3131, loss = 638.25973724\n",
      "Iteration 3132, loss = 637.67919178\n",
      "Iteration 3133, loss = 637.10273300\n",
      "Iteration 3134, loss = 636.53552239\n",
      "Iteration 3135, loss = 635.95954880\n",
      "Iteration 3136, loss = 635.37817183\n",
      "Iteration 3137, loss = 634.79918528\n",
      "Iteration 3138, loss = 634.22611852\n",
      "Iteration 3139, loss = 633.65705232\n",
      "Iteration 3140, loss = 633.08631694\n",
      "Iteration 3141, loss = 632.51965189\n",
      "Iteration 3142, loss = 631.94832585\n",
      "Iteration 3143, loss = 631.37642926\n",
      "Iteration 3144, loss = 630.80931241\n",
      "Iteration 3145, loss = 630.24422634\n",
      "Iteration 3146, loss = 629.67886340\n",
      "Iteration 3147, loss = 629.11608130\n",
      "Iteration 3148, loss = 628.55235123\n",
      "Iteration 3149, loss = 627.99335035\n",
      "Iteration 3150, loss = 627.43365179\n",
      "Iteration 3151, loss = 626.87266145\n",
      "Iteration 3152, loss = 626.31411957\n",
      "Iteration 3153, loss = 625.76558033\n",
      "Iteration 3154, loss = 625.21688297\n",
      "Iteration 3155, loss = 624.66670462\n",
      "Iteration 3156, loss = 624.11468662\n",
      "Iteration 3157, loss = 623.56525632\n",
      "Iteration 3158, loss = 623.01776023\n",
      "Iteration 3159, loss = 622.47321901\n",
      "Iteration 3160, loss = 621.92729386\n",
      "Iteration 3161, loss = 621.38830394\n",
      "Iteration 3162, loss = 620.84532782\n",
      "Iteration 3163, loss = 620.31288686\n",
      "Iteration 3164, loss = 619.77770078\n",
      "Iteration 3165, loss = 619.23475827\n",
      "Iteration 3166, loss = 618.69943879\n",
      "Iteration 3167, loss = 618.17021708\n",
      "Iteration 3168, loss = 617.64026437\n",
      "Iteration 3169, loss = 617.11343367\n",
      "Iteration 3170, loss = 616.58748950\n",
      "Iteration 3171, loss = 616.06020316\n",
      "Iteration 3172, loss = 615.53190157\n",
      "Iteration 3173, loss = 615.00915780\n",
      "Iteration 3174, loss = 614.49118470\n",
      "Iteration 3175, loss = 613.97246277\n",
      "Iteration 3176, loss = 613.45330289\n",
      "Iteration 3177, loss = 612.93236449\n",
      "Iteration 3178, loss = 612.41742726\n",
      "Iteration 3179, loss = 611.90741483\n",
      "Iteration 3180, loss = 611.39404423\n",
      "Iteration 3181, loss = 610.88055848\n",
      "Iteration 3182, loss = 610.37254543\n",
      "Iteration 3183, loss = 609.86635072\n",
      "Iteration 3184, loss = 609.36041428\n",
      "Iteration 3185, loss = 608.85543924\n",
      "Iteration 3186, loss = 608.35571916\n",
      "Iteration 3187, loss = 607.85722645\n",
      "Iteration 3188, loss = 607.35709460\n",
      "Iteration 3189, loss = 606.85681060\n",
      "Iteration 3190, loss = 606.36112391\n",
      "Iteration 3191, loss = 605.86365001\n",
      "Iteration 3192, loss = 605.36133859\n",
      "Iteration 3193, loss = 604.86264935\n",
      "Iteration 3194, loss = 604.36975317\n",
      "Iteration 3195, loss = 603.87235846\n",
      "Iteration 3196, loss = 603.37775607\n",
      "Iteration 3197, loss = 602.88516402\n",
      "Iteration 3198, loss = 602.39301804\n",
      "Iteration 3199, loss = 601.89898207\n",
      "Iteration 3200, loss = 601.40684646\n",
      "Iteration 3201, loss = 600.91958737\n",
      "Iteration 3202, loss = 600.43401405\n",
      "Iteration 3203, loss = 599.94673359\n",
      "Iteration 3204, loss = 599.46410797\n",
      "Iteration 3205, loss = 598.98261306\n",
      "Iteration 3206, loss = 598.50161586\n",
      "Iteration 3207, loss = 598.01869453\n",
      "Iteration 3208, loss = 597.53819393\n",
      "Iteration 3209, loss = 597.06042563\n",
      "Iteration 3210, loss = 596.58588595\n",
      "Iteration 3211, loss = 596.11236362\n",
      "Iteration 3212, loss = 595.63684334\n",
      "Iteration 3213, loss = 595.16588240\n",
      "Iteration 3214, loss = 594.69899799\n",
      "Iteration 3215, loss = 594.22921383\n",
      "Iteration 3216, loss = 593.75469777\n",
      "Iteration 3217, loss = 593.28490985\n",
      "Iteration 3218, loss = 592.82070242\n",
      "Iteration 3219, loss = 592.35960340\n",
      "Iteration 3220, loss = 591.89285518\n",
      "Iteration 3221, loss = 591.42567185\n",
      "Iteration 3222, loss = 590.96935733\n",
      "Iteration 3223, loss = 590.51462712\n",
      "Iteration 3224, loss = 590.05318467\n",
      "Iteration 3225, loss = 589.59434487\n",
      "Iteration 3226, loss = 589.14014648\n",
      "Iteration 3227, loss = 588.68717691\n",
      "Iteration 3228, loss = 588.23498275\n",
      "Iteration 3229, loss = 587.78222056\n",
      "Iteration 3230, loss = 587.33082679\n",
      "Iteration 3231, loss = 586.88423320\n",
      "Iteration 3232, loss = 586.43779275\n",
      "Iteration 3233, loss = 585.99196275\n",
      "Iteration 3234, loss = 585.54869793\n",
      "Iteration 3235, loss = 585.10425870\n",
      "Iteration 3236, loss = 584.66235209\n",
      "Iteration 3237, loss = 584.22197344\n",
      "Iteration 3238, loss = 583.78123426\n",
      "Iteration 3239, loss = 583.34433908\n",
      "Iteration 3240, loss = 582.90669576\n",
      "Iteration 3241, loss = 582.47208136\n",
      "Iteration 3242, loss = 582.03874078\n",
      "Iteration 3243, loss = 581.60529210\n",
      "Iteration 3244, loss = 581.17386791\n",
      "Iteration 3245, loss = 580.74475978\n",
      "Iteration 3246, loss = 580.31805889\n",
      "Iteration 3247, loss = 579.88884322\n",
      "Iteration 3248, loss = 579.46486768\n",
      "Iteration 3249, loss = 579.03967672\n",
      "Iteration 3250, loss = 578.61587774\n",
      "Iteration 3251, loss = 578.19394037\n",
      "Iteration 3252, loss = 577.77211552\n",
      "Iteration 3253, loss = 577.35338357\n",
      "Iteration 3254, loss = 576.93374267\n",
      "Iteration 3255, loss = 576.51774932\n",
      "Iteration 3256, loss = 576.10225146\n",
      "Iteration 3257, loss = 575.68767994\n",
      "Iteration 3258, loss = 575.27136621\n",
      "Iteration 3259, loss = 574.86027349\n",
      "Iteration 3260, loss = 574.45139492\n",
      "Iteration 3261, loss = 574.04279403\n",
      "Iteration 3262, loss = 573.63298750\n",
      "Iteration 3263, loss = 573.22300537\n",
      "Iteration 3264, loss = 572.81409609\n",
      "Iteration 3265, loss = 572.40998308\n",
      "Iteration 3266, loss = 572.00399874\n",
      "Iteration 3267, loss = 571.59918499\n",
      "Iteration 3268, loss = 571.19845121\n",
      "Iteration 3269, loss = 570.80033054\n",
      "Iteration 3270, loss = 570.40154715\n",
      "Iteration 3271, loss = 570.00067067\n",
      "Iteration 3272, loss = 569.59864994\n",
      "Iteration 3273, loss = 569.21138367\n",
      "Iteration 3274, loss = 568.83064473\n",
      "Iteration 3275, loss = 568.43990243\n",
      "Iteration 3276, loss = 568.04232840\n",
      "Iteration 3277, loss = 567.64566116\n",
      "Iteration 3278, loss = 567.25565281\n",
      "Iteration 3279, loss = 566.87342077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3280, loss = 566.49236050\n",
      "Iteration 3281, loss = 566.10684567\n",
      "Iteration 3282, loss = 565.72022789\n",
      "Iteration 3283, loss = 565.33807358\n",
      "Iteration 3284, loss = 564.95962445\n",
      "Iteration 3285, loss = 564.57804853\n",
      "Iteration 3286, loss = 564.19849065\n",
      "Iteration 3287, loss = 563.81971141\n",
      "Iteration 3288, loss = 563.44186573\n",
      "Iteration 3289, loss = 563.06746269\n",
      "Iteration 3290, loss = 562.69351453\n",
      "Iteration 3291, loss = 562.31452437\n",
      "Iteration 3292, loss = 561.93861352\n",
      "Iteration 3293, loss = 561.56798390\n",
      "Iteration 3294, loss = 561.19503238\n",
      "Iteration 3295, loss = 560.82432127\n",
      "Iteration 3296, loss = 560.45412075\n",
      "Iteration 3297, loss = 560.08714495\n",
      "Iteration 3298, loss = 559.72222247\n",
      "Iteration 3299, loss = 559.36054501\n",
      "Iteration 3300, loss = 558.99734972\n",
      "Iteration 3301, loss = 558.63305971\n",
      "Iteration 3302, loss = 558.26959358\n",
      "Iteration 3303, loss = 557.90735715\n",
      "Iteration 3304, loss = 557.54348670\n",
      "Iteration 3305, loss = 557.18919231\n",
      "Iteration 3306, loss = 556.83578509\n",
      "Iteration 3307, loss = 556.48012144\n",
      "Iteration 3308, loss = 556.12077320\n",
      "Iteration 3309, loss = 555.76353664\n",
      "Iteration 3310, loss = 555.41030424\n",
      "Iteration 3311, loss = 555.05685460\n",
      "Iteration 3312, loss = 554.70370891\n",
      "Iteration 3313, loss = 554.35105665\n",
      "Iteration 3314, loss = 554.00237613\n",
      "Iteration 3315, loss = 553.65779483\n",
      "Iteration 3316, loss = 553.31101440\n",
      "Iteration 3317, loss = 552.96492856\n",
      "Iteration 3318, loss = 552.62036159\n",
      "Iteration 3319, loss = 552.27671968\n",
      "Iteration 3320, loss = 551.93424517\n",
      "Iteration 3321, loss = 551.59130997\n",
      "Iteration 3322, loss = 551.25257047\n",
      "Iteration 3323, loss = 550.91173772\n",
      "Iteration 3324, loss = 550.57971762\n",
      "Iteration 3325, loss = 550.24831905\n",
      "Iteration 3326, loss = 549.91759584\n",
      "Iteration 3327, loss = 549.59382303\n",
      "Iteration 3328, loss = 549.27369313\n",
      "Iteration 3329, loss = 548.95298837\n",
      "Iteration 3330, loss = 548.62657581\n",
      "Iteration 3331, loss = 548.28592357\n",
      "Iteration 3332, loss = 547.93395219\n",
      "Iteration 3333, loss = 547.57909857\n",
      "Iteration 3334, loss = 547.23658056\n",
      "Iteration 3335, loss = 546.91649745\n",
      "Iteration 3336, loss = 546.60649384\n",
      "Iteration 3337, loss = 546.28792779\n",
      "Iteration 3338, loss = 545.95291804\n",
      "Iteration 3339, loss = 545.61537362\n",
      "Iteration 3340, loss = 545.28718145\n",
      "Iteration 3341, loss = 544.97124238\n",
      "Iteration 3342, loss = 544.65488492\n",
      "Iteration 3343, loss = 544.34031105\n",
      "Iteration 3344, loss = 544.01380338\n",
      "Iteration 3345, loss = 543.68888654\n",
      "Iteration 3346, loss = 543.37151686\n",
      "Iteration 3347, loss = 543.06144473\n",
      "Iteration 3348, loss = 542.74958147\n",
      "Iteration 3349, loss = 542.43231582\n",
      "Iteration 3350, loss = 542.11101949\n",
      "Iteration 3351, loss = 541.80059969\n",
      "Iteration 3352, loss = 541.49193952\n",
      "Iteration 3353, loss = 541.18096615\n",
      "Iteration 3354, loss = 540.87113006\n",
      "Iteration 3355, loss = 540.56014683\n",
      "Iteration 3356, loss = 540.24817084\n",
      "Iteration 3357, loss = 539.94636056\n",
      "Iteration 3358, loss = 539.64316281\n",
      "Iteration 3359, loss = 539.33477150\n",
      "Iteration 3360, loss = 539.03048789\n",
      "Iteration 3361, loss = 538.72658349\n",
      "Iteration 3362, loss = 538.42635023\n",
      "Iteration 3363, loss = 538.12704924\n",
      "Iteration 3364, loss = 537.82490688\n",
      "Iteration 3365, loss = 537.52060342\n",
      "Iteration 3366, loss = 537.21772105\n",
      "Iteration 3367, loss = 536.92427915\n",
      "Iteration 3368, loss = 536.62612323\n",
      "Iteration 3369, loss = 536.32466027\n",
      "Iteration 3370, loss = 536.03223402\n",
      "Iteration 3371, loss = 535.73836710\n",
      "Iteration 3372, loss = 535.44609740\n",
      "Iteration 3373, loss = 535.15043661\n",
      "Iteration 3374, loss = 534.85765696\n",
      "Iteration 3375, loss = 534.56632159\n",
      "Iteration 3376, loss = 534.27721627\n",
      "Iteration 3377, loss = 533.98715504\n",
      "Iteration 3378, loss = 533.69834376\n",
      "Iteration 3379, loss = 533.41318132\n",
      "Iteration 3380, loss = 533.12589816\n",
      "Iteration 3381, loss = 532.83577263\n",
      "Iteration 3382, loss = 532.55221331\n",
      "Iteration 3383, loss = 532.26862748\n",
      "Iteration 3384, loss = 531.98461402\n",
      "Iteration 3385, loss = 531.69615945\n",
      "Iteration 3386, loss = 531.41468805\n",
      "Iteration 3387, loss = 531.13708685\n",
      "Iteration 3388, loss = 530.85866988\n",
      "Iteration 3389, loss = 530.57734539\n",
      "Iteration 3390, loss = 530.30176154\n",
      "Iteration 3391, loss = 530.02223942\n",
      "Iteration 3392, loss = 529.74171133\n",
      "Iteration 3393, loss = 529.46494650\n",
      "Iteration 3394, loss = 529.18714439\n",
      "Iteration 3395, loss = 528.90961447\n",
      "Iteration 3396, loss = 528.64104191\n",
      "Iteration 3397, loss = 528.36711802\n",
      "Iteration 3398, loss = 528.08799454\n",
      "Iteration 3399, loss = 527.81386070\n",
      "Iteration 3400, loss = 527.54585995\n",
      "Iteration 3401, loss = 527.27730621\n",
      "Iteration 3402, loss = 527.00560882\n",
      "Iteration 3403, loss = 526.73045166\n",
      "Iteration 3404, loss = 526.46197387\n",
      "Iteration 3405, loss = 526.19125266\n",
      "Iteration 3406, loss = 525.92766492\n",
      "Iteration 3407, loss = 525.66326457\n",
      "Iteration 3408, loss = 525.39119364\n",
      "Iteration 3409, loss = 525.11850488\n",
      "Iteration 3410, loss = 524.85374445\n",
      "Iteration 3411, loss = 524.59214278\n",
      "Iteration 3412, loss = 524.32958478\n",
      "Iteration 3413, loss = 524.06373799\n",
      "Iteration 3414, loss = 523.79792188\n",
      "Iteration 3415, loss = 523.53244385\n",
      "Iteration 3416, loss = 523.26968509\n",
      "Iteration 3417, loss = 523.00884782\n",
      "Iteration 3418, loss = 522.74553503\n",
      "Iteration 3419, loss = 522.49049046\n",
      "Iteration 3420, loss = 522.22974830\n",
      "Iteration 3421, loss = 521.96971362\n",
      "Iteration 3422, loss = 521.71138482\n",
      "Iteration 3423, loss = 521.45726029\n",
      "Iteration 3424, loss = 521.20148974\n",
      "Iteration 3425, loss = 520.94626112\n",
      "Iteration 3426, loss = 520.68803417\n",
      "Iteration 3427, loss = 520.42797248\n",
      "Iteration 3428, loss = 520.16791915\n",
      "Iteration 3429, loss = 519.90881307\n",
      "Iteration 3430, loss = 519.65543734\n",
      "Iteration 3431, loss = 519.39941424\n",
      "Iteration 3432, loss = 519.14064852\n",
      "Iteration 3433, loss = 518.88433914\n",
      "Iteration 3434, loss = 518.63274787\n",
      "Iteration 3435, loss = 518.37487834\n",
      "Iteration 3436, loss = 518.11462566\n",
      "Iteration 3437, loss = 517.86412132\n",
      "Iteration 3438, loss = 517.61450112\n",
      "Iteration 3439, loss = 517.35888039\n",
      "Iteration 3440, loss = 517.10689006\n",
      "Iteration 3441, loss = 516.85541096\n",
      "Iteration 3442, loss = 516.59965498\n",
      "Iteration 3443, loss = 516.34735242\n",
      "Iteration 3444, loss = 516.10393628\n",
      "Iteration 3445, loss = 515.85342651\n",
      "Iteration 3446, loss = 515.59743213\n",
      "Iteration 3447, loss = 515.35035453\n",
      "Iteration 3448, loss = 515.10283120\n",
      "Iteration 3449, loss = 514.85845358\n",
      "Iteration 3450, loss = 514.61182548\n",
      "Iteration 3451, loss = 514.36503523\n",
      "Iteration 3452, loss = 514.12042980\n",
      "Iteration 3453, loss = 513.87353422\n",
      "Iteration 3454, loss = 513.63331803\n",
      "Iteration 3455, loss = 513.39146689\n",
      "Iteration 3456, loss = 513.15014859\n",
      "Iteration 3457, loss = 512.90958657\n",
      "Iteration 3458, loss = 512.66795566\n",
      "Iteration 3459, loss = 512.42647868\n",
      "Iteration 3460, loss = 512.18918593\n",
      "Iteration 3461, loss = 511.95143085\n",
      "Iteration 3462, loss = 511.71464327\n",
      "Iteration 3463, loss = 511.48024468\n",
      "Iteration 3464, loss = 511.25044421\n",
      "Iteration 3465, loss = 511.01800187\n",
      "Iteration 3466, loss = 510.78292756\n",
      "Iteration 3467, loss = 510.55266124\n",
      "Iteration 3468, loss = 510.32426708\n",
      "Iteration 3469, loss = 510.09437883\n",
      "Iteration 3470, loss = 509.86372494\n",
      "Iteration 3471, loss = 509.63570938\n",
      "Iteration 3472, loss = 509.40757518\n",
      "Iteration 3473, loss = 509.18186606\n",
      "Iteration 3474, loss = 508.95565143\n",
      "Iteration 3475, loss = 508.73384147\n",
      "Iteration 3476, loss = 508.51059637\n",
      "Iteration 3477, loss = 508.29042776\n",
      "Iteration 3478, loss = 508.07205636\n",
      "Iteration 3479, loss = 507.85662555\n",
      "Iteration 3480, loss = 507.63979350\n",
      "Iteration 3481, loss = 507.42108537\n",
      "Iteration 3482, loss = 507.20200987\n",
      "Iteration 3483, loss = 506.98317388\n",
      "Iteration 3484, loss = 506.76723912\n",
      "Iteration 3485, loss = 506.55252263\n",
      "Iteration 3486, loss = 506.33638522\n",
      "Iteration 3487, loss = 506.11949028\n",
      "Iteration 3488, loss = 505.90555307\n",
      "Iteration 3489, loss = 505.69433680\n",
      "Iteration 3490, loss = 505.47988920\n",
      "Iteration 3491, loss = 505.26891142\n",
      "Iteration 3492, loss = 505.06041312\n",
      "Iteration 3493, loss = 504.84898350\n",
      "Iteration 3494, loss = 504.64046386\n",
      "Iteration 3495, loss = 504.43471618\n",
      "Iteration 3496, loss = 504.23068388\n",
      "Iteration 3497, loss = 504.02198132\n",
      "Iteration 3498, loss = 503.81929831\n",
      "Iteration 3499, loss = 503.61497824\n",
      "Iteration 3500, loss = 503.40705811\n",
      "Iteration 3501, loss = 503.20032095\n",
      "Iteration 3502, loss = 502.99270249\n",
      "Iteration 3503, loss = 502.78694342\n",
      "Iteration 3504, loss = 502.58342628\n",
      "Iteration 3505, loss = 502.37844481\n",
      "Iteration 3506, loss = 502.17420064\n",
      "Iteration 3507, loss = 501.97160141\n",
      "Iteration 3508, loss = 501.76715056\n",
      "Iteration 3509, loss = 501.56122125\n",
      "Iteration 3510, loss = 501.35398801\n",
      "Iteration 3511, loss = 501.14934592\n",
      "Iteration 3512, loss = 500.94151486\n",
      "Iteration 3513, loss = 500.73847180\n",
      "Iteration 3514, loss = 500.52803608\n",
      "Iteration 3515, loss = 500.31900472\n",
      "Iteration 3516, loss = 500.11594680\n",
      "Iteration 3517, loss = 499.91316489\n",
      "Iteration 3518, loss = 499.70594672\n",
      "Iteration 3519, loss = 499.50111892\n",
      "Iteration 3520, loss = 499.29764127\n",
      "Iteration 3521, loss = 499.09092488\n",
      "Iteration 3522, loss = 498.89127106\n",
      "Iteration 3523, loss = 498.69030179\n",
      "Iteration 3524, loss = 498.48820314\n",
      "Iteration 3525, loss = 498.28681323\n",
      "Iteration 3526, loss = 498.08744417\n",
      "Iteration 3527, loss = 497.88815111\n",
      "Iteration 3528, loss = 497.69035444\n",
      "Iteration 3529, loss = 497.49400820\n",
      "Iteration 3530, loss = 497.29699006\n",
      "Iteration 3531, loss = 497.10003374\n",
      "Iteration 3532, loss = 496.90429233\n",
      "Iteration 3533, loss = 496.71022096\n",
      "Iteration 3534, loss = 496.51839265\n",
      "Iteration 3535, loss = 496.32386851\n",
      "Iteration 3536, loss = 496.12951747\n",
      "Iteration 3537, loss = 495.93729844\n",
      "Iteration 3538, loss = 495.74536963\n",
      "Iteration 3539, loss = 495.54091084\n",
      "Iteration 3540, loss = 495.31663982\n",
      "Iteration 3541, loss = 495.08099088\n",
      "Iteration 3542, loss = 494.83348515\n",
      "Iteration 3543, loss = 494.57543987\n",
      "Iteration 3544, loss = 494.31222042\n",
      "Iteration 3545, loss = 494.04603654\n",
      "Iteration 3546, loss = 493.77117560\n",
      "Iteration 3547, loss = 493.49024704\n",
      "Iteration 3548, loss = 493.20648557\n",
      "Iteration 3549, loss = 492.92154279\n",
      "Iteration 3550, loss = 492.63278936\n",
      "Iteration 3551, loss = 492.34056350\n",
      "Iteration 3552, loss = 492.04519556\n",
      "Iteration 3553, loss = 491.74809346\n",
      "Iteration 3554, loss = 491.45082075\n",
      "Iteration 3555, loss = 491.15743199\n",
      "Iteration 3556, loss = 490.85840306\n",
      "Iteration 3557, loss = 490.55640317\n",
      "Iteration 3558, loss = 490.25584717\n",
      "Iteration 3559, loss = 489.96054378\n",
      "Iteration 3560, loss = 489.66248358\n",
      "Iteration 3561, loss = 489.35796676\n",
      "Iteration 3562, loss = 489.05580642\n",
      "Iteration 3563, loss = 488.75516214\n",
      "Iteration 3564, loss = 488.45678785\n",
      "Iteration 3565, loss = 488.15883415\n",
      "Iteration 3566, loss = 487.86339803\n",
      "Iteration 3567, loss = 487.56387775\n",
      "Iteration 3568, loss = 487.26525490\n",
      "Iteration 3569, loss = 486.96985468\n",
      "Iteration 3570, loss = 486.67606278\n",
      "Iteration 3571, loss = 486.38441825\n",
      "Iteration 3572, loss = 486.09095551\n",
      "Iteration 3573, loss = 485.79690272\n",
      "Iteration 3574, loss = 485.50654916\n",
      "Iteration 3575, loss = 485.21893984\n",
      "Iteration 3576, loss = 484.93091450\n",
      "Iteration 3577, loss = 484.64677920\n",
      "Iteration 3578, loss = 484.36551481\n",
      "Iteration 3579, loss = 484.08416389\n",
      "Iteration 3580, loss = 483.80363068\n",
      "Iteration 3581, loss = 483.52390270\n",
      "Iteration 3582, loss = 483.24883805\n",
      "Iteration 3583, loss = 482.97031194\n",
      "Iteration 3584, loss = 482.70718808\n",
      "Iteration 3585, loss = 482.45032290\n",
      "Iteration 3586, loss = 482.19301974\n",
      "Iteration 3587, loss = 481.93592144\n",
      "Iteration 3588, loss = 481.68191113\n",
      "Iteration 3589, loss = 481.43762677\n",
      "Iteration 3590, loss = 481.20460034\n",
      "Iteration 3591, loss = 480.97344966\n",
      "Iteration 3592, loss = 480.73857190\n",
      "Iteration 3593, loss = 480.50192291\n",
      "Iteration 3594, loss = 480.26343997\n",
      "Iteration 3595, loss = 480.02844641\n",
      "Iteration 3596, loss = 479.79500759\n",
      "Iteration 3597, loss = 479.56490896\n",
      "Iteration 3598, loss = 479.33911908\n",
      "Iteration 3599, loss = 479.11354031\n",
      "Iteration 3600, loss = 478.88909748\n",
      "Iteration 3601, loss = 478.66642332\n",
      "Iteration 3602, loss = 478.43917029\n",
      "Iteration 3603, loss = 478.21918224\n",
      "Iteration 3604, loss = 478.00448492\n",
      "Iteration 3605, loss = 477.79340808\n",
      "Iteration 3606, loss = 477.58314109\n",
      "Iteration 3607, loss = 477.37357271\n",
      "Iteration 3608, loss = 477.16300253\n",
      "Iteration 3609, loss = 476.95348965\n",
      "Iteration 3610, loss = 476.75558993\n",
      "Iteration 3611, loss = 476.57209535\n",
      "Iteration 3612, loss = 476.39170565\n",
      "Iteration 3613, loss = 476.21171949\n",
      "Iteration 3614, loss = 476.03684897\n",
      "Iteration 3615, loss = 475.86064309\n",
      "Iteration 3616, loss = 475.68632308\n",
      "Iteration 3617, loss = 475.51305385\n",
      "Iteration 3618, loss = 475.34014493\n",
      "Iteration 3619, loss = 475.17310020\n",
      "Iteration 3620, loss = 475.00650146\n",
      "Iteration 3621, loss = 474.83401558\n",
      "Iteration 3622, loss = 474.66256787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3623, loss = 474.49963060\n",
      "Iteration 3624, loss = 474.33437761\n",
      "Iteration 3625, loss = 474.17063982\n",
      "Iteration 3626, loss = 474.00387035\n",
      "Iteration 3627, loss = 473.84068682\n",
      "Iteration 3628, loss = 473.68075474\n",
      "Iteration 3629, loss = 473.51834569\n",
      "Iteration 3630, loss = 473.35697736\n",
      "Iteration 3631, loss = 473.19366574\n",
      "Iteration 3632, loss = 473.03242250\n",
      "Iteration 3633, loss = 472.87005355\n",
      "Iteration 3634, loss = 472.70991252\n",
      "Iteration 3635, loss = 472.54949182\n",
      "Iteration 3636, loss = 472.38780860\n",
      "Iteration 3637, loss = 472.22958606\n",
      "Iteration 3638, loss = 472.06643627\n",
      "Iteration 3639, loss = 471.90412062\n",
      "Iteration 3640, loss = 471.74389785\n",
      "Iteration 3641, loss = 471.58336443\n",
      "Iteration 3642, loss = 471.42348339\n",
      "Iteration 3643, loss = 471.26808108\n",
      "Iteration 3644, loss = 471.11179152\n",
      "Iteration 3645, loss = 470.95132953\n",
      "Iteration 3646, loss = 470.79220175\n",
      "Iteration 3647, loss = 470.63170400\n",
      "Iteration 3648, loss = 470.47673733\n",
      "Iteration 3649, loss = 470.32213865\n",
      "Iteration 3650, loss = 470.16614815\n",
      "Iteration 3651, loss = 470.00456996\n",
      "Iteration 3652, loss = 469.85133370\n",
      "Iteration 3653, loss = 469.69764488\n",
      "Iteration 3654, loss = 469.54505332\n",
      "Iteration 3655, loss = 469.38995384\n",
      "Iteration 3656, loss = 469.23426964\n",
      "Iteration 3657, loss = 469.08211005\n",
      "Iteration 3658, loss = 468.93055290\n",
      "Iteration 3659, loss = 468.77647209\n",
      "Iteration 3660, loss = 468.62289608\n",
      "Iteration 3661, loss = 468.47198678\n",
      "Iteration 3662, loss = 468.32178617\n",
      "Iteration 3663, loss = 468.17395597\n",
      "Iteration 3664, loss = 468.02396068\n",
      "Iteration 3665, loss = 467.87337059\n",
      "Iteration 3666, loss = 467.72499652\n",
      "Iteration 3667, loss = 467.57619148\n",
      "Iteration 3668, loss = 467.42797654\n",
      "Iteration 3669, loss = 467.28072298\n",
      "Iteration 3670, loss = 467.13527293\n",
      "Iteration 3671, loss = 466.98666751\n",
      "Iteration 3672, loss = 466.84596526\n",
      "Iteration 3673, loss = 466.70568985\n",
      "Iteration 3674, loss = 466.56721776\n",
      "Iteration 3675, loss = 466.42920322\n",
      "Iteration 3676, loss = 466.28978961\n",
      "Iteration 3677, loss = 466.14925368\n",
      "Iteration 3678, loss = 466.01194584\n",
      "Iteration 3679, loss = 465.87838613\n",
      "Iteration 3680, loss = 465.73957873\n",
      "Iteration 3681, loss = 465.60401721\n",
      "Iteration 3682, loss = 465.47060449\n",
      "Iteration 3683, loss = 465.33575444\n",
      "Iteration 3684, loss = 465.19841336\n",
      "Iteration 3685, loss = 465.06133031\n",
      "Iteration 3686, loss = 464.92632538\n",
      "Iteration 3687, loss = 464.79281106\n",
      "Iteration 3688, loss = 464.65713168\n",
      "Iteration 3689, loss = 464.52163787\n",
      "Iteration 3690, loss = 464.38743365\n",
      "Iteration 3691, loss = 464.25720540\n",
      "Iteration 3692, loss = 464.12544883\n",
      "Iteration 3693, loss = 463.99552512\n",
      "Iteration 3694, loss = 463.86080339\n",
      "Iteration 3695, loss = 463.73034311\n",
      "Iteration 3696, loss = 463.60089828\n",
      "Iteration 3697, loss = 463.47158422\n",
      "Iteration 3698, loss = 463.34414380\n",
      "Iteration 3699, loss = 463.21329149\n",
      "Iteration 3700, loss = 463.08463857\n",
      "Iteration 3701, loss = 462.95676727\n",
      "Iteration 3702, loss = 462.82894046\n",
      "Iteration 3703, loss = 462.70258885\n",
      "Iteration 3704, loss = 462.57312732\n",
      "Iteration 3705, loss = 462.44613398\n",
      "Iteration 3706, loss = 462.32109284\n",
      "Iteration 3707, loss = 462.19638464\n",
      "Iteration 3708, loss = 462.06735826\n",
      "Iteration 3709, loss = 461.93664084\n",
      "Iteration 3710, loss = 461.81006944\n",
      "Iteration 3711, loss = 461.68466617\n",
      "Iteration 3712, loss = 461.56194153\n",
      "Iteration 3713, loss = 461.43512551\n",
      "Iteration 3714, loss = 461.31021935\n",
      "Iteration 3715, loss = 461.19049223\n",
      "Iteration 3716, loss = 461.06734867\n",
      "Iteration 3717, loss = 460.94536134\n",
      "Iteration 3718, loss = 460.82309419\n",
      "Iteration 3719, loss = 460.70039779\n",
      "Iteration 3720, loss = 460.57959464\n",
      "Iteration 3721, loss = 460.46137209\n",
      "Iteration 3722, loss = 460.33981811\n",
      "Iteration 3723, loss = 460.21853461\n",
      "Iteration 3724, loss = 460.09924400\n",
      "Iteration 3725, loss = 459.97971943\n",
      "Iteration 3726, loss = 459.86124025\n",
      "Iteration 3727, loss = 459.74224188\n",
      "Iteration 3728, loss = 459.62524872\n",
      "Iteration 3729, loss = 459.50861108\n",
      "Iteration 3730, loss = 459.38871842\n",
      "Iteration 3731, loss = 459.26975804\n",
      "Iteration 3732, loss = 459.15468249\n",
      "Iteration 3733, loss = 459.04004844\n",
      "Iteration 3734, loss = 458.92292661\n",
      "Iteration 3735, loss = 458.80541629\n",
      "Iteration 3736, loss = 458.69419889\n",
      "Iteration 3737, loss = 458.58003323\n",
      "Iteration 3738, loss = 458.46288841\n",
      "Iteration 3739, loss = 458.35246223\n",
      "Iteration 3740, loss = 458.24164510\n",
      "Iteration 3741, loss = 458.12937404\n",
      "Iteration 3742, loss = 458.01982702\n",
      "Iteration 3743, loss = 457.91280782\n",
      "Iteration 3744, loss = 457.80301608\n",
      "Iteration 3745, loss = 457.69678236\n",
      "Iteration 3746, loss = 457.58700445\n",
      "Iteration 3747, loss = 457.47138503\n",
      "Iteration 3748, loss = 457.35277757\n",
      "Iteration 3749, loss = 457.23385860\n",
      "Iteration 3750, loss = 457.11428147\n",
      "Iteration 3751, loss = 457.00115204\n",
      "Iteration 3752, loss = 456.89384338\n",
      "Iteration 3753, loss = 456.78629727\n",
      "Iteration 3754, loss = 456.67889416\n",
      "Iteration 3755, loss = 456.57084361\n",
      "Iteration 3756, loss = 456.46014607\n",
      "Iteration 3757, loss = 456.34614361\n",
      "Iteration 3758, loss = 456.23605649\n",
      "Iteration 3759, loss = 456.12672399\n",
      "Iteration 3760, loss = 456.01804361\n",
      "Iteration 3761, loss = 455.91201576\n",
      "Iteration 3762, loss = 455.80931895\n",
      "Iteration 3763, loss = 455.70244305\n",
      "Iteration 3764, loss = 455.59382843\n",
      "Iteration 3765, loss = 455.48600068\n",
      "Iteration 3766, loss = 455.37866310\n",
      "Iteration 3767, loss = 455.27048939\n",
      "Iteration 3768, loss = 455.16738214\n",
      "Iteration 3769, loss = 455.06427294\n",
      "Iteration 3770, loss = 454.96028996\n",
      "Iteration 3771, loss = 454.85624280\n",
      "Iteration 3772, loss = 454.75125084\n",
      "Iteration 3773, loss = 454.64559889\n",
      "Iteration 3774, loss = 454.54258579\n",
      "Iteration 3775, loss = 454.44254462\n",
      "Iteration 3776, loss = 454.34094150\n",
      "Iteration 3777, loss = 454.23629124\n",
      "Iteration 3778, loss = 454.13140984\n",
      "Iteration 3779, loss = 454.02876040\n",
      "Iteration 3780, loss = 453.93127746\n",
      "Iteration 3781, loss = 453.83011414\n",
      "Iteration 3782, loss = 453.72731601\n",
      "Iteration 3783, loss = 453.62491929\n",
      "Iteration 3784, loss = 453.52524390\n",
      "Iteration 3785, loss = 453.42769551\n",
      "Iteration 3786, loss = 453.32839022\n",
      "Iteration 3787, loss = 453.22468474\n",
      "Iteration 3788, loss = 453.12243636\n",
      "Iteration 3789, loss = 453.02234858\n",
      "Iteration 3790, loss = 452.92045794\n",
      "Iteration 3791, loss = 452.82040941\n",
      "Iteration 3792, loss = 452.72219636\n",
      "Iteration 3793, loss = 452.62517508\n",
      "Iteration 3794, loss = 452.52927134\n",
      "Iteration 3795, loss = 452.43308685\n",
      "Iteration 3796, loss = 452.33541279\n",
      "Iteration 3797, loss = 452.23943983\n",
      "Iteration 3798, loss = 452.13989865\n",
      "Iteration 3799, loss = 452.04028629\n",
      "Iteration 3800, loss = 451.94130691\n",
      "Iteration 3801, loss = 451.84291309\n",
      "Iteration 3802, loss = 451.74794640\n",
      "Iteration 3803, loss = 451.65163505\n",
      "Iteration 3804, loss = 451.55816972\n",
      "Iteration 3805, loss = 451.46468693\n",
      "Iteration 3806, loss = 451.37121185\n",
      "Iteration 3807, loss = 451.27749570\n",
      "Iteration 3808, loss = 451.18287676\n",
      "Iteration 3809, loss = 451.08685463\n",
      "Iteration 3810, loss = 450.99474550\n",
      "Iteration 3811, loss = 450.90163383\n",
      "Iteration 3812, loss = 450.80694510\n",
      "Iteration 3813, loss = 450.71660462\n",
      "Iteration 3814, loss = 450.62628250\n",
      "Iteration 3815, loss = 450.53420894\n",
      "Iteration 3816, loss = 450.44913676\n",
      "Iteration 3817, loss = 450.36420511\n",
      "Iteration 3818, loss = 450.27273221\n",
      "Iteration 3819, loss = 450.18696660\n",
      "Iteration 3820, loss = 450.10211917\n",
      "Iteration 3821, loss = 450.01621882\n",
      "Iteration 3822, loss = 449.93003456\n",
      "Iteration 3823, loss = 449.84430484\n",
      "Iteration 3824, loss = 449.75802675\n",
      "Iteration 3825, loss = 449.67316404\n",
      "Iteration 3826, loss = 449.58536171\n",
      "Iteration 3827, loss = 449.49977331\n",
      "Iteration 3828, loss = 449.41584204\n",
      "Iteration 3829, loss = 449.33045381\n",
      "Iteration 3830, loss = 449.24579344\n",
      "Iteration 3831, loss = 449.16436671\n",
      "Iteration 3832, loss = 449.08065628\n",
      "Iteration 3833, loss = 448.99662114\n",
      "Iteration 3834, loss = 448.91158287\n",
      "Iteration 3835, loss = 448.82868938\n",
      "Iteration 3836, loss = 448.74646008\n",
      "Iteration 3837, loss = 448.66638964\n",
      "Iteration 3838, loss = 448.58556561\n",
      "Iteration 3839, loss = 448.50479331\n",
      "Iteration 3840, loss = 448.42197653\n",
      "Iteration 3841, loss = 448.33886334\n",
      "Iteration 3842, loss = 448.25594219\n",
      "Iteration 3843, loss = 448.17485256\n",
      "Iteration 3844, loss = 448.09462083\n",
      "Iteration 3845, loss = 448.01185493\n",
      "Iteration 3846, loss = 447.93298519\n",
      "Iteration 3847, loss = 447.85366267\n",
      "Iteration 3848, loss = 447.77426240\n",
      "Iteration 3849, loss = 447.69296878\n",
      "Iteration 3850, loss = 447.61391406\n",
      "Iteration 3851, loss = 447.53344083\n",
      "Iteration 3852, loss = 447.45542406\n",
      "Iteration 3853, loss = 447.37696693\n",
      "Iteration 3854, loss = 447.29851165\n",
      "Iteration 3855, loss = 447.21859808\n",
      "Iteration 3856, loss = 447.14065223\n",
      "Iteration 3857, loss = 447.06224130\n",
      "Iteration 3858, loss = 446.98466186\n",
      "Iteration 3859, loss = 446.90765511\n",
      "Iteration 3860, loss = 446.82922582\n",
      "Iteration 3861, loss = 446.75244556\n",
      "Iteration 3862, loss = 446.67637587\n",
      "Iteration 3863, loss = 446.59923302\n",
      "Iteration 3864, loss = 446.52274205\n",
      "Iteration 3865, loss = 446.44600784\n",
      "Iteration 3866, loss = 446.36999401\n",
      "Iteration 3867, loss = 446.29544665\n",
      "Iteration 3868, loss = 446.21743852\n",
      "Iteration 3869, loss = 446.14283697\n",
      "Iteration 3870, loss = 446.06952080\n",
      "Iteration 3871, loss = 445.99358483\n",
      "Iteration 3872, loss = 445.91881130\n",
      "Iteration 3873, loss = 445.84391587\n",
      "Iteration 3874, loss = 445.76904154\n",
      "Iteration 3875, loss = 445.69535216\n",
      "Iteration 3876, loss = 445.62098714\n",
      "Iteration 3877, loss = 445.54670498\n",
      "Iteration 3878, loss = 445.47674643\n",
      "Iteration 3879, loss = 445.40204805\n",
      "Iteration 3880, loss = 445.32957853\n",
      "Iteration 3881, loss = 445.25851736\n",
      "Iteration 3882, loss = 445.18441290\n",
      "Iteration 3883, loss = 445.11169927\n",
      "Iteration 3884, loss = 445.04074147\n",
      "Iteration 3885, loss = 444.96821182\n",
      "Iteration 3886, loss = 444.89677324\n",
      "Iteration 3887, loss = 444.82378120\n",
      "Iteration 3888, loss = 444.75113001\n",
      "Iteration 3889, loss = 444.67962171\n",
      "Iteration 3890, loss = 444.60805223\n",
      "Iteration 3891, loss = 444.53667570\n",
      "Iteration 3892, loss = 444.46629355\n",
      "Iteration 3893, loss = 444.39641789\n",
      "Iteration 3894, loss = 444.32915460\n",
      "Iteration 3895, loss = 444.26290873\n",
      "Iteration 3896, loss = 444.19715503\n",
      "Iteration 3897, loss = 444.13306658\n",
      "Iteration 3898, loss = 444.07051778\n",
      "Iteration 3899, loss = 444.00510240\n",
      "Iteration 3900, loss = 443.93783576\n",
      "Iteration 3901, loss = 443.86284698\n",
      "Iteration 3902, loss = 443.78135750\n",
      "Iteration 3903, loss = 443.70127424\n",
      "Iteration 3904, loss = 443.62670137\n",
      "Iteration 3905, loss = 443.55827745\n",
      "Iteration 3906, loss = 443.49497417\n",
      "Iteration 3907, loss = 443.43168092\n",
      "Iteration 3908, loss = 443.36580143\n",
      "Iteration 3909, loss = 443.29810445\n",
      "Iteration 3910, loss = 443.22290198\n",
      "Iteration 3911, loss = 443.15108981\n",
      "Iteration 3912, loss = 443.08304289\n",
      "Iteration 3913, loss = 443.01755237\n",
      "Iteration 3914, loss = 442.95595253\n",
      "Iteration 3915, loss = 442.89716647\n",
      "Iteration 3916, loss = 442.83401781\n",
      "Iteration 3917, loss = 442.76450369\n",
      "Iteration 3918, loss = 442.69749834\n",
      "Iteration 3919, loss = 442.63142971\n",
      "Iteration 3920, loss = 442.56850735\n",
      "Iteration 3921, loss = 442.50610219\n",
      "Iteration 3922, loss = 442.44376015\n",
      "Iteration 3923, loss = 442.38247751\n",
      "Iteration 3924, loss = 442.31959843\n",
      "Iteration 3925, loss = 442.25477650\n",
      "Iteration 3926, loss = 442.19130593\n",
      "Iteration 3927, loss = 442.13000846\n",
      "Iteration 3928, loss = 442.06898212\n",
      "Iteration 3929, loss = 442.00852623\n",
      "Iteration 3930, loss = 441.94694042\n",
      "Iteration 3931, loss = 441.88450740\n",
      "Iteration 3932, loss = 441.82244272\n",
      "Iteration 3933, loss = 441.76081149\n",
      "Iteration 3934, loss = 441.70108882\n",
      "Iteration 3935, loss = 441.64282513\n",
      "Iteration 3936, loss = 441.58368916\n",
      "Iteration 3937, loss = 441.52502489\n",
      "Iteration 3938, loss = 441.46395471\n",
      "Iteration 3939, loss = 441.40370273\n",
      "Iteration 3940, loss = 441.34469078\n",
      "Iteration 3941, loss = 441.28436426\n",
      "Iteration 3942, loss = 441.22487752\n",
      "Iteration 3943, loss = 441.16500739\n",
      "Iteration 3944, loss = 441.10477401\n",
      "Iteration 3945, loss = 441.04645017\n",
      "Iteration 3946, loss = 440.98744398\n",
      "Iteration 3947, loss = 440.92801370\n",
      "Iteration 3948, loss = 440.86994933\n",
      "Iteration 3949, loss = 440.81161568\n",
      "Iteration 3950, loss = 440.75463059\n",
      "Iteration 3951, loss = 440.69712202\n",
      "Iteration 3952, loss = 440.64019368\n",
      "Iteration 3953, loss = 440.58320209\n",
      "Iteration 3954, loss = 440.52473686\n",
      "Iteration 3955, loss = 440.46695943\n",
      "Iteration 3956, loss = 440.40870196\n",
      "Iteration 3957, loss = 440.35101796\n",
      "Iteration 3958, loss = 440.29508932\n",
      "Iteration 3959, loss = 440.23835840\n",
      "Iteration 3960, loss = 440.18297842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3961, loss = 440.12710802\n",
      "Iteration 3962, loss = 440.07104865\n",
      "Iteration 3963, loss = 440.01375607\n",
      "Iteration 3964, loss = 439.95852216\n",
      "Iteration 3965, loss = 439.90261284\n",
      "Iteration 3966, loss = 439.84754104\n",
      "Iteration 3967, loss = 439.79240353\n",
      "Iteration 3968, loss = 439.73744832\n",
      "Iteration 3969, loss = 439.68269020\n",
      "Iteration 3970, loss = 439.62790756\n",
      "Iteration 3971, loss = 439.57254146\n",
      "Iteration 3972, loss = 439.51814797\n",
      "Iteration 3973, loss = 439.46560035\n",
      "Iteration 3974, loss = 439.41106422\n",
      "Iteration 3975, loss = 439.35596476\n",
      "Iteration 3976, loss = 439.30250502\n",
      "Iteration 3977, loss = 439.24870493\n",
      "Iteration 3978, loss = 439.19379554\n",
      "Iteration 3979, loss = 439.14109271\n",
      "Iteration 3980, loss = 439.08829744\n",
      "Iteration 3981, loss = 439.03465194\n",
      "Iteration 3982, loss = 438.98177016\n",
      "Iteration 3983, loss = 438.92849458\n",
      "Iteration 3984, loss = 438.87627219\n",
      "Iteration 3985, loss = 438.82355635\n",
      "Iteration 3986, loss = 438.77101535\n",
      "Iteration 3987, loss = 438.71908333\n",
      "Iteration 3988, loss = 438.66650590\n",
      "Iteration 3989, loss = 438.61410210\n",
      "Iteration 3990, loss = 438.56295665\n",
      "Iteration 3991, loss = 438.51100340\n",
      "Iteration 3992, loss = 438.45907755\n",
      "Iteration 3993, loss = 438.40673703\n",
      "Iteration 3994, loss = 438.35654294\n",
      "Iteration 3995, loss = 438.30420477\n",
      "Iteration 3996, loss = 438.25177013\n",
      "Iteration 3997, loss = 438.20277681\n",
      "Iteration 3998, loss = 438.15265302\n",
      "Iteration 3999, loss = 438.10051193\n",
      "Iteration 4000, loss = 438.04912765\n",
      "Iteration 4001, loss = 438.00051347\n",
      "Iteration 4002, loss = 437.95115181\n",
      "Iteration 4003, loss = 437.90021816\n",
      "Iteration 4004, loss = 437.84776262\n",
      "Iteration 4005, loss = 437.79673260\n",
      "Iteration 4006, loss = 437.75021998\n",
      "Iteration 4007, loss = 437.70038381\n",
      "Iteration 4008, loss = 437.64941598\n",
      "Iteration 4009, loss = 437.59804263\n",
      "Iteration 4010, loss = 437.54706661\n",
      "Iteration 4011, loss = 437.49888527\n",
      "Iteration 4012, loss = 437.44920064\n",
      "Iteration 4013, loss = 437.39924453\n",
      "Iteration 4014, loss = 437.35062633\n",
      "Iteration 4015, loss = 437.30052599\n",
      "Iteration 4016, loss = 437.25152837\n",
      "Iteration 4017, loss = 437.20346936\n",
      "Iteration 4018, loss = 437.15543232\n",
      "Iteration 4019, loss = 437.10608382\n",
      "Iteration 4020, loss = 437.05772955\n",
      "Iteration 4021, loss = 437.00981523\n",
      "Iteration 4022, loss = 436.96179461\n",
      "Iteration 4023, loss = 436.91321729\n",
      "Iteration 4024, loss = 436.86427795\n",
      "Iteration 4025, loss = 436.81771703\n",
      "Iteration 4026, loss = 436.77038279\n",
      "Iteration 4027, loss = 436.72143341\n",
      "Iteration 4028, loss = 436.67479751\n",
      "Iteration 4029, loss = 436.62659377\n",
      "Iteration 4030, loss = 436.57886230\n",
      "Iteration 4031, loss = 436.53190892\n",
      "Iteration 4032, loss = 436.48510741\n",
      "Iteration 4033, loss = 436.43943804\n",
      "Iteration 4034, loss = 436.39317368\n",
      "Iteration 4035, loss = 436.34521064\n",
      "Iteration 4036, loss = 436.29799180\n",
      "Iteration 4037, loss = 436.25115991\n",
      "Iteration 4038, loss = 436.20584936\n",
      "Iteration 4039, loss = 436.16003320\n",
      "Iteration 4040, loss = 436.11561791\n",
      "Iteration 4041, loss = 436.06865738\n",
      "Iteration 4042, loss = 436.02415095\n",
      "Iteration 4043, loss = 435.97886829\n",
      "Iteration 4044, loss = 435.93364551\n",
      "Iteration 4045, loss = 435.88871797\n",
      "Iteration 4046, loss = 435.84346124\n",
      "Iteration 4047, loss = 435.79990602\n",
      "Iteration 4048, loss = 435.75765045\n",
      "Iteration 4049, loss = 435.71220998\n",
      "Iteration 4050, loss = 435.66654472\n",
      "Iteration 4051, loss = 435.62239408\n",
      "Iteration 4052, loss = 435.57945537\n",
      "Iteration 4053, loss = 435.53628757\n",
      "Iteration 4054, loss = 435.48982428\n",
      "Iteration 4055, loss = 435.44504597\n",
      "Iteration 4056, loss = 435.40024040\n",
      "Iteration 4057, loss = 435.35596204\n",
      "Iteration 4058, loss = 435.31035349\n",
      "Iteration 4059, loss = 435.26952142\n",
      "Iteration 4060, loss = 435.22487796\n",
      "Iteration 4061, loss = 435.18303717\n",
      "Iteration 4062, loss = 435.14136910\n",
      "Iteration 4063, loss = 435.09972973\n",
      "Iteration 4064, loss = 435.05789925\n",
      "Iteration 4065, loss = 435.01489884\n",
      "Iteration 4066, loss = 434.97406658\n",
      "Iteration 4067, loss = 434.93442529\n",
      "Iteration 4068, loss = 434.89569345\n",
      "Iteration 4069, loss = 434.85459600\n",
      "Iteration 4070, loss = 434.81256402\n",
      "Iteration 4071, loss = 434.77100211\n",
      "Iteration 4072, loss = 434.73264200\n",
      "Iteration 4073, loss = 434.69460876\n",
      "Iteration 4074, loss = 434.65789228\n",
      "Iteration 4075, loss = 434.62213196\n",
      "Iteration 4076, loss = 434.58990975\n",
      "Iteration 4077, loss = 434.55351025\n",
      "Iteration 4078, loss = 434.51044110\n",
      "Iteration 4079, loss = 434.45548953\n",
      "Iteration 4080, loss = 434.39885637\n",
      "Iteration 4081, loss = 434.34603920\n",
      "Iteration 4082, loss = 434.30338458\n",
      "Iteration 4083, loss = 434.26750202\n",
      "Iteration 4084, loss = 434.23383122\n",
      "Iteration 4085, loss = 434.19684451\n",
      "Iteration 4086, loss = 434.15287722\n",
      "Iteration 4087, loss = 434.10552473\n",
      "Iteration 4088, loss = 434.05995053\n",
      "Iteration 4089, loss = 434.01852855\n",
      "Iteration 4090, loss = 433.98276154\n",
      "Iteration 4091, loss = 433.94763195\n",
      "Iteration 4092, loss = 433.90763211\n",
      "Iteration 4093, loss = 433.86542478\n",
      "Iteration 4094, loss = 433.82161045\n",
      "Iteration 4095, loss = 433.78096573\n",
      "Iteration 4096, loss = 433.74021248\n",
      "Iteration 4097, loss = 433.70309371\n",
      "Iteration 4098, loss = 433.66615429\n",
      "Iteration 4099, loss = 433.62617241\n",
      "Iteration 4100, loss = 433.58337621\n",
      "Iteration 4101, loss = 433.54426585\n",
      "Iteration 4102, loss = 433.50355233\n",
      "Iteration 4103, loss = 433.46625636\n",
      "Iteration 4104, loss = 433.42648790\n",
      "Iteration 4105, loss = 433.38765558\n",
      "Iteration 4106, loss = 433.35017592\n",
      "Iteration 4107, loss = 433.30964400\n",
      "Iteration 4108, loss = 433.27071977\n",
      "Iteration 4109, loss = 433.23135946\n",
      "Iteration 4110, loss = 433.19210909\n",
      "Iteration 4111, loss = 433.15498589\n",
      "Iteration 4112, loss = 433.11651032\n",
      "Iteration 4113, loss = 433.07637468\n",
      "Iteration 4114, loss = 433.03890667\n",
      "Iteration 4115, loss = 433.00034285\n",
      "Iteration 4116, loss = 432.96395425\n",
      "Iteration 4117, loss = 432.92609475\n",
      "Iteration 4118, loss = 432.88683772\n",
      "Iteration 4119, loss = 432.84944157\n",
      "Iteration 4120, loss = 432.81088627\n",
      "Iteration 4121, loss = 432.77405179\n",
      "Iteration 4122, loss = 432.73650742\n",
      "Iteration 4123, loss = 432.69888046\n",
      "Iteration 4124, loss = 432.66253426\n",
      "Iteration 4125, loss = 432.62474247\n",
      "Iteration 4126, loss = 432.58824801\n",
      "Iteration 4127, loss = 432.55050642\n",
      "Iteration 4128, loss = 432.51330513\n",
      "Iteration 4129, loss = 432.47627287\n",
      "Iteration 4130, loss = 432.43922197\n",
      "Iteration 4131, loss = 432.40375168\n",
      "Iteration 4132, loss = 432.36827799\n",
      "Iteration 4133, loss = 432.33156186\n",
      "Iteration 4134, loss = 432.29425210\n",
      "Iteration 4135, loss = 432.25758598\n",
      "Iteration 4136, loss = 432.22307533\n",
      "Iteration 4137, loss = 432.18714824\n",
      "Iteration 4138, loss = 432.14961910\n",
      "Iteration 4139, loss = 432.11531360\n",
      "Iteration 4140, loss = 432.08101760\n",
      "Iteration 4141, loss = 432.04533969\n",
      "Iteration 4142, loss = 432.00896416\n",
      "Iteration 4143, loss = 431.97061478\n",
      "Iteration 4144, loss = 431.93412354\n",
      "Iteration 4145, loss = 431.89801505\n",
      "Iteration 4146, loss = 431.86032716\n",
      "Iteration 4147, loss = 431.82297784\n",
      "Iteration 4148, loss = 431.78784370\n",
      "Iteration 4149, loss = 431.75211639\n",
      "Iteration 4150, loss = 431.71771360\n",
      "Iteration 4151, loss = 431.68292638\n",
      "Iteration 4152, loss = 431.64867829\n",
      "Iteration 4153, loss = 431.61361440\n",
      "Iteration 4154, loss = 431.57853724\n",
      "Iteration 4155, loss = 431.54287222\n",
      "Iteration 4156, loss = 431.50718031\n",
      "Iteration 4157, loss = 431.47373229\n",
      "Iteration 4158, loss = 431.43895036\n",
      "Iteration 4159, loss = 431.40333396\n",
      "Iteration 4160, loss = 431.36911162\n",
      "Iteration 4161, loss = 431.33241577\n",
      "Iteration 4162, loss = 431.29964989\n",
      "Iteration 4163, loss = 431.26466532\n",
      "Iteration 4164, loss = 431.23017478\n",
      "Iteration 4165, loss = 431.19578423\n",
      "Iteration 4166, loss = 431.16175559\n",
      "Iteration 4167, loss = 431.12729103\n",
      "Iteration 4168, loss = 431.09379244\n",
      "Iteration 4169, loss = 431.05931135\n",
      "Iteration 4170, loss = 431.02595123\n",
      "Iteration 4171, loss = 430.99171897\n",
      "Iteration 4172, loss = 430.95818038\n",
      "Iteration 4173, loss = 430.92535229\n",
      "Iteration 4174, loss = 430.89067467\n",
      "Iteration 4175, loss = 430.85594851\n",
      "Iteration 4176, loss = 430.82298963\n",
      "Iteration 4177, loss = 430.79127527\n",
      "Iteration 4178, loss = 430.75707803\n",
      "Iteration 4179, loss = 430.72417806\n",
      "Iteration 4180, loss = 430.69104329\n",
      "Iteration 4181, loss = 430.65827662\n",
      "Iteration 4182, loss = 430.62543496\n",
      "Iteration 4183, loss = 430.59379994\n",
      "Iteration 4184, loss = 430.55696094\n",
      "Iteration 4185, loss = 430.52603005\n",
      "Iteration 4186, loss = 430.49592501\n",
      "Iteration 4187, loss = 430.46352021\n",
      "Iteration 4188, loss = 430.42922858\n",
      "Iteration 4189, loss = 430.39605641\n",
      "Iteration 4190, loss = 430.36549785\n",
      "Iteration 4191, loss = 430.33307079\n",
      "Iteration 4192, loss = 430.29867527\n",
      "Iteration 4193, loss = 430.26639368\n",
      "Iteration 4194, loss = 430.23433936\n",
      "Iteration 4195, loss = 430.19993601\n",
      "Iteration 4196, loss = 430.16582517\n",
      "Iteration 4197, loss = 430.13264771\n",
      "Iteration 4198, loss = 430.10129742\n",
      "Iteration 4199, loss = 430.07047197\n",
      "Iteration 4200, loss = 430.04028374\n",
      "Iteration 4201, loss = 430.00567294\n",
      "Iteration 4202, loss = 429.97207951\n",
      "Iteration 4203, loss = 429.94337867\n",
      "Iteration 4204, loss = 429.91179077\n",
      "Iteration 4205, loss = 429.87930129\n",
      "Iteration 4206, loss = 429.84866810\n",
      "Iteration 4207, loss = 429.81515769\n",
      "Iteration 4208, loss = 429.78372892\n",
      "Iteration 4209, loss = 429.75402453\n",
      "Iteration 4210, loss = 429.72287250\n",
      "Iteration 4211, loss = 429.69174557\n",
      "Iteration 4212, loss = 429.65947448\n",
      "Iteration 4213, loss = 429.62647592\n",
      "Iteration 4214, loss = 429.59514379\n",
      "Iteration 4215, loss = 429.56289265\n",
      "Iteration 4216, loss = 429.53106946\n",
      "Iteration 4217, loss = 429.50064787\n",
      "Iteration 4218, loss = 429.47067438\n",
      "Iteration 4219, loss = 429.44053859\n",
      "Iteration 4220, loss = 429.40872413\n",
      "Iteration 4221, loss = 429.37839628\n",
      "Iteration 4222, loss = 429.34989907\n",
      "Iteration 4223, loss = 429.31957634\n",
      "Iteration 4224, loss = 429.28887081\n",
      "Iteration 4225, loss = 429.25589644\n",
      "Iteration 4226, loss = 429.22489961\n",
      "Iteration 4227, loss = 429.19641132\n",
      "Iteration 4228, loss = 429.16495315\n",
      "Iteration 4229, loss = 429.13381105\n",
      "Iteration 4230, loss = 429.10446259\n",
      "Iteration 4231, loss = 429.07546919\n",
      "Iteration 4232, loss = 429.04369104\n",
      "Iteration 4233, loss = 429.01456109\n",
      "Iteration 4234, loss = 428.98440168\n",
      "Iteration 4235, loss = 428.95411665\n",
      "Iteration 4236, loss = 428.92528909\n",
      "Iteration 4237, loss = 428.89547540\n",
      "Iteration 4238, loss = 428.86535161\n",
      "Iteration 4239, loss = 428.83383826\n",
      "Iteration 4240, loss = 428.80385730\n",
      "Iteration 4241, loss = 428.77412405\n",
      "Iteration 4242, loss = 428.74624438\n",
      "Iteration 4243, loss = 428.71538957\n",
      "Iteration 4244, loss = 428.68528290\n",
      "Iteration 4245, loss = 428.65534028\n",
      "Iteration 4246, loss = 428.62687473\n",
      "Iteration 4247, loss = 428.59661671\n",
      "Iteration 4248, loss = 428.56898814\n",
      "Iteration 4249, loss = 428.54099827\n",
      "Iteration 4250, loss = 428.51167678\n",
      "Iteration 4251, loss = 428.48530050\n",
      "Iteration 4252, loss = 428.45806283\n",
      "Iteration 4253, loss = 428.43242954\n",
      "Iteration 4254, loss = 428.40600193\n",
      "Iteration 4255, loss = 428.38282935\n",
      "Iteration 4256, loss = 428.35378795\n",
      "Iteration 4257, loss = 428.32441310\n",
      "Iteration 4258, loss = 428.29205848\n",
      "Iteration 4259, loss = 428.25753973\n",
      "Iteration 4260, loss = 428.22395821\n",
      "Iteration 4261, loss = 428.19369184\n",
      "Iteration 4262, loss = 428.16496906\n",
      "Iteration 4263, loss = 428.13767464\n",
      "Iteration 4264, loss = 428.11149681\n",
      "Iteration 4265, loss = 428.08285208\n",
      "Iteration 4266, loss = 428.05031881\n",
      "Iteration 4267, loss = 428.02036990\n",
      "Iteration 4268, loss = 427.98987814\n",
      "Iteration 4269, loss = 427.96247046\n",
      "Iteration 4270, loss = 427.93495475\n",
      "Iteration 4271, loss = 427.90794481\n",
      "Iteration 4272, loss = 427.88186765\n",
      "Iteration 4273, loss = 427.85758337\n",
      "Iteration 4274, loss = 427.83406590\n",
      "Iteration 4275, loss = 427.80714880\n",
      "Iteration 4276, loss = 427.77483956\n",
      "Iteration 4277, loss = 427.73672202\n",
      "Iteration 4278, loss = 427.69357715\n",
      "Iteration 4279, loss = 427.64614681\n",
      "Iteration 4280, loss = 427.60631983\n",
      "Iteration 4281, loss = 427.57632518\n",
      "Iteration 4282, loss = 427.55443705\n",
      "Iteration 4283, loss = 427.53034509\n",
      "Iteration 4284, loss = 427.49897771\n",
      "Iteration 4285, loss = 427.46103452\n",
      "Iteration 4286, loss = 427.42337697\n",
      "Iteration 4287, loss = 427.38999338\n",
      "Iteration 4288, loss = 427.36064819\n",
      "Iteration 4289, loss = 427.33229237\n",
      "Iteration 4290, loss = 427.30459037\n",
      "Iteration 4291, loss = 427.27229478\n",
      "Iteration 4292, loss = 427.23767417\n",
      "Iteration 4293, loss = 427.20345166\n",
      "Iteration 4294, loss = 427.17275806\n",
      "Iteration 4295, loss = 427.14387651\n",
      "Iteration 4296, loss = 427.11473763\n",
      "Iteration 4297, loss = 427.08607360\n",
      "Iteration 4298, loss = 427.05493777\n",
      "Iteration 4299, loss = 427.02291628\n",
      "Iteration 4300, loss = 426.99140011\n",
      "Iteration 4301, loss = 426.96556274\n",
      "Iteration 4302, loss = 426.93505767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4303, loss = 426.90600620\n",
      "Iteration 4304, loss = 426.87611483\n",
      "Iteration 4305, loss = 426.84546935\n",
      "Iteration 4306, loss = 426.81276320\n",
      "Iteration 4307, loss = 426.78186368\n",
      "Iteration 4308, loss = 426.75699004\n",
      "Iteration 4309, loss = 426.72586748\n",
      "Iteration 4310, loss = 426.69435855\n",
      "Iteration 4311, loss = 426.66615974\n",
      "Iteration 4312, loss = 426.63760530\n",
      "Iteration 4313, loss = 426.60990469\n",
      "Iteration 4314, loss = 426.58033813\n",
      "Iteration 4315, loss = 426.55175052\n",
      "Iteration 4316, loss = 426.52347198\n",
      "Iteration 4317, loss = 426.49253837\n",
      "Iteration 4318, loss = 426.46364778\n",
      "Iteration 4319, loss = 426.43436657\n",
      "Iteration 4320, loss = 426.40532243\n",
      "Iteration 4321, loss = 426.37870646\n",
      "Iteration 4322, loss = 426.35122168\n",
      "Iteration 4323, loss = 426.32193838\n",
      "Iteration 4324, loss = 426.29143717\n",
      "Iteration 4325, loss = 426.26293238\n",
      "Iteration 4326, loss = 426.23458064\n",
      "Iteration 4327, loss = 426.20758349\n",
      "Iteration 4328, loss = 426.17875158\n",
      "Iteration 4329, loss = 426.15210398\n",
      "Iteration 4330, loss = 426.12259654\n",
      "Iteration 4331, loss = 426.09406663\n",
      "Iteration 4332, loss = 426.06626288\n",
      "Iteration 4333, loss = 426.03945764\n",
      "Iteration 4334, loss = 426.01241541\n",
      "Iteration 4335, loss = 425.98319233\n",
      "Iteration 4336, loss = 425.95516442\n",
      "Iteration 4337, loss = 425.92964422\n",
      "Iteration 4338, loss = 425.90240453\n",
      "Iteration 4339, loss = 425.87412203\n",
      "Iteration 4340, loss = 425.84835392\n",
      "Iteration 4341, loss = 425.82109084\n",
      "Iteration 4342, loss = 425.79443477\n",
      "Iteration 4343, loss = 425.76652333\n",
      "Iteration 4344, loss = 425.74060240\n",
      "Iteration 4345, loss = 425.71440585\n",
      "Iteration 4346, loss = 425.68777196\n",
      "Iteration 4347, loss = 425.65825097\n",
      "Iteration 4348, loss = 425.62869429\n",
      "Iteration 4349, loss = 425.60261615\n",
      "Iteration 4350, loss = 425.57591371\n",
      "Iteration 4351, loss = 425.54863319\n",
      "Iteration 4352, loss = 425.52139198\n",
      "Iteration 4353, loss = 425.49262714\n",
      "Iteration 4354, loss = 425.46528038\n",
      "Iteration 4355, loss = 425.43876270\n",
      "Iteration 4356, loss = 425.41110593\n",
      "Iteration 4357, loss = 425.38494588\n",
      "Iteration 4358, loss = 425.35815205\n",
      "Iteration 4359, loss = 425.33151341\n",
      "Iteration 4360, loss = 425.30610034\n",
      "Iteration 4361, loss = 425.27683992\n",
      "Iteration 4362, loss = 425.25043418\n",
      "Iteration 4363, loss = 425.22350793\n",
      "Iteration 4364, loss = 425.19760144\n",
      "Iteration 4365, loss = 425.17120292\n",
      "Iteration 4366, loss = 425.14163712\n",
      "Iteration 4367, loss = 425.11550604\n",
      "Iteration 4368, loss = 425.09003644\n",
      "Iteration 4369, loss = 425.06352887\n",
      "Iteration 4370, loss = 425.03535966\n",
      "Iteration 4371, loss = 425.00985749\n",
      "Iteration 4372, loss = 424.98354353\n",
      "Iteration 4373, loss = 424.96017494\n",
      "Iteration 4374, loss = 424.93299214\n",
      "Iteration 4375, loss = 424.90465022\n",
      "Iteration 4376, loss = 424.87932996\n",
      "Iteration 4377, loss = 424.85424321\n",
      "Iteration 4378, loss = 424.82965592\n",
      "Iteration 4379, loss = 424.80014230\n",
      "Iteration 4380, loss = 424.77391016\n",
      "Iteration 4381, loss = 424.74980035\n",
      "Iteration 4382, loss = 424.72245464\n",
      "Iteration 4383, loss = 424.69466799\n",
      "Iteration 4384, loss = 424.66853093\n",
      "Iteration 4385, loss = 424.64582996\n",
      "Iteration 4386, loss = 424.62065223\n",
      "Iteration 4387, loss = 424.59330849\n",
      "Iteration 4388, loss = 424.56567491\n",
      "Iteration 4389, loss = 424.53979872\n",
      "Iteration 4390, loss = 424.51599263\n",
      "Iteration 4391, loss = 424.49125621\n",
      "Iteration 4392, loss = 424.46360966\n",
      "Iteration 4393, loss = 424.43440386\n",
      "Iteration 4394, loss = 424.41004493\n",
      "Iteration 4395, loss = 424.38526380\n",
      "Iteration 4396, loss = 424.36043657\n",
      "Iteration 4397, loss = 424.33423624\n",
      "Iteration 4398, loss = 424.31029623\n",
      "Iteration 4399, loss = 424.28485989\n",
      "Iteration 4400, loss = 424.26008617\n",
      "Iteration 4401, loss = 424.23439671\n",
      "Iteration 4402, loss = 424.21027548\n",
      "Iteration 4403, loss = 424.18176672\n",
      "Iteration 4404, loss = 424.15779348\n",
      "Iteration 4405, loss = 424.13221564\n",
      "Iteration 4406, loss = 424.10890550\n",
      "Iteration 4407, loss = 424.08521610\n",
      "Iteration 4408, loss = 424.05740694\n",
      "Iteration 4409, loss = 424.03218440\n",
      "Iteration 4410, loss = 424.01053161\n",
      "Iteration 4411, loss = 423.98433860\n",
      "Iteration 4412, loss = 423.96119551\n",
      "Iteration 4413, loss = 423.93615074\n",
      "Iteration 4414, loss = 423.91283149\n",
      "Iteration 4415, loss = 423.88901000\n",
      "Iteration 4416, loss = 423.86393903\n",
      "Iteration 4417, loss = 423.83774447\n",
      "Iteration 4418, loss = 423.81394213\n",
      "Iteration 4419, loss = 423.79271708\n",
      "Iteration 4420, loss = 423.76719223\n",
      "Iteration 4421, loss = 423.74279513\n",
      "Iteration 4422, loss = 423.71676850\n",
      "Iteration 4423, loss = 423.69030827\n",
      "Iteration 4424, loss = 423.66690779\n",
      "Iteration 4425, loss = 423.64285001\n",
      "Iteration 4426, loss = 423.61834137\n",
      "Iteration 4427, loss = 423.59208288\n",
      "Iteration 4428, loss = 423.56472649\n",
      "Iteration 4429, loss = 423.53731022\n",
      "Iteration 4430, loss = 423.51393314\n",
      "Iteration 4431, loss = 423.49050396\n",
      "Iteration 4432, loss = 423.46459001\n",
      "Iteration 4433, loss = 423.44039340\n",
      "Iteration 4434, loss = 423.41759170\n",
      "Iteration 4435, loss = 423.39145658\n",
      "Iteration 4436, loss = 423.36745374\n",
      "Iteration 4437, loss = 423.34371366\n",
      "Iteration 4438, loss = 423.32081714\n",
      "Iteration 4439, loss = 423.29442096\n",
      "Iteration 4440, loss = 423.26941663\n",
      "Iteration 4441, loss = 423.24667905\n",
      "Iteration 4442, loss = 423.22252980\n",
      "Iteration 4443, loss = 423.19678266\n",
      "Iteration 4444, loss = 423.17392380\n",
      "Iteration 4445, loss = 423.15270250\n",
      "Iteration 4446, loss = 423.12565768\n",
      "Iteration 4447, loss = 423.10234772\n",
      "Iteration 4448, loss = 423.08136806\n",
      "Iteration 4449, loss = 423.05958163\n",
      "Iteration 4450, loss = 423.03641046\n",
      "Iteration 4451, loss = 423.01615414\n",
      "Iteration 4452, loss = 422.99464778\n",
      "Iteration 4453, loss = 422.97215758\n",
      "Iteration 4454, loss = 422.94871145\n",
      "Iteration 4455, loss = 422.92769382\n",
      "Iteration 4456, loss = 422.90745538\n",
      "Iteration 4457, loss = 422.88521722\n",
      "Iteration 4458, loss = 422.86552658\n",
      "Iteration 4459, loss = 422.84498514\n",
      "Iteration 4460, loss = 422.82526362\n",
      "Iteration 4461, loss = 422.80633345\n",
      "Iteration 4462, loss = 422.78976220\n",
      "Iteration 4463, loss = 422.77208262\n",
      "Iteration 4464, loss = 422.75420297\n",
      "Iteration 4465, loss = 422.73564745\n",
      "Iteration 4466, loss = 422.71329369\n",
      "Iteration 4467, loss = 422.68691430\n",
      "Iteration 4468, loss = 422.65695105\n",
      "Iteration 4469, loss = 422.63119583\n",
      "Iteration 4470, loss = 422.60356080\n",
      "Iteration 4471, loss = 422.57668931\n",
      "Iteration 4472, loss = 422.55717093\n",
      "Iteration 4473, loss = 422.54150528\n",
      "Iteration 4474, loss = 422.52256481\n",
      "Iteration 4475, loss = 422.50115693\n",
      "Iteration 4476, loss = 422.48170748\n",
      "Iteration 4477, loss = 422.45737220\n",
      "Iteration 4478, loss = 422.43325316\n",
      "Iteration 4479, loss = 422.40816569\n",
      "Iteration 4480, loss = 422.38931470\n",
      "Iteration 4481, loss = 422.37199311\n",
      "Iteration 4482, loss = 422.35194109\n",
      "Iteration 4483, loss = 422.33133628\n",
      "Iteration 4484, loss = 422.31023350\n",
      "Iteration 4485, loss = 422.28738143\n",
      "Iteration 4486, loss = 422.26411383\n",
      "Iteration 4487, loss = 422.24247364\n",
      "Iteration 4488, loss = 422.21957745\n",
      "Iteration 4489, loss = 422.19920810\n",
      "Iteration 4490, loss = 422.17955320\n",
      "Iteration 4491, loss = 422.15848522\n",
      "Iteration 4492, loss = 422.13746765\n",
      "Iteration 4493, loss = 422.11656109\n",
      "Iteration 4494, loss = 422.09621368\n",
      "Iteration 4495, loss = 422.07595581\n",
      "Iteration 4496, loss = 422.05536919\n",
      "Iteration 4497, loss = 422.03521398\n",
      "Iteration 4498, loss = 422.01449277\n",
      "Iteration 4499, loss = 421.99473916\n",
      "Iteration 4500, loss = 421.97394136\n",
      "Iteration 4501, loss = 421.95348523\n",
      "Iteration 4502, loss = 421.93078711\n",
      "Iteration 4503, loss = 421.91380623\n",
      "Iteration 4504, loss = 421.89468380\n",
      "Iteration 4505, loss = 421.87169133\n",
      "Iteration 4506, loss = 421.85095024\n",
      "Iteration 4507, loss = 421.83329647\n",
      "Iteration 4508, loss = 421.81568532\n",
      "Iteration 4509, loss = 421.79425754\n",
      "Iteration 4510, loss = 421.77202255\n",
      "Iteration 4511, loss = 421.75202962\n",
      "Iteration 4512, loss = 421.73294482\n",
      "Iteration 4513, loss = 421.71314470\n",
      "Iteration 4514, loss = 421.69340636\n",
      "Iteration 4515, loss = 421.67066274\n",
      "Iteration 4516, loss = 421.65167866\n",
      "Iteration 4517, loss = 421.63407831\n",
      "Iteration 4518, loss = 421.61426955\n",
      "Iteration 4519, loss = 421.59215127\n",
      "Iteration 4520, loss = 421.57381491\n",
      "Iteration 4521, loss = 421.55515218\n",
      "Iteration 4522, loss = 421.53643053\n",
      "Iteration 4523, loss = 421.51440279\n",
      "Iteration 4524, loss = 421.49413268\n",
      "Iteration 4525, loss = 421.47638249\n",
      "Iteration 4526, loss = 421.45762178\n",
      "Iteration 4527, loss = 421.43990001\n",
      "Iteration 4528, loss = 421.42116718\n",
      "Iteration 4529, loss = 421.40131502\n",
      "Iteration 4530, loss = 421.38450831\n",
      "Iteration 4531, loss = 421.36973996\n",
      "Iteration 4532, loss = 421.35204455\n",
      "Iteration 4533, loss = 421.33368046\n",
      "Iteration 4534, loss = 421.31421633\n",
      "Iteration 4535, loss = 421.29290391\n",
      "Iteration 4536, loss = 421.27179930\n",
      "Iteration 4537, loss = 421.25344377\n",
      "Iteration 4538, loss = 421.23002805\n",
      "Iteration 4539, loss = 421.20798554\n",
      "Iteration 4540, loss = 421.18287515\n",
      "Iteration 4541, loss = 421.16466887\n",
      "Iteration 4542, loss = 421.14813810\n",
      "Iteration 4543, loss = 421.13089290\n",
      "Iteration 4544, loss = 421.11312221\n",
      "Iteration 4545, loss = 421.09362432\n",
      "Iteration 4546, loss = 421.07072450\n",
      "Iteration 4547, loss = 421.05267065\n",
      "Iteration 4548, loss = 421.03550442\n",
      "Iteration 4549, loss = 421.01632837\n",
      "Iteration 4550, loss = 420.99446237\n",
      "Iteration 4551, loss = 420.97311602\n",
      "Iteration 4552, loss = 420.95220916\n",
      "Iteration 4553, loss = 420.94020692\n",
      "Iteration 4554, loss = 420.92104065\n",
      "Iteration 4555, loss = 420.89999883\n",
      "Iteration 4556, loss = 420.88103210\n",
      "Iteration 4557, loss = 420.86139868\n",
      "Iteration 4558, loss = 420.84553462\n",
      "Iteration 4559, loss = 420.82829521\n",
      "Iteration 4560, loss = 420.80993211\n",
      "Iteration 4561, loss = 420.78901512\n",
      "Iteration 4562, loss = 420.76877721\n",
      "Iteration 4563, loss = 420.75299592\n",
      "Iteration 4564, loss = 420.73675588\n",
      "Iteration 4565, loss = 420.72020753\n",
      "Iteration 4566, loss = 420.70289098\n",
      "Iteration 4567, loss = 420.68268965\n",
      "Iteration 4568, loss = 420.66319105\n",
      "Iteration 4569, loss = 420.64470116\n",
      "Iteration 4570, loss = 420.62934161\n",
      "Iteration 4571, loss = 420.61087702\n",
      "Iteration 4572, loss = 420.59382463\n",
      "Iteration 4573, loss = 420.57674753\n",
      "Iteration 4574, loss = 420.55534724\n",
      "Iteration 4575, loss = 420.53903878\n",
      "Iteration 4576, loss = 420.52495150\n",
      "Iteration 4577, loss = 420.50878448\n",
      "Iteration 4578, loss = 420.48938722\n",
      "Iteration 4579, loss = 420.47313422\n",
      "Iteration 4580, loss = 420.45707524\n",
      "Iteration 4581, loss = 420.43826046\n",
      "Iteration 4582, loss = 420.42216463\n",
      "Iteration 4583, loss = 420.40538882\n",
      "Iteration 4584, loss = 420.38951290\n",
      "Iteration 4585, loss = 420.37068829\n",
      "Iteration 4586, loss = 420.35140939\n",
      "Iteration 4587, loss = 420.33395404\n",
      "Iteration 4588, loss = 420.31904552\n",
      "Iteration 4589, loss = 420.29992425\n",
      "Iteration 4590, loss = 420.28156040\n",
      "Iteration 4591, loss = 420.26398048\n",
      "Iteration 4592, loss = 420.25114278\n",
      "Iteration 4593, loss = 420.23388520\n",
      "Iteration 4594, loss = 420.21659266\n",
      "Iteration 4595, loss = 420.20190471\n",
      "Iteration 4596, loss = 420.18457980\n",
      "Iteration 4597, loss = 420.16807553\n",
      "Iteration 4598, loss = 420.15242804\n",
      "Iteration 4599, loss = 420.13686127\n",
      "Iteration 4600, loss = 420.12009796\n",
      "Iteration 4601, loss = 420.10380856\n",
      "Iteration 4602, loss = 420.08976707\n",
      "Iteration 4603, loss = 420.07346700\n",
      "Iteration 4604, loss = 420.06046098\n",
      "Iteration 4605, loss = 420.05234797\n",
      "Iteration 4606, loss = 420.03914819\n",
      "Iteration 4607, loss = 420.02854741\n",
      "Iteration 4608, loss = 420.01615328\n",
      "Iteration 4609, loss = 420.00211773\n",
      "Iteration 4610, loss = 419.98612010\n",
      "Iteration 4611, loss = 419.95913260\n",
      "Iteration 4612, loss = 419.93271898\n",
      "Iteration 4613, loss = 419.90866159\n",
      "Iteration 4614, loss = 419.88714816\n",
      "Iteration 4615, loss = 419.87597506\n",
      "Iteration 4616, loss = 419.86678856\n",
      "Iteration 4617, loss = 419.85502013\n",
      "Iteration 4618, loss = 419.83975276\n",
      "Iteration 4619, loss = 419.82020761\n",
      "Iteration 4620, loss = 419.79898117\n",
      "Iteration 4621, loss = 419.77923250\n",
      "Iteration 4622, loss = 419.76421460\n",
      "Iteration 4623, loss = 419.74622628\n",
      "Iteration 4624, loss = 419.73180313\n",
      "Iteration 4625, loss = 419.72383628\n",
      "Iteration 4626, loss = 419.70770368\n",
      "Iteration 4627, loss = 419.68846275\n",
      "Iteration 4628, loss = 419.67415639\n",
      "Iteration 4629, loss = 419.65745471\n",
      "Iteration 4630, loss = 419.64287336\n",
      "Iteration 4631, loss = 419.63077186\n",
      "Iteration 4632, loss = 419.61545215\n",
      "Iteration 4633, loss = 419.59920912\n",
      "Iteration 4634, loss = 419.57936010\n",
      "Iteration 4635, loss = 419.56357312\n",
      "Iteration 4636, loss = 419.54753705\n",
      "Iteration 4637, loss = 419.53126822\n",
      "Iteration 4638, loss = 419.51281434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4639, loss = 419.49654584\n",
      "Iteration 4640, loss = 419.48031794\n",
      "Iteration 4641, loss = 419.46322444\n",
      "Iteration 4642, loss = 419.44618551\n",
      "Iteration 4643, loss = 419.42825057\n",
      "Iteration 4644, loss = 419.41344190\n",
      "Iteration 4645, loss = 419.39855189\n",
      "Iteration 4646, loss = 419.38220935\n",
      "Iteration 4647, loss = 419.36649943\n",
      "Iteration 4648, loss = 419.35268205\n",
      "Iteration 4649, loss = 419.33629048\n",
      "Iteration 4650, loss = 419.31952478\n",
      "Iteration 4651, loss = 419.30555414\n",
      "Iteration 4652, loss = 419.28967468\n",
      "Iteration 4653, loss = 419.27399559\n",
      "Iteration 4654, loss = 419.25791162\n",
      "Iteration 4655, loss = 419.24215714\n",
      "Iteration 4656, loss = 419.22592782\n",
      "Iteration 4657, loss = 419.21113742\n",
      "Iteration 4658, loss = 419.19941428\n",
      "Iteration 4659, loss = 419.18352891\n",
      "Iteration 4660, loss = 419.16526837\n",
      "Iteration 4661, loss = 419.15061595\n",
      "Iteration 4662, loss = 419.13600350\n",
      "Iteration 4663, loss = 419.12002302\n",
      "Iteration 4664, loss = 419.10760681\n",
      "Iteration 4665, loss = 419.09189319\n",
      "Iteration 4666, loss = 419.07556359\n",
      "Iteration 4667, loss = 419.06075125\n",
      "Iteration 4668, loss = 419.04756296\n",
      "Iteration 4669, loss = 419.03300296\n",
      "Iteration 4670, loss = 419.01699249\n",
      "Iteration 4671, loss = 418.99802427\n",
      "Iteration 4672, loss = 418.98565590\n",
      "Iteration 4673, loss = 418.97099698\n",
      "Iteration 4674, loss = 418.95721208\n",
      "Iteration 4675, loss = 418.93881068\n",
      "Iteration 4676, loss = 418.92508683\n",
      "Iteration 4677, loss = 418.90959313\n",
      "Iteration 4678, loss = 418.89588261\n",
      "Iteration 4679, loss = 418.88244297\n",
      "Iteration 4680, loss = 418.86874462\n",
      "Iteration 4681, loss = 418.85257629\n",
      "Iteration 4682, loss = 418.83945825\n",
      "Iteration 4683, loss = 418.82417341\n",
      "Iteration 4684, loss = 418.81047453\n",
      "Iteration 4685, loss = 418.79530380\n",
      "Iteration 4686, loss = 418.78117297\n",
      "Iteration 4687, loss = 418.77133177\n",
      "Iteration 4688, loss = 418.75541434\n",
      "Iteration 4689, loss = 418.74414309\n",
      "Iteration 4690, loss = 418.72910662\n",
      "Iteration 4691, loss = 418.71401198\n",
      "Iteration 4692, loss = 418.70120908\n",
      "Iteration 4693, loss = 418.68665133\n",
      "Iteration 4694, loss = 418.67381672\n",
      "Iteration 4695, loss = 418.66058027\n",
      "Iteration 4696, loss = 418.64608987\n",
      "Iteration 4697, loss = 418.63168244\n",
      "Iteration 4698, loss = 418.62176412\n",
      "Iteration 4699, loss = 418.60787271\n",
      "Iteration 4700, loss = 418.59467663\n",
      "Iteration 4701, loss = 418.58118370\n",
      "Iteration 4702, loss = 418.56840752\n",
      "Iteration 4703, loss = 418.55604285\n",
      "Iteration 4704, loss = 418.54506544\n",
      "Iteration 4705, loss = 418.53256304\n",
      "Iteration 4706, loss = 418.51743404\n",
      "Iteration 4707, loss = 418.50494454\n",
      "Iteration 4708, loss = 418.49238523\n",
      "Iteration 4709, loss = 418.47926422\n",
      "Iteration 4710, loss = 418.46594021\n",
      "Iteration 4711, loss = 418.45313620\n",
      "Iteration 4712, loss = 418.43990842\n",
      "Iteration 4713, loss = 418.42816305\n",
      "Iteration 4714, loss = 418.41718580\n",
      "Iteration 4715, loss = 418.40588589\n",
      "Iteration 4716, loss = 418.39135777\n",
      "Iteration 4717, loss = 418.37943948\n",
      "Iteration 4718, loss = 418.36543759\n",
      "Iteration 4719, loss = 418.35259454\n",
      "Iteration 4720, loss = 418.34029840\n",
      "Iteration 4721, loss = 418.32600035\n",
      "Iteration 4722, loss = 418.31224893\n",
      "Iteration 4723, loss = 418.29679478\n",
      "Iteration 4724, loss = 418.28458729\n",
      "Iteration 4725, loss = 418.27090851\n",
      "Iteration 4726, loss = 418.25756098\n",
      "Iteration 4727, loss = 418.24136045\n",
      "Iteration 4728, loss = 418.23230800\n",
      "Iteration 4729, loss = 418.21903951\n",
      "Iteration 4730, loss = 418.20703021\n",
      "Iteration 4731, loss = 418.19606971\n",
      "Iteration 4732, loss = 418.18381958\n",
      "Iteration 4733, loss = 418.16898509\n",
      "Iteration 4734, loss = 418.15564312\n",
      "Iteration 4735, loss = 418.14620953\n",
      "Iteration 4736, loss = 418.13226311\n",
      "Iteration 4737, loss = 418.12000476\n",
      "Iteration 4738, loss = 418.10347486\n",
      "Iteration 4739, loss = 418.08905903\n",
      "Iteration 4740, loss = 418.07862668\n",
      "Iteration 4741, loss = 418.06615543\n",
      "Iteration 4742, loss = 418.05368029\n",
      "Iteration 4743, loss = 418.04055394\n",
      "Iteration 4744, loss = 418.02883407\n",
      "Iteration 4745, loss = 418.02002261\n",
      "Iteration 4746, loss = 418.00902985\n",
      "Iteration 4747, loss = 417.99293112\n",
      "Iteration 4748, loss = 417.97869813\n",
      "Iteration 4749, loss = 417.96712128\n",
      "Iteration 4750, loss = 417.96048981\n",
      "Iteration 4751, loss = 417.94783300\n",
      "Iteration 4752, loss = 417.93356436\n",
      "Iteration 4753, loss = 417.91948518\n",
      "Iteration 4754, loss = 417.90687315\n",
      "Iteration 4755, loss = 417.89529019\n",
      "Iteration 4756, loss = 417.88440806\n",
      "Iteration 4757, loss = 417.87215501\n",
      "Iteration 4758, loss = 417.85661598\n",
      "Iteration 4759, loss = 417.84430133\n",
      "Iteration 4760, loss = 417.83213578\n",
      "Iteration 4761, loss = 417.81965358\n",
      "Iteration 4762, loss = 417.80380760\n",
      "Iteration 4763, loss = 417.79550885\n",
      "Iteration 4764, loss = 417.78538323\n",
      "Iteration 4765, loss = 417.77252188\n",
      "Iteration 4766, loss = 417.75996515\n",
      "Iteration 4767, loss = 417.74728605\n",
      "Iteration 4768, loss = 417.73598392\n",
      "Iteration 4769, loss = 417.72536205\n",
      "Iteration 4770, loss = 417.71704305\n",
      "Iteration 4771, loss = 417.70706705\n",
      "Iteration 4772, loss = 417.69770249\n",
      "Iteration 4773, loss = 417.69072405\n",
      "Iteration 4774, loss = 417.68691377\n",
      "Iteration 4775, loss = 417.68039676\n",
      "Iteration 4776, loss = 417.67030510\n",
      "Iteration 4777, loss = 417.65747076\n",
      "Iteration 4778, loss = 417.64217895\n",
      "Iteration 4779, loss = 417.62186555\n",
      "Iteration 4780, loss = 417.59655083\n",
      "Iteration 4781, loss = 417.57867526\n",
      "Iteration 4782, loss = 417.56734593\n",
      "Iteration 4783, loss = 417.55923406\n",
      "Iteration 4784, loss = 417.55457098\n",
      "Iteration 4785, loss = 417.54448622\n",
      "Iteration 4786, loss = 417.53167000\n",
      "Iteration 4787, loss = 417.51680071\n",
      "Iteration 4788, loss = 417.49999859\n",
      "Iteration 4789, loss = 417.48577526\n",
      "Iteration 4790, loss = 417.47393835\n",
      "Iteration 4791, loss = 417.46717937\n",
      "Iteration 4792, loss = 417.45823581\n",
      "Iteration 4793, loss = 417.44558416\n",
      "Iteration 4794, loss = 417.43139567\n",
      "Iteration 4795, loss = 417.41572130\n",
      "Iteration 4796, loss = 417.40442548\n",
      "Iteration 4797, loss = 417.39427180\n",
      "Iteration 4798, loss = 417.38512618\n",
      "Iteration 4799, loss = 417.37409696\n",
      "Iteration 4800, loss = 417.36220941\n",
      "Iteration 4801, loss = 417.34791388\n",
      "Iteration 4802, loss = 417.34034221\n",
      "Iteration 4803, loss = 417.32755978\n",
      "Iteration 4804, loss = 417.31707458\n",
      "Iteration 4805, loss = 417.30877692\n",
      "Iteration 4806, loss = 417.29959301\n",
      "Iteration 4807, loss = 417.29080849\n",
      "Iteration 4808, loss = 417.28131878\n",
      "Iteration 4809, loss = 417.27141035\n",
      "Iteration 4810, loss = 417.26068703\n",
      "Iteration 4811, loss = 417.25526410\n",
      "Iteration 4812, loss = 417.24932649\n",
      "Iteration 4813, loss = 417.23418434\n",
      "Iteration 4814, loss = 417.22345938\n",
      "Iteration 4815, loss = 417.20971262\n",
      "Iteration 4816, loss = 417.19376251\n",
      "Iteration 4817, loss = 417.17838022\n",
      "Iteration 4818, loss = 417.16423211\n",
      "Iteration 4819, loss = 417.15163606\n",
      "Iteration 4820, loss = 417.13976324\n",
      "Iteration 4821, loss = 417.13043280\n",
      "Iteration 4822, loss = 417.12043751\n",
      "Iteration 4823, loss = 417.11394272\n",
      "Iteration 4824, loss = 417.10207593\n",
      "Iteration 4825, loss = 417.08862196\n",
      "Iteration 4826, loss = 417.07621404\n",
      "Iteration 4827, loss = 417.06374145\n",
      "Iteration 4828, loss = 417.05309110\n",
      "Iteration 4829, loss = 417.04199353\n",
      "Iteration 4830, loss = 417.03043174\n",
      "Iteration 4831, loss = 417.02051486\n",
      "Iteration 4832, loss = 417.01066471\n",
      "Iteration 4833, loss = 416.99979928\n",
      "Iteration 4834, loss = 416.98996466\n",
      "Iteration 4835, loss = 416.97966617\n",
      "Iteration 4836, loss = 416.96852281\n",
      "Iteration 4837, loss = 416.95814042\n",
      "Iteration 4838, loss = 416.94763997\n",
      "Iteration 4839, loss = 416.93824421\n",
      "Iteration 4840, loss = 416.92989058\n",
      "Iteration 4841, loss = 416.91919361\n",
      "Iteration 4842, loss = 416.90835937\n",
      "Iteration 4843, loss = 416.89733632\n",
      "Iteration 4844, loss = 416.88636950\n",
      "Iteration 4845, loss = 416.87497348\n",
      "Iteration 4846, loss = 416.86653792\n",
      "Iteration 4847, loss = 416.85767060\n",
      "Iteration 4848, loss = 416.84456981\n",
      "Iteration 4849, loss = 416.83228495\n",
      "Iteration 4850, loss = 416.82693068\n",
      "Iteration 4851, loss = 416.81821928\n",
      "Iteration 4852, loss = 416.80546396\n",
      "Iteration 4853, loss = 416.79264121\n",
      "Iteration 4854, loss = 416.78567949\n",
      "Iteration 4855, loss = 416.77236818\n",
      "Iteration 4856, loss = 416.76333047\n",
      "Iteration 4857, loss = 416.75242821\n",
      "Iteration 4858, loss = 416.74258313\n",
      "Iteration 4859, loss = 416.73357250\n",
      "Iteration 4860, loss = 416.72287304\n",
      "Iteration 4861, loss = 416.71251946\n",
      "Iteration 4862, loss = 416.70116797\n",
      "Iteration 4863, loss = 416.69107988\n",
      "Iteration 4864, loss = 416.68235030\n",
      "Iteration 4865, loss = 416.67392601\n",
      "Iteration 4866, loss = 416.66407070\n",
      "Iteration 4867, loss = 416.65401856\n",
      "Iteration 4868, loss = 416.64349331\n",
      "Iteration 4869, loss = 416.63356777\n",
      "Iteration 4870, loss = 416.62211716\n",
      "Iteration 4871, loss = 416.61665253\n",
      "Iteration 4872, loss = 416.60681883\n",
      "Iteration 4873, loss = 416.59941537\n",
      "Iteration 4874, loss = 416.58548529\n",
      "Iteration 4875, loss = 416.57688286\n",
      "Iteration 4876, loss = 416.56913536\n",
      "Iteration 4877, loss = 416.55892477\n",
      "Iteration 4878, loss = 416.55323673\n",
      "Iteration 4879, loss = 416.54349550\n",
      "Iteration 4880, loss = 416.53241383\n",
      "Iteration 4881, loss = 416.52338264\n",
      "Iteration 4882, loss = 416.51307068\n",
      "Iteration 4883, loss = 416.50308504\n",
      "Iteration 4884, loss = 416.49150089\n",
      "Iteration 4885, loss = 416.48338946\n",
      "Iteration 4886, loss = 416.47402776\n",
      "Iteration 4887, loss = 416.46365105\n",
      "Iteration 4888, loss = 416.45295336\n",
      "Iteration 4889, loss = 416.44385265\n",
      "Iteration 4890, loss = 416.43452812\n",
      "Iteration 4891, loss = 416.42319663\n",
      "Iteration 4892, loss = 416.41372597\n",
      "Iteration 4893, loss = 416.40515962\n",
      "Iteration 4894, loss = 416.39739499\n",
      "Iteration 4895, loss = 416.38679222\n",
      "Iteration 4896, loss = 416.37841054\n",
      "Iteration 4897, loss = 416.36784121\n",
      "Iteration 4898, loss = 416.35973894\n",
      "Iteration 4899, loss = 416.35156727\n",
      "Iteration 4900, loss = 416.34118727\n",
      "Iteration 4901, loss = 416.32894875\n",
      "Iteration 4902, loss = 416.31859345\n",
      "Iteration 4903, loss = 416.31281537\n",
      "Iteration 4904, loss = 416.30388544\n",
      "Iteration 4905, loss = 416.29218841\n",
      "Iteration 4906, loss = 416.27987039\n",
      "Iteration 4907, loss = 416.27344544\n",
      "Iteration 4908, loss = 416.26721169\n",
      "Iteration 4909, loss = 416.25612524\n",
      "Iteration 4910, loss = 416.24683024\n",
      "Iteration 4911, loss = 416.23847293\n",
      "Iteration 4912, loss = 416.22615279\n",
      "Iteration 4913, loss = 416.21476379\n",
      "Iteration 4914, loss = 416.20825205\n",
      "Iteration 4915, loss = 416.19935679\n",
      "Iteration 4916, loss = 416.19253426\n",
      "Iteration 4917, loss = 416.18120470\n",
      "Iteration 4918, loss = 416.17111618\n",
      "Iteration 4919, loss = 416.16362407\n",
      "Iteration 4920, loss = 416.15521077\n",
      "Iteration 4921, loss = 416.14657273\n",
      "Iteration 4922, loss = 416.13495866\n",
      "Iteration 4923, loss = 416.12390246\n",
      "Iteration 4924, loss = 416.11929207\n",
      "Iteration 4925, loss = 416.11026605\n",
      "Iteration 4926, loss = 416.10062475\n",
      "Iteration 4927, loss = 416.09265998\n",
      "Iteration 4928, loss = 416.08590583\n",
      "Iteration 4929, loss = 416.08200039\n",
      "Iteration 4930, loss = 416.07638064\n",
      "Iteration 4931, loss = 416.07065100\n",
      "Iteration 4932, loss = 416.06787131\n",
      "Iteration 4933, loss = 416.06470917\n",
      "Iteration 4934, loss = 416.06307561\n",
      "Iteration 4935, loss = 416.05593977\n",
      "Iteration 4936, loss = 416.05095677\n",
      "Iteration 4937, loss = 416.03521557\n",
      "Iteration 4938, loss = 416.01880746\n",
      "Iteration 4939, loss = 416.00404585\n",
      "Iteration 4940, loss = 415.99830157\n",
      "Iteration 4941, loss = 415.99595615\n",
      "Iteration 4942, loss = 415.99317385\n",
      "Iteration 4943, loss = 415.98884981\n",
      "Iteration 4944, loss = 415.97518862\n",
      "Iteration 4945, loss = 415.95212291\n",
      "Iteration 4946, loss = 415.93359874\n",
      "Iteration 4947, loss = 415.91777883\n",
      "Iteration 4948, loss = 415.90602098\n",
      "Iteration 4949, loss = 415.89936725\n",
      "Iteration 4950, loss = 415.89488054\n",
      "Iteration 4951, loss = 415.88965076\n",
      "Iteration 4952, loss = 415.88247416\n",
      "Iteration 4953, loss = 415.87114202\n",
      "Iteration 4954, loss = 415.85870713\n",
      "Iteration 4955, loss = 415.84368225\n",
      "Iteration 4956, loss = 415.83041471\n",
      "Iteration 4957, loss = 415.82701158\n",
      "Iteration 4958, loss = 415.82178114\n",
      "Iteration 4959, loss = 415.81204559\n",
      "Iteration 4960, loss = 415.80553119\n",
      "Iteration 4961, loss = 415.79351613\n",
      "Iteration 4962, loss = 415.77939011\n",
      "Iteration 4963, loss = 415.76985183\n",
      "Iteration 4964, loss = 415.76072081\n",
      "Iteration 4965, loss = 415.75561539\n",
      "Iteration 4966, loss = 415.74909593\n",
      "Iteration 4967, loss = 415.74049808\n",
      "Iteration 4968, loss = 415.72893742\n",
      "Iteration 4969, loss = 415.72049250\n",
      "Iteration 4970, loss = 415.71357021\n",
      "Iteration 4971, loss = 415.70283804\n",
      "Iteration 4972, loss = 415.69184453\n",
      "Iteration 4973, loss = 415.68298575\n",
      "Iteration 4974, loss = 415.67668348\n",
      "Iteration 4975, loss = 415.66900593\n",
      "Iteration 4976, loss = 415.66422592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4977, loss = 415.65458171\n",
      "Iteration 4978, loss = 415.64126297\n",
      "Iteration 4979, loss = 415.63287422\n",
      "Iteration 4980, loss = 415.62514117\n",
      "Iteration 4981, loss = 415.61846472\n",
      "Iteration 4982, loss = 415.60658810\n",
      "Iteration 4983, loss = 415.59850182\n",
      "Iteration 4984, loss = 415.59037832\n",
      "Iteration 4985, loss = 415.58286169\n",
      "Iteration 4986, loss = 415.57371377\n",
      "Iteration 4987, loss = 415.57008548\n",
      "Iteration 4988, loss = 415.56101617\n",
      "Iteration 4989, loss = 415.54965084\n",
      "Iteration 4990, loss = 415.53764894\n",
      "Iteration 4991, loss = 415.53004718\n",
      "Iteration 4992, loss = 415.52525346\n",
      "Iteration 4993, loss = 415.51440854\n",
      "Iteration 4994, loss = 415.50467185\n",
      "Iteration 4995, loss = 415.49657377\n",
      "Iteration 4996, loss = 415.48871651\n",
      "Iteration 4997, loss = 415.48178909\n",
      "Iteration 4998, loss = 415.47454468\n",
      "Iteration 4999, loss = 415.46332378\n",
      "Iteration 5000, loss = 415.45551782\n",
      "Iteration 5001, loss = 415.44798317\n",
      "Iteration 5002, loss = 415.44085362\n",
      "Iteration 5003, loss = 415.43560877\n",
      "Iteration 5004, loss = 415.42471458\n",
      "Iteration 5005, loss = 415.41477390\n",
      "Iteration 5006, loss = 415.40499162\n",
      "Iteration 5007, loss = 415.39605210\n",
      "Iteration 5008, loss = 415.39072512\n",
      "Iteration 5009, loss = 415.38268098\n",
      "Iteration 5010, loss = 415.37268904\n",
      "Iteration 5011, loss = 415.36218436\n",
      "Iteration 5012, loss = 415.35353867\n",
      "Iteration 5013, loss = 415.34508522\n",
      "Iteration 5014, loss = 415.34131458\n",
      "Iteration 5015, loss = 415.33134032\n",
      "Iteration 5016, loss = 415.31961590\n",
      "Iteration 5017, loss = 415.31248628\n",
      "Iteration 5018, loss = 415.30601313\n",
      "Iteration 5019, loss = 415.29682109\n",
      "Iteration 5020, loss = 415.28637820\n",
      "Iteration 5021, loss = 415.27908684\n",
      "Iteration 5022, loss = 415.27238214\n",
      "Iteration 5023, loss = 415.26333560\n",
      "Iteration 5024, loss = 415.25404257\n",
      "Iteration 5025, loss = 415.24767656\n",
      "Iteration 5026, loss = 415.23912794\n",
      "Iteration 5027, loss = 415.22693021\n",
      "Iteration 5028, loss = 415.21878969\n",
      "Iteration 5029, loss = 415.21564566\n",
      "Iteration 5030, loss = 415.20767592\n",
      "Iteration 5031, loss = 415.19629829\n",
      "Iteration 5032, loss = 415.18718179\n",
      "Iteration 5033, loss = 415.17860331\n",
      "Iteration 5034, loss = 415.17095447\n",
      "Iteration 5035, loss = 415.16256538\n",
      "Iteration 5036, loss = 415.15401054\n",
      "Iteration 5037, loss = 415.14385877\n",
      "Iteration 5038, loss = 415.13659306\n",
      "Iteration 5039, loss = 415.13214655\n",
      "Iteration 5040, loss = 415.12305086\n",
      "Iteration 5041, loss = 415.11430304\n",
      "Iteration 5042, loss = 415.10596147\n",
      "Iteration 5043, loss = 415.09889943\n",
      "Iteration 5044, loss = 415.08836050\n",
      "Iteration 5045, loss = 415.08338759\n",
      "Iteration 5046, loss = 415.07405999\n",
      "Iteration 5047, loss = 415.06546404\n",
      "Iteration 5048, loss = 415.06072361\n",
      "Iteration 5049, loss = 415.05067414\n",
      "Iteration 5050, loss = 415.03983953\n",
      "Iteration 5051, loss = 415.03101420\n",
      "Iteration 5052, loss = 415.02602285\n",
      "Iteration 5053, loss = 415.01991344\n",
      "Iteration 5054, loss = 415.01228304\n",
      "Iteration 5055, loss = 415.00425512\n",
      "Iteration 5056, loss = 414.99573497\n",
      "Iteration 5057, loss = 414.98426310\n",
      "Iteration 5058, loss = 414.97729927\n",
      "Iteration 5059, loss = 414.97161206\n",
      "Iteration 5060, loss = 414.96389227\n",
      "Iteration 5061, loss = 414.95487258\n",
      "Iteration 5062, loss = 414.94495907\n",
      "Iteration 5063, loss = 414.93729933\n",
      "Iteration 5064, loss = 414.93180806\n",
      "Iteration 5065, loss = 414.92508474\n",
      "Iteration 5066, loss = 414.91745525\n",
      "Iteration 5067, loss = 414.90598475\n",
      "Iteration 5068, loss = 414.89459614\n",
      "Iteration 5069, loss = 414.89096073\n",
      "Iteration 5070, loss = 414.88360490\n",
      "Iteration 5071, loss = 414.87904424\n",
      "Iteration 5072, loss = 414.87186670\n",
      "Iteration 5073, loss = 414.86115100\n",
      "Iteration 5074, loss = 414.85184247\n",
      "Iteration 5075, loss = 414.84543090\n",
      "Iteration 5076, loss = 414.83939550\n",
      "Iteration 5077, loss = 414.83021712\n",
      "Iteration 5078, loss = 414.81800995\n",
      "Iteration 5079, loss = 414.81291966\n",
      "Iteration 5080, loss = 414.80373999\n",
      "Iteration 5081, loss = 414.79742325\n",
      "Iteration 5082, loss = 414.79087916\n",
      "Iteration 5083, loss = 414.78254736\n",
      "Iteration 5084, loss = 414.77243051\n",
      "Iteration 5085, loss = 414.76770204\n",
      "Iteration 5086, loss = 414.76329270\n",
      "Iteration 5087, loss = 414.75707069\n",
      "Iteration 5088, loss = 414.75422945\n",
      "Iteration 5089, loss = 414.75407957\n",
      "Iteration 5090, loss = 414.75587549\n",
      "Iteration 5091, loss = 414.75699782\n",
      "Iteration 5092, loss = 414.75160483\n",
      "Iteration 5093, loss = 414.74011637\n",
      "Iteration 5094, loss = 414.72295474\n",
      "Iteration 5095, loss = 414.70236309\n",
      "Iteration 5096, loss = 414.68813876\n",
      "Iteration 5097, loss = 414.68640929\n",
      "Iteration 5098, loss = 414.68762148\n",
      "Iteration 5099, loss = 414.69531330\n",
      "Iteration 5100, loss = 414.70267143\n",
      "Iteration 5101, loss = 414.69131545\n",
      "Iteration 5102, loss = 414.66957757\n",
      "Iteration 5103, loss = 414.64533092\n",
      "Iteration 5104, loss = 414.62087176\n",
      "Iteration 5105, loss = 414.60578240\n",
      "Iteration 5106, loss = 414.60444696\n",
      "Iteration 5107, loss = 414.60535654\n",
      "Iteration 5108, loss = 414.59912105\n",
      "Iteration 5109, loss = 414.58976879\n",
      "Iteration 5110, loss = 414.57574792\n",
      "Iteration 5111, loss = 414.56368953\n",
      "Iteration 5112, loss = 414.55707429\n",
      "Iteration 5113, loss = 414.55116021\n",
      "Iteration 5114, loss = 414.54306184\n",
      "Iteration 5115, loss = 414.53560391\n",
      "Iteration 5116, loss = 414.52740174\n",
      "Iteration 5117, loss = 414.51713975\n",
      "Iteration 5118, loss = 414.50840189\n",
      "Iteration 5119, loss = 414.50169700\n",
      "Iteration 5120, loss = 414.49654344\n",
      "Iteration 5121, loss = 414.48896921\n",
      "Iteration 5122, loss = 414.47738172\n",
      "Iteration 5123, loss = 414.47041463\n",
      "Iteration 5124, loss = 414.46300421\n",
      "Iteration 5125, loss = 414.45309864\n",
      "Iteration 5126, loss = 414.44703463\n",
      "Iteration 5127, loss = 414.43852472\n",
      "Iteration 5128, loss = 414.42799803\n",
      "Iteration 5129, loss = 414.41729712\n",
      "Iteration 5130, loss = 414.41573313\n",
      "Iteration 5131, loss = 414.40682441\n",
      "Iteration 5132, loss = 414.39850177\n",
      "Iteration 5133, loss = 414.39375425\n",
      "Iteration 5134, loss = 414.38558059\n",
      "Iteration 5135, loss = 414.37569978\n",
      "Iteration 5136, loss = 414.36752734\n",
      "Iteration 5137, loss = 414.35855792\n",
      "Iteration 5138, loss = 414.35261770\n",
      "Iteration 5139, loss = 414.34525230\n",
      "Iteration 5140, loss = 414.33837610\n",
      "Iteration 5141, loss = 414.33089027\n",
      "Iteration 5142, loss = 414.32328043\n",
      "Iteration 5143, loss = 414.31435754\n",
      "Iteration 5144, loss = 414.30656803\n",
      "Iteration 5145, loss = 414.29745319\n",
      "Iteration 5146, loss = 414.29207365\n",
      "Iteration 5147, loss = 414.28924919\n",
      "Iteration 5148, loss = 414.27832013\n",
      "Iteration 5149, loss = 414.26927476\n",
      "Iteration 5150, loss = 414.25993413\n",
      "Iteration 5151, loss = 414.25458437\n",
      "Iteration 5152, loss = 414.24496530\n",
      "Iteration 5153, loss = 414.23923294\n",
      "Iteration 5154, loss = 414.23218018\n",
      "Iteration 5155, loss = 414.22773614\n",
      "Iteration 5156, loss = 414.22313244\n",
      "Iteration 5157, loss = 414.21820461\n",
      "Iteration 5158, loss = 414.20793648\n",
      "Iteration 5159, loss = 414.20009319\n",
      "Iteration 5160, loss = 414.19330381\n",
      "Iteration 5161, loss = 414.18750666\n",
      "Iteration 5162, loss = 414.18452563\n",
      "Iteration 5163, loss = 414.17891679\n",
      "Iteration 5164, loss = 414.16744393\n",
      "Iteration 5165, loss = 414.15730676\n",
      "Iteration 5166, loss = 414.14965433\n",
      "Iteration 5167, loss = 414.14746366\n",
      "Iteration 5168, loss = 414.14002027\n",
      "Iteration 5169, loss = 414.13013893\n",
      "Iteration 5170, loss = 414.12375690\n",
      "Iteration 5171, loss = 414.11806803\n",
      "Iteration 5172, loss = 414.11446421\n",
      "Iteration 5173, loss = 414.10296133\n",
      "Iteration 5174, loss = 414.09624447\n",
      "Iteration 5175, loss = 414.09270215\n",
      "Iteration 5176, loss = 414.08966984\n",
      "Iteration 5177, loss = 414.08161593\n",
      "Iteration 5178, loss = 414.06978283\n",
      "Iteration 5179, loss = 414.06476041\n",
      "Iteration 5180, loss = 414.06012124\n",
      "Iteration 5181, loss = 414.05266472\n",
      "Iteration 5182, loss = 414.04696824\n",
      "Iteration 5183, loss = 414.03751173\n",
      "Iteration 5184, loss = 414.03104181\n",
      "Iteration 5185, loss = 414.02482907\n",
      "Iteration 5186, loss = 414.01607843\n",
      "Iteration 5187, loss = 414.00711643\n",
      "Iteration 5188, loss = 414.00156986\n",
      "Iteration 5189, loss = 413.99407836\n",
      "Iteration 5190, loss = 413.98566626\n",
      "Iteration 5191, loss = 413.98036695\n",
      "Iteration 5192, loss = 413.97706852\n",
      "Iteration 5193, loss = 413.96863984\n",
      "Iteration 5194, loss = 413.95758122\n",
      "Iteration 5195, loss = 413.95471881\n",
      "Iteration 5196, loss = 413.94924883\n",
      "Iteration 5197, loss = 413.93997613\n",
      "Iteration 5198, loss = 413.93427702\n",
      "Iteration 5199, loss = 413.92600489\n",
      "Iteration 5200, loss = 413.92112070\n",
      "Iteration 5201, loss = 413.91591794\n",
      "Iteration 5202, loss = 413.90902432\n",
      "Iteration 5203, loss = 413.89897069\n",
      "Iteration 5204, loss = 413.89122842\n",
      "Iteration 5205, loss = 413.88562581\n",
      "Iteration 5206, loss = 413.87892996\n",
      "Iteration 5207, loss = 413.87366486\n",
      "Iteration 5208, loss = 413.86405942\n",
      "Iteration 5209, loss = 413.86164388\n",
      "Iteration 5210, loss = 413.85665272\n",
      "Iteration 5211, loss = 413.85084185\n",
      "Iteration 5212, loss = 413.84083293\n",
      "Iteration 5213, loss = 413.83604705\n",
      "Iteration 5214, loss = 413.82983571\n",
      "Iteration 5215, loss = 413.82304842\n",
      "Iteration 5216, loss = 413.81766901\n",
      "Iteration 5217, loss = 413.81007173\n",
      "Iteration 5218, loss = 413.80229554\n",
      "Iteration 5219, loss = 413.79613665\n",
      "Iteration 5220, loss = 413.78607540\n",
      "Iteration 5221, loss = 413.78135282\n",
      "Iteration 5222, loss = 413.77520792\n",
      "Iteration 5223, loss = 413.76614555\n",
      "Iteration 5224, loss = 413.76064587\n",
      "Iteration 5225, loss = 413.75862866\n",
      "Iteration 5226, loss = 413.75231065\n",
      "Iteration 5227, loss = 413.74501745\n",
      "Iteration 5228, loss = 413.73669062\n",
      "Iteration 5229, loss = 413.72851350\n",
      "Iteration 5230, loss = 413.72540495\n",
      "Iteration 5231, loss = 413.71876100\n",
      "Iteration 5232, loss = 413.71221641\n",
      "Iteration 5233, loss = 413.70331221\n",
      "Iteration 5234, loss = 413.69734816\n",
      "Iteration 5235, loss = 413.69135504\n",
      "Iteration 5236, loss = 413.68358943\n",
      "Iteration 5237, loss = 413.67681343\n",
      "Iteration 5238, loss = 413.66895916\n",
      "Iteration 5239, loss = 413.66377572\n",
      "Iteration 5240, loss = 413.65789135\n",
      "Iteration 5241, loss = 413.65218109\n",
      "Iteration 5242, loss = 413.64069779\n",
      "Iteration 5243, loss = 413.63371306\n",
      "Iteration 5244, loss = 413.62815236\n",
      "Iteration 5245, loss = 413.62136459\n",
      "Iteration 5246, loss = 413.61728943\n",
      "Iteration 5247, loss = 413.61420898\n",
      "Iteration 5248, loss = 413.60748642\n",
      "Iteration 5249, loss = 413.59978656\n",
      "Iteration 5250, loss = 413.59297449\n",
      "Iteration 5251, loss = 413.58871551\n",
      "Iteration 5252, loss = 413.58273854\n",
      "Iteration 5253, loss = 413.57736544\n",
      "Iteration 5254, loss = 413.56917544\n",
      "Iteration 5255, loss = 413.56182628\n",
      "Iteration 5256, loss = 413.55893931\n",
      "Iteration 5257, loss = 413.55477769\n",
      "Iteration 5258, loss = 413.55038041\n",
      "Iteration 5259, loss = 413.54790736\n",
      "Iteration 5260, loss = 413.54393184\n",
      "Iteration 5261, loss = 413.53895941\n",
      "Iteration 5262, loss = 413.53373060\n",
      "Iteration 5263, loss = 413.53018085\n",
      "Iteration 5264, loss = 413.52315204\n",
      "Iteration 5265, loss = 413.51383190\n",
      "Iteration 5266, loss = 413.49974317\n",
      "Iteration 5267, loss = 413.49219847\n",
      "Iteration 5268, loss = 413.48624559\n",
      "Iteration 5269, loss = 413.47964581\n",
      "Iteration 5270, loss = 413.47242335\n",
      "Iteration 5271, loss = 413.46681705\n",
      "Iteration 5272, loss = 413.46266487\n",
      "Iteration 5273, loss = 413.45355029\n",
      "Iteration 5274, loss = 413.44655493\n",
      "Iteration 5275, loss = 413.44126894\n",
      "Iteration 5276, loss = 413.43969200\n",
      "Iteration 5277, loss = 413.43636273\n",
      "Iteration 5278, loss = 413.43667399\n",
      "Iteration 5279, loss = 413.43846128\n",
      "Iteration 5280, loss = 413.43905623\n",
      "Iteration 5281, loss = 413.44094432\n",
      "Iteration 5282, loss = 413.43693999\n",
      "Iteration 5283, loss = 413.42459973\n",
      "Iteration 5284, loss = 413.40283221\n",
      "Iteration 5285, loss = 413.38562686\n",
      "Iteration 5286, loss = 413.37087027\n",
      "Iteration 5287, loss = 413.36273635\n",
      "Iteration 5288, loss = 413.36839743\n",
      "Iteration 5289, loss = 413.36826751\n",
      "Iteration 5290, loss = 413.36142002\n",
      "Iteration 5291, loss = 413.35195170\n",
      "Iteration 5292, loss = 413.34008097\n",
      "Iteration 5293, loss = 413.32940201\n",
      "Iteration 5294, loss = 413.32379845\n",
      "Iteration 5295, loss = 413.32429712\n",
      "Iteration 5296, loss = 413.32259224\n",
      "Iteration 5297, loss = 413.31543200\n",
      "Iteration 5298, loss = 413.30276290\n",
      "Iteration 5299, loss = 413.29388385\n",
      "Iteration 5300, loss = 413.29085272\n",
      "Iteration 5301, loss = 413.28493536\n",
      "Iteration 5302, loss = 413.28266516\n",
      "Iteration 5303, loss = 413.27669244\n",
      "Iteration 5304, loss = 413.26998106\n",
      "Iteration 5305, loss = 413.26012144\n",
      "Iteration 5306, loss = 413.25321902\n",
      "Iteration 5307, loss = 413.24238096\n",
      "Iteration 5308, loss = 413.23951738\n",
      "Iteration 5309, loss = 413.23615178\n",
      "Iteration 5310, loss = 413.23398112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5311, loss = 413.22932602\n",
      "Iteration 5312, loss = 413.21979819\n",
      "Iteration 5313, loss = 413.21298998\n",
      "Iteration 5314, loss = 413.20634432\n",
      "Iteration 5315, loss = 413.19873261\n",
      "Iteration 5316, loss = 413.19066080\n",
      "Iteration 5317, loss = 413.18890331\n",
      "Iteration 5318, loss = 413.18260606\n",
      "Iteration 5319, loss = 413.17761718\n",
      "Iteration 5320, loss = 413.16925325\n",
      "Iteration 5321, loss = 413.16394014\n",
      "Iteration 5322, loss = 413.15547284\n",
      "Iteration 5323, loss = 413.15000028\n",
      "Iteration 5324, loss = 413.14484613\n",
      "Iteration 5325, loss = 413.13881072\n",
      "Iteration 5326, loss = 413.13241314\n",
      "Iteration 5327, loss = 413.12543517\n",
      "Iteration 5328, loss = 413.12270741\n",
      "Iteration 5329, loss = 413.11813238\n",
      "Iteration 5330, loss = 413.10880191\n",
      "Iteration 5331, loss = 413.10509023\n",
      "Iteration 5332, loss = 413.09994869\n",
      "Iteration 5333, loss = 413.09213270\n",
      "Iteration 5334, loss = 413.08798513\n",
      "Iteration 5335, loss = 413.08184389\n",
      "Iteration 5336, loss = 413.07239677\n",
      "Iteration 5337, loss = 413.06874433\n",
      "Iteration 5338, loss = 413.06330578\n",
      "Iteration 5339, loss = 413.06001865\n",
      "Iteration 5340, loss = 413.05008450\n",
      "Iteration 5341, loss = 413.04671656\n",
      "Iteration 5342, loss = 413.04198934\n",
      "Iteration 5343, loss = 413.03680128\n",
      "Iteration 5344, loss = 413.03289301\n",
      "Iteration 5345, loss = 413.02465836\n",
      "Iteration 5346, loss = 413.02056967\n",
      "Iteration 5347, loss = 413.01839529\n",
      "Iteration 5348, loss = 413.01210097\n",
      "Iteration 5349, loss = 413.00649551\n",
      "Iteration 5350, loss = 413.00564863\n",
      "Iteration 5351, loss = 413.00180636\n",
      "Iteration 5352, loss = 412.99421193\n",
      "Iteration 5353, loss = 412.99101100\n",
      "Iteration 5354, loss = 412.98601620\n",
      "Iteration 5355, loss = 412.97791682\n",
      "Iteration 5356, loss = 412.96948915\n",
      "Iteration 5357, loss = 412.95800557\n",
      "Iteration 5358, loss = 412.95174480\n",
      "Iteration 5359, loss = 412.94594968\n",
      "Iteration 5360, loss = 412.93832940\n",
      "Iteration 5361, loss = 412.93756244\n",
      "Iteration 5362, loss = 412.93495871\n",
      "Iteration 5363, loss = 412.92733770\n",
      "Iteration 5364, loss = 412.91885092\n",
      "Iteration 5365, loss = 412.91031436\n",
      "Iteration 5366, loss = 412.91181552\n",
      "Iteration 5367, loss = 412.90435043\n",
      "Iteration 5368, loss = 412.89404439\n",
      "Iteration 5369, loss = 412.88963518\n",
      "Iteration 5370, loss = 412.88501474\n",
      "Iteration 5371, loss = 412.87908619\n",
      "Iteration 5372, loss = 412.87077614\n",
      "Iteration 5373, loss = 412.86449589\n",
      "Iteration 5374, loss = 412.85791647\n",
      "Iteration 5375, loss = 412.85339435\n",
      "Iteration 5376, loss = 412.84546402\n",
      "Iteration 5377, loss = 412.83914544\n",
      "Iteration 5378, loss = 412.83450121\n",
      "Iteration 5379, loss = 412.83331089\n",
      "Iteration 5380, loss = 412.82736783\n",
      "Iteration 5381, loss = 412.81974476\n",
      "Iteration 5382, loss = 412.81469352\n",
      "Iteration 5383, loss = 412.80998566\n",
      "Iteration 5384, loss = 412.80123278\n",
      "Iteration 5385, loss = 412.79887005\n",
      "Iteration 5386, loss = 412.79389151\n",
      "Iteration 5387, loss = 412.78624280\n",
      "Iteration 5388, loss = 412.77968508\n",
      "Iteration 5389, loss = 412.77625319\n",
      "Iteration 5390, loss = 412.77409452\n",
      "Iteration 5391, loss = 412.76891293\n",
      "Iteration 5392, loss = 412.75941012\n",
      "Iteration 5393, loss = 412.75169069\n",
      "Iteration 5394, loss = 412.75104129\n",
      "Iteration 5395, loss = 412.74842571\n",
      "Iteration 5396, loss = 412.74344425\n",
      "Iteration 5397, loss = 412.73656420\n",
      "Iteration 5398, loss = 412.72853543\n",
      "Iteration 5399, loss = 412.71964166\n",
      "Iteration 5400, loss = 412.71723396\n",
      "Iteration 5401, loss = 412.71143101\n",
      "Iteration 5402, loss = 412.70401660\n",
      "Iteration 5403, loss = 412.69557495\n",
      "Iteration 5404, loss = 412.69285989\n",
      "Iteration 5405, loss = 412.68779734\n",
      "Iteration 5406, loss = 412.68236271\n",
      "Iteration 5407, loss = 412.67594535\n",
      "Iteration 5408, loss = 412.66816312\n",
      "Iteration 5409, loss = 412.66636917\n",
      "Iteration 5410, loss = 412.66206165\n",
      "Iteration 5411, loss = 412.65641236\n",
      "Iteration 5412, loss = 412.64889747\n",
      "Iteration 5413, loss = 412.64614697\n",
      "Iteration 5414, loss = 412.64159651\n",
      "Iteration 5415, loss = 412.63509791\n",
      "Iteration 5416, loss = 412.62720928\n",
      "Iteration 5417, loss = 412.62351524\n",
      "Iteration 5418, loss = 412.61604105\n",
      "Iteration 5419, loss = 412.61011607\n",
      "Iteration 5420, loss = 412.60175728\n",
      "Iteration 5421, loss = 412.59967443\n",
      "Iteration 5422, loss = 412.59248597\n",
      "Iteration 5423, loss = 412.58870636\n",
      "Iteration 5424, loss = 412.58499795\n",
      "Iteration 5425, loss = 412.58130689\n",
      "Iteration 5426, loss = 412.57465819\n",
      "Iteration 5427, loss = 412.56899895\n",
      "Iteration 5428, loss = 412.56967768\n",
      "Iteration 5429, loss = 412.56954235\n",
      "Iteration 5430, loss = 412.55849205\n",
      "Iteration 5431, loss = 412.55408620\n",
      "Iteration 5432, loss = 412.55258918\n",
      "Iteration 5433, loss = 412.55287267\n",
      "Iteration 5434, loss = 412.54972134\n",
      "Iteration 5435, loss = 412.54840410\n",
      "Iteration 5436, loss = 412.54246609\n",
      "Iteration 5437, loss = 412.54389282\n",
      "Iteration 5438, loss = 412.53692552\n",
      "Iteration 5439, loss = 412.52392516\n",
      "Iteration 5440, loss = 412.51856431\n",
      "Iteration 5441, loss = 412.51059670\n",
      "Iteration 5442, loss = 412.50341468\n",
      "Iteration 5443, loss = 412.49552140\n",
      "Iteration 5444, loss = 412.49075187\n",
      "Iteration 5445, loss = 412.48380863\n",
      "Iteration 5446, loss = 412.47902738\n",
      "Iteration 5447, loss = 412.46962772\n",
      "Iteration 5448, loss = 412.46268340\n",
      "Iteration 5449, loss = 412.46416959\n",
      "Iteration 5450, loss = 412.45995471\n",
      "Iteration 5451, loss = 412.45933342\n",
      "Iteration 5452, loss = 412.45902635\n",
      "Iteration 5453, loss = 412.45663972\n",
      "Iteration 5454, loss = 412.45196028\n",
      "Iteration 5455, loss = 412.44157525\n",
      "Iteration 5456, loss = 412.44206327\n",
      "Iteration 5457, loss = 412.43238975\n",
      "Iteration 5458, loss = 412.42253361\n",
      "Iteration 5459, loss = 412.41224999\n",
      "Iteration 5460, loss = 412.40467771\n",
      "Iteration 5461, loss = 412.39543698\n",
      "Iteration 5462, loss = 412.39031872\n",
      "Iteration 5463, loss = 412.38504681\n",
      "Iteration 5464, loss = 412.38196609\n",
      "Iteration 5465, loss = 412.37737152\n",
      "Iteration 5466, loss = 412.37257968\n",
      "Iteration 5467, loss = 412.36267760\n",
      "Iteration 5468, loss = 412.35855132\n",
      "Iteration 5469, loss = 412.35435093\n",
      "Iteration 5470, loss = 412.34669918\n",
      "Iteration 5471, loss = 412.34107100\n",
      "Iteration 5472, loss = 412.33796799\n",
      "Iteration 5473, loss = 412.33102730\n",
      "Iteration 5474, loss = 412.33058739\n",
      "Iteration 5475, loss = 412.32871084\n",
      "Iteration 5476, loss = 412.31832039\n",
      "Iteration 5477, loss = 412.31246620\n",
      "Iteration 5478, loss = 412.30964893\n",
      "Iteration 5479, loss = 412.30396201\n",
      "Iteration 5480, loss = 412.30122707\n",
      "Iteration 5481, loss = 412.29414385\n",
      "Iteration 5482, loss = 412.28628832\n",
      "Iteration 5483, loss = 412.28288326\n",
      "Iteration 5484, loss = 412.27412027\n",
      "Iteration 5485, loss = 412.26966652\n",
      "Iteration 5486, loss = 412.26562649\n",
      "Iteration 5487, loss = 412.26215520\n",
      "Iteration 5488, loss = 412.25295144\n",
      "Iteration 5489, loss = 412.24788532\n",
      "Iteration 5490, loss = 412.24181577\n",
      "Iteration 5491, loss = 412.23641521\n",
      "Iteration 5492, loss = 412.23128781\n",
      "Iteration 5493, loss = 412.22527787\n",
      "Iteration 5494, loss = 412.22564086\n",
      "Iteration 5495, loss = 412.22186710\n",
      "Iteration 5496, loss = 412.21022517\n",
      "Iteration 5497, loss = 412.20443948\n",
      "Iteration 5498, loss = 412.20189099\n",
      "Iteration 5499, loss = 412.20138160\n",
      "Iteration 5500, loss = 412.19077255\n",
      "Iteration 5501, loss = 412.18542342\n",
      "Iteration 5502, loss = 412.17980212\n",
      "Iteration 5503, loss = 412.17872118\n",
      "Iteration 5504, loss = 412.17447050\n",
      "Iteration 5505, loss = 412.16537325\n",
      "Iteration 5506, loss = 412.15762945\n",
      "Iteration 5507, loss = 412.15475235\n",
      "Iteration 5508, loss = 412.15041507\n",
      "Iteration 5509, loss = 412.14706409\n",
      "Iteration 5510, loss = 412.14095359\n",
      "Iteration 5511, loss = 412.13085753\n",
      "Iteration 5512, loss = 412.13232998\n",
      "Iteration 5513, loss = 412.12857563\n",
      "Iteration 5514, loss = 412.12351712\n",
      "Iteration 5515, loss = 412.11954548\n",
      "Iteration 5516, loss = 412.11515529\n",
      "Iteration 5517, loss = 412.10881557\n",
      "Iteration 5518, loss = 412.10294934\n",
      "Iteration 5519, loss = 412.09529895\n",
      "Iteration 5520, loss = 412.08999144\n",
      "Iteration 5521, loss = 412.08527008\n",
      "Iteration 5522, loss = 412.07862232\n",
      "Iteration 5523, loss = 412.07391216\n",
      "Iteration 5524, loss = 412.06996899\n",
      "Iteration 5525, loss = 412.06850965\n",
      "Iteration 5526, loss = 412.06302208\n",
      "Iteration 5527, loss = 412.05800893\n",
      "Iteration 5528, loss = 412.05536648\n",
      "Iteration 5529, loss = 412.04958415\n",
      "Iteration 5530, loss = 412.04853950\n",
      "Iteration 5531, loss = 412.04258737\n",
      "Iteration 5532, loss = 412.03633384\n",
      "Iteration 5533, loss = 412.03408363\n",
      "Iteration 5534, loss = 412.03357794\n",
      "Iteration 5535, loss = 412.02808898\n",
      "Iteration 5536, loss = 412.02095390\n",
      "Iteration 5537, loss = 412.02110957\n",
      "Iteration 5538, loss = 412.01678680\n",
      "Iteration 5539, loss = 412.00984523\n",
      "Iteration 5540, loss = 412.00157332\n",
      "Iteration 5541, loss = 412.00181580\n",
      "Iteration 5542, loss = 411.99781001\n",
      "Iteration 5543, loss = 411.99313306\n",
      "Iteration 5544, loss = 411.98799821\n",
      "Iteration 5545, loss = 411.98416126\n",
      "Iteration 5546, loss = 411.98098129\n",
      "Iteration 5547, loss = 411.98071423\n",
      "Iteration 5548, loss = 411.97338199\n",
      "Iteration 5549, loss = 411.96515962\n",
      "Iteration 5550, loss = 411.96442480\n",
      "Iteration 5551, loss = 411.95818795\n",
      "Iteration 5552, loss = 411.95177305\n",
      "Iteration 5553, loss = 411.94633991\n",
      "Iteration 5554, loss = 411.94116070\n",
      "Iteration 5555, loss = 411.93770120\n",
      "Iteration 5556, loss = 411.93275622\n",
      "Iteration 5557, loss = 411.92599681\n",
      "Iteration 5558, loss = 411.92118609\n",
      "Iteration 5559, loss = 411.91456957\n",
      "Iteration 5560, loss = 411.90781453\n",
      "Iteration 5561, loss = 411.90227765\n",
      "Iteration 5562, loss = 411.90390046\n",
      "Iteration 5563, loss = 411.89534461\n",
      "Iteration 5564, loss = 411.89171134\n",
      "Iteration 5565, loss = 411.88827558\n",
      "Iteration 5566, loss = 411.88499906\n",
      "Iteration 5567, loss = 411.88260845\n",
      "Iteration 5568, loss = 411.88010553\n",
      "Iteration 5569, loss = 411.87490864\n",
      "Iteration 5570, loss = 411.86664734\n",
      "Iteration 5571, loss = 411.86776943\n",
      "Iteration 5572, loss = 411.86358373\n",
      "Iteration 5573, loss = 411.85689256\n",
      "Iteration 5574, loss = 411.85462343\n",
      "Iteration 5575, loss = 411.85756052\n",
      "Iteration 5576, loss = 411.85836664\n",
      "Iteration 5577, loss = 411.85638517\n",
      "Iteration 5578, loss = 411.85406743\n",
      "Iteration 5579, loss = 411.85262460\n",
      "Iteration 5580, loss = 411.84584205\n",
      "Iteration 5581, loss = 411.83743671\n",
      "Iteration 5582, loss = 411.82940643\n",
      "Iteration 5583, loss = 411.82241933\n",
      "Iteration 5584, loss = 411.81386829\n",
      "Iteration 5585, loss = 411.80292787\n",
      "Iteration 5586, loss = 411.80333355\n",
      "Iteration 5587, loss = 411.80685953\n",
      "Iteration 5588, loss = 411.80469346\n",
      "Iteration 5589, loss = 411.79967366\n",
      "Iteration 5590, loss = 411.78950895\n",
      "Iteration 5591, loss = 411.77651336\n",
      "Iteration 5592, loss = 411.77880020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5593, loss = 411.77481601\n",
      "Iteration 5594, loss = 411.76390250\n",
      "Iteration 5595, loss = 411.76292608\n",
      "Iteration 5596, loss = 411.75798087\n",
      "Iteration 5597, loss = 411.75375071\n",
      "Iteration 5598, loss = 411.75480183\n",
      "Iteration 5599, loss = 411.74699148\n",
      "Iteration 5600, loss = 411.74002693\n",
      "Iteration 5601, loss = 411.73755185\n",
      "Iteration 5602, loss = 411.73237690\n",
      "Iteration 5603, loss = 411.72211379\n",
      "Iteration 5604, loss = 411.71567067\n",
      "Iteration 5605, loss = 411.71314222\n",
      "Iteration 5606, loss = 411.70994238\n",
      "Iteration 5607, loss = 411.70564351\n",
      "Iteration 5608, loss = 411.70177343\n",
      "Iteration 5609, loss = 411.69583624\n",
      "Iteration 5610, loss = 411.68731911\n",
      "Iteration 5611, loss = 411.68958367\n",
      "Iteration 5612, loss = 411.68645202\n",
      "Iteration 5613, loss = 411.67884061\n",
      "Iteration 5614, loss = 411.67539514\n",
      "Iteration 5615, loss = 411.67012407\n",
      "Iteration 5616, loss = 411.67251999\n",
      "Iteration 5617, loss = 411.67216992\n",
      "Iteration 5618, loss = 411.66764396\n",
      "Iteration 5619, loss = 411.65564127\n",
      "Iteration 5620, loss = 411.65038689\n",
      "Iteration 5621, loss = 411.65600810\n",
      "Iteration 5622, loss = 411.65172314\n",
      "Iteration 5623, loss = 411.64992015\n",
      "Iteration 5624, loss = 411.64672283\n",
      "Iteration 5625, loss = 411.64168397\n",
      "Iteration 5626, loss = 411.63562994\n",
      "Iteration 5627, loss = 411.63680024\n",
      "Iteration 5628, loss = 411.63656205\n",
      "Iteration 5629, loss = 411.63018359\n",
      "Iteration 5630, loss = 411.62942441\n",
      "Iteration 5631, loss = 411.62730446\n",
      "Iteration 5632, loss = 411.62557916\n",
      "Iteration 5633, loss = 411.62464321\n",
      "Iteration 5634, loss = 411.61527848\n",
      "Iteration 5635, loss = 411.60651684\n",
      "Iteration 5636, loss = 411.59719255\n",
      "Iteration 5637, loss = 411.59047218\n",
      "Iteration 5638, loss = 411.58240779\n",
      "Iteration 5639, loss = 411.57927772\n",
      "Iteration 5640, loss = 411.57609998\n",
      "Iteration 5641, loss = 411.57164270\n",
      "Iteration 5642, loss = 411.57277587\n",
      "Iteration 5643, loss = 411.56742673\n",
      "Iteration 5644, loss = 411.56947964\n",
      "Iteration 5645, loss = 411.56133535\n",
      "Iteration 5646, loss = 411.54960194\n",
      "Iteration 5647, loss = 411.55021327\n",
      "Iteration 5648, loss = 411.54509015\n",
      "Iteration 5649, loss = 411.53956874\n",
      "Iteration 5650, loss = 411.53690798\n",
      "Iteration 5651, loss = 411.53849247\n",
      "Iteration 5652, loss = 411.53055982\n",
      "Iteration 5653, loss = 411.52614222\n",
      "Iteration 5654, loss = 411.52411136\n",
      "Iteration 5655, loss = 411.52098589\n",
      "Iteration 5656, loss = 411.51483795\n",
      "Iteration 5657, loss = 411.51187790\n",
      "Iteration 5658, loss = 411.50369637\n",
      "Iteration 5659, loss = 411.50438847\n",
      "Iteration 5660, loss = 411.50299379\n",
      "Iteration 5661, loss = 411.49785526\n",
      "Iteration 5662, loss = 411.49143420\n",
      "Iteration 5663, loss = 411.49367399\n",
      "Iteration 5664, loss = 411.49220706\n",
      "Iteration 5665, loss = 411.48654441\n",
      "Iteration 5666, loss = 411.48189802\n",
      "Iteration 5667, loss = 411.47498493\n",
      "Iteration 5668, loss = 411.47598130\n",
      "Iteration 5669, loss = 411.47198644\n",
      "Iteration 5670, loss = 411.46523266\n",
      "Iteration 5671, loss = 411.46197072\n",
      "Iteration 5672, loss = 411.45808730\n",
      "Iteration 5673, loss = 411.45206065\n",
      "Iteration 5674, loss = 411.44466258\n",
      "Iteration 5675, loss = 411.44164314\n",
      "Iteration 5676, loss = 411.44174284\n",
      "Iteration 5677, loss = 411.43414034\n",
      "Iteration 5678, loss = 411.43276075\n",
      "Iteration 5679, loss = 411.42755039\n",
      "Iteration 5680, loss = 411.42464425\n",
      "Iteration 5681, loss = 411.41895067\n",
      "Iteration 5682, loss = 411.41707902\n",
      "Iteration 5683, loss = 411.41624012\n",
      "Iteration 5684, loss = 411.41017950\n",
      "Iteration 5685, loss = 411.40505352\n",
      "Iteration 5686, loss = 411.40266752\n",
      "Iteration 5687, loss = 411.39922225\n",
      "Iteration 5688, loss = 411.39767980\n",
      "Iteration 5689, loss = 411.39801693\n",
      "Iteration 5690, loss = 411.39606589\n",
      "Iteration 5691, loss = 411.39631078\n",
      "Iteration 5692, loss = 411.39143639\n",
      "Iteration 5693, loss = 411.39056912\n",
      "Iteration 5694, loss = 411.39042036\n",
      "Iteration 5695, loss = 411.39122265\n",
      "Iteration 5696, loss = 411.39424989\n",
      "Iteration 5697, loss = 411.39331587\n",
      "Iteration 5698, loss = 411.37944780\n",
      "Iteration 5699, loss = 411.37605814\n",
      "Iteration 5700, loss = 411.37112348\n",
      "Iteration 5701, loss = 411.35888624\n",
      "Iteration 5702, loss = 411.34907147\n",
      "Iteration 5703, loss = 411.34342416\n",
      "Iteration 5704, loss = 411.34067194\n",
      "Iteration 5705, loss = 411.33862231\n",
      "Iteration 5706, loss = 411.33241385\n",
      "Iteration 5707, loss = 411.33124423\n",
      "Iteration 5708, loss = 411.32886749\n",
      "Iteration 5709, loss = 411.32383290\n",
      "Iteration 5710, loss = 411.31539998\n",
      "Iteration 5711, loss = 411.30765581\n",
      "Iteration 5712, loss = 411.30363413\n",
      "Iteration 5713, loss = 411.30154042\n",
      "Iteration 5714, loss = 411.29813939\n",
      "Iteration 5715, loss = 411.29283833\n",
      "Iteration 5716, loss = 411.28851657\n",
      "Iteration 5717, loss = 411.28874689\n",
      "Iteration 5718, loss = 411.28266317\n",
      "Iteration 5719, loss = 411.27573543\n",
      "Iteration 5720, loss = 411.27361121\n",
      "Iteration 5721, loss = 411.26735101\n",
      "Iteration 5722, loss = 411.27141125\n",
      "Iteration 5723, loss = 411.26524744\n",
      "Iteration 5724, loss = 411.25719326\n",
      "Iteration 5725, loss = 411.25284364\n",
      "Iteration 5726, loss = 411.25607515\n",
      "Iteration 5727, loss = 411.25084041\n",
      "Iteration 5728, loss = 411.24151868\n",
      "Iteration 5729, loss = 411.24009236\n",
      "Iteration 5730, loss = 411.23771848\n",
      "Iteration 5731, loss = 411.23238124\n",
      "Iteration 5732, loss = 411.22813108\n",
      "Iteration 5733, loss = 411.22249350\n",
      "Iteration 5734, loss = 411.22456591\n",
      "Iteration 5735, loss = 411.21919664\n",
      "Iteration 5736, loss = 411.21408540\n",
      "Iteration 5737, loss = 411.21098935\n",
      "Iteration 5738, loss = 411.20897443\n",
      "Iteration 5739, loss = 411.20911996\n",
      "Iteration 5740, loss = 411.20468883\n",
      "Iteration 5741, loss = 411.20252995\n",
      "Iteration 5742, loss = 411.19515096\n",
      "Iteration 5743, loss = 411.19307081\n",
      "Iteration 5744, loss = 411.18678294\n",
      "Iteration 5745, loss = 411.18504760\n",
      "Iteration 5746, loss = 411.17862598\n",
      "Iteration 5747, loss = 411.17396003\n",
      "Iteration 5748, loss = 411.17543785\n",
      "Iteration 5749, loss = 411.17376442\n",
      "Iteration 5750, loss = 411.17072926\n",
      "Iteration 5751, loss = 411.17118947\n",
      "Iteration 5752, loss = 411.17206819\n",
      "Iteration 5753, loss = 411.17663000\n",
      "Iteration 5754, loss = 411.18202119\n",
      "Iteration 5755, loss = 411.18147589\n",
      "Iteration 5756, loss = 411.17555904\n",
      "Iteration 5757, loss = 411.16831496\n",
      "Iteration 5758, loss = 411.15146187\n",
      "Iteration 5759, loss = 411.14448314\n",
      "Iteration 5760, loss = 411.13005751\n",
      "Iteration 5761, loss = 411.12019325\n",
      "Iteration 5762, loss = 411.12307742\n",
      "Iteration 5763, loss = 411.12213734\n",
      "Iteration 5764, loss = 411.12314550\n",
      "Iteration 5765, loss = 411.11873031\n",
      "Iteration 5766, loss = 411.11503828\n",
      "Iteration 5767, loss = 411.10594247\n",
      "Iteration 5768, loss = 411.09707051\n",
      "Iteration 5769, loss = 411.09108922\n",
      "Iteration 5770, loss = 411.09080757\n",
      "Iteration 5771, loss = 411.09465277\n",
      "Iteration 5772, loss = 411.08504952\n",
      "Iteration 5773, loss = 411.08072120\n",
      "Iteration 5774, loss = 411.07523389\n",
      "Iteration 5775, loss = 411.07458461\n",
      "Iteration 5776, loss = 411.07007084\n",
      "Iteration 5777, loss = 411.07261242\n",
      "Iteration 5778, loss = 411.07202257\n",
      "Iteration 5779, loss = 411.06185697\n",
      "Iteration 5780, loss = 411.05682890\n",
      "Iteration 5781, loss = 411.05303619\n",
      "Iteration 5782, loss = 411.04552785\n",
      "Iteration 5783, loss = 411.04298036\n",
      "Iteration 5784, loss = 411.04209037\n",
      "Iteration 5785, loss = 411.03882385\n",
      "Iteration 5786, loss = 411.03374885\n",
      "Iteration 5787, loss = 411.03079323\n",
      "Iteration 5788, loss = 411.02982993\n",
      "Iteration 5789, loss = 411.02789412\n",
      "Iteration 5790, loss = 411.01935915\n",
      "Iteration 5791, loss = 411.01756484\n",
      "Iteration 5792, loss = 411.01220039\n",
      "Iteration 5793, loss = 411.01088071\n",
      "Iteration 5794, loss = 411.00382797\n",
      "Iteration 5795, loss = 410.99648116\n",
      "Iteration 5796, loss = 411.00051492\n",
      "Iteration 5797, loss = 410.99298943\n",
      "Iteration 5798, loss = 410.98607799\n",
      "Iteration 5799, loss = 410.98118532\n",
      "Iteration 5800, loss = 410.98226495\n",
      "Iteration 5801, loss = 410.97865033\n",
      "Iteration 5802, loss = 410.97392274\n",
      "Iteration 5803, loss = 410.96781735\n",
      "Iteration 5804, loss = 410.96442212\n",
      "Iteration 5805, loss = 410.95883652\n",
      "Iteration 5806, loss = 410.95542761\n",
      "Iteration 5807, loss = 410.95213192\n",
      "Iteration 5808, loss = 410.94340404\n",
      "Iteration 5809, loss = 410.94405028\n",
      "Iteration 5810, loss = 410.94203390\n",
      "Iteration 5811, loss = 410.94254676\n",
      "Iteration 5812, loss = 410.93737096\n",
      "Iteration 5813, loss = 410.93167389\n",
      "Iteration 5814, loss = 410.92838829\n",
      "Iteration 5815, loss = 410.92332510\n",
      "Iteration 5816, loss = 410.92197173\n",
      "Iteration 5817, loss = 410.92260899\n",
      "Iteration 5818, loss = 410.91991311\n",
      "Iteration 5819, loss = 410.91702929\n",
      "Iteration 5820, loss = 410.91674702\n",
      "Iteration 5821, loss = 410.91842811\n",
      "Iteration 5822, loss = 410.91654382\n",
      "Iteration 5823, loss = 410.91140527\n",
      "Iteration 5824, loss = 410.90629084\n",
      "Iteration 5825, loss = 410.90566282\n",
      "Iteration 5826, loss = 410.89778211\n",
      "Iteration 5827, loss = 410.89067106\n",
      "Iteration 5828, loss = 410.88215558\n",
      "Iteration 5829, loss = 410.87513568\n",
      "Iteration 5830, loss = 410.87385440\n",
      "Iteration 5831, loss = 410.86899049\n",
      "Iteration 5832, loss = 410.86024192\n",
      "Iteration 5833, loss = 410.85962922\n",
      "Iteration 5834, loss = 410.85736306\n",
      "Iteration 5835, loss = 410.85395942\n",
      "Iteration 5836, loss = 410.84977432\n",
      "Iteration 5837, loss = 410.84918591\n",
      "Iteration 5838, loss = 410.84655334\n",
      "Iteration 5839, loss = 410.83651437\n",
      "Iteration 5840, loss = 410.83049359\n",
      "Iteration 5841, loss = 410.82696108\n",
      "Iteration 5842, loss = 410.82419626\n",
      "Iteration 5843, loss = 410.82110457\n",
      "Iteration 5844, loss = 410.81664227\n",
      "Iteration 5845, loss = 410.81493583\n",
      "Iteration 5846, loss = 410.81880185\n",
      "Iteration 5847, loss = 410.81377614\n",
      "Iteration 5848, loss = 410.80346293\n",
      "Iteration 5849, loss = 410.80173907\n",
      "Iteration 5850, loss = 410.79758344\n",
      "Iteration 5851, loss = 410.79697815\n",
      "Iteration 5852, loss = 410.79537185\n",
      "Iteration 5853, loss = 410.79277883\n",
      "Iteration 5854, loss = 410.78164338\n",
      "Iteration 5855, loss = 410.78245169\n",
      "Iteration 5856, loss = 410.78086942\n",
      "Iteration 5857, loss = 410.77898832\n",
      "Iteration 5858, loss = 410.77063316\n",
      "Iteration 5859, loss = 410.77084908\n",
      "Iteration 5860, loss = 410.76894209\n",
      "Iteration 5861, loss = 410.76675790\n",
      "Iteration 5862, loss = 410.75961754\n",
      "Iteration 5863, loss = 410.75499504\n",
      "Iteration 5864, loss = 410.75321353\n",
      "Iteration 5865, loss = 410.75242746\n",
      "Iteration 5866, loss = 410.75049976\n",
      "Iteration 5867, loss = 410.74125229\n",
      "Iteration 5868, loss = 410.74345562\n",
      "Iteration 5869, loss = 410.74419486\n",
      "Iteration 5870, loss = 410.73396245\n",
      "Iteration 5871, loss = 410.72480000\n",
      "Iteration 5872, loss = 410.72757564\n",
      "Iteration 5873, loss = 410.72359298\n",
      "Iteration 5874, loss = 410.71846151\n",
      "Iteration 5875, loss = 410.71411077\n",
      "Iteration 5876, loss = 410.71078190\n",
      "Iteration 5877, loss = 410.70381380\n",
      "Iteration 5878, loss = 410.69190889\n",
      "Iteration 5879, loss = 410.70528547\n",
      "Iteration 5880, loss = 410.70188106\n",
      "Iteration 5881, loss = 410.69617425\n",
      "Iteration 5882, loss = 410.69324660\n",
      "Iteration 5883, loss = 410.68313051\n",
      "Iteration 5884, loss = 410.68035053\n",
      "Iteration 5885, loss = 410.67105769\n",
      "Iteration 5886, loss = 410.66403570\n",
      "Iteration 5887, loss = 410.67326850\n",
      "Iteration 5888, loss = 410.66339761\n",
      "Iteration 5889, loss = 410.65998327\n",
      "Iteration 5890, loss = 410.65995620\n",
      "Iteration 5891, loss = 410.65359439\n",
      "Iteration 5892, loss = 410.65425119\n",
      "Iteration 5893, loss = 410.65459817\n",
      "Iteration 5894, loss = 410.64901937\n",
      "Iteration 5895, loss = 410.64559938\n",
      "Iteration 5896, loss = 410.63975144\n",
      "Iteration 5897, loss = 410.63528718\n",
      "Iteration 5898, loss = 410.63145739\n",
      "Iteration 5899, loss = 410.63090743\n",
      "Iteration 5900, loss = 410.62582705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5901, loss = 410.62442818\n",
      "Iteration 5902, loss = 410.61976530\n",
      "Iteration 5903, loss = 410.61411778\n",
      "Iteration 5904, loss = 410.61665640\n",
      "Iteration 5905, loss = 410.61207989\n",
      "Iteration 5906, loss = 410.60256493\n",
      "Iteration 5907, loss = 410.60136506\n",
      "Iteration 5908, loss = 410.59933682\n",
      "Iteration 5909, loss = 410.59459623\n",
      "Iteration 5910, loss = 410.59415331\n",
      "Iteration 5911, loss = 410.58961864\n",
      "Iteration 5912, loss = 410.59040618\n",
      "Iteration 5913, loss = 410.58767168\n",
      "Iteration 5914, loss = 410.58154791\n",
      "Iteration 5915, loss = 410.57694628\n",
      "Iteration 5916, loss = 410.57239503\n",
      "Iteration 5917, loss = 410.56919777\n",
      "Iteration 5918, loss = 410.55781866\n",
      "Iteration 5919, loss = 410.55179659\n",
      "Iteration 5920, loss = 410.54974292\n",
      "Iteration 5921, loss = 410.54866589\n",
      "Iteration 5922, loss = 410.54663180\n",
      "Iteration 5923, loss = 410.54752669\n",
      "Iteration 5924, loss = 410.54711768\n",
      "Iteration 5925, loss = 410.54501690\n",
      "Iteration 5926, loss = 410.54889068\n",
      "Iteration 5927, loss = 410.54772237\n",
      "Iteration 5928, loss = 410.54138879\n",
      "Iteration 5929, loss = 410.54089020\n",
      "Iteration 5930, loss = 410.53563253\n",
      "Iteration 5931, loss = 410.52939892\n",
      "Iteration 5932, loss = 410.51903279\n",
      "Iteration 5933, loss = 410.50548356\n",
      "Iteration 5934, loss = 410.49790844\n",
      "Iteration 5935, loss = 410.49587161\n",
      "Iteration 5936, loss = 410.49369948\n",
      "Iteration 5937, loss = 410.48928589\n",
      "Iteration 5938, loss = 410.49064488\n",
      "Iteration 5939, loss = 410.49245953\n",
      "Iteration 5940, loss = 410.48810141\n",
      "Iteration 5941, loss = 410.47949109\n",
      "Iteration 5942, loss = 410.47261897\n",
      "Iteration 5943, loss = 410.47101360\n",
      "Iteration 5944, loss = 410.46394161\n",
      "Iteration 5945, loss = 410.46187923\n",
      "Iteration 5946, loss = 410.46066812\n",
      "Iteration 5947, loss = 410.46198519\n",
      "Iteration 5948, loss = 410.45339363\n",
      "Iteration 5949, loss = 410.45449071\n",
      "Iteration 5950, loss = 410.45088336\n",
      "Iteration 5951, loss = 410.44776389\n",
      "Iteration 5952, loss = 410.44589783\n",
      "Iteration 5953, loss = 410.44671256\n",
      "Iteration 5954, loss = 410.43858284\n",
      "Iteration 5955, loss = 410.42789307\n",
      "Iteration 5956, loss = 410.42577870\n",
      "Iteration 5957, loss = 410.43001806\n",
      "Iteration 5958, loss = 410.43024582\n",
      "Iteration 5959, loss = 410.42126133\n",
      "Iteration 5960, loss = 410.41594221\n",
      "Iteration 5961, loss = 410.40633331\n",
      "Iteration 5962, loss = 410.40490556\n",
      "Iteration 5963, loss = 410.40636730\n",
      "Iteration 5964, loss = 410.40212009\n",
      "Iteration 5965, loss = 410.39202252\n",
      "Iteration 5966, loss = 410.39311687\n",
      "Iteration 5967, loss = 410.39358929\n",
      "Iteration 5968, loss = 410.39049365\n",
      "Iteration 5969, loss = 410.38684900\n",
      "Iteration 5970, loss = 410.37834470\n",
      "Iteration 5971, loss = 410.37136740\n",
      "Iteration 5972, loss = 410.36475636\n",
      "Iteration 5973, loss = 410.36077333\n",
      "Iteration 5974, loss = 410.35519970\n",
      "Iteration 5975, loss = 410.35811466\n",
      "Iteration 5976, loss = 410.34670554\n",
      "Iteration 5977, loss = 410.33741923\n",
      "Iteration 5978, loss = 410.33008555\n",
      "Iteration 5979, loss = 410.31778530\n",
      "Iteration 5980, loss = 410.29845260\n",
      "Iteration 5981, loss = 410.27856789\n",
      "Iteration 5982, loss = 410.26650102\n",
      "Iteration 5983, loss = 410.25393944\n",
      "Iteration 5984, loss = 410.23385826\n",
      "Iteration 5985, loss = 410.22895811\n",
      "Iteration 5986, loss = 410.21513196\n",
      "Iteration 5987, loss = 410.19081439\n",
      "Iteration 5988, loss = 410.18194264\n",
      "Iteration 5989, loss = 410.17398788\n",
      "Iteration 5990, loss = 410.16404793\n",
      "Iteration 5991, loss = 410.15056365\n",
      "Iteration 5992, loss = 410.13154279\n",
      "Iteration 5993, loss = 410.11730465\n",
      "Iteration 5994, loss = 410.09853493\n",
      "Iteration 5995, loss = 410.07165291\n",
      "Iteration 5996, loss = 410.05576328\n",
      "Iteration 5997, loss = 410.03201602\n",
      "Iteration 5998, loss = 410.01257264\n",
      "Iteration 5999, loss = 409.99724725\n",
      "Iteration 6000, loss = 409.98509322\n",
      "Iteration 6001, loss = 409.97191209\n",
      "Iteration 6002, loss = 409.95484143\n",
      "Iteration 6003, loss = 409.94227173\n",
      "Iteration 6004, loss = 409.93097729\n",
      "Iteration 6005, loss = 409.91446198\n",
      "Iteration 6006, loss = 409.90291696\n",
      "Iteration 6007, loss = 409.89031879\n",
      "Iteration 6008, loss = 409.87745807\n",
      "Iteration 6009, loss = 409.87140610\n",
      "Iteration 6010, loss = 409.86269238\n",
      "Iteration 6011, loss = 409.86373809\n",
      "Iteration 6012, loss = 409.85526717\n",
      "Iteration 6013, loss = 409.84879527\n",
      "Iteration 6014, loss = 409.84013377\n",
      "Iteration 6015, loss = 409.82874633\n",
      "Iteration 6016, loss = 409.82389485\n",
      "Iteration 6017, loss = 409.81479746\n",
      "Iteration 6018, loss = 409.80216924\n",
      "Iteration 6019, loss = 409.79710246\n",
      "Iteration 6020, loss = 409.79112564\n",
      "Iteration 6021, loss = 409.77353259\n",
      "Iteration 6022, loss = 409.77049460\n",
      "Iteration 6023, loss = 409.76528979\n",
      "Iteration 6024, loss = 409.76568524\n",
      "Iteration 6025, loss = 409.75554100\n",
      "Iteration 6026, loss = 409.73983550\n",
      "Iteration 6027, loss = 409.73669041\n",
      "Iteration 6028, loss = 409.73747545\n",
      "Iteration 6029, loss = 409.73386760\n",
      "Iteration 6030, loss = 409.71965124\n",
      "Iteration 6031, loss = 409.71557275\n",
      "Iteration 6032, loss = 409.71519162\n",
      "Iteration 6033, loss = 409.70923496\n",
      "Iteration 6034, loss = 409.69772372\n",
      "Iteration 6035, loss = 409.68979245\n",
      "Iteration 6036, loss = 409.68257673\n",
      "Iteration 6037, loss = 409.67086975\n",
      "Iteration 6038, loss = 409.67160356\n",
      "Iteration 6039, loss = 409.67044402\n",
      "Iteration 6040, loss = 409.65843851\n",
      "Iteration 6041, loss = 409.65780677\n",
      "Iteration 6042, loss = 409.66244622\n",
      "Iteration 6043, loss = 409.66082618\n",
      "Iteration 6044, loss = 409.65502685\n",
      "Iteration 6045, loss = 409.64443437\n",
      "Iteration 6046, loss = 409.63498496\n",
      "Iteration 6047, loss = 409.63568087\n",
      "Iteration 6048, loss = 409.64033644\n",
      "Iteration 6049, loss = 409.63604050\n",
      "Iteration 6050, loss = 409.62564979\n",
      "Iteration 6051, loss = 409.61659415\n",
      "Iteration 6052, loss = 409.60830301\n",
      "Iteration 6053, loss = 409.59679481\n",
      "Iteration 6054, loss = 409.58645505\n",
      "Iteration 6055, loss = 409.58237856\n",
      "Iteration 6056, loss = 409.57712780\n",
      "Iteration 6057, loss = 409.56745530\n",
      "Iteration 6058, loss = 409.56667997\n",
      "Iteration 6059, loss = 409.55870123\n",
      "Iteration 6060, loss = 409.54895921\n",
      "Iteration 6061, loss = 409.55228651\n",
      "Iteration 6062, loss = 409.55194287\n",
      "Iteration 6063, loss = 409.54157977\n",
      "Iteration 6064, loss = 409.53399334\n",
      "Iteration 6065, loss = 409.53700537\n",
      "Iteration 6066, loss = 409.53300260\n",
      "Iteration 6067, loss = 409.52727567\n",
      "Iteration 6068, loss = 409.51571546\n",
      "Iteration 6069, loss = 409.51517696\n",
      "Iteration 6070, loss = 409.51169612\n",
      "Iteration 6071, loss = 409.50914934\n",
      "Iteration 6072, loss = 409.49965634\n",
      "Iteration 6073, loss = 409.50064692\n",
      "Iteration 6074, loss = 409.49087059\n",
      "Iteration 6075, loss = 409.48524819\n",
      "Iteration 6076, loss = 409.48552309\n",
      "Iteration 6077, loss = 409.48579021\n",
      "Iteration 6078, loss = 409.48018522\n",
      "Iteration 6079, loss = 409.47416087\n",
      "Iteration 6080, loss = 409.46592322\n",
      "Iteration 6081, loss = 409.45188364\n",
      "Iteration 6082, loss = 409.45290749\n",
      "Iteration 6083, loss = 409.44516212\n",
      "Iteration 6084, loss = 409.44914990\n",
      "Iteration 6085, loss = 409.44800662\n",
      "Iteration 6086, loss = 409.44323163\n",
      "Iteration 6087, loss = 409.43708400\n",
      "Iteration 6088, loss = 409.42697068\n",
      "Iteration 6089, loss = 409.41755944\n",
      "Iteration 6090, loss = 409.42493547\n",
      "Iteration 6091, loss = 409.42516168\n",
      "Iteration 6092, loss = 409.41378498\n",
      "Iteration 6093, loss = 409.40983540\n",
      "Iteration 6094, loss = 409.40715899\n",
      "Iteration 6095, loss = 409.40558873\n",
      "Iteration 6096, loss = 409.40596377\n",
      "Iteration 6097, loss = 409.39953116\n",
      "Iteration 6098, loss = 409.39151445\n",
      "Iteration 6099, loss = 409.38620692\n",
      "Iteration 6100, loss = 409.39452249\n",
      "Iteration 6101, loss = 409.38481629\n",
      "Iteration 6102, loss = 409.37324939\n",
      "Iteration 6103, loss = 409.36910247\n",
      "Iteration 6104, loss = 409.36961982\n",
      "Iteration 6105, loss = 409.36881581\n",
      "Iteration 6106, loss = 409.36489519\n",
      "Iteration 6107, loss = 409.36295394\n",
      "Iteration 6108, loss = 409.35799088\n",
      "Iteration 6109, loss = 409.35144254\n",
      "Iteration 6110, loss = 409.35446013\n",
      "Iteration 6111, loss = 409.35100340\n",
      "Iteration 6112, loss = 409.34556752\n",
      "Iteration 6113, loss = 409.33991310\n",
      "Iteration 6114, loss = 409.34337367\n",
      "Iteration 6115, loss = 409.34219937\n",
      "Iteration 6116, loss = 409.33277367\n",
      "Iteration 6117, loss = 409.32912954\n",
      "Iteration 6118, loss = 409.32974467\n",
      "Iteration 6119, loss = 409.32923813\n",
      "Iteration 6120, loss = 409.33139402\n",
      "Iteration 6121, loss = 409.32602722\n",
      "Iteration 6122, loss = 409.32200056\n",
      "Iteration 6123, loss = 409.31698614\n",
      "Iteration 6124, loss = 409.30827826\n",
      "Iteration 6125, loss = 409.30840612\n",
      "Iteration 6126, loss = 409.30495529\n",
      "Iteration 6127, loss = 409.29773811\n",
      "Iteration 6128, loss = 409.29015924\n",
      "Iteration 6129, loss = 409.29892721\n",
      "Iteration 6130, loss = 409.29593495\n",
      "Iteration 6131, loss = 409.28054913\n",
      "Iteration 6132, loss = 409.27450522\n",
      "Iteration 6133, loss = 409.27714643\n",
      "Iteration 6134, loss = 409.27560401\n",
      "Iteration 6135, loss = 409.26463481\n",
      "Iteration 6136, loss = 409.26231405\n",
      "Iteration 6137, loss = 409.26216481\n",
      "Iteration 6138, loss = 409.24891921\n",
      "Iteration 6139, loss = 409.24856826\n",
      "Iteration 6140, loss = 409.25255161\n",
      "Iteration 6141, loss = 409.25328039\n",
      "Iteration 6142, loss = 409.24741135\n",
      "Iteration 6143, loss = 409.24142649\n",
      "Iteration 6144, loss = 409.23560627\n",
      "Iteration 6145, loss = 409.22983584\n",
      "Iteration 6146, loss = 409.22720018\n",
      "Iteration 6147, loss = 409.21915042\n",
      "Iteration 6148, loss = 409.21655117\n",
      "Iteration 6149, loss = 409.21569244\n",
      "Iteration 6150, loss = 409.21107974\n",
      "Iteration 6151, loss = 409.20439700\n",
      "Iteration 6152, loss = 409.20520204\n",
      "Iteration 6153, loss = 409.20908782\n",
      "Iteration 6154, loss = 409.20220698\n",
      "Iteration 6155, loss = 409.19279790\n",
      "Iteration 6156, loss = 409.19442529\n",
      "Iteration 6157, loss = 409.19687446\n",
      "Iteration 6158, loss = 409.19384044\n",
      "Iteration 6159, loss = 409.19519228\n",
      "Iteration 6160, loss = 409.18967948\n",
      "Iteration 6161, loss = 409.17682593\n",
      "Iteration 6162, loss = 409.18996323\n",
      "Iteration 6163, loss = 409.19095000\n",
      "Iteration 6164, loss = 409.17955401\n",
      "Iteration 6165, loss = 409.17058966\n",
      "Iteration 6166, loss = 409.17075383\n",
      "Iteration 6167, loss = 409.16112814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6168, loss = 409.14327351\n",
      "Iteration 6169, loss = 409.14347594\n",
      "Iteration 6170, loss = 409.13786997\n",
      "Iteration 6171, loss = 409.13412757\n",
      "Iteration 6172, loss = 409.13609972\n",
      "Iteration 6173, loss = 409.13601003\n",
      "Iteration 6174, loss = 409.13770489\n",
      "Iteration 6175, loss = 409.12903522\n",
      "Iteration 6176, loss = 409.12629120\n",
      "Iteration 6177, loss = 409.12091249\n",
      "Iteration 6178, loss = 409.11610335\n",
      "Iteration 6179, loss = 409.11076693\n",
      "Iteration 6180, loss = 409.10386079\n",
      "Iteration 6181, loss = 409.09838976\n",
      "Iteration 6182, loss = 409.09581976\n",
      "Iteration 6183, loss = 409.09189225\n",
      "Iteration 6184, loss = 409.08395415\n",
      "Iteration 6185, loss = 409.08657389\n",
      "Iteration 6186, loss = 409.08413957\n",
      "Iteration 6187, loss = 409.07912367\n",
      "Iteration 6188, loss = 409.07371409\n",
      "Iteration 6189, loss = 409.06895122\n",
      "Iteration 6190, loss = 409.07165954\n",
      "Iteration 6191, loss = 409.06593557\n",
      "Iteration 6192, loss = 409.05954277\n",
      "Iteration 6193, loss = 409.05883488\n",
      "Iteration 6194, loss = 409.05616010\n",
      "Iteration 6195, loss = 409.05327852\n",
      "Iteration 6196, loss = 409.04807583\n",
      "Iteration 6197, loss = 409.04324263\n",
      "Iteration 6198, loss = 409.03846895\n",
      "Iteration 6199, loss = 409.03517239\n",
      "Iteration 6200, loss = 409.02989665\n",
      "Iteration 6201, loss = 409.02795477\n",
      "Iteration 6202, loss = 409.02936434\n",
      "Iteration 6203, loss = 409.01870522\n",
      "Iteration 6204, loss = 409.01808724\n",
      "Iteration 6205, loss = 409.01830920\n",
      "Iteration 6206, loss = 409.01053899\n",
      "Iteration 6207, loss = 409.00520391\n",
      "Iteration 6208, loss = 408.99907350\n",
      "Iteration 6209, loss = 408.99432315\n",
      "Iteration 6210, loss = 408.99572963\n",
      "Iteration 6211, loss = 408.99514441\n",
      "Iteration 6212, loss = 408.98791634\n",
      "Iteration 6213, loss = 408.98269927\n",
      "Iteration 6214, loss = 408.97997936\n",
      "Iteration 6215, loss = 408.98105518\n",
      "Iteration 6216, loss = 408.98553945\n",
      "Iteration 6217, loss = 408.98348450\n",
      "Iteration 6218, loss = 408.97100784\n",
      "Iteration 6219, loss = 408.96714810\n",
      "Iteration 6220, loss = 408.96138395\n",
      "Iteration 6221, loss = 408.96413746\n",
      "Iteration 6222, loss = 408.96065963\n",
      "Iteration 6223, loss = 408.95771349\n",
      "Iteration 6224, loss = 408.95283006\n",
      "Iteration 6225, loss = 408.94649256\n",
      "Iteration 6226, loss = 408.94496210\n",
      "Iteration 6227, loss = 408.93793770\n",
      "Iteration 6228, loss = 408.93672606\n",
      "Iteration 6229, loss = 408.92871866\n",
      "Iteration 6230, loss = 408.92093186\n",
      "Iteration 6231, loss = 408.92381814\n",
      "Iteration 6232, loss = 408.92026842\n",
      "Iteration 6233, loss = 408.91743255\n",
      "Iteration 6234, loss = 408.91621013\n",
      "Iteration 6235, loss = 408.91376562\n",
      "Iteration 6236, loss = 408.91173798\n",
      "Iteration 6237, loss = 408.90250579\n",
      "Iteration 6238, loss = 408.88822887\n",
      "Iteration 6239, loss = 408.89489563\n",
      "Iteration 6240, loss = 408.89097408\n",
      "Iteration 6241, loss = 408.88291135\n",
      "Iteration 6242, loss = 408.87539746\n",
      "Iteration 6243, loss = 408.88162755\n",
      "Iteration 6244, loss = 408.88211036\n",
      "Iteration 6245, loss = 408.86790048\n",
      "Iteration 6246, loss = 408.86735477\n",
      "Iteration 6247, loss = 408.86651348\n",
      "Iteration 6248, loss = 408.87212384\n",
      "Iteration 6249, loss = 408.86607093\n",
      "Iteration 6250, loss = 408.85808328\n",
      "Iteration 6251, loss = 408.85037637\n",
      "Iteration 6252, loss = 408.85498797\n",
      "Iteration 6253, loss = 408.84905188\n",
      "Iteration 6254, loss = 408.84998069\n",
      "Iteration 6255, loss = 408.84723199\n",
      "Iteration 6256, loss = 408.84576961\n",
      "Iteration 6257, loss = 408.84564749\n",
      "Iteration 6258, loss = 408.84052450\n",
      "Iteration 6259, loss = 408.83878622\n",
      "Iteration 6260, loss = 408.83439827\n",
      "Iteration 6261, loss = 408.83256646\n",
      "Iteration 6262, loss = 408.82141913\n",
      "Iteration 6263, loss = 408.82125422\n",
      "Iteration 6264, loss = 408.81789544\n",
      "Iteration 6265, loss = 408.82110227\n",
      "Iteration 6266, loss = 408.81709459\n",
      "Iteration 6267, loss = 408.81103360\n",
      "Iteration 6268, loss = 408.80356653\n",
      "Iteration 6269, loss = 408.80453209\n",
      "Iteration 6270, loss = 408.80298976\n",
      "Iteration 6271, loss = 408.79222501\n",
      "Iteration 6272, loss = 408.79444342\n",
      "Iteration 6273, loss = 408.79557607\n",
      "Iteration 6274, loss = 408.79432271\n",
      "Iteration 6275, loss = 408.77778187\n",
      "Iteration 6276, loss = 408.77531606\n",
      "Iteration 6277, loss = 408.77782553\n",
      "Iteration 6278, loss = 408.77331505\n",
      "Iteration 6279, loss = 408.76168609\n",
      "Iteration 6280, loss = 408.75550319\n",
      "Iteration 6281, loss = 408.74579461\n",
      "Iteration 6282, loss = 408.74955148\n",
      "Iteration 6283, loss = 408.74734099\n",
      "Iteration 6284, loss = 408.74641664\n",
      "Iteration 6285, loss = 408.73744305\n",
      "Iteration 6286, loss = 408.73295931\n",
      "Iteration 6287, loss = 408.73763308\n",
      "Iteration 6288, loss = 408.73686144\n",
      "Iteration 6289, loss = 408.73642876\n",
      "Iteration 6290, loss = 408.72643971\n",
      "Iteration 6291, loss = 408.71372633\n",
      "Iteration 6292, loss = 408.71333554\n",
      "Iteration 6293, loss = 408.70988512\n",
      "Iteration 6294, loss = 408.70768002\n",
      "Iteration 6295, loss = 408.69899742\n",
      "Iteration 6296, loss = 408.69682000\n",
      "Iteration 6297, loss = 408.69031956\n",
      "Iteration 6298, loss = 408.68691003\n",
      "Iteration 6299, loss = 408.69028096\n",
      "Iteration 6300, loss = 408.68798408\n",
      "Iteration 6301, loss = 408.68247621\n",
      "Iteration 6302, loss = 408.67648086\n",
      "Iteration 6303, loss = 408.67498969\n",
      "Iteration 6304, loss = 408.67318505\n",
      "Iteration 6305, loss = 408.67548588\n",
      "Iteration 6306, loss = 408.67300711\n",
      "Iteration 6307, loss = 408.66323384\n",
      "Iteration 6308, loss = 408.65974930\n",
      "Iteration 6309, loss = 408.66001978\n",
      "Iteration 6310, loss = 408.65695411\n",
      "Iteration 6311, loss = 408.64785733\n",
      "Iteration 6312, loss = 408.64105243\n",
      "Iteration 6313, loss = 408.65296000\n",
      "Iteration 6314, loss = 408.64960813\n",
      "Iteration 6315, loss = 408.63536195\n",
      "Iteration 6316, loss = 408.62917256\n",
      "Iteration 6317, loss = 408.62902102\n",
      "Iteration 6318, loss = 408.63491246\n",
      "Iteration 6319, loss = 408.63128386\n",
      "Iteration 6320, loss = 408.62090051\n",
      "Iteration 6321, loss = 408.61975269\n",
      "Iteration 6322, loss = 408.61637683\n",
      "Iteration 6323, loss = 408.60771148\n",
      "Iteration 6324, loss = 408.60701186\n",
      "Iteration 6325, loss = 408.61195520\n",
      "Iteration 6326, loss = 408.60985598\n",
      "Iteration 6327, loss = 408.59451094\n",
      "Iteration 6328, loss = 408.59391903\n",
      "Iteration 6329, loss = 408.59248280\n",
      "Iteration 6330, loss = 408.58531708\n",
      "Iteration 6331, loss = 408.58557560\n",
      "Iteration 6332, loss = 408.58660731\n",
      "Iteration 6333, loss = 408.58471163\n",
      "Iteration 6334, loss = 408.57348303\n",
      "Iteration 6335, loss = 408.58096485\n",
      "Iteration 6336, loss = 408.58005572\n",
      "Iteration 6337, loss = 408.56441889\n",
      "Iteration 6338, loss = 408.55360238\n",
      "Iteration 6339, loss = 408.54813990\n",
      "Iteration 6340, loss = 408.55092358\n",
      "Iteration 6341, loss = 408.55188127\n",
      "Iteration 6342, loss = 408.54266498\n",
      "Iteration 6343, loss = 408.53315392\n",
      "Iteration 6344, loss = 408.53608655\n",
      "Iteration 6345, loss = 408.53691934\n",
      "Iteration 6346, loss = 408.52340294\n",
      "Iteration 6347, loss = 408.52964923\n",
      "Iteration 6348, loss = 408.53381829\n",
      "Iteration 6349, loss = 408.52972670\n",
      "Iteration 6350, loss = 408.52102756\n",
      "Iteration 6351, loss = 408.51527947\n",
      "Iteration 6352, loss = 408.50871897\n",
      "Iteration 6353, loss = 408.50297361\n",
      "Iteration 6354, loss = 408.50502910\n",
      "Iteration 6355, loss = 408.50258633\n",
      "Iteration 6356, loss = 408.49671642\n",
      "Iteration 6357, loss = 408.49343799\n",
      "Iteration 6358, loss = 408.49075115\n",
      "Iteration 6359, loss = 408.48392656\n",
      "Iteration 6360, loss = 408.48127530\n",
      "Iteration 6361, loss = 408.47508656\n",
      "Iteration 6362, loss = 408.46893131\n",
      "Iteration 6363, loss = 408.46911339\n",
      "Iteration 6364, loss = 408.46370945\n",
      "Iteration 6365, loss = 408.44720383\n",
      "Iteration 6366, loss = 408.45567714\n",
      "Iteration 6367, loss = 408.46723351\n",
      "Iteration 6368, loss = 408.45948733\n",
      "Iteration 6369, loss = 408.45072263\n",
      "Iteration 6370, loss = 408.44668893\n",
      "Iteration 6371, loss = 408.44320847\n",
      "Iteration 6372, loss = 408.43818003\n",
      "Iteration 6373, loss = 408.42981909\n",
      "Iteration 6374, loss = 408.42343309\n",
      "Iteration 6375, loss = 408.42180928\n",
      "Iteration 6376, loss = 408.41710692\n",
      "Iteration 6377, loss = 408.41823615\n",
      "Iteration 6378, loss = 408.41254982\n",
      "Iteration 6379, loss = 408.40929601\n",
      "Iteration 6380, loss = 408.40037583\n",
      "Iteration 6381, loss = 408.40327929\n",
      "Iteration 6382, loss = 408.40027775\n",
      "Iteration 6383, loss = 408.39785146\n",
      "Iteration 6384, loss = 408.39404452\n",
      "Iteration 6385, loss = 408.39034258\n",
      "Iteration 6386, loss = 408.38811200\n",
      "Iteration 6387, loss = 408.38392988\n",
      "Iteration 6388, loss = 408.38983897\n",
      "Iteration 6389, loss = 408.38162554\n",
      "Iteration 6390, loss = 408.37522575\n",
      "Iteration 6391, loss = 408.37268526\n",
      "Iteration 6392, loss = 408.36587970\n",
      "Iteration 6393, loss = 408.37658694\n",
      "Iteration 6394, loss = 408.37325496\n",
      "Iteration 6395, loss = 408.36354545\n",
      "Iteration 6396, loss = 408.36385864\n",
      "Iteration 6397, loss = 408.36266011\n",
      "Iteration 6398, loss = 408.36021265\n",
      "Iteration 6399, loss = 408.34541213\n",
      "Iteration 6400, loss = 408.34111129\n",
      "Iteration 6401, loss = 408.34424830\n",
      "Iteration 6402, loss = 408.34180492\n",
      "Iteration 6403, loss = 408.32969607\n",
      "Iteration 6404, loss = 408.32520005\n",
      "Iteration 6405, loss = 408.32410159\n",
      "Iteration 6406, loss = 408.31576013\n",
      "Iteration 6407, loss = 408.32853908\n",
      "Iteration 6408, loss = 408.32263821\n",
      "Iteration 6409, loss = 408.31386623\n",
      "Iteration 6410, loss = 408.31598729\n",
      "Iteration 6411, loss = 408.31558535\n",
      "Iteration 6412, loss = 408.30685917\n",
      "Iteration 6413, loss = 408.29871598\n",
      "Iteration 6414, loss = 408.29764523\n",
      "Iteration 6415, loss = 408.30067177\n",
      "Iteration 6416, loss = 408.28840626\n",
      "Iteration 6417, loss = 408.28216601\n",
      "Iteration 6418, loss = 408.28417931\n",
      "Iteration 6419, loss = 408.28260968\n",
      "Iteration 6420, loss = 408.28160491\n",
      "Iteration 6421, loss = 408.27921210\n",
      "Iteration 6422, loss = 408.27871578\n",
      "Iteration 6423, loss = 408.27176069\n",
      "Iteration 6424, loss = 408.26529753\n",
      "Iteration 6425, loss = 408.26011746\n",
      "Iteration 6426, loss = 408.25680613\n",
      "Iteration 6427, loss = 408.25181129\n",
      "Iteration 6428, loss = 408.25509891\n",
      "Iteration 6429, loss = 408.25333170\n",
      "Iteration 6430, loss = 408.24481136\n",
      "Iteration 6431, loss = 408.24067173\n",
      "Iteration 6432, loss = 408.23692475\n",
      "Iteration 6433, loss = 408.22795991\n",
      "Iteration 6434, loss = 408.23258368\n",
      "Iteration 6435, loss = 408.23828234\n",
      "Iteration 6436, loss = 408.23108378\n",
      "Iteration 6437, loss = 408.21387943\n",
      "Iteration 6438, loss = 408.21415957\n",
      "Iteration 6439, loss = 408.21953378\n",
      "Iteration 6440, loss = 408.21314429\n",
      "Iteration 6441, loss = 408.21062290\n",
      "Iteration 6442, loss = 408.20937533\n",
      "Iteration 6443, loss = 408.19970579\n",
      "Iteration 6444, loss = 408.18995365\n",
      "Iteration 6445, loss = 408.19540278\n",
      "Iteration 6446, loss = 408.19558265\n",
      "Iteration 6447, loss = 408.19385764\n",
      "Iteration 6448, loss = 408.18674065\n",
      "Iteration 6449, loss = 408.17965271\n",
      "Iteration 6450, loss = 408.18118262\n",
      "Iteration 6451, loss = 408.17313764\n",
      "Iteration 6452, loss = 408.16956580\n",
      "Iteration 6453, loss = 408.17368060\n",
      "Iteration 6454, loss = 408.16193712\n",
      "Iteration 6455, loss = 408.15845565\n",
      "Iteration 6456, loss = 408.16193502\n",
      "Iteration 6457, loss = 408.15633086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6458, loss = 408.15014456\n",
      "Iteration 6459, loss = 408.14746743\n",
      "Iteration 6460, loss = 408.14207316\n",
      "Iteration 6461, loss = 408.14326321\n",
      "Iteration 6462, loss = 408.14658026\n",
      "Iteration 6463, loss = 408.14271902\n",
      "Iteration 6464, loss = 408.13550606\n",
      "Iteration 6465, loss = 408.12948187\n",
      "Iteration 6466, loss = 408.13055070\n",
      "Iteration 6467, loss = 408.13113149\n",
      "Iteration 6468, loss = 408.11869665\n",
      "Iteration 6469, loss = 408.12049575\n",
      "Iteration 6470, loss = 408.11792239\n",
      "Iteration 6471, loss = 408.12030983\n",
      "Iteration 6472, loss = 408.12128909\n",
      "Iteration 6473, loss = 408.11651980\n",
      "Iteration 6474, loss = 408.10946435\n",
      "Iteration 6475, loss = 408.11351417\n",
      "Iteration 6476, loss = 408.11869579\n",
      "Iteration 6477, loss = 408.11107788\n",
      "Iteration 6478, loss = 408.10343738\n",
      "Iteration 6479, loss = 408.09913089\n",
      "Iteration 6480, loss = 408.09296278\n",
      "Iteration 6481, loss = 408.08292108\n",
      "Iteration 6482, loss = 408.07185348\n",
      "Iteration 6483, loss = 408.07158425\n",
      "Iteration 6484, loss = 408.06849525\n",
      "Iteration 6485, loss = 408.07717426\n",
      "Iteration 6486, loss = 408.07291811\n",
      "Iteration 6487, loss = 408.07415788\n",
      "Iteration 6488, loss = 408.06931457\n",
      "Iteration 6489, loss = 408.06978728\n",
      "Iteration 6490, loss = 408.06909735\n",
      "Iteration 6491, loss = 408.07479291\n",
      "Iteration 6492, loss = 408.07007229\n",
      "Iteration 6493, loss = 408.06243941\n",
      "Iteration 6494, loss = 408.05924461\n",
      "Iteration 6495, loss = 408.05338098\n",
      "Iteration 6496, loss = 408.04927002\n",
      "Iteration 6497, loss = 408.04421449\n",
      "Iteration 6498, loss = 408.03412758\n",
      "Iteration 6499, loss = 408.02647121\n",
      "Iteration 6500, loss = 408.02336489\n",
      "Iteration 6501, loss = 408.01267653\n",
      "Iteration 6502, loss = 408.00580958\n",
      "Iteration 6503, loss = 408.00314472\n",
      "Iteration 6504, loss = 408.00564524\n",
      "Iteration 6505, loss = 408.00338564\n",
      "Iteration 6506, loss = 407.99529361\n",
      "Iteration 6507, loss = 407.99311989\n",
      "Iteration 6508, loss = 407.98147910\n",
      "Iteration 6509, loss = 407.98249119\n",
      "Iteration 6510, loss = 407.97654626\n",
      "Iteration 6511, loss = 407.97204386\n",
      "Iteration 6512, loss = 407.97363104\n",
      "Iteration 6513, loss = 407.97091758\n",
      "Iteration 6514, loss = 407.96407413\n",
      "Iteration 6515, loss = 407.96238778\n",
      "Iteration 6516, loss = 407.96124009\n",
      "Iteration 6517, loss = 407.96081119\n",
      "Iteration 6518, loss = 407.95239459\n",
      "Iteration 6519, loss = 407.95155171\n",
      "Iteration 6520, loss = 407.95666032\n",
      "Iteration 6521, loss = 407.95510934\n",
      "Iteration 6522, loss = 407.94615241\n",
      "Iteration 6523, loss = 407.94013436\n",
      "Iteration 6524, loss = 407.93518062\n",
      "Iteration 6525, loss = 407.94067124\n",
      "Iteration 6526, loss = 407.93293015\n",
      "Iteration 6527, loss = 407.92599473\n",
      "Iteration 6528, loss = 407.92495882\n",
      "Iteration 6529, loss = 407.93206318\n",
      "Iteration 6530, loss = 407.92481957\n",
      "Iteration 6531, loss = 407.91295297\n",
      "Iteration 6532, loss = 407.90994929\n",
      "Iteration 6533, loss = 407.91451125\n",
      "Iteration 6534, loss = 407.91167698\n",
      "Iteration 6535, loss = 407.89935671\n",
      "Iteration 6536, loss = 407.88851542\n",
      "Iteration 6537, loss = 407.88877981\n",
      "Iteration 6538, loss = 407.89070348\n",
      "Iteration 6539, loss = 407.89190247\n",
      "Iteration 6540, loss = 407.88723154\n",
      "Iteration 6541, loss = 407.87810057\n",
      "Iteration 6542, loss = 407.87778379\n",
      "Iteration 6543, loss = 407.87441750\n",
      "Iteration 6544, loss = 407.86566826\n",
      "Iteration 6545, loss = 407.87214008\n",
      "Iteration 6546, loss = 407.86194146\n",
      "Iteration 6547, loss = 407.85709685\n",
      "Iteration 6548, loss = 407.85522985\n",
      "Iteration 6549, loss = 407.85903467\n",
      "Iteration 6550, loss = 407.85091005\n",
      "Iteration 6551, loss = 407.85307001\n",
      "Iteration 6552, loss = 407.84838130\n",
      "Iteration 6553, loss = 407.83789842\n",
      "Iteration 6554, loss = 407.83096933\n",
      "Iteration 6555, loss = 407.83203283\n",
      "Iteration 6556, loss = 407.83276243\n",
      "Iteration 6557, loss = 407.83264206\n",
      "Iteration 6558, loss = 407.83242426\n",
      "Iteration 6559, loss = 407.82218557\n",
      "Iteration 6560, loss = 407.82038370\n",
      "Iteration 6561, loss = 407.82097163\n",
      "Iteration 6562, loss = 407.82177880\n",
      "Iteration 6563, loss = 407.81556669\n",
      "Iteration 6564, loss = 407.81550313\n",
      "Iteration 6565, loss = 407.81606527\n",
      "Iteration 6566, loss = 407.80157403\n",
      "Iteration 6567, loss = 407.79476727\n",
      "Iteration 6568, loss = 407.80787599\n",
      "Iteration 6569, loss = 407.80080579\n",
      "Iteration 6570, loss = 407.78438814\n",
      "Iteration 6571, loss = 407.78531069\n",
      "Iteration 6572, loss = 407.78845369\n",
      "Iteration 6573, loss = 407.78791649\n",
      "Iteration 6574, loss = 407.77757526\n",
      "Iteration 6575, loss = 407.78183547\n",
      "Iteration 6576, loss = 407.78120461\n",
      "Iteration 6577, loss = 407.76435905\n",
      "Iteration 6578, loss = 407.74889480\n",
      "Iteration 6579, loss = 407.75907636\n",
      "Iteration 6580, loss = 407.75115616\n",
      "Iteration 6581, loss = 407.74150357\n",
      "Iteration 6582, loss = 407.74924172\n",
      "Iteration 6583, loss = 407.74887726\n",
      "Iteration 6584, loss = 407.72487436\n",
      "Iteration 6585, loss = 407.72686417\n",
      "Iteration 6586, loss = 407.73275597\n",
      "Iteration 6587, loss = 407.73557864\n",
      "Iteration 6588, loss = 407.72968816\n",
      "Iteration 6589, loss = 407.72460728\n",
      "Iteration 6590, loss = 407.71581175\n",
      "Iteration 6591, loss = 407.70626567\n",
      "Iteration 6592, loss = 407.69256173\n",
      "Iteration 6593, loss = 407.69152539\n",
      "Iteration 6594, loss = 407.69219001\n",
      "Iteration 6595, loss = 407.68797790\n",
      "Iteration 6596, loss = 407.68408972\n",
      "Iteration 6597, loss = 407.67075814\n",
      "Iteration 6598, loss = 407.66276373\n",
      "Iteration 6599, loss = 407.66059441\n",
      "Iteration 6600, loss = 407.66217171\n",
      "Iteration 6601, loss = 407.65578246\n",
      "Iteration 6602, loss = 407.64698241\n",
      "Iteration 6603, loss = 407.63654127\n",
      "Iteration 6604, loss = 407.64870244\n",
      "Iteration 6605, loss = 407.63966461\n",
      "Iteration 6606, loss = 407.63098819\n",
      "Iteration 6607, loss = 407.64277700\n",
      "Iteration 6608, loss = 407.63966153\n",
      "Iteration 6609, loss = 407.63343340\n",
      "Iteration 6610, loss = 407.62780710\n",
      "Iteration 6611, loss = 407.61909071\n",
      "Iteration 6612, loss = 407.61003235\n",
      "Iteration 6613, loss = 407.59883794\n",
      "Iteration 6614, loss = 407.60979623\n",
      "Iteration 6615, loss = 407.62161891\n",
      "Iteration 6616, loss = 407.61122913\n",
      "Iteration 6617, loss = 407.59537396\n",
      "Iteration 6618, loss = 407.59926551\n",
      "Iteration 6619, loss = 407.59982297\n",
      "Iteration 6620, loss = 407.59248052\n",
      "Iteration 6621, loss = 407.58106249\n",
      "Iteration 6622, loss = 407.57355818\n",
      "Iteration 6623, loss = 407.57646546\n",
      "Iteration 6624, loss = 407.56415332\n",
      "Iteration 6625, loss = 407.54966656\n",
      "Iteration 6626, loss = 407.54473376\n",
      "Iteration 6627, loss = 407.54431129\n",
      "Iteration 6628, loss = 407.54764741\n",
      "Iteration 6629, loss = 407.55765204\n",
      "Iteration 6630, loss = 407.54792855\n",
      "Iteration 6631, loss = 407.53087221\n",
      "Iteration 6632, loss = 407.52797229\n",
      "Iteration 6633, loss = 407.52989803\n",
      "Iteration 6634, loss = 407.51917946\n",
      "Iteration 6635, loss = 407.52020501\n",
      "Iteration 6636, loss = 407.51059345\n",
      "Iteration 6637, loss = 407.50122867\n",
      "Iteration 6638, loss = 407.50617236\n",
      "Iteration 6639, loss = 407.50106892\n",
      "Iteration 6640, loss = 407.49933969\n",
      "Iteration 6641, loss = 407.49438747\n",
      "Iteration 6642, loss = 407.48069594\n",
      "Iteration 6643, loss = 407.47216369\n",
      "Iteration 6644, loss = 407.47103753\n",
      "Iteration 6645, loss = 407.46902362\n",
      "Iteration 6646, loss = 407.45812851\n",
      "Iteration 6647, loss = 407.45585596\n",
      "Iteration 6648, loss = 407.45037366\n",
      "Iteration 6649, loss = 407.44896000\n",
      "Iteration 6650, loss = 407.43902361\n",
      "Iteration 6651, loss = 407.44277835\n",
      "Iteration 6652, loss = 407.44440383\n",
      "Iteration 6653, loss = 407.43625662\n",
      "Iteration 6654, loss = 407.42827503\n",
      "Iteration 6655, loss = 407.41920383\n",
      "Iteration 6656, loss = 407.41465146\n",
      "Iteration 6657, loss = 407.41830594\n",
      "Iteration 6658, loss = 407.40573479\n",
      "Iteration 6659, loss = 407.40648283\n",
      "Iteration 6660, loss = 407.41095614\n",
      "Iteration 6661, loss = 407.40168786\n",
      "Iteration 6662, loss = 407.39963830\n",
      "Iteration 6663, loss = 407.40130195\n",
      "Iteration 6664, loss = 407.39052989\n",
      "Iteration 6665, loss = 407.38427539\n",
      "Iteration 6666, loss = 407.38699812\n",
      "Iteration 6667, loss = 407.38417931\n",
      "Iteration 6668, loss = 407.38291211\n",
      "Iteration 6669, loss = 407.38631142\n",
      "Iteration 6670, loss = 407.37444998\n",
      "Iteration 6671, loss = 407.36355347\n",
      "Iteration 6672, loss = 407.36028353\n",
      "Iteration 6673, loss = 407.35948034\n",
      "Iteration 6674, loss = 407.35223078\n",
      "Iteration 6675, loss = 407.35767701\n",
      "Iteration 6676, loss = 407.35914478\n",
      "Iteration 6677, loss = 407.35677452\n",
      "Iteration 6678, loss = 407.34547181\n",
      "Iteration 6679, loss = 407.33808821\n",
      "Iteration 6680, loss = 407.33631105\n",
      "Iteration 6681, loss = 407.31615313\n",
      "Iteration 6682, loss = 407.31452408\n",
      "Iteration 6683, loss = 407.30954362\n",
      "Iteration 6684, loss = 407.30381150\n",
      "Iteration 6685, loss = 407.30207059\n",
      "Iteration 6686, loss = 407.29770586\n",
      "Iteration 6687, loss = 407.29329014\n",
      "Iteration 6688, loss = 407.30271871\n",
      "Iteration 6689, loss = 407.30287200\n",
      "Iteration 6690, loss = 407.29971061\n",
      "Iteration 6691, loss = 407.28679509\n",
      "Iteration 6692, loss = 407.28207422\n",
      "Iteration 6693, loss = 407.27655864\n",
      "Iteration 6694, loss = 407.27145442\n",
      "Iteration 6695, loss = 407.27020929\n",
      "Iteration 6696, loss = 407.26270274\n",
      "Iteration 6697, loss = 407.25881180\n",
      "Iteration 6698, loss = 407.25416214\n",
      "Iteration 6699, loss = 407.25497685\n",
      "Iteration 6700, loss = 407.24758543\n",
      "Iteration 6701, loss = 407.24481881\n",
      "Iteration 6702, loss = 407.24520582\n",
      "Iteration 6703, loss = 407.24157373\n",
      "Iteration 6704, loss = 407.23767289\n",
      "Iteration 6705, loss = 407.22977832\n",
      "Iteration 6706, loss = 407.21748706\n",
      "Iteration 6707, loss = 407.22148544\n",
      "Iteration 6708, loss = 407.21918494\n",
      "Iteration 6709, loss = 407.21035547\n",
      "Iteration 6710, loss = 407.21139819\n",
      "Iteration 6711, loss = 407.21202555\n",
      "Iteration 6712, loss = 407.20643831\n",
      "Iteration 6713, loss = 407.20123604\n",
      "Iteration 6714, loss = 407.19288598\n",
      "Iteration 6715, loss = 407.19349847\n",
      "Iteration 6716, loss = 407.18161844\n",
      "Iteration 6717, loss = 407.16971581\n",
      "Iteration 6718, loss = 407.17385916\n",
      "Iteration 6719, loss = 407.18959784\n",
      "Iteration 6720, loss = 407.18297057\n",
      "Iteration 6721, loss = 407.16654472\n",
      "Iteration 6722, loss = 407.16397086\n",
      "Iteration 6723, loss = 407.16056367\n",
      "Iteration 6724, loss = 407.15620806\n",
      "Iteration 6725, loss = 407.15201293\n",
      "Iteration 6726, loss = 407.14265665\n",
      "Iteration 6727, loss = 407.14788876\n",
      "Iteration 6728, loss = 407.14531706\n",
      "Iteration 6729, loss = 407.14463478\n",
      "Iteration 6730, loss = 407.14580557\n",
      "Iteration 6731, loss = 407.15029519\n",
      "Iteration 6732, loss = 407.14577734\n",
      "Iteration 6733, loss = 407.14259193\n",
      "Iteration 6734, loss = 407.12898848\n",
      "Iteration 6735, loss = 407.12302411\n",
      "Iteration 6736, loss = 407.11241612\n",
      "Iteration 6737, loss = 407.11085388\n",
      "Iteration 6738, loss = 407.10537390\n",
      "Iteration 6739, loss = 407.09224272\n",
      "Iteration 6740, loss = 407.08138433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6741, loss = 407.08024867\n",
      "Iteration 6742, loss = 407.07803718\n",
      "Iteration 6743, loss = 407.07149072\n",
      "Iteration 6744, loss = 407.07551422\n",
      "Iteration 6745, loss = 407.06267562\n",
      "Iteration 6746, loss = 407.05940899\n",
      "Iteration 6747, loss = 407.05507395\n",
      "Iteration 6748, loss = 407.04577396\n",
      "Iteration 6749, loss = 407.06224080\n",
      "Iteration 6750, loss = 407.05772617\n",
      "Iteration 6751, loss = 407.05068086\n",
      "Iteration 6752, loss = 407.04616817\n",
      "Iteration 6753, loss = 407.04777784\n",
      "Iteration 6754, loss = 407.04024176\n",
      "Iteration 6755, loss = 407.02787073\n",
      "Iteration 6756, loss = 407.01751544\n",
      "Iteration 6757, loss = 407.03255793\n",
      "Iteration 6758, loss = 407.02388588\n",
      "Iteration 6759, loss = 407.01386081\n",
      "Iteration 6760, loss = 406.99934381\n",
      "Iteration 6761, loss = 407.00071015\n",
      "Iteration 6762, loss = 406.99900354\n",
      "Iteration 6763, loss = 407.00259122\n",
      "Iteration 6764, loss = 406.99335287\n",
      "Iteration 6765, loss = 406.99257620\n",
      "Iteration 6766, loss = 406.98885554\n",
      "Iteration 6767, loss = 406.98147194\n",
      "Iteration 6768, loss = 406.96696296\n",
      "Iteration 6769, loss = 406.97097046\n",
      "Iteration 6770, loss = 406.96543366\n",
      "Iteration 6771, loss = 406.96452088\n",
      "Iteration 6772, loss = 406.96423441\n",
      "Iteration 6773, loss = 406.96391262\n",
      "Iteration 6774, loss = 406.96096638\n",
      "Iteration 6775, loss = 406.96256668\n",
      "Iteration 6776, loss = 406.96497217\n",
      "Iteration 6777, loss = 406.95869890\n",
      "Iteration 6778, loss = 406.95863631\n",
      "Iteration 6779, loss = 406.95093612\n",
      "Iteration 6780, loss = 406.95075361\n",
      "Iteration 6781, loss = 406.95057519\n",
      "Iteration 6782, loss = 406.94374760\n",
      "Iteration 6783, loss = 406.94400094\n",
      "Iteration 6784, loss = 406.93840331\n",
      "Iteration 6785, loss = 406.93063137\n",
      "Iteration 6786, loss = 406.93705241\n",
      "Iteration 6787, loss = 406.92981544\n",
      "Iteration 6788, loss = 406.92680500\n",
      "Iteration 6789, loss = 406.91366332\n",
      "Iteration 6790, loss = 406.89334776\n",
      "Iteration 6791, loss = 406.87746776\n",
      "Iteration 6792, loss = 406.87715647\n",
      "Iteration 6793, loss = 406.88494210\n",
      "Iteration 6794, loss = 406.88470601\n",
      "Iteration 6795, loss = 406.87337237\n",
      "Iteration 6796, loss = 406.86883563\n",
      "Iteration 6797, loss = 406.87659685\n",
      "Iteration 6798, loss = 406.87193387\n",
      "Iteration 6799, loss = 406.85566075\n",
      "Iteration 6800, loss = 406.84902242\n",
      "Iteration 6801, loss = 406.84497764\n",
      "Iteration 6802, loss = 406.83174229\n",
      "Iteration 6803, loss = 406.83764466\n",
      "Iteration 6804, loss = 406.84203727\n",
      "Iteration 6805, loss = 406.82901982\n",
      "Iteration 6806, loss = 406.83564994\n",
      "Iteration 6807, loss = 406.83250673\n",
      "Iteration 6808, loss = 406.82485299\n",
      "Iteration 6809, loss = 406.81151976\n",
      "Iteration 6810, loss = 406.80509777\n",
      "Iteration 6811, loss = 406.80728927\n",
      "Iteration 6812, loss = 406.80528255\n",
      "Iteration 6813, loss = 406.79711265\n",
      "Iteration 6814, loss = 406.79682498\n",
      "Iteration 6815, loss = 406.79788580\n",
      "Iteration 6816, loss = 406.79550179\n",
      "Iteration 6817, loss = 406.78634599\n",
      "Iteration 6818, loss = 406.78735620\n",
      "Iteration 6819, loss = 406.78511271\n",
      "Iteration 6820, loss = 406.76476390\n",
      "Iteration 6821, loss = 406.76071490\n",
      "Iteration 6822, loss = 406.76840439\n",
      "Iteration 6823, loss = 406.76395073\n",
      "Iteration 6824, loss = 406.74693450\n",
      "Iteration 6825, loss = 406.74701481\n",
      "Iteration 6826, loss = 406.75744154\n",
      "Iteration 6827, loss = 406.74721256\n",
      "Iteration 6828, loss = 406.73516733\n",
      "Iteration 6829, loss = 406.74067650\n",
      "Iteration 6830, loss = 406.73665595\n",
      "Iteration 6831, loss = 406.72734322\n",
      "Iteration 6832, loss = 406.72409202\n",
      "Iteration 6833, loss = 406.71927754\n",
      "Iteration 6834, loss = 406.71865214\n",
      "Iteration 6835, loss = 406.71350801\n",
      "Iteration 6836, loss = 406.70994914\n",
      "Iteration 6837, loss = 406.70509267\n",
      "Iteration 6838, loss = 406.70155307\n",
      "Iteration 6839, loss = 406.70042813\n",
      "Iteration 6840, loss = 406.70340360\n",
      "Iteration 6841, loss = 406.69495891\n",
      "Iteration 6842, loss = 406.69361398\n",
      "Iteration 6843, loss = 406.69853892\n",
      "Iteration 6844, loss = 406.69575784\n",
      "Iteration 6845, loss = 406.68125237\n",
      "Iteration 6846, loss = 406.67752605\n",
      "Iteration 6847, loss = 406.67184191\n",
      "Iteration 6848, loss = 406.66369100\n",
      "Iteration 6849, loss = 406.66919257\n",
      "Iteration 6850, loss = 406.64856289\n",
      "Iteration 6851, loss = 406.64321320\n",
      "Iteration 6852, loss = 406.64550349\n",
      "Iteration 6853, loss = 406.63990519\n",
      "Iteration 6854, loss = 406.63889620\n",
      "Iteration 6855, loss = 406.63376047\n",
      "Iteration 6856, loss = 406.63429243\n",
      "Iteration 6857, loss = 406.63178294\n",
      "Iteration 6858, loss = 406.61428375\n",
      "Iteration 6859, loss = 406.61639885\n",
      "Iteration 6860, loss = 406.62027531\n",
      "Iteration 6861, loss = 406.61637753\n",
      "Iteration 6862, loss = 406.59753182\n",
      "Iteration 6863, loss = 406.59082109\n",
      "Iteration 6864, loss = 406.59657721\n",
      "Iteration 6865, loss = 406.59635224\n",
      "Iteration 6866, loss = 406.59278443\n",
      "Iteration 6867, loss = 406.59355502\n",
      "Iteration 6868, loss = 406.59428187\n",
      "Iteration 6869, loss = 406.58278908\n",
      "Iteration 6870, loss = 406.57440725\n",
      "Iteration 6871, loss = 406.56623310\n",
      "Iteration 6872, loss = 406.57228800\n",
      "Iteration 6873, loss = 406.57173481\n",
      "Iteration 6874, loss = 406.55805398\n",
      "Iteration 6875, loss = 406.55453394\n",
      "Iteration 6876, loss = 406.54857448\n",
      "Iteration 6877, loss = 406.54057012\n",
      "Iteration 6878, loss = 406.54371336\n",
      "Iteration 6879, loss = 406.53514978\n",
      "Iteration 6880, loss = 406.52306242\n",
      "Iteration 6881, loss = 406.51203872\n",
      "Iteration 6882, loss = 406.52621901\n",
      "Iteration 6883, loss = 406.50982315\n",
      "Iteration 6884, loss = 406.50764075\n",
      "Iteration 6885, loss = 406.50693533\n",
      "Iteration 6886, loss = 406.49949395\n",
      "Iteration 6887, loss = 406.49945238\n",
      "Iteration 6888, loss = 406.49874185\n",
      "Iteration 6889, loss = 406.49413659\n",
      "Iteration 6890, loss = 406.49243029\n",
      "Iteration 6891, loss = 406.49453580\n",
      "Iteration 6892, loss = 406.48203504\n",
      "Iteration 6893, loss = 406.47618965\n",
      "Iteration 6894, loss = 406.47108089\n",
      "Iteration 6895, loss = 406.47828549\n",
      "Iteration 6896, loss = 406.46883699\n",
      "Iteration 6897, loss = 406.45894841\n",
      "Iteration 6898, loss = 406.46066186\n",
      "Iteration 6899, loss = 406.45199400\n",
      "Iteration 6900, loss = 406.44597804\n",
      "Iteration 6901, loss = 406.44463705\n",
      "Iteration 6902, loss = 406.44953292\n",
      "Iteration 6903, loss = 406.44680062\n",
      "Iteration 6904, loss = 406.44033536\n",
      "Iteration 6905, loss = 406.44019824\n",
      "Iteration 6906, loss = 406.43532016\n",
      "Iteration 6907, loss = 406.43501893\n",
      "Iteration 6908, loss = 406.43397467\n",
      "Iteration 6909, loss = 406.43017528\n",
      "Iteration 6910, loss = 406.43016032\n",
      "Iteration 6911, loss = 406.41999099\n",
      "Iteration 6912, loss = 406.40999733\n",
      "Iteration 6913, loss = 406.40790944\n",
      "Iteration 6914, loss = 406.40512924\n",
      "Iteration 6915, loss = 406.39446976\n",
      "Iteration 6916, loss = 406.38364882\n",
      "Iteration 6917, loss = 406.38531687\n",
      "Iteration 6918, loss = 406.38197085\n",
      "Iteration 6919, loss = 406.37460576\n",
      "Iteration 6920, loss = 406.37034864\n",
      "Iteration 6921, loss = 406.36834895\n",
      "Iteration 6922, loss = 406.35425389\n",
      "Iteration 6923, loss = 406.36137437\n",
      "Iteration 6924, loss = 406.36116721\n",
      "Iteration 6925, loss = 406.35288277\n",
      "Iteration 6926, loss = 406.35372282\n",
      "Iteration 6927, loss = 406.35513089\n",
      "Iteration 6928, loss = 406.35247609\n",
      "Iteration 6929, loss = 406.35132835\n",
      "Iteration 6930, loss = 406.35891053\n",
      "Iteration 6931, loss = 406.34251309\n",
      "Iteration 6932, loss = 406.32457555\n",
      "Iteration 6933, loss = 406.31812369\n",
      "Iteration 6934, loss = 406.32875575\n",
      "Iteration 6935, loss = 406.32408192\n",
      "Iteration 6936, loss = 406.30576159\n",
      "Iteration 6937, loss = 406.31233191\n",
      "Iteration 6938, loss = 406.31257330\n",
      "Iteration 6939, loss = 406.30112319\n",
      "Iteration 6940, loss = 406.29162133\n",
      "Iteration 6941, loss = 406.29118798\n",
      "Iteration 6942, loss = 406.28647848\n",
      "Iteration 6943, loss = 406.27300732\n",
      "Iteration 6944, loss = 406.28262398\n",
      "Iteration 6945, loss = 406.27703827\n",
      "Iteration 6946, loss = 406.27217055\n",
      "Iteration 6947, loss = 406.26269509\n",
      "Iteration 6948, loss = 406.25990392\n",
      "Iteration 6949, loss = 406.26106881\n",
      "Iteration 6950, loss = 406.25956846\n",
      "Iteration 6951, loss = 406.25843675\n",
      "Iteration 6952, loss = 406.24799697\n",
      "Iteration 6953, loss = 406.23567484\n",
      "Iteration 6954, loss = 406.24187921\n",
      "Iteration 6955, loss = 406.23838153\n",
      "Iteration 6956, loss = 406.22545901\n",
      "Iteration 6957, loss = 406.22834012\n",
      "Iteration 6958, loss = 406.22734215\n",
      "Iteration 6959, loss = 406.22369908\n",
      "Iteration 6960, loss = 406.21842246\n",
      "Iteration 6961, loss = 406.21081688\n",
      "Iteration 6962, loss = 406.21687443\n",
      "Iteration 6963, loss = 406.20941460\n",
      "Iteration 6964, loss = 406.19897102\n",
      "Iteration 6965, loss = 406.20170086\n",
      "Iteration 6966, loss = 406.19426163\n",
      "Iteration 6967, loss = 406.18798355\n",
      "Iteration 6968, loss = 406.18798709\n",
      "Iteration 6969, loss = 406.18563410\n",
      "Iteration 6970, loss = 406.18251110\n",
      "Iteration 6971, loss = 406.17550821\n",
      "Iteration 6972, loss = 406.17155515\n",
      "Iteration 6973, loss = 406.16708691\n",
      "Iteration 6974, loss = 406.16507327\n",
      "Iteration 6975, loss = 406.16400924\n",
      "Iteration 6976, loss = 406.16286354\n",
      "Iteration 6977, loss = 406.15611867\n",
      "Iteration 6978, loss = 406.14632228\n",
      "Iteration 6979, loss = 406.14526652\n",
      "Iteration 6980, loss = 406.15779626\n",
      "Iteration 6981, loss = 406.14380057\n",
      "Iteration 6982, loss = 406.13984979\n",
      "Iteration 6983, loss = 406.14302764\n",
      "Iteration 6984, loss = 406.14755065\n",
      "Iteration 6985, loss = 406.14546011\n",
      "Iteration 6986, loss = 406.11689499\n",
      "Iteration 6987, loss = 406.11544522\n",
      "Iteration 6988, loss = 406.11075610\n",
      "Iteration 6989, loss = 406.09994675\n",
      "Iteration 6990, loss = 406.09921179\n",
      "Iteration 6991, loss = 406.09346417\n",
      "Iteration 6992, loss = 406.09556759\n",
      "Iteration 6993, loss = 406.08838832\n",
      "Iteration 6994, loss = 406.08793204\n",
      "Iteration 6995, loss = 406.08466140\n",
      "Iteration 6996, loss = 406.08913526\n",
      "Iteration 6997, loss = 406.09491384\n",
      "Iteration 6998, loss = 406.10136734\n",
      "Iteration 6999, loss = 406.10760551\n",
      "Iteration 7000, loss = 406.08960581\n",
      "Iteration 7001, loss = 406.07636013\n",
      "Iteration 7002, loss = 406.07563743\n",
      "Iteration 7003, loss = 406.05709386\n",
      "Iteration 7004, loss = 406.05032415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7005, loss = 406.05028027\n",
      "Iteration 7006, loss = 406.05038793\n",
      "Iteration 7007, loss = 406.04311442\n",
      "Iteration 7008, loss = 406.04093865\n",
      "Iteration 7009, loss = 406.03810874\n",
      "Iteration 7010, loss = 406.03890136\n",
      "Iteration 7011, loss = 406.04269991\n",
      "Iteration 7012, loss = 406.02751365\n",
      "Iteration 7013, loss = 406.01872062\n",
      "Iteration 7014, loss = 406.01582221\n",
      "Iteration 7015, loss = 406.03049700\n",
      "Iteration 7016, loss = 406.02698877\n",
      "Iteration 7017, loss = 405.99853466\n",
      "Iteration 7018, loss = 406.00133529\n",
      "Iteration 7019, loss = 405.99923689\n",
      "Iteration 7020, loss = 405.97892199\n",
      "Iteration 7021, loss = 405.97082432\n",
      "Iteration 7022, loss = 405.98054452\n",
      "Iteration 7023, loss = 405.98436076\n",
      "Iteration 7024, loss = 405.97416374\n",
      "Iteration 7025, loss = 405.96181981\n",
      "Iteration 7026, loss = 405.96098081\n",
      "Iteration 7027, loss = 405.96094046\n",
      "Iteration 7028, loss = 405.95211246\n",
      "Iteration 7029, loss = 405.94600139\n",
      "Iteration 7030, loss = 405.94019123\n",
      "Iteration 7031, loss = 405.93465198\n",
      "Iteration 7032, loss = 405.94211073\n",
      "Iteration 7033, loss = 405.93414755\n",
      "Iteration 7034, loss = 405.91824341\n",
      "Iteration 7035, loss = 405.92041159\n",
      "Iteration 7036, loss = 405.91357578\n",
      "Iteration 7037, loss = 405.91629476\n",
      "Iteration 7038, loss = 405.90689170\n",
      "Iteration 7039, loss = 405.90079041\n",
      "Iteration 7040, loss = 405.89851055\n",
      "Iteration 7041, loss = 405.89645978\n",
      "Iteration 7042, loss = 405.89370385\n",
      "Iteration 7043, loss = 405.88106538\n",
      "Iteration 7044, loss = 405.88578366\n",
      "Iteration 7045, loss = 405.87989954\n",
      "Iteration 7046, loss = 405.86909365\n",
      "Iteration 7047, loss = 405.87503451\n",
      "Iteration 7048, loss = 405.87096724\n",
      "Iteration 7049, loss = 405.85910176\n",
      "Iteration 7050, loss = 405.86667435\n",
      "Iteration 7051, loss = 405.86757460\n",
      "Iteration 7052, loss = 405.86483673\n",
      "Iteration 7053, loss = 405.85381719\n",
      "Iteration 7054, loss = 405.85084810\n",
      "Iteration 7055, loss = 405.85449855\n",
      "Iteration 7056, loss = 405.85478978\n",
      "Iteration 7057, loss = 405.84074016\n",
      "Iteration 7058, loss = 405.82502747\n",
      "Iteration 7059, loss = 405.83876445\n",
      "Iteration 7060, loss = 405.83648271\n",
      "Iteration 7061, loss = 405.82617105\n",
      "Iteration 7062, loss = 405.81231868\n",
      "Iteration 7063, loss = 405.81074586\n",
      "Iteration 7064, loss = 405.81313242\n",
      "Iteration 7065, loss = 405.80963164\n",
      "Iteration 7066, loss = 405.80796045\n",
      "Iteration 7067, loss = 405.79768618\n",
      "Iteration 7068, loss = 405.79445425\n",
      "Iteration 7069, loss = 405.79356471\n",
      "Iteration 7070, loss = 405.79338173\n",
      "Iteration 7071, loss = 405.78167431\n",
      "Iteration 7072, loss = 405.78207699\n",
      "Iteration 7073, loss = 405.77582823\n",
      "Iteration 7074, loss = 405.77477318\n",
      "Iteration 7075, loss = 405.77639096\n",
      "Iteration 7076, loss = 405.77243485\n",
      "Iteration 7077, loss = 405.75981196\n",
      "Iteration 7078, loss = 405.74997306\n",
      "Iteration 7079, loss = 405.74268740\n",
      "Iteration 7080, loss = 405.74599061\n",
      "Iteration 7081, loss = 405.74886832\n",
      "Iteration 7082, loss = 405.73739090\n",
      "Iteration 7083, loss = 405.73562084\n",
      "Iteration 7084, loss = 405.73652921\n",
      "Iteration 7085, loss = 405.73341059\n",
      "Iteration 7086, loss = 405.72463841\n",
      "Iteration 7087, loss = 405.71949477\n",
      "Iteration 7088, loss = 405.72208232\n",
      "Iteration 7089, loss = 405.71930436\n",
      "Iteration 7090, loss = 405.69834143\n",
      "Iteration 7091, loss = 405.70389623\n",
      "Iteration 7092, loss = 405.70636765\n",
      "Iteration 7093, loss = 405.69939322\n",
      "Iteration 7094, loss = 405.69762092\n",
      "Iteration 7095, loss = 405.69246407\n",
      "Iteration 7096, loss = 405.70359404\n",
      "Iteration 7097, loss = 405.68422095\n",
      "Iteration 7098, loss = 405.68429728\n",
      "Iteration 7099, loss = 405.68306084\n",
      "Iteration 7100, loss = 405.67947099\n",
      "Iteration 7101, loss = 405.69355394\n",
      "Iteration 7102, loss = 405.69215575\n",
      "Iteration 7103, loss = 405.68612450\n",
      "Iteration 7104, loss = 405.67971460\n",
      "Iteration 7105, loss = 405.68884034\n",
      "Iteration 7106, loss = 405.69512934\n",
      "Iteration 7107, loss = 405.69746853\n",
      "Iteration 7108, loss = 405.68775303\n",
      "Iteration 7109, loss = 405.66918305\n",
      "Iteration 7110, loss = 405.64530582\n",
      "Iteration 7111, loss = 405.63465874\n",
      "Iteration 7112, loss = 405.64427215\n",
      "Iteration 7113, loss = 405.62219258\n",
      "Iteration 7114, loss = 405.61934979\n",
      "Iteration 7115, loss = 405.61722564\n",
      "Iteration 7116, loss = 405.61805648\n",
      "Iteration 7117, loss = 405.60461071\n",
      "Iteration 7118, loss = 405.61168684\n",
      "Iteration 7119, loss = 405.60954198\n",
      "Iteration 7120, loss = 405.59792441\n",
      "Iteration 7121, loss = 405.58585061\n",
      "Iteration 7122, loss = 405.58398228\n",
      "Iteration 7123, loss = 405.58493752\n",
      "Iteration 7124, loss = 405.57913250\n",
      "Iteration 7125, loss = 405.57599674\n",
      "Iteration 7126, loss = 405.57294531\n",
      "Iteration 7127, loss = 405.56831812\n",
      "Iteration 7128, loss = 405.56185078\n",
      "Iteration 7129, loss = 405.56175055\n",
      "Iteration 7130, loss = 405.55449212\n",
      "Iteration 7131, loss = 405.55187345\n",
      "Iteration 7132, loss = 405.55584639\n",
      "Iteration 7133, loss = 405.54693728\n",
      "Iteration 7134, loss = 405.54446511\n",
      "Iteration 7135, loss = 405.53210069\n",
      "Iteration 7136, loss = 405.52457203\n",
      "Iteration 7137, loss = 405.52262460\n",
      "Iteration 7138, loss = 405.53627314\n",
      "Iteration 7139, loss = 405.52515613\n",
      "Iteration 7140, loss = 405.51157912\n",
      "Iteration 7141, loss = 405.51775678\n",
      "Iteration 7142, loss = 405.50898998\n",
      "Iteration 7143, loss = 405.52722938\n",
      "Iteration 7144, loss = 405.52254088\n",
      "Iteration 7145, loss = 405.49984823\n",
      "Iteration 7146, loss = 405.50410296\n",
      "Iteration 7147, loss = 405.49571950\n",
      "Iteration 7148, loss = 405.48950659\n",
      "Iteration 7149, loss = 405.47448391\n",
      "Iteration 7150, loss = 405.48147120\n",
      "Iteration 7151, loss = 405.49251256\n",
      "Iteration 7152, loss = 405.48191695\n",
      "Iteration 7153, loss = 405.47060057\n",
      "Iteration 7154, loss = 405.46741674\n",
      "Iteration 7155, loss = 405.47190304\n",
      "Iteration 7156, loss = 405.46433540\n",
      "Iteration 7157, loss = 405.46658563\n",
      "Iteration 7158, loss = 405.46716333\n",
      "Iteration 7159, loss = 405.45110453\n",
      "Iteration 7160, loss = 405.44489932\n",
      "Iteration 7161, loss = 405.43733502\n",
      "Iteration 7162, loss = 405.42725240\n",
      "Iteration 7163, loss = 405.43610352\n",
      "Iteration 7164, loss = 405.42968423\n",
      "Iteration 7165, loss = 405.41503974\n",
      "Iteration 7166, loss = 405.42483829\n",
      "Iteration 7167, loss = 405.43647239\n",
      "Iteration 7168, loss = 405.42220028\n",
      "Iteration 7169, loss = 405.41678413\n",
      "Iteration 7170, loss = 405.41978080\n",
      "Iteration 7171, loss = 405.42100536\n",
      "Iteration 7172, loss = 405.41611535\n",
      "Iteration 7173, loss = 405.39971025\n",
      "Iteration 7174, loss = 405.39543106\n",
      "Iteration 7175, loss = 405.39958018\n",
      "Iteration 7176, loss = 405.38722012\n",
      "Iteration 7177, loss = 405.38376174\n",
      "Iteration 7178, loss = 405.38397774\n",
      "Iteration 7179, loss = 405.37411538\n",
      "Iteration 7180, loss = 405.38034840\n",
      "Iteration 7181, loss = 405.38193373\n",
      "Iteration 7182, loss = 405.37122106\n",
      "Iteration 7183, loss = 405.36703489\n",
      "Iteration 7184, loss = 405.35689651\n",
      "Iteration 7185, loss = 405.35826881\n",
      "Iteration 7186, loss = 405.35843934\n",
      "Iteration 7187, loss = 405.34192542\n",
      "Iteration 7188, loss = 405.35892631\n",
      "Iteration 7189, loss = 405.35833511\n",
      "Iteration 7190, loss = 405.34870609\n",
      "Iteration 7191, loss = 405.34209100\n",
      "Iteration 7192, loss = 405.34791162\n",
      "Iteration 7193, loss = 405.34241485\n",
      "Iteration 7194, loss = 405.33462059\n",
      "Iteration 7195, loss = 405.32766101\n",
      "Iteration 7196, loss = 405.34070856\n",
      "Iteration 7197, loss = 405.34251504\n",
      "Iteration 7198, loss = 405.33084655\n",
      "Iteration 7199, loss = 405.31964176\n",
      "Iteration 7200, loss = 405.31986178\n",
      "Iteration 7201, loss = 405.31818505\n",
      "Iteration 7202, loss = 405.30092629\n",
      "Iteration 7203, loss = 405.30109653\n",
      "Iteration 7204, loss = 405.30460062\n",
      "Iteration 7205, loss = 405.29967607\n",
      "Iteration 7206, loss = 405.28952247\n",
      "Iteration 7207, loss = 405.29436364\n",
      "Iteration 7208, loss = 405.29098734\n",
      "Iteration 7209, loss = 405.27230789\n",
      "Iteration 7210, loss = 405.27259888\n",
      "Iteration 7211, loss = 405.26579759\n",
      "Iteration 7212, loss = 405.26419748\n",
      "Iteration 7213, loss = 405.25730493\n",
      "Iteration 7214, loss = 405.24149605\n",
      "Iteration 7215, loss = 405.24390585\n",
      "Iteration 7216, loss = 405.25202602\n",
      "Iteration 7217, loss = 405.24916629\n",
      "Iteration 7218, loss = 405.23386996\n",
      "Iteration 7219, loss = 405.22972492\n",
      "Iteration 7220, loss = 405.24033457\n",
      "Iteration 7221, loss = 405.23577852\n",
      "Iteration 7222, loss = 405.23335764\n",
      "Iteration 7223, loss = 405.22833215\n",
      "Iteration 7224, loss = 405.22803832\n",
      "Iteration 7225, loss = 405.22664979\n",
      "Iteration 7226, loss = 405.20261277\n",
      "Iteration 7227, loss = 405.19203566\n",
      "Iteration 7228, loss = 405.20841521\n",
      "Iteration 7229, loss = 405.20437732\n",
      "Iteration 7230, loss = 405.20314625\n",
      "Iteration 7231, loss = 405.20201304\n",
      "Iteration 7232, loss = 405.19455844\n",
      "Iteration 7233, loss = 405.18679688\n",
      "Iteration 7234, loss = 405.20301591\n",
      "Iteration 7235, loss = 405.19628798\n",
      "Iteration 7236, loss = 405.18358470\n",
      "Iteration 7237, loss = 405.16701429\n",
      "Iteration 7238, loss = 405.15512743\n",
      "Iteration 7239, loss = 405.16078893\n",
      "Iteration 7240, loss = 405.16180516\n",
      "Iteration 7241, loss = 405.15146910\n",
      "Iteration 7242, loss = 405.15059800\n",
      "Iteration 7243, loss = 405.14338013\n",
      "Iteration 7244, loss = 405.13237685\n",
      "Iteration 7245, loss = 405.12850713\n",
      "Iteration 7246, loss = 405.12829488\n",
      "Iteration 7247, loss = 405.13698620\n",
      "Iteration 7248, loss = 405.13007640\n",
      "Iteration 7249, loss = 405.11434051\n",
      "Iteration 7250, loss = 405.11701431\n",
      "Iteration 7251, loss = 405.11446276\n",
      "Iteration 7252, loss = 405.10249055\n",
      "Iteration 7253, loss = 405.10202284\n",
      "Iteration 7254, loss = 405.09988938\n",
      "Iteration 7255, loss = 405.09364795\n",
      "Iteration 7256, loss = 405.08782241\n",
      "Iteration 7257, loss = 405.10085841\n",
      "Iteration 7258, loss = 405.10029517\n",
      "Iteration 7259, loss = 405.08572738\n",
      "Iteration 7260, loss = 405.08052913\n",
      "Iteration 7261, loss = 405.07002998\n",
      "Iteration 7262, loss = 405.07647835\n",
      "Iteration 7263, loss = 405.07494928\n",
      "Iteration 7264, loss = 405.06500434\n",
      "Iteration 7265, loss = 405.06307222\n",
      "Iteration 7266, loss = 405.04693175\n",
      "Iteration 7267, loss = 405.05614394\n",
      "Iteration 7268, loss = 405.06033722\n",
      "Iteration 7269, loss = 405.05374350\n",
      "Iteration 7270, loss = 405.05673801\n",
      "Iteration 7271, loss = 405.04528163\n",
      "Iteration 7272, loss = 405.04254665\n",
      "Iteration 7273, loss = 405.03898933\n",
      "Iteration 7274, loss = 405.02480687\n",
      "Iteration 7275, loss = 405.02836637\n",
      "Iteration 7276, loss = 405.02781440\n",
      "Iteration 7277, loss = 405.02617559\n",
      "Iteration 7278, loss = 405.03266107\n",
      "Iteration 7279, loss = 405.02891006\n",
      "Iteration 7280, loss = 405.02313937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7281, loss = 405.02304758\n",
      "Iteration 7282, loss = 405.02492575\n",
      "Iteration 7283, loss = 405.01764364\n",
      "Iteration 7284, loss = 405.01205358\n",
      "Iteration 7285, loss = 405.01030431\n",
      "Iteration 7286, loss = 405.00744944\n",
      "Iteration 7287, loss = 404.99717587\n",
      "Iteration 7288, loss = 404.97890850\n",
      "Iteration 7289, loss = 404.97338982\n",
      "Iteration 7290, loss = 404.97251655\n",
      "Iteration 7291, loss = 404.97524771\n",
      "Iteration 7292, loss = 404.96240157\n",
      "Iteration 7293, loss = 404.96303931\n",
      "Iteration 7294, loss = 404.96335413\n",
      "Iteration 7295, loss = 404.95998213\n",
      "Iteration 7296, loss = 404.94886591\n",
      "Iteration 7297, loss = 404.94727520\n",
      "Iteration 7298, loss = 404.94112715\n",
      "Iteration 7299, loss = 404.93412950\n",
      "Iteration 7300, loss = 404.92826857\n",
      "Iteration 7301, loss = 404.92781980\n",
      "Iteration 7302, loss = 404.93971552\n",
      "Iteration 7303, loss = 404.94330536\n",
      "Iteration 7304, loss = 404.93404239\n",
      "Iteration 7305, loss = 404.93324386\n",
      "Iteration 7306, loss = 404.93656584\n",
      "Iteration 7307, loss = 404.91478469\n",
      "Iteration 7308, loss = 404.91117463\n",
      "Iteration 7309, loss = 404.91544286\n",
      "Iteration 7310, loss = 404.91236679\n",
      "Iteration 7311, loss = 404.90531732\n",
      "Iteration 7312, loss = 404.90804333\n",
      "Iteration 7313, loss = 404.90859746\n",
      "Iteration 7314, loss = 404.89371324\n",
      "Iteration 7315, loss = 404.88136831\n",
      "Iteration 7316, loss = 404.89873634\n",
      "Iteration 7317, loss = 404.88934460\n",
      "Iteration 7318, loss = 404.88405088\n",
      "Iteration 7319, loss = 404.88579546\n",
      "Iteration 7320, loss = 404.88744761\n",
      "Iteration 7321, loss = 404.87774739\n",
      "Iteration 7322, loss = 404.88306023\n",
      "Iteration 7323, loss = 404.87619630\n",
      "Iteration 7324, loss = 404.86277773\n",
      "Iteration 7325, loss = 404.86200379\n",
      "Iteration 7326, loss = 404.86289717\n",
      "Iteration 7327, loss = 404.87484577\n",
      "Iteration 7328, loss = 404.87426451\n",
      "Iteration 7329, loss = 404.86725254\n",
      "Iteration 7330, loss = 404.85853996\n",
      "Iteration 7331, loss = 404.85657811\n",
      "Iteration 7332, loss = 404.85010962\n",
      "Iteration 7333, loss = 404.83792470\n",
      "Iteration 7334, loss = 404.84601919\n",
      "Iteration 7335, loss = 404.83820271\n",
      "Iteration 7336, loss = 404.83395112\n",
      "Iteration 7337, loss = 404.84637567\n",
      "Iteration 7338, loss = 404.84001481\n",
      "Iteration 7339, loss = 404.82559312\n",
      "Iteration 7340, loss = 404.82545287\n",
      "Iteration 7341, loss = 404.82978098\n",
      "Iteration 7342, loss = 404.82406214\n",
      "Iteration 7343, loss = 404.81055751\n",
      "Iteration 7344, loss = 404.81499406\n",
      "Iteration 7345, loss = 404.81318274\n",
      "Iteration 7346, loss = 404.81057812\n",
      "Iteration 7347, loss = 404.80266932\n",
      "Iteration 7348, loss = 404.80950702\n",
      "Iteration 7349, loss = 404.80354224\n",
      "Iteration 7350, loss = 404.80148147\n",
      "Iteration 7351, loss = 404.79736761\n",
      "Iteration 7352, loss = 404.80801981\n",
      "Iteration 7353, loss = 404.79648769\n",
      "Iteration 7354, loss = 404.79579612\n",
      "Iteration 7355, loss = 404.79899195\n",
      "Iteration 7356, loss = 404.78761978\n",
      "Iteration 7357, loss = 404.79385820\n",
      "Iteration 7358, loss = 404.78775944\n",
      "Iteration 7359, loss = 404.78566194\n",
      "Iteration 7360, loss = 404.78252381\n",
      "Iteration 7361, loss = 404.78059933\n",
      "Iteration 7362, loss = 404.77681444\n",
      "Iteration 7363, loss = 404.78015533\n",
      "Iteration 7364, loss = 404.76967326\n",
      "Iteration 7365, loss = 404.78334083\n",
      "Iteration 7366, loss = 404.78423821\n",
      "Iteration 7367, loss = 404.77634492\n",
      "Iteration 7368, loss = 404.76202293\n",
      "Iteration 7369, loss = 404.76899941\n",
      "Iteration 7370, loss = 404.77369262\n",
      "Iteration 7371, loss = 404.76897529\n",
      "Iteration 7372, loss = 404.76277985\n",
      "Iteration 7373, loss = 404.74808506\n",
      "Iteration 7374, loss = 404.74272269\n",
      "Iteration 7375, loss = 404.74466238\n",
      "Iteration 7376, loss = 404.75128333\n",
      "Iteration 7377, loss = 404.73667818\n",
      "Iteration 7378, loss = 404.72476537\n",
      "Iteration 7379, loss = 404.73941149\n",
      "Iteration 7380, loss = 404.74414387\n",
      "Iteration 7381, loss = 404.73989484\n",
      "Iteration 7382, loss = 404.73421198\n",
      "Iteration 7383, loss = 404.72487267\n",
      "Iteration 7384, loss = 404.72773304\n",
      "Iteration 7385, loss = 404.72827170\n",
      "Iteration 7386, loss = 404.72676244\n",
      "Iteration 7387, loss = 404.71628763\n",
      "Iteration 7388, loss = 404.70586022\n",
      "Iteration 7389, loss = 404.69903196\n",
      "Iteration 7390, loss = 404.69294726\n",
      "Iteration 7391, loss = 404.69536024\n",
      "Iteration 7392, loss = 404.68477148\n",
      "Iteration 7393, loss = 404.68171907\n",
      "Iteration 7394, loss = 404.68519902\n",
      "Iteration 7395, loss = 404.67882033\n",
      "Iteration 7396, loss = 404.67715805\n",
      "Iteration 7397, loss = 404.67411399\n",
      "Iteration 7398, loss = 404.66096347\n",
      "Iteration 7399, loss = 404.67285607\n",
      "Iteration 7400, loss = 404.67518407\n",
      "Iteration 7401, loss = 404.67403145\n",
      "Iteration 7402, loss = 404.66548545\n",
      "Iteration 7403, loss = 404.66302875\n",
      "Iteration 7404, loss = 404.66631360\n",
      "Iteration 7405, loss = 404.65815461\n",
      "Iteration 7406, loss = 404.65788543\n",
      "Iteration 7407, loss = 404.64903568\n",
      "Iteration 7408, loss = 404.65062648\n",
      "Iteration 7409, loss = 404.64846860\n",
      "Iteration 7410, loss = 404.65197750\n",
      "Iteration 7411, loss = 404.65408148\n",
      "Iteration 7412, loss = 404.64931147\n",
      "Iteration 7413, loss = 404.65058251\n",
      "Iteration 7414, loss = 404.64391359\n",
      "Iteration 7415, loss = 404.64364338\n",
      "Iteration 7416, loss = 404.63706526\n",
      "Iteration 7417, loss = 404.62821169\n",
      "Iteration 7418, loss = 404.63653975\n",
      "Iteration 7419, loss = 404.61986897\n",
      "Iteration 7420, loss = 404.61778690\n",
      "Iteration 7421, loss = 404.62197769\n",
      "Iteration 7422, loss = 404.61267207\n",
      "Iteration 7423, loss = 404.61513263\n",
      "Iteration 7424, loss = 404.62134998\n",
      "Iteration 7425, loss = 404.60783268\n",
      "Iteration 7426, loss = 404.60826366\n",
      "Iteration 7427, loss = 404.60739368\n",
      "Iteration 7428, loss = 404.60378526\n",
      "Iteration 7429, loss = 404.59852385\n",
      "Iteration 7430, loss = 404.59898621\n",
      "Iteration 7431, loss = 404.59322029\n",
      "Iteration 7432, loss = 404.58991824\n",
      "Iteration 7433, loss = 404.58498884\n",
      "Iteration 7434, loss = 404.57833322\n",
      "Iteration 7435, loss = 404.57967656\n",
      "Iteration 7436, loss = 404.58048364\n",
      "Iteration 7437, loss = 404.56974033\n",
      "Iteration 7438, loss = 404.57617001\n",
      "Iteration 7439, loss = 404.57516045\n",
      "Iteration 7440, loss = 404.56616344\n",
      "Iteration 7441, loss = 404.56851407\n",
      "Iteration 7442, loss = 404.55962887\n",
      "Iteration 7443, loss = 404.55421662\n",
      "Iteration 7444, loss = 404.54857353\n",
      "Iteration 7445, loss = 404.55170765\n",
      "Iteration 7446, loss = 404.54784137\n",
      "Iteration 7447, loss = 404.54169448\n",
      "Iteration 7448, loss = 404.53226649\n",
      "Iteration 7449, loss = 404.52965678\n",
      "Iteration 7450, loss = 404.53146250\n",
      "Iteration 7451, loss = 404.52310439\n",
      "Iteration 7452, loss = 404.52463203\n",
      "Iteration 7453, loss = 404.52193139\n",
      "Iteration 7454, loss = 404.51789948\n",
      "Iteration 7455, loss = 404.51712415\n",
      "Iteration 7456, loss = 404.51192297\n",
      "Iteration 7457, loss = 404.51513618\n",
      "Iteration 7458, loss = 404.51404611\n",
      "Iteration 7459, loss = 404.50565031\n",
      "Iteration 7460, loss = 404.51596801\n",
      "Iteration 7461, loss = 404.51050613\n",
      "Iteration 7462, loss = 404.50589274\n",
      "Iteration 7463, loss = 404.50932856\n",
      "Iteration 7464, loss = 404.51393357\n",
      "Iteration 7465, loss = 404.50393834\n",
      "Iteration 7466, loss = 404.50673985\n",
      "Iteration 7467, loss = 404.50551273\n",
      "Iteration 7468, loss = 404.50487198\n",
      "Iteration 7469, loss = 404.50059756\n",
      "Iteration 7470, loss = 404.49939715\n",
      "Iteration 7471, loss = 404.50514402\n",
      "Iteration 7472, loss = 404.50538716\n",
      "Iteration 7473, loss = 404.50073209\n",
      "Iteration 7474, loss = 404.50426434\n",
      "Iteration 7475, loss = 404.48873417\n",
      "Iteration 7476, loss = 404.46916607\n",
      "Iteration 7477, loss = 404.46659104\n",
      "Iteration 7478, loss = 404.46368427\n",
      "Iteration 7479, loss = 404.46916949\n",
      "Iteration 7480, loss = 404.45325952\n",
      "Iteration 7481, loss = 404.45607078\n",
      "Iteration 7482, loss = 404.44906862\n",
      "Iteration 7483, loss = 404.45474523\n",
      "Iteration 7484, loss = 404.44632266\n",
      "Iteration 7485, loss = 404.43253694\n",
      "Iteration 7486, loss = 404.43768409\n",
      "Iteration 7487, loss = 404.43046500\n",
      "Iteration 7488, loss = 404.42803604\n",
      "Iteration 7489, loss = 404.42743273\n",
      "Iteration 7490, loss = 404.43476875\n",
      "Iteration 7491, loss = 404.42020484\n",
      "Iteration 7492, loss = 404.41175540\n",
      "Iteration 7493, loss = 404.41503253\n",
      "Iteration 7494, loss = 404.40796494\n",
      "Iteration 7495, loss = 404.40907289\n",
      "Iteration 7496, loss = 404.40983192\n",
      "Iteration 7497, loss = 404.40140494\n",
      "Iteration 7498, loss = 404.40324565\n",
      "Iteration 7499, loss = 404.39477598\n",
      "Iteration 7500, loss = 404.40750464\n",
      "Iteration 7501, loss = 404.40156066\n",
      "Iteration 7502, loss = 404.39440200\n",
      "Iteration 7503, loss = 404.40099039\n",
      "Iteration 7504, loss = 404.39245206\n",
      "Iteration 7505, loss = 404.39491608\n",
      "Iteration 7506, loss = 404.39120044\n",
      "Iteration 7507, loss = 404.38579770\n",
      "Iteration 7508, loss = 404.39265889\n",
      "Iteration 7509, loss = 404.38337495\n",
      "Iteration 7510, loss = 404.37854580\n",
      "Iteration 7511, loss = 404.37219628\n",
      "Iteration 7512, loss = 404.37777681\n",
      "Iteration 7513, loss = 404.37074974\n",
      "Iteration 7514, loss = 404.37854047\n",
      "Iteration 7515, loss = 404.38449689\n",
      "Iteration 7516, loss = 404.37598934\n",
      "Iteration 7517, loss = 404.35989839\n",
      "Iteration 7518, loss = 404.35169665\n",
      "Iteration 7519, loss = 404.36178626\n",
      "Iteration 7520, loss = 404.35416314\n",
      "Iteration 7521, loss = 404.33760883\n",
      "Iteration 7522, loss = 404.33685702\n",
      "Iteration 7523, loss = 404.35334213\n",
      "Iteration 7524, loss = 404.34737989\n",
      "Iteration 7525, loss = 404.35457697\n",
      "Iteration 7526, loss = 404.34947369\n",
      "Iteration 7527, loss = 404.34462652\n",
      "Iteration 7528, loss = 404.33350758\n",
      "Iteration 7529, loss = 404.35685398\n",
      "Iteration 7530, loss = 404.36047426\n",
      "Iteration 7531, loss = 404.33875576\n",
      "Iteration 7532, loss = 404.34968825\n",
      "Iteration 7533, loss = 404.35599421\n",
      "Iteration 7534, loss = 404.34159540\n",
      "Iteration 7535, loss = 404.34144021\n",
      "Iteration 7536, loss = 404.34073736\n",
      "Iteration 7537, loss = 404.33297836\n",
      "Iteration 7538, loss = 404.32815218\n",
      "Iteration 7539, loss = 404.30270624\n",
      "Iteration 7540, loss = 404.29156475\n",
      "Iteration 7541, loss = 404.30860650\n",
      "Iteration 7542, loss = 404.31968806\n",
      "Iteration 7543, loss = 404.31799626\n",
      "Iteration 7544, loss = 404.30713569\n",
      "Iteration 7545, loss = 404.28838674\n",
      "Iteration 7546, loss = 404.28804678\n",
      "Iteration 7547, loss = 404.30016747\n",
      "Iteration 7548, loss = 404.30060148\n",
      "Iteration 7549, loss = 404.29070159\n",
      "Iteration 7550, loss = 404.27356113\n",
      "Iteration 7551, loss = 404.26295091\n",
      "Iteration 7552, loss = 404.28233231\n",
      "Iteration 7553, loss = 404.28245754\n",
      "Iteration 7554, loss = 404.25839757\n",
      "Iteration 7555, loss = 404.25929418\n",
      "Iteration 7556, loss = 404.25378560\n",
      "Iteration 7557, loss = 404.27431253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7558, loss = 404.26593262\n",
      "Iteration 7559, loss = 404.26646705\n",
      "Iteration 7560, loss = 404.25963332\n",
      "Iteration 7561, loss = 404.26378018\n",
      "Iteration 7562, loss = 404.26154794\n",
      "Iteration 7563, loss = 404.24745394\n",
      "Iteration 7564, loss = 404.24107682\n",
      "Iteration 7565, loss = 404.23950346\n",
      "Iteration 7566, loss = 404.24776339\n",
      "Iteration 7567, loss = 404.24086185\n",
      "Iteration 7568, loss = 404.23334693\n",
      "Iteration 7569, loss = 404.22902526\n",
      "Iteration 7570, loss = 404.22438606\n",
      "Iteration 7571, loss = 404.23438312\n",
      "Iteration 7572, loss = 404.23114357\n",
      "Iteration 7573, loss = 404.22259893\n",
      "Iteration 7574, loss = 404.21912147\n",
      "Iteration 7575, loss = 404.20485586\n",
      "Iteration 7576, loss = 404.20262128\n",
      "Iteration 7577, loss = 404.20721373\n",
      "Iteration 7578, loss = 404.21298983\n",
      "Iteration 7579, loss = 404.20762126\n",
      "Iteration 7580, loss = 404.19506608\n",
      "Iteration 7581, loss = 404.19238341\n",
      "Iteration 7582, loss = 404.19373405\n",
      "Iteration 7583, loss = 404.18836550\n",
      "Iteration 7584, loss = 404.17945070\n",
      "Iteration 7585, loss = 404.18423266\n",
      "Iteration 7586, loss = 404.17572470\n",
      "Iteration 7587, loss = 404.17240942\n",
      "Iteration 7588, loss = 404.16875771\n",
      "Iteration 7589, loss = 404.16453822\n",
      "Iteration 7590, loss = 404.17061630\n",
      "Iteration 7591, loss = 404.16714876\n",
      "Iteration 7592, loss = 404.15951990\n",
      "Iteration 7593, loss = 404.16305610\n",
      "Iteration 7594, loss = 404.15804717\n",
      "Iteration 7595, loss = 404.17000827\n",
      "Iteration 7596, loss = 404.16468354\n",
      "Iteration 7597, loss = 404.16310494\n",
      "Iteration 7598, loss = 404.15672267\n",
      "Iteration 7599, loss = 404.15375114\n",
      "Iteration 7600, loss = 404.15482076\n",
      "Iteration 7601, loss = 404.15784984\n",
      "Iteration 7602, loss = 404.14551609\n",
      "Iteration 7603, loss = 404.14246726\n",
      "Iteration 7604, loss = 404.14744047\n",
      "Iteration 7605, loss = 404.14663183\n",
      "Iteration 7606, loss = 404.13997282\n",
      "Iteration 7607, loss = 404.13827703\n",
      "Iteration 7608, loss = 404.15223528\n",
      "Iteration 7609, loss = 404.13589696\n",
      "Iteration 7610, loss = 404.13784232\n",
      "Iteration 7611, loss = 404.13023122\n",
      "Iteration 7612, loss = 404.12439951\n",
      "Iteration 7613, loss = 404.11951030\n",
      "Iteration 7614, loss = 404.12238378\n",
      "Iteration 7615, loss = 404.11560115\n",
      "Iteration 7616, loss = 404.11284852\n",
      "Iteration 7617, loss = 404.11154269\n",
      "Iteration 7618, loss = 404.10084022\n",
      "Iteration 7619, loss = 404.10705193\n",
      "Iteration 7620, loss = 404.10710750\n",
      "Iteration 7621, loss = 404.08904454\n",
      "Iteration 7622, loss = 404.08871944\n",
      "Iteration 7623, loss = 404.08916955\n",
      "Iteration 7624, loss = 404.10096973\n",
      "Iteration 7625, loss = 404.08339106\n",
      "Iteration 7626, loss = 404.08940085\n",
      "Iteration 7627, loss = 404.08526388\n",
      "Iteration 7628, loss = 404.08392293\n",
      "Iteration 7629, loss = 404.08821193\n",
      "Iteration 7630, loss = 404.08276180\n",
      "Iteration 7631, loss = 404.07078488\n",
      "Iteration 7632, loss = 404.06358928\n",
      "Iteration 7633, loss = 404.05669709\n",
      "Iteration 7634, loss = 404.06556634\n",
      "Iteration 7635, loss = 404.06975239\n",
      "Iteration 7636, loss = 404.04950611\n",
      "Iteration 7637, loss = 404.04799284\n",
      "Iteration 7638, loss = 404.05980975\n",
      "Iteration 7639, loss = 404.05149421\n",
      "Iteration 7640, loss = 404.06061437\n",
      "Iteration 7641, loss = 404.04982068\n",
      "Iteration 7642, loss = 404.05102234\n",
      "Iteration 7643, loss = 404.04493015\n",
      "Iteration 7644, loss = 404.03386067\n",
      "Iteration 7645, loss = 404.04823776\n",
      "Iteration 7646, loss = 404.04850938\n",
      "Iteration 7647, loss = 404.05142796\n",
      "Iteration 7648, loss = 404.02807470\n",
      "Iteration 7649, loss = 404.03281823\n",
      "Iteration 7650, loss = 404.04288905\n",
      "Iteration 7651, loss = 404.03204042\n",
      "Iteration 7652, loss = 404.03455674\n",
      "Iteration 7653, loss = 404.03234578\n",
      "Iteration 7654, loss = 404.01194139\n",
      "Iteration 7655, loss = 404.01530524\n",
      "Iteration 7656, loss = 404.01877549\n",
      "Iteration 7657, loss = 404.01637777\n",
      "Iteration 7658, loss = 404.01444240\n",
      "Iteration 7659, loss = 404.01036304\n",
      "Iteration 7660, loss = 404.00673734\n",
      "Iteration 7661, loss = 404.00624648\n",
      "Iteration 7662, loss = 404.00753651\n",
      "Iteration 7663, loss = 403.99531319\n",
      "Iteration 7664, loss = 403.99267522\n",
      "Iteration 7665, loss = 403.99542882\n",
      "Iteration 7666, loss = 403.98711554\n",
      "Iteration 7667, loss = 403.98350793\n",
      "Iteration 7668, loss = 403.97940346\n",
      "Iteration 7669, loss = 403.97714055\n",
      "Iteration 7670, loss = 403.97717349\n",
      "Iteration 7671, loss = 403.97195177\n",
      "Iteration 7672, loss = 403.96460808\n",
      "Iteration 7673, loss = 403.95852619\n",
      "Iteration 7674, loss = 403.96019439\n",
      "Iteration 7675, loss = 403.96183138\n",
      "Iteration 7676, loss = 403.95858957\n",
      "Iteration 7677, loss = 403.95676590\n",
      "Iteration 7678, loss = 403.96679159\n",
      "Iteration 7679, loss = 403.96400321\n",
      "Iteration 7680, loss = 403.95560065\n",
      "Iteration 7681, loss = 403.95197706\n",
      "Iteration 7682, loss = 403.94736458\n",
      "Iteration 7683, loss = 403.94956357\n",
      "Iteration 7684, loss = 403.94480658\n",
      "Iteration 7685, loss = 403.93557234\n",
      "Iteration 7686, loss = 403.93250316\n",
      "Iteration 7687, loss = 403.93480674\n",
      "Iteration 7688, loss = 403.94780167\n",
      "Iteration 7689, loss = 403.94561841\n",
      "Iteration 7690, loss = 403.93370329\n",
      "Iteration 7691, loss = 403.92713372\n",
      "Iteration 7692, loss = 403.92278152\n",
      "Iteration 7693, loss = 403.93572715\n",
      "Iteration 7694, loss = 403.92970256\n",
      "Iteration 7695, loss = 403.92404113\n",
      "Iteration 7696, loss = 403.90201724\n",
      "Iteration 7697, loss = 403.90971696\n",
      "Iteration 7698, loss = 403.91283738\n",
      "Iteration 7699, loss = 403.89967473\n",
      "Iteration 7700, loss = 403.88907674\n",
      "Iteration 7701, loss = 403.88455780\n",
      "Iteration 7702, loss = 403.89189930\n",
      "Iteration 7703, loss = 403.88349663\n",
      "Iteration 7704, loss = 403.88125103\n",
      "Iteration 7705, loss = 403.87205635\n",
      "Iteration 7706, loss = 403.86769383\n",
      "Iteration 7707, loss = 403.86756027\n",
      "Iteration 7708, loss = 403.86837461\n",
      "Iteration 7709, loss = 403.87438107\n",
      "Iteration 7710, loss = 403.87342098\n",
      "Iteration 7711, loss = 403.86733205\n",
      "Iteration 7712, loss = 403.86277063\n",
      "Iteration 7713, loss = 403.87595589\n",
      "Iteration 7714, loss = 403.86898499\n",
      "Iteration 7715, loss = 403.85888480\n",
      "Iteration 7716, loss = 403.85162299\n",
      "Iteration 7717, loss = 403.85082433\n",
      "Iteration 7718, loss = 403.84847550\n",
      "Iteration 7719, loss = 403.84819191\n",
      "Iteration 7720, loss = 403.84920000\n",
      "Iteration 7721, loss = 403.84720444\n",
      "Iteration 7722, loss = 403.84897818\n",
      "Iteration 7723, loss = 403.84252459\n",
      "Iteration 7724, loss = 403.84869252\n",
      "Iteration 7725, loss = 403.85060110\n",
      "Iteration 7726, loss = 403.85458151\n",
      "Iteration 7727, loss = 403.84082884\n",
      "Iteration 7728, loss = 403.83367573\n",
      "Iteration 7729, loss = 403.81894603\n",
      "Iteration 7730, loss = 403.83361703\n",
      "Iteration 7731, loss = 403.83733724\n",
      "Iteration 7732, loss = 403.82954943\n",
      "Iteration 7733, loss = 403.82316369\n",
      "Iteration 7734, loss = 403.81848905\n",
      "Iteration 7735, loss = 403.80603023\n",
      "Iteration 7736, loss = 403.79369862\n",
      "Iteration 7737, loss = 403.80539702\n",
      "Iteration 7738, loss = 403.80753811\n",
      "Iteration 7739, loss = 403.80210327\n",
      "Iteration 7740, loss = 403.80597569\n",
      "Iteration 7741, loss = 403.79874546\n",
      "Iteration 7742, loss = 403.79900994\n",
      "Iteration 7743, loss = 403.78785675\n",
      "Iteration 7744, loss = 403.79367089\n",
      "Iteration 7745, loss = 403.79196155\n",
      "Iteration 7746, loss = 403.78791433\n",
      "Iteration 7747, loss = 403.78157775\n",
      "Iteration 7748, loss = 403.78346258\n",
      "Iteration 7749, loss = 403.77887315\n",
      "Iteration 7750, loss = 403.77230070\n",
      "Iteration 7751, loss = 403.76081840\n",
      "Iteration 7752, loss = 403.77117211\n",
      "Iteration 7753, loss = 403.77150088\n",
      "Iteration 7754, loss = 403.76387882\n",
      "Iteration 7755, loss = 403.76999957\n",
      "Iteration 7756, loss = 403.74615756\n",
      "Iteration 7757, loss = 403.75742223\n",
      "Iteration 7758, loss = 403.75987581\n",
      "Iteration 7759, loss = 403.75235550\n",
      "Iteration 7760, loss = 403.74597196\n",
      "Iteration 7761, loss = 403.75079253\n",
      "Iteration 7762, loss = 403.75277587\n",
      "Iteration 7763, loss = 403.74813968\n",
      "Iteration 7764, loss = 403.73099033\n",
      "Iteration 7765, loss = 403.72534646\n",
      "Iteration 7766, loss = 403.72424373\n",
      "Iteration 7767, loss = 403.72434927\n",
      "Iteration 7768, loss = 403.71891804\n",
      "Iteration 7769, loss = 403.73122780\n",
      "Iteration 7770, loss = 403.70519561\n",
      "Iteration 7771, loss = 403.72041830\n",
      "Iteration 7772, loss = 403.72606594\n",
      "Iteration 7773, loss = 403.71801934\n",
      "Iteration 7774, loss = 403.70637849\n",
      "Iteration 7775, loss = 403.71369988\n",
      "Iteration 7776, loss = 403.71557441\n",
      "Iteration 7777, loss = 403.71952210\n",
      "Iteration 7778, loss = 403.70916492\n",
      "Iteration 7779, loss = 403.70043585\n",
      "Iteration 7780, loss = 403.69390659\n",
      "Iteration 7781, loss = 403.69051416\n",
      "Iteration 7782, loss = 403.68517408\n",
      "Iteration 7783, loss = 403.69102459\n",
      "Iteration 7784, loss = 403.68173772\n",
      "Iteration 7785, loss = 403.69161102\n",
      "Iteration 7786, loss = 403.68988565\n",
      "Iteration 7787, loss = 403.67911520\n",
      "Iteration 7788, loss = 403.68156142\n",
      "Iteration 7789, loss = 403.68096646\n",
      "Iteration 7790, loss = 403.67150803\n",
      "Iteration 7791, loss = 403.66384603\n",
      "Iteration 7792, loss = 403.67189365\n",
      "Iteration 7793, loss = 403.66311505\n",
      "Iteration 7794, loss = 403.65860240\n",
      "Iteration 7795, loss = 403.65148049\n",
      "Iteration 7796, loss = 403.63378382\n",
      "Iteration 7797, loss = 403.63986800\n",
      "Iteration 7798, loss = 403.64363198\n",
      "Iteration 7799, loss = 403.63992525\n",
      "Iteration 7800, loss = 403.63781748\n",
      "Iteration 7801, loss = 403.63122957\n",
      "Iteration 7802, loss = 403.63969731\n",
      "Iteration 7803, loss = 403.63681312\n",
      "Iteration 7804, loss = 403.63002576\n",
      "Iteration 7805, loss = 403.64608216\n",
      "Iteration 7806, loss = 403.64121116\n",
      "Iteration 7807, loss = 403.62574099\n",
      "Iteration 7808, loss = 403.62941590\n",
      "Iteration 7809, loss = 403.62312163\n",
      "Iteration 7810, loss = 403.62232114\n",
      "Iteration 7811, loss = 403.62560367\n",
      "Iteration 7812, loss = 403.61081908\n",
      "Iteration 7813, loss = 403.60360051\n",
      "Iteration 7814, loss = 403.60818439\n",
      "Iteration 7815, loss = 403.61616671\n",
      "Iteration 7816, loss = 403.61962667\n",
      "Iteration 7817, loss = 403.59603853\n",
      "Iteration 7818, loss = 403.58560258\n",
      "Iteration 7819, loss = 403.59886861\n",
      "Iteration 7820, loss = 403.60065790\n",
      "Iteration 7821, loss = 403.59666123\n",
      "Iteration 7822, loss = 403.58012321\n",
      "Iteration 7823, loss = 403.58382576\n",
      "Iteration 7824, loss = 403.57368258\n",
      "Iteration 7825, loss = 403.58133759\n",
      "Iteration 7826, loss = 403.57197510\n",
      "Iteration 7827, loss = 403.57256615\n",
      "Iteration 7828, loss = 403.57455501\n",
      "Iteration 7829, loss = 403.57655741\n",
      "Iteration 7830, loss = 403.56952829\n",
      "Iteration 7831, loss = 403.57562661\n",
      "Iteration 7832, loss = 403.56415796\n",
      "Iteration 7833, loss = 403.57167830\n",
      "Iteration 7834, loss = 403.55643524\n",
      "Iteration 7835, loss = 403.55981609\n",
      "Iteration 7836, loss = 403.56537941\n",
      "Iteration 7837, loss = 403.56426232\n",
      "Iteration 7838, loss = 403.55101189\n",
      "Iteration 7839, loss = 403.54903758\n",
      "Iteration 7840, loss = 403.55071738\n",
      "Iteration 7841, loss = 403.54851953\n",
      "Iteration 7842, loss = 403.53694066\n",
      "Iteration 7843, loss = 403.53353405\n",
      "Iteration 7844, loss = 403.53515719\n",
      "Iteration 7845, loss = 403.53210452\n",
      "Iteration 7846, loss = 403.53465367\n",
      "Iteration 7847, loss = 403.52037584\n",
      "Iteration 7848, loss = 403.52030870\n",
      "Iteration 7849, loss = 403.51607375\n",
      "Iteration 7850, loss = 403.51552553\n",
      "Iteration 7851, loss = 403.51233298\n",
      "Iteration 7852, loss = 403.51221573\n",
      "Iteration 7853, loss = 403.51137264\n",
      "Iteration 7854, loss = 403.52298188\n",
      "Iteration 7855, loss = 403.50472952\n",
      "Iteration 7856, loss = 403.49415757\n",
      "Iteration 7857, loss = 403.50009140\n",
      "Iteration 7858, loss = 403.50230995\n",
      "Iteration 7859, loss = 403.49264895\n",
      "Iteration 7860, loss = 403.49029448\n",
      "Iteration 7861, loss = 403.48526966\n",
      "Iteration 7862, loss = 403.48376407\n",
      "Iteration 7863, loss = 403.49986227\n",
      "Iteration 7864, loss = 403.48120930\n",
      "Iteration 7865, loss = 403.48206324\n",
      "Iteration 7866, loss = 403.48396352\n",
      "Iteration 7867, loss = 403.49007396\n",
      "Iteration 7868, loss = 403.48647770\n",
      "Iteration 7869, loss = 403.47036389\n",
      "Iteration 7870, loss = 403.46527264\n",
      "Iteration 7871, loss = 403.46465773\n",
      "Iteration 7872, loss = 403.47317995\n",
      "Iteration 7873, loss = 403.47261566\n",
      "Iteration 7874, loss = 403.47029416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7875, loss = 403.46073152\n",
      "Iteration 7876, loss = 403.45748864\n",
      "Iteration 7877, loss = 403.45100694\n",
      "Iteration 7878, loss = 403.43663697\n",
      "Iteration 7879, loss = 403.46235801\n",
      "Iteration 7880, loss = 403.46363271\n",
      "Iteration 7881, loss = 403.44897747\n",
      "Iteration 7882, loss = 403.44658578\n",
      "Iteration 7883, loss = 403.43439541\n",
      "Iteration 7884, loss = 403.43817815\n",
      "Iteration 7885, loss = 403.43493146\n",
      "Iteration 7886, loss = 403.44124583\n",
      "Iteration 7887, loss = 403.43918657\n",
      "Iteration 7888, loss = 403.43612183\n",
      "Iteration 7889, loss = 403.42807251\n",
      "Iteration 7890, loss = 403.42110712\n",
      "Iteration 7891, loss = 403.41984571\n",
      "Iteration 7892, loss = 403.41415955\n",
      "Iteration 7893, loss = 403.40049334\n",
      "Iteration 7894, loss = 403.41298160\n",
      "Iteration 7895, loss = 403.41537277\n",
      "Iteration 7896, loss = 403.42516782\n",
      "Iteration 7897, loss = 403.42587142\n",
      "Iteration 7898, loss = 403.40526321\n",
      "Iteration 7899, loss = 403.43341236\n",
      "Iteration 7900, loss = 403.43394827\n",
      "Iteration 7901, loss = 403.43871940\n",
      "Iteration 7902, loss = 403.43582749\n",
      "Iteration 7903, loss = 403.43567865\n",
      "Iteration 7904, loss = 403.41590963\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean squared error: 808597.96\n"
     ]
    }
   ],
   "source": [
    "#Antrenam modeul folosind setul de train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Facem predictii\n",
    "y_pred = regr.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([10178,   558,   330,    22]),\n",
       " array([3294,  137,  319,   19]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([ 2,  0, -1,  0]),\n",
       " array([1888,   59,  246,   11]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([-2,  0,  0,  0]),\n",
       " array([7668,  386,  382,   20]),\n",
       " array([6330,  309,  368,   20]),\n",
       " array([823,  12, 151,   4]),\n",
       " array([-1,  0,  0,  0]),\n",
       " array([-1,  0,  0,  0]),\n",
       " array([-1, -1,  0,  0]),\n",
       " array([2198,   76,  264,   13]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([-1,  0,  0,  0]),\n",
       " array([4126,  182,  340,   21]),\n",
       " array([-1,  0,  0,  0])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertim din float in int\n",
    "result_int = []\n",
    "for x in y_pred:\n",
    "    result_int.append(x.astype(int))\n",
    "\n",
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41007804e+03, -1.32397155e+03, -5.94215491e+02,  7.74466575e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#MLP Regressor pentru NN Multy Layer\n",
    "regr = MLPRegressor(solver='adam', hidden_layer_sizes=(200,100), max_iter=10000,activation='relu')\n",
    "#regr = MLPRegressor(solver=â€™lbfgsâ€™, hiddenlayersizes=(200,150), maxiter=20000,activation=â€™reluâ€™, alpha = 0.0003)\n",
    "#regr = MLPRegressor(solver=â€™adamâ€™, hiddenlayersizes=(200,100), maxiter=10000,activation=â€™reluâ€™)\n",
    "\n",
    "#Cross validation score\n",
    "cross_val_score(regr, y_test, X_test, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6106,    -6,    85,    -7,   -12,     1,  1233,    11,    -5,\n",
       "         -14,    93,   122,   196,  1449,  7677,   246,     6,   323,\n",
       "         221, 11679,    17])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregatim coloana pentru cazuri de persoane infectate\n",
    "y = data.iloc[:, 2].values\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "X_final = data.iloc[:, 0:2].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.17)\n",
    "\n",
    "regr.fit(X_train, y_train.ravel())\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5990],\n",
       "       [    0],\n",
       "       [   45],\n",
       "       [    0],\n",
       "       [    0],\n",
       "       [    0],\n",
       "       [ 1029],\n",
       "       [    3],\n",
       "       [    0],\n",
       "       [    0],\n",
       "       [    0],\n",
       "       [   89],\n",
       "       [  184],\n",
       "       [ 1292],\n",
       "       [ 7707],\n",
       "       [  277],\n",
       "       [    0],\n",
       "       [  308],\n",
       "       [    0],\n",
       "       [11978],\n",
       "       [    9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6106,     0,    85,     0,     0,     1,  1233,    11,     0,\n",
       "           0,    93,   122,   196,  1449,  7677,   246,     6,   323,\n",
       "         221, 11679,    17])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daca avem numere negative, le facem 0 pentru a putea aplica metricile de evaluare\n",
    "num = 0\n",
    "while(num < len(y_pred)): \n",
    "      \n",
    "    if y_pred[num] < 0: \n",
    "        y_pred[num] = 0\n",
    "    num = num + 1\n",
    "    \n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989264372755813"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Am folosit diferite metrici pentru a putea estima acuritatea rezultatelor obtinute\n",
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298.09753935656954"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import max_error\n",
    "max_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.95082109273548"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11038.275925048712"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7232104926734797"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.534019723698975"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988518416658613"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
