{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.  Country        Date  Confirmed  Death  newConfirmed  newDeath\n",
       "0    1  Romania  2019-12-31          0      0             0         0\n",
       "1    2  Romania  2020-01-01          0      0             0         0\n",
       "2    3  Romania  2020-01-02          0      0             0         0\n",
       "3    4  Romania  2020-01-03          0      0             0         0\n",
       "4    5  Romania  2020-01-04          0      0             0         0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#importam datasetul nostru\n",
    "input_file = \"Dataset.csv\"\n",
    "\n",
    "#citim din csv si punem in data\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>10635</td>\n",
       "      <td>601</td>\n",
       "      <td>218</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>11036</td>\n",
       "      <td>619</td>\n",
       "      <td>401</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>11339</td>\n",
       "      <td>641</td>\n",
       "      <td>303</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11616</td>\n",
       "      <td>663</td>\n",
       "      <td>277</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>11978</td>\n",
       "      <td>693</td>\n",
       "      <td>362</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country        Date  Confirmed  Death  newConfirmed  newDeath\n",
       "0    Romania  2019-12-31          0      0             0         0\n",
       "1    Romania  2020-01-01          0      0             0         0\n",
       "2    Romania  2020-01-02          0      0             0         0\n",
       "3    Romania  2020-01-03          0      0             0         0\n",
       "4    Romania  2020-01-04          0      0             0         0\n",
       "..       ...         ...        ...    ...           ...       ...\n",
       "116  Romania  2020-04-25      10635    601           218        34\n",
       "117  Romania  2020-04-26      11036    619           401        18\n",
       "118  Romania  2020-04-27      11339    641           303        22\n",
       "119  Romania  2020-04-28      11616    663           277        22\n",
       "120  Romania  2020-04-29      11978    693           362        30\n",
       "\n",
       "[121 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stergem coloana cu numarul deoarece nu avem nevoie de ele in prelucrarea datelor\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#folosim un label encoder pentru coloanele country si date pentru a le putea transforma in valori numerice\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(data['Date'])\n",
    "data.loc[:, 'Date'] = le.transform(data['Date'])\n",
    "\n",
    "le.fit(data['Country'])\n",
    "data.loc[:, 'Country'] = le.transform(data['Country'])\n",
    "\n",
    "#punem in y doar Country si Date\n",
    "y = data.drop(data.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "\n",
    "#In X_final punem restul coloanelor\n",
    "X_final = data.drop(data.columns[1], axis=1)\n",
    "X_final = X_final.drop(X_final.columns[0], axis=1)\n",
    "\n",
    "y_train, y_test, X_train, X_test = train_test_split(X_final, y, test_size=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Date\n",
       "31         0    31\n",
       "44         0    44\n",
       "40         0    40\n",
       "24         0    24\n",
       "97         0    97\n",
       "..       ...   ...\n",
       "91         0    91\n",
       "103        0   103\n",
       "4          0     4\n",
       "36         0    36\n",
       "72         0    72\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train contine datele de train pentru input\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4057</td>\n",
       "      <td>176</td>\n",
       "      <td>193</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2245</td>\n",
       "      <td>82</td>\n",
       "      <td>136</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6300</td>\n",
       "      <td>316</td>\n",
       "      <td>310</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Confirmed  Death  newConfirmed  newDeath\n",
       "31           0      0             0         0\n",
       "44           0      0             0         0\n",
       "40           0      0             0         0\n",
       "24           0      0             0         0\n",
       "97        4057    176           193        25\n",
       "..         ...    ...           ...       ...\n",
       "91        2245     82           136        17\n",
       "103       6300    316           310        25\n",
       "4            0      0             0         0\n",
       "36           0      0             0         0\n",
       "72          49      0             4         0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train contine datele de train pentru rezultatul inputului\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Date\n",
       "19         0    19\n",
       "51         0    51\n",
       "84         0    84\n",
       "108        0   108\n",
       "20         0    20\n",
       "92         0    92\n",
       "107        0   107\n",
       "102        0   102\n",
       "116        0   116\n",
       "60         0    60\n",
       "38         0    38\n",
       "65         0    65\n",
       "0          0     0\n",
       "90         0    90\n",
       "25         0    25\n",
       "5          0     5\n",
       "104        0   104\n",
       "3          0     3\n",
       "30         0    30\n",
       "21         0    21\n",
       "2          0     2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test contine datele de input pentru test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>794</td>\n",
       "      <td>11</td>\n",
       "      <td>218</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>8067</td>\n",
       "      <td>411</td>\n",
       "      <td>360</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2460</td>\n",
       "      <td>92</td>\n",
       "      <td>215</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7707</td>\n",
       "      <td>392</td>\n",
       "      <td>491</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5990</td>\n",
       "      <td>291</td>\n",
       "      <td>523</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>10635</td>\n",
       "      <td>601</td>\n",
       "      <td>218</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2109</td>\n",
       "      <td>65</td>\n",
       "      <td>294</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6633</td>\n",
       "      <td>331</td>\n",
       "      <td>333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Confirmed  Death  newConfirmed  newDeath\n",
       "19           0      0             0         0\n",
       "51           0      0             0         0\n",
       "84         794     11           218         4\n",
       "108       8067    411           360        19\n",
       "20           0      0             0         0\n",
       "92        2460     92           215        10\n",
       "107       7707    392           491        20\n",
       "102       5990    291           523        21\n",
       "116      10635    601           218        34\n",
       "60           3      0             0         0\n",
       "38           0      0             0         0\n",
       "65           6      0             2         0\n",
       "0            0      0             0         0\n",
       "90        2109     65           294        22\n",
       "25           0      0             0         0\n",
       "5            0      0             0         0\n",
       "104       6633    331           333        15\n",
       "3            0      0             0         0\n",
       "30           0      0             0         0\n",
       "21           0      0             0         0\n",
       "2            0      0             0         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test contine datele rezultate in urma inputului de test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1839576.52382839\n",
      "Iteration 2, loss = 1835705.17493724\n",
      "Iteration 3, loss = 1832167.65345703\n",
      "Iteration 4, loss = 1828860.47253918\n",
      "Iteration 5, loss = 1825608.12058476\n",
      "Iteration 6, loss = 1822586.61318607\n",
      "Iteration 7, loss = 1819599.25877494\n",
      "Iteration 8, loss = 1816579.41308579\n",
      "Iteration 9, loss = 1813590.05694228\n",
      "Iteration 10, loss = 1810681.72753734\n",
      "Iteration 11, loss = 1807937.99214857\n",
      "Iteration 12, loss = 1805364.68736434\n",
      "Iteration 13, loss = 1802853.20216062\n",
      "Iteration 14, loss = 1800273.05631136\n",
      "Iteration 15, loss = 1797636.74221220\n",
      "Iteration 16, loss = 1794925.65643179\n",
      "Iteration 17, loss = 1792185.82949955\n",
      "Iteration 18, loss = 1789386.53445071\n",
      "Iteration 19, loss = 1786547.88836348\n",
      "Iteration 20, loss = 1783600.52546629\n",
      "Iteration 21, loss = 1780615.30970590\n",
      "Iteration 22, loss = 1777534.35260283\n",
      "Iteration 23, loss = 1774354.05833270\n",
      "Iteration 24, loss = 1771070.89103991\n",
      "Iteration 25, loss = 1767694.84758094\n",
      "Iteration 26, loss = 1764208.62735806\n",
      "Iteration 27, loss = 1760607.85234363\n",
      "Iteration 28, loss = 1756889.64155918\n",
      "Iteration 29, loss = 1753050.51587204\n",
      "Iteration 30, loss = 1749087.04905412\n",
      "Iteration 31, loss = 1745029.84370766\n",
      "Iteration 32, loss = 1740775.01763408\n",
      "Iteration 33, loss = 1736420.27683937\n",
      "Iteration 34, loss = 1731928.70619081\n",
      "Iteration 35, loss = 1727297.45288717\n",
      "Iteration 36, loss = 1722523.70661480\n",
      "Iteration 37, loss = 1717604.74703835\n",
      "Iteration 38, loss = 1712537.94548122\n",
      "Iteration 39, loss = 1707335.20600178\n",
      "Iteration 40, loss = 1701952.11922323\n",
      "Iteration 41, loss = 1696428.02336152\n",
      "Iteration 42, loss = 1690748.37245766\n",
      "Iteration 43, loss = 1684910.86227177\n",
      "Iteration 44, loss = 1678914.12051899\n",
      "Iteration 45, loss = 1672756.86895345\n",
      "Iteration 46, loss = 1666439.20269183\n",
      "Iteration 47, loss = 1659956.51971786\n",
      "Iteration 48, loss = 1653313.44707951\n",
      "Iteration 49, loss = 1646505.08652524\n",
      "Iteration 50, loss = 1639531.80771839\n",
      "Iteration 51, loss = 1632396.46337287\n",
      "Iteration 52, loss = 1625097.44666892\n",
      "Iteration 53, loss = 1617634.38047970\n",
      "Iteration 54, loss = 1610007.87823842\n",
      "Iteration 55, loss = 1602223.92565494\n",
      "Iteration 56, loss = 1594266.87334955\n",
      "Iteration 57, loss = 1586152.55254305\n",
      "Iteration 58, loss = 1577880.73573355\n",
      "Iteration 59, loss = 1569437.25873168\n",
      "Iteration 60, loss = 1560842.37067292\n",
      "Iteration 61, loss = 1552071.53934019\n",
      "Iteration 62, loss = 1543143.46825896\n",
      "Iteration 63, loss = 1534053.45546105\n",
      "Iteration 64, loss = 1524793.10123868\n",
      "Iteration 65, loss = 1515369.48249117\n",
      "Iteration 66, loss = 1505778.62772363\n",
      "Iteration 67, loss = 1496019.97650126\n",
      "Iteration 68, loss = 1486103.53587280\n",
      "Iteration 69, loss = 1476010.51508902\n",
      "Iteration 70, loss = 1465754.91311576\n",
      "Iteration 71, loss = 1455338.63391527\n",
      "Iteration 72, loss = 1444766.60702404\n",
      "Iteration 73, loss = 1434038.45938959\n",
      "Iteration 74, loss = 1423157.85927868\n",
      "Iteration 75, loss = 1412152.20687852\n",
      "Iteration 76, loss = 1400968.03394682\n",
      "Iteration 77, loss = 1389666.98760811\n",
      "Iteration 78, loss = 1378238.56109967\n",
      "Iteration 79, loss = 1366688.17514022\n",
      "Iteration 80, loss = 1355023.46876503\n",
      "Iteration 81, loss = 1343251.53280014\n",
      "Iteration 82, loss = 1331390.22658643\n",
      "Iteration 83, loss = 1319431.94234456\n",
      "Iteration 84, loss = 1307405.01664512\n",
      "Iteration 85, loss = 1295298.09729768\n",
      "Iteration 86, loss = 1283143.13725689\n",
      "Iteration 87, loss = 1270954.47223139\n",
      "Iteration 88, loss = 1258705.26418310\n",
      "Iteration 89, loss = 1246452.89901349\n",
      "Iteration 90, loss = 1234190.17832915\n",
      "Iteration 91, loss = 1221938.31672038\n",
      "Iteration 92, loss = 1209685.05505494\n",
      "Iteration 93, loss = 1197468.02517565\n",
      "Iteration 94, loss = 1185300.89896836\n",
      "Iteration 95, loss = 1173179.16656010\n",
      "Iteration 96, loss = 1161127.77100490\n",
      "Iteration 97, loss = 1149154.12215231\n",
      "Iteration 98, loss = 1137293.03357093\n",
      "Iteration 99, loss = 1125504.12027667\n",
      "Iteration 100, loss = 1113856.58917442\n",
      "Iteration 101, loss = 1102343.93320624\n",
      "Iteration 102, loss = 1090955.38907153\n",
      "Iteration 103, loss = 1079744.18857844\n",
      "Iteration 104, loss = 1068694.23980798\n",
      "Iteration 105, loss = 1057819.43681984\n",
      "Iteration 106, loss = 1047131.32360896\n",
      "Iteration 107, loss = 1036688.61423632\n",
      "Iteration 108, loss = 1026447.89751083\n",
      "Iteration 109, loss = 1016445.58439361\n",
      "Iteration 110, loss = 1006688.43302601\n",
      "Iteration 111, loss = 997198.72830159\n",
      "Iteration 112, loss = 987964.80064947\n",
      "Iteration 113, loss = 979033.09332168\n",
      "Iteration 114, loss = 970394.66393936\n",
      "Iteration 115, loss = 962049.10330715\n",
      "Iteration 116, loss = 954007.91251132\n",
      "Iteration 117, loss = 946290.44263387\n",
      "Iteration 118, loss = 938885.03658015\n",
      "Iteration 119, loss = 931811.49297173\n",
      "Iteration 120, loss = 925049.61145697\n",
      "Iteration 121, loss = 918610.03204097\n",
      "Iteration 122, loss = 912530.82381971\n",
      "Iteration 123, loss = 906768.01501858\n",
      "Iteration 124, loss = 901317.08104504\n",
      "Iteration 125, loss = 896200.12497152\n",
      "Iteration 126, loss = 891410.76558699\n",
      "Iteration 127, loss = 886951.98085268\n",
      "Iteration 128, loss = 882788.88790807\n",
      "Iteration 129, loss = 878940.68667428\n",
      "Iteration 130, loss = 875384.49315925\n",
      "Iteration 131, loss = 872123.27686743\n",
      "Iteration 132, loss = 869131.06995257\n",
      "Iteration 133, loss = 866398.77854596\n",
      "Iteration 134, loss = 863926.23623220\n",
      "Iteration 135, loss = 861695.82253899\n",
      "Iteration 136, loss = 859705.57350701\n",
      "Iteration 137, loss = 857925.98140232\n",
      "Iteration 138, loss = 856348.54761845\n",
      "Iteration 139, loss = 854952.38355660\n",
      "Iteration 140, loss = 853725.89707711\n",
      "Iteration 141, loss = 852658.08858463\n",
      "Iteration 142, loss = 851735.32739644\n",
      "Iteration 143, loss = 850934.92716374\n",
      "Iteration 144, loss = 850266.45631473\n",
      "Iteration 145, loss = 849704.01955590\n",
      "Iteration 146, loss = 849222.39717919\n",
      "Iteration 147, loss = 848842.51932692\n",
      "Iteration 148, loss = 848514.93224215\n",
      "Iteration 149, loss = 848250.72950781\n",
      "Iteration 150, loss = 848038.96270563\n",
      "Iteration 151, loss = 847871.99719123\n",
      "Iteration 152, loss = 847739.23179038\n",
      "Iteration 153, loss = 847645.51174288\n",
      "Iteration 154, loss = 847547.16336225\n",
      "Iteration 155, loss = 847477.37803295\n",
      "Iteration 156, loss = 847417.27463735\n",
      "Iteration 157, loss = 847363.75928320\n",
      "Iteration 158, loss = 847312.67023255\n",
      "Iteration 159, loss = 847258.55119280\n",
      "Iteration 160, loss = 847201.77805052\n",
      "Iteration 161, loss = 847135.32948409\n",
      "Iteration 162, loss = 847043.69582002\n",
      "Iteration 163, loss = 846973.60133701\n",
      "Iteration 164, loss = 846871.41605185\n",
      "Iteration 165, loss = 846779.52221758\n",
      "Iteration 166, loss = 846693.78853121\n",
      "Iteration 167, loss = 846604.05387846\n",
      "Iteration 168, loss = 846510.71368060\n",
      "Iteration 169, loss = 846412.67383674\n",
      "Iteration 170, loss = 846305.60835565\n",
      "Iteration 171, loss = 846205.62854067\n",
      "Iteration 172, loss = 846101.24363968\n",
      "Iteration 173, loss = 845993.43458410\n",
      "Iteration 174, loss = 845885.29386307\n",
      "Iteration 175, loss = 845787.21816440\n",
      "Iteration 176, loss = 845690.86104150\n",
      "Iteration 177, loss = 845596.38128028\n",
      "Iteration 178, loss = 845503.70679988\n",
      "Iteration 179, loss = 845412.30361914\n",
      "Iteration 180, loss = 845318.38731276\n",
      "Iteration 181, loss = 845223.47181648\n",
      "Iteration 182, loss = 845137.70347266\n",
      "Iteration 183, loss = 845048.45609727\n",
      "Iteration 184, loss = 844964.86599902\n",
      "Iteration 185, loss = 844881.61758702\n",
      "Iteration 186, loss = 844798.18320470\n",
      "Iteration 187, loss = 844714.06205501\n",
      "Iteration 188, loss = 844628.58801612\n",
      "Iteration 189, loss = 844540.70290901\n",
      "Iteration 190, loss = 844446.95043910\n",
      "Iteration 191, loss = 844332.44746839\n",
      "Iteration 192, loss = 844188.97001483\n",
      "Iteration 193, loss = 844097.75878911\n",
      "Iteration 194, loss = 844013.60470311\n",
      "Iteration 195, loss = 843907.11790590\n",
      "Iteration 196, loss = 843793.88549590\n",
      "Iteration 197, loss = 843644.31166023\n",
      "Iteration 198, loss = 843544.98004823\n",
      "Iteration 199, loss = 843434.33391935\n",
      "Iteration 200, loss = 843332.34109893\n",
      "Iteration 201, loss = 843232.06581413\n",
      "Iteration 202, loss = 843130.35241805\n",
      "Iteration 203, loss = 843047.46370203\n",
      "Iteration 204, loss = 842924.10038251\n",
      "Iteration 205, loss = 842819.75132099\n",
      "Iteration 206, loss = 842713.11000072\n",
      "Iteration 207, loss = 842601.66928746\n",
      "Iteration 208, loss = 842495.30215062\n",
      "Iteration 209, loss = 842388.16568112\n",
      "Iteration 210, loss = 842279.57471376\n",
      "Iteration 211, loss = 842160.94572340\n",
      "Iteration 212, loss = 842047.59003746\n",
      "Iteration 213, loss = 841938.08234936\n",
      "Iteration 214, loss = 841827.87897684\n",
      "Iteration 215, loss = 841717.02102163\n",
      "Iteration 216, loss = 841605.48849365\n",
      "Iteration 217, loss = 841493.29583586\n",
      "Iteration 218, loss = 841380.37243067\n",
      "Iteration 219, loss = 841265.47246008\n",
      "Iteration 220, loss = 841150.49297080\n",
      "Iteration 221, loss = 841034.45235164\n",
      "Iteration 222, loss = 840917.36552075\n",
      "Iteration 223, loss = 840799.14555689\n",
      "Iteration 224, loss = 840679.64862287\n",
      "Iteration 225, loss = 840557.85077671\n",
      "Iteration 226, loss = 840442.68137355\n",
      "Iteration 227, loss = 840276.03681773\n",
      "Iteration 228, loss = 840131.02807708\n",
      "Iteration 229, loss = 839978.88890927\n",
      "Iteration 230, loss = 839853.17389768\n",
      "Iteration 231, loss = 839738.16502326\n",
      "Iteration 232, loss = 839601.91109707\n",
      "Iteration 233, loss = 839470.83143167\n",
      "Iteration 234, loss = 839341.07693946\n",
      "Iteration 235, loss = 839209.09749383\n",
      "Iteration 236, loss = 839073.90159331\n",
      "Iteration 237, loss = 838931.98824508\n",
      "Iteration 238, loss = 838774.73534209\n",
      "Iteration 239, loss = 838591.00943432\n",
      "Iteration 240, loss = 838391.47912382\n",
      "Iteration 241, loss = 838252.58640658\n",
      "Iteration 242, loss = 838111.41349829\n",
      "Iteration 243, loss = 837967.81959101\n",
      "Iteration 244, loss = 837821.75611185\n",
      "Iteration 245, loss = 837673.18758170\n",
      "Iteration 246, loss = 837521.16905425\n",
      "Iteration 247, loss = 837386.36614755\n",
      "Iteration 248, loss = 837194.76393194\n",
      "Iteration 249, loss = 836983.86094862\n",
      "Iteration 250, loss = 836773.65114719\n",
      "Iteration 251, loss = 836621.62994112\n",
      "Iteration 252, loss = 836467.81569703\n",
      "Iteration 253, loss = 836312.26289815\n",
      "Iteration 254, loss = 836157.34014898\n",
      "Iteration 255, loss = 835998.33719920\n",
      "Iteration 256, loss = 835840.03841375\n",
      "Iteration 257, loss = 835680.13728953\n",
      "Iteration 258, loss = 835518.72288003\n",
      "Iteration 259, loss = 835356.13810660\n",
      "Iteration 260, loss = 835192.27909423\n",
      "Iteration 261, loss = 835028.48650476\n",
      "Iteration 262, loss = 834861.55131801\n",
      "Iteration 263, loss = 834694.82159018\n",
      "Iteration 264, loss = 834527.16586516\n",
      "Iteration 265, loss = 834358.55877622\n",
      "Iteration 266, loss = 834188.96881781\n",
      "Iteration 267, loss = 834018.38226172\n",
      "Iteration 268, loss = 833846.78215358\n",
      "Iteration 269, loss = 833675.29275913\n",
      "Iteration 270, loss = 833500.54888255\n",
      "Iteration 271, loss = 833325.92796320\n",
      "Iteration 272, loss = 833150.26710363\n",
      "Iteration 273, loss = 832973.50719011\n",
      "Iteration 274, loss = 832795.68712382\n",
      "Iteration 275, loss = 832616.84613413\n",
      "Iteration 276, loss = 832436.99556876\n",
      "Iteration 277, loss = 832256.13540730\n",
      "Iteration 278, loss = 832074.36007897\n",
      "Iteration 279, loss = 831891.15387023\n",
      "Iteration 280, loss = 831706.88783066\n",
      "Iteration 281, loss = 831521.37215522\n",
      "Iteration 282, loss = 831334.60420934\n",
      "Iteration 283, loss = 831146.35388567\n",
      "Iteration 284, loss = 830956.38564389\n",
      "Iteration 285, loss = 830764.19327497\n",
      "Iteration 286, loss = 830569.02652109\n",
      "Iteration 287, loss = 830369.05933037\n",
      "Iteration 288, loss = 830160.03221611\n",
      "Iteration 289, loss = 829923.45001956\n",
      "Iteration 290, loss = 829693.07284853\n",
      "Iteration 291, loss = 829497.39092040\n",
      "Iteration 292, loss = 829302.90970847\n",
      "Iteration 293, loss = 829105.41667360\n",
      "Iteration 294, loss = 828908.67571769\n",
      "Iteration 295, loss = 828708.19637386\n",
      "Iteration 296, loss = 828503.93152146\n",
      "Iteration 297, loss = 828297.42493014\n",
      "Iteration 298, loss = 828090.69781093\n",
      "Iteration 299, loss = 827883.62090461\n",
      "Iteration 300, loss = 827675.80213794\n",
      "Iteration 301, loss = 827466.59985246\n",
      "Iteration 302, loss = 827256.10138799\n",
      "Iteration 303, loss = 827044.73689102\n",
      "Iteration 304, loss = 826832.37802398\n",
      "Iteration 305, loss = 826619.68663951\n",
      "Iteration 306, loss = 826406.15644630\n",
      "Iteration 307, loss = 826191.09620838\n",
      "Iteration 308, loss = 825974.22525796\n",
      "Iteration 309, loss = 825755.85986850\n",
      "Iteration 310, loss = 825536.43810369\n",
      "Iteration 311, loss = 825316.18704681\n",
      "Iteration 312, loss = 825095.11683304\n",
      "Iteration 313, loss = 824873.05730663\n",
      "Iteration 314, loss = 824649.82168896\n",
      "Iteration 315, loss = 824425.44341745\n",
      "Iteration 316, loss = 824200.09409800\n",
      "Iteration 317, loss = 823975.63534394\n",
      "Iteration 318, loss = 823748.93732735\n",
      "Iteration 319, loss = 823523.25928208\n",
      "Iteration 320, loss = 823294.14680689\n",
      "Iteration 321, loss = 823061.61944879\n",
      "Iteration 322, loss = 822827.78200033\n",
      "Iteration 323, loss = 822594.35629549\n",
      "Iteration 324, loss = 822368.43137413\n",
      "Iteration 325, loss = 822125.47216964\n",
      "Iteration 326, loss = 821890.14019132\n",
      "Iteration 327, loss = 821654.71716480\n",
      "Iteration 328, loss = 821418.76810021\n",
      "Iteration 329, loss = 821179.74648701\n",
      "Iteration 330, loss = 820937.51939527\n",
      "Iteration 331, loss = 820694.34997837\n",
      "Iteration 332, loss = 820475.55213334\n",
      "Iteration 333, loss = 820208.82658339\n",
      "Iteration 334, loss = 819965.96433228\n",
      "Iteration 335, loss = 819721.51175813\n",
      "Iteration 336, loss = 819474.50070111\n",
      "Iteration 337, loss = 819225.20089203\n",
      "Iteration 338, loss = 818975.08313506\n",
      "Iteration 339, loss = 818725.11456960\n",
      "Iteration 340, loss = 818474.46485782\n",
      "Iteration 341, loss = 818222.14842704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 342, loss = 817968.32283220\n",
      "Iteration 343, loss = 817713.57251465\n",
      "Iteration 344, loss = 817458.29323875\n",
      "Iteration 345, loss = 817202.65473590\n",
      "Iteration 346, loss = 816946.17342210\n",
      "Iteration 347, loss = 816687.75998390\n",
      "Iteration 348, loss = 816446.06754274\n",
      "Iteration 349, loss = 816169.76280792\n",
      "Iteration 350, loss = 815909.95532474\n",
      "Iteration 351, loss = 815646.28678313\n",
      "Iteration 352, loss = 815381.33423895\n",
      "Iteration 353, loss = 815117.26012114\n",
      "Iteration 354, loss = 814852.91588316\n",
      "Iteration 355, loss = 814586.08131135\n",
      "Iteration 356, loss = 814315.63385926\n",
      "Iteration 357, loss = 814045.02551269\n",
      "Iteration 358, loss = 813775.33602063\n",
      "Iteration 359, loss = 813506.00376414\n",
      "Iteration 360, loss = 813235.05308731\n",
      "Iteration 361, loss = 812959.27041200\n",
      "Iteration 362, loss = 812681.64760123\n",
      "Iteration 363, loss = 812405.46598002\n",
      "Iteration 364, loss = 812129.79694320\n",
      "Iteration 365, loss = 811851.51982275\n",
      "Iteration 366, loss = 811570.07997576\n",
      "Iteration 367, loss = 811287.89772498\n",
      "Iteration 368, loss = 811006.45975044\n",
      "Iteration 369, loss = 810724.28867661\n",
      "Iteration 370, loss = 810439.50197722\n",
      "Iteration 371, loss = 810152.60190625\n",
      "Iteration 372, loss = 809878.65316551\n",
      "Iteration 373, loss = 809581.42741759\n",
      "Iteration 374, loss = 809298.09236945\n",
      "Iteration 375, loss = 809007.50268668\n",
      "Iteration 376, loss = 808730.20224824\n",
      "Iteration 377, loss = 808437.21632700\n",
      "Iteration 378, loss = 808194.23730182\n",
      "Iteration 379, loss = 807890.82501073\n",
      "Iteration 380, loss = 807586.94609999\n",
      "Iteration 381, loss = 807294.23185888\n",
      "Iteration 382, loss = 806991.28224534\n",
      "Iteration 383, loss = 806754.43765194\n",
      "Iteration 384, loss = 806360.86298042\n",
      "Iteration 385, loss = 806062.54346934\n",
      "Iteration 386, loss = 805774.36540365\n",
      "Iteration 387, loss = 805473.90787735\n",
      "Iteration 388, loss = 805157.58056085\n",
      "Iteration 389, loss = 804843.50136520\n",
      "Iteration 390, loss = 804563.63666224\n",
      "Iteration 391, loss = 804234.33482893\n",
      "Iteration 392, loss = 803925.43671820\n",
      "Iteration 393, loss = 803618.60136689\n",
      "Iteration 394, loss = 803311.14772244\n",
      "Iteration 395, loss = 802999.90782528\n",
      "Iteration 396, loss = 802685.86680600\n",
      "Iteration 397, loss = 802372.22458204\n",
      "Iteration 398, loss = 802059.33394127\n",
      "Iteration 399, loss = 801744.65022100\n",
      "Iteration 400, loss = 801427.15165491\n",
      "Iteration 401, loss = 801108.56649270\n",
      "Iteration 402, loss = 800790.41444619\n",
      "Iteration 403, loss = 800471.38901327\n",
      "Iteration 404, loss = 800149.89146730\n",
      "Iteration 405, loss = 799826.82828762\n",
      "Iteration 406, loss = 799503.63086322\n",
      "Iteration 407, loss = 799179.94664845\n",
      "Iteration 408, loss = 798854.52726496\n",
      "Iteration 409, loss = 798527.27643186\n",
      "Iteration 410, loss = 798199.71469971\n",
      "Iteration 411, loss = 797873.51729002\n",
      "Iteration 412, loss = 797546.19193655\n",
      "Iteration 413, loss = 797213.19684337\n",
      "Iteration 414, loss = 796899.81693197\n",
      "Iteration 415, loss = 796550.66409113\n",
      "Iteration 416, loss = 796220.31203335\n",
      "Iteration 417, loss = 795882.75739586\n",
      "Iteration 418, loss = 795543.66155733\n",
      "Iteration 419, loss = 795207.46225430\n",
      "Iteration 420, loss = 794870.22239746\n",
      "Iteration 421, loss = 794528.29992164\n",
      "Iteration 422, loss = 794185.16214678\n",
      "Iteration 423, loss = 793844.35053071\n",
      "Iteration 424, loss = 793503.17548327\n",
      "Iteration 425, loss = 793158.25183571\n",
      "Iteration 426, loss = 792811.42997974\n",
      "Iteration 427, loss = 792465.28299719\n",
      "Iteration 428, loss = 792118.22138633\n",
      "Iteration 429, loss = 791768.39239322\n",
      "Iteration 430, loss = 791417.22617479\n",
      "Iteration 431, loss = 791066.52404173\n",
      "Iteration 432, loss = 790715.05152411\n",
      "Iteration 433, loss = 790361.26616430\n",
      "Iteration 434, loss = 790006.14241488\n",
      "Iteration 435, loss = 789650.77454893\n",
      "Iteration 436, loss = 789294.18080338\n",
      "Iteration 437, loss = 788935.58630774\n",
      "Iteration 438, loss = 788575.94531033\n",
      "Iteration 439, loss = 788215.90431833\n",
      "Iteration 440, loss = 787854.61338166\n",
      "Iteration 441, loss = 787491.70515024\n",
      "Iteration 442, loss = 787132.04074453\n",
      "Iteration 443, loss = 786767.88985927\n",
      "Iteration 444, loss = 786405.98170769\n",
      "Iteration 445, loss = 786035.23747433\n",
      "Iteration 446, loss = 785665.22966827\n",
      "Iteration 447, loss = 785299.93671212\n",
      "Iteration 448, loss = 784930.38678170\n",
      "Iteration 449, loss = 784555.33345186\n",
      "Iteration 450, loss = 784182.37728049\n",
      "Iteration 451, loss = 783810.94059724\n",
      "Iteration 452, loss = 783434.85955818\n",
      "Iteration 453, loss = 783055.97311449\n",
      "Iteration 454, loss = 782678.90954750\n",
      "Iteration 455, loss = 782300.65351058\n",
      "Iteration 456, loss = 781918.45692364\n",
      "Iteration 457, loss = 781536.31644097\n",
      "Iteration 458, loss = 781152.37076440\n",
      "Iteration 459, loss = 780764.48320298\n",
      "Iteration 460, loss = 780375.98919937\n",
      "Iteration 461, loss = 779987.52601942\n",
      "Iteration 462, loss = 779595.12205874\n",
      "Iteration 463, loss = 779200.56226258\n",
      "Iteration 464, loss = 778806.45159912\n",
      "Iteration 465, loss = 778411.12367633\n",
      "Iteration 466, loss = 778013.72788717\n",
      "Iteration 467, loss = 777615.39178364\n",
      "Iteration 468, loss = 777215.53812610\n",
      "Iteration 469, loss = 776813.44245155\n",
      "Iteration 470, loss = 776410.49549983\n",
      "Iteration 471, loss = 776007.29389324\n",
      "Iteration 472, loss = 775603.95074655\n",
      "Iteration 473, loss = 775199.19834836\n",
      "Iteration 474, loss = 774793.33318195\n",
      "Iteration 475, loss = 774384.34137654\n",
      "Iteration 476, loss = 773974.83992288\n",
      "Iteration 477, loss = 773559.76545544\n",
      "Iteration 478, loss = 773145.67913553\n",
      "Iteration 479, loss = 772733.44567755\n",
      "Iteration 480, loss = 772315.46801058\n",
      "Iteration 481, loss = 771898.10843056\n",
      "Iteration 482, loss = 771465.54767951\n",
      "Iteration 483, loss = 771015.58665644\n",
      "Iteration 484, loss = 770528.19175457\n",
      "Iteration 485, loss = 770108.69198792\n",
      "Iteration 486, loss = 769686.26584682\n",
      "Iteration 487, loss = 769256.19646459\n",
      "Iteration 488, loss = 768823.31068666\n",
      "Iteration 489, loss = 768390.63558750\n",
      "Iteration 490, loss = 767958.57776195\n",
      "Iteration 491, loss = 767526.41518455\n",
      "Iteration 492, loss = 767094.10846171\n",
      "Iteration 493, loss = 766658.67826430\n",
      "Iteration 494, loss = 766219.41460956\n",
      "Iteration 495, loss = 765778.29946693\n",
      "Iteration 496, loss = 765336.29956826\n",
      "Iteration 497, loss = 764893.49347375\n",
      "Iteration 498, loss = 764450.70526396\n",
      "Iteration 499, loss = 764006.84152435\n",
      "Iteration 500, loss = 763563.28736981\n",
      "Iteration 501, loss = 763120.47712545\n",
      "Iteration 502, loss = 762673.16961439\n",
      "Iteration 503, loss = 762214.00218734\n",
      "Iteration 504, loss = 761797.61486635\n",
      "Iteration 505, loss = 761324.69466812\n",
      "Iteration 506, loss = 760890.79014097\n",
      "Iteration 507, loss = 760409.12175965\n",
      "Iteration 508, loss = 759971.34586920\n",
      "Iteration 509, loss = 759490.24884455\n",
      "Iteration 510, loss = 759033.45126813\n",
      "Iteration 511, loss = 758585.62943048\n",
      "Iteration 512, loss = 758159.52609441\n",
      "Iteration 513, loss = 757688.74149178\n",
      "Iteration 514, loss = 757199.30166589\n",
      "Iteration 515, loss = 756736.62683498\n",
      "Iteration 516, loss = 756339.83848732\n",
      "Iteration 517, loss = 755826.42138657\n",
      "Iteration 518, loss = 755419.58590801\n",
      "Iteration 519, loss = 754902.59166703\n",
      "Iteration 520, loss = 754408.88535896\n",
      "Iteration 521, loss = 753987.76408667\n",
      "Iteration 522, loss = 753501.59408862\n",
      "Iteration 523, loss = 752994.19513790\n",
      "Iteration 524, loss = 752549.95371572\n",
      "Iteration 525, loss = 752086.16056667\n",
      "Iteration 526, loss = 751578.17589610\n",
      "Iteration 527, loss = 751109.88996649\n",
      "Iteration 528, loss = 750653.62183269\n",
      "Iteration 529, loss = 750157.85044180\n",
      "Iteration 530, loss = 749671.48177989\n",
      "Iteration 531, loss = 749205.03542760\n",
      "Iteration 532, loss = 748713.57915858\n",
      "Iteration 533, loss = 748220.09225219\n",
      "Iteration 534, loss = 747747.94880798\n",
      "Iteration 535, loss = 747263.07526344\n",
      "Iteration 536, loss = 746766.51252278\n",
      "Iteration 537, loss = 746284.30289505\n",
      "Iteration 538, loss = 745797.32900959\n",
      "Iteration 539, loss = 745298.28960429\n",
      "Iteration 540, loss = 744829.87171482\n",
      "Iteration 541, loss = 744320.31113967\n",
      "Iteration 542, loss = 743838.96687952\n",
      "Iteration 543, loss = 743336.92713160\n",
      "Iteration 544, loss = 742838.90187459\n",
      "Iteration 545, loss = 742351.80172067\n",
      "Iteration 546, loss = 741843.80093670\n",
      "Iteration 547, loss = 741351.37977599\n",
      "Iteration 548, loss = 740855.42547762\n",
      "Iteration 549, loss = 740348.54172058\n",
      "Iteration 550, loss = 739850.15869324\n",
      "Iteration 551, loss = 739387.21609099\n",
      "Iteration 552, loss = 738891.88956333\n",
      "Iteration 553, loss = 738431.90085277\n",
      "Iteration 554, loss = 737853.19551981\n",
      "Iteration 555, loss = 737609.95930401\n",
      "Iteration 556, loss = 736898.43833974\n",
      "Iteration 557, loss = 736507.72266319\n",
      "Iteration 558, loss = 735941.38623269\n",
      "Iteration 559, loss = 735335.11725827\n",
      "Iteration 560, loss = 734850.88061142\n",
      "Iteration 561, loss = 734321.67760295\n",
      "Iteration 562, loss = 733812.38947159\n",
      "Iteration 563, loss = 733309.93036104\n",
      "Iteration 564, loss = 732798.00884286\n",
      "Iteration 565, loss = 732282.99445397\n",
      "Iteration 566, loss = 731778.58141710\n",
      "Iteration 567, loss = 731272.77353690\n",
      "Iteration 568, loss = 730758.48782404\n",
      "Iteration 569, loss = 730245.71617925\n",
      "Iteration 570, loss = 729734.50924939\n",
      "Iteration 571, loss = 729216.91445063\n",
      "Iteration 572, loss = 728699.41181608\n",
      "Iteration 573, loss = 728186.64346810\n",
      "Iteration 574, loss = 727670.62865642\n",
      "Iteration 575, loss = 727151.26814005\n",
      "Iteration 576, loss = 726633.32883635\n",
      "Iteration 577, loss = 726113.73526785\n",
      "Iteration 578, loss = 725590.80958855\n",
      "Iteration 579, loss = 725090.15384696\n",
      "Iteration 580, loss = 724557.53441006\n",
      "Iteration 581, loss = 724042.60379052\n",
      "Iteration 582, loss = 723509.29702407\n",
      "Iteration 583, loss = 722988.01531578\n",
      "Iteration 584, loss = 722471.29286792\n",
      "Iteration 585, loss = 721940.83596888\n",
      "Iteration 586, loss = 721416.81144744\n",
      "Iteration 587, loss = 720902.62333436\n",
      "Iteration 588, loss = 720363.37016815\n",
      "Iteration 589, loss = 719832.83447939\n",
      "Iteration 590, loss = 719314.87674520\n",
      "Iteration 591, loss = 718779.04695304\n",
      "Iteration 592, loss = 718244.07886148\n",
      "Iteration 593, loss = 717721.33241019\n",
      "Iteration 594, loss = 717186.97366311\n",
      "Iteration 595, loss = 716649.29389137\n",
      "Iteration 596, loss = 716121.69470159\n",
      "Iteration 597, loss = 715587.24577874\n",
      "Iteration 598, loss = 715048.07127808\n",
      "Iteration 599, loss = 714516.49765819\n",
      "Iteration 600, loss = 713994.95549628\n",
      "Iteration 601, loss = 713449.15441571\n",
      "Iteration 602, loss = 712913.96367096\n",
      "Iteration 603, loss = 712380.28936311\n",
      "Iteration 604, loss = 711843.31692798\n",
      "Iteration 605, loss = 711303.43699193\n",
      "Iteration 606, loss = 710772.54740671\n",
      "Iteration 607, loss = 710238.07822939\n",
      "Iteration 608, loss = 709702.24397355\n",
      "Iteration 609, loss = 709158.37352099\n",
      "Iteration 610, loss = 708612.50803190\n",
      "Iteration 611, loss = 708072.30165014\n",
      "Iteration 612, loss = 707530.91092852\n",
      "Iteration 613, loss = 706996.72526536\n",
      "Iteration 614, loss = 706458.04779646\n",
      "Iteration 615, loss = 705921.96757667\n",
      "Iteration 616, loss = 705367.98854622\n",
      "Iteration 617, loss = 704867.54642434\n",
      "Iteration 618, loss = 704290.70115558\n",
      "Iteration 619, loss = 703765.12145065\n",
      "Iteration 620, loss = 703201.21089593\n",
      "Iteration 621, loss = 702708.99641198\n",
      "Iteration 622, loss = 702111.91912542\n",
      "Iteration 623, loss = 701572.06454304\n",
      "Iteration 624, loss = 701031.80302156\n",
      "Iteration 625, loss = 700485.92442645\n",
      "Iteration 626, loss = 699940.50837615\n",
      "Iteration 627, loss = 699395.09275664\n",
      "Iteration 628, loss = 698850.15052797\n",
      "Iteration 629, loss = 698304.67676444\n",
      "Iteration 630, loss = 697761.94381218\n",
      "Iteration 631, loss = 697216.99197404\n",
      "Iteration 632, loss = 696671.18418139\n",
      "Iteration 633, loss = 696137.88860996\n",
      "Iteration 634, loss = 695607.80230045\n",
      "Iteration 635, loss = 695038.38329457\n",
      "Iteration 636, loss = 694485.45886983\n",
      "Iteration 637, loss = 693958.81531409\n",
      "Iteration 638, loss = 693387.85908507\n",
      "Iteration 639, loss = 692842.01868390\n",
      "Iteration 640, loss = 692314.28576313\n",
      "Iteration 641, loss = 691747.51296342\n",
      "Iteration 642, loss = 691232.56034582\n",
      "Iteration 643, loss = 690647.07071408\n",
      "Iteration 644, loss = 690102.88404247\n",
      "Iteration 645, loss = 689546.25852710\n",
      "Iteration 646, loss = 689004.70262666\n",
      "Iteration 647, loss = 688454.63704447\n",
      "Iteration 648, loss = 687914.29500559\n",
      "Iteration 649, loss = 687398.15188072\n",
      "Iteration 650, loss = 686921.90301746\n",
      "Iteration 651, loss = 686327.76055411\n",
      "Iteration 652, loss = 685900.89799882\n",
      "Iteration 653, loss = 685165.96440878\n",
      "Iteration 654, loss = 684631.07481613\n",
      "Iteration 655, loss = 684082.43871240\n",
      "Iteration 656, loss = 683524.53457454\n",
      "Iteration 657, loss = 682984.28542802\n",
      "Iteration 658, loss = 682427.25908930\n",
      "Iteration 659, loss = 681881.32733304\n",
      "Iteration 660, loss = 681331.47525513\n",
      "Iteration 661, loss = 680783.08716858\n",
      "Iteration 662, loss = 680234.12852886\n",
      "Iteration 663, loss = 679683.23658146\n",
      "Iteration 664, loss = 679134.66698199\n",
      "Iteration 665, loss = 678584.51208379\n",
      "Iteration 666, loss = 678055.60791913\n",
      "Iteration 667, loss = 677490.96458387\n",
      "Iteration 668, loss = 676939.62956718\n",
      "Iteration 669, loss = 676382.89502944\n",
      "Iteration 670, loss = 675839.96700715\n",
      "Iteration 671, loss = 675280.67265623\n",
      "Iteration 672, loss = 674732.53835612\n",
      "Iteration 673, loss = 674181.65458595\n",
      "Iteration 674, loss = 673640.18415941\n",
      "Iteration 675, loss = 673085.45968303\n",
      "Iteration 676, loss = 672531.69900211\n",
      "Iteration 677, loss = 671975.71921226\n",
      "Iteration 678, loss = 671431.13638203\n",
      "Iteration 679, loss = 670874.39163986\n",
      "Iteration 680, loss = 670359.84650408\n",
      "Iteration 681, loss = 669801.24374695\n",
      "Iteration 682, loss = 669228.73993840\n",
      "Iteration 683, loss = 668675.52629171\n",
      "Iteration 684, loss = 668124.14267084\n",
      "Iteration 685, loss = 667585.29770918\n",
      "Iteration 686, loss = 667035.52482033\n",
      "Iteration 687, loss = 666473.25202398\n",
      "Iteration 688, loss = 665927.21321736\n",
      "Iteration 689, loss = 665374.85254089\n",
      "Iteration 690, loss = 664818.84557308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 691, loss = 664273.81383488\n",
      "Iteration 692, loss = 663716.15143339\n",
      "Iteration 693, loss = 663191.58266611\n",
      "Iteration 694, loss = 662616.42159015\n",
      "Iteration 695, loss = 662067.37231060\n",
      "Iteration 696, loss = 661504.82255739\n",
      "Iteration 697, loss = 660957.84878177\n",
      "Iteration 698, loss = 660404.14380966\n",
      "Iteration 699, loss = 659852.59224834\n",
      "Iteration 700, loss = 659314.70853586\n",
      "Iteration 701, loss = 658817.70369697\n",
      "Iteration 702, loss = 658231.51234660\n",
      "Iteration 703, loss = 657761.64471844\n",
      "Iteration 704, loss = 657150.28524429\n",
      "Iteration 705, loss = 656633.27304763\n",
      "Iteration 706, loss = 656033.69799845\n",
      "Iteration 707, loss = 655719.19169511\n",
      "Iteration 708, loss = 655321.92318633\n",
      "Iteration 709, loss = 654895.73012791\n",
      "Iteration 710, loss = 654153.14909358\n",
      "Iteration 711, loss = 653380.09136641\n",
      "Iteration 712, loss = 652830.02644068\n",
      "Iteration 713, loss = 652279.54192729\n",
      "Iteration 714, loss = 651770.28212835\n",
      "Iteration 715, loss = 651228.50195149\n",
      "Iteration 716, loss = 650735.52225642\n",
      "Iteration 717, loss = 650232.83941822\n",
      "Iteration 718, loss = 649675.02235576\n",
      "Iteration 719, loss = 649167.19517511\n",
      "Iteration 720, loss = 648634.63369892\n",
      "Iteration 721, loss = 648064.08521415\n",
      "Iteration 722, loss = 647522.15653632\n",
      "Iteration 723, loss = 647025.33603310\n",
      "Iteration 724, loss = 646462.64170068\n",
      "Iteration 725, loss = 645991.14917583\n",
      "Iteration 726, loss = 645411.29032080\n",
      "Iteration 727, loss = 644925.24895723\n",
      "Iteration 728, loss = 644357.18593018\n",
      "Iteration 729, loss = 643820.83270242\n",
      "Iteration 730, loss = 643321.31578796\n",
      "Iteration 731, loss = 642773.87794670\n",
      "Iteration 732, loss = 642243.83331090\n",
      "Iteration 733, loss = 641728.91837343\n",
      "Iteration 734, loss = 641178.54484557\n",
      "Iteration 735, loss = 640650.61872890\n",
      "Iteration 736, loss = 640126.91690221\n",
      "Iteration 737, loss = 639584.84972689\n",
      "Iteration 738, loss = 639061.96528736\n",
      "Iteration 739, loss = 638520.29473165\n",
      "Iteration 740, loss = 637990.97430217\n",
      "Iteration 741, loss = 637463.35968767\n",
      "Iteration 742, loss = 636934.46690980\n",
      "Iteration 743, loss = 636398.95094544\n",
      "Iteration 744, loss = 635870.71600766\n",
      "Iteration 745, loss = 635339.64429027\n",
      "Iteration 746, loss = 634804.52242518\n",
      "Iteration 747, loss = 634275.57425443\n",
      "Iteration 748, loss = 633745.66539150\n",
      "Iteration 749, loss = 633216.70241779\n",
      "Iteration 750, loss = 632683.75544796\n",
      "Iteration 751, loss = 632175.57092548\n",
      "Iteration 752, loss = 631664.93437252\n",
      "Iteration 753, loss = 631146.94009317\n",
      "Iteration 754, loss = 630588.91752359\n",
      "Iteration 755, loss = 630065.23676084\n",
      "Iteration 756, loss = 629537.01252432\n",
      "Iteration 757, loss = 629024.04623724\n",
      "Iteration 758, loss = 628500.67665651\n",
      "Iteration 759, loss = 627982.60898581\n",
      "Iteration 760, loss = 627492.17774064\n",
      "Iteration 761, loss = 626943.91084913\n",
      "Iteration 762, loss = 626497.86697825\n",
      "Iteration 763, loss = 625905.00298952\n",
      "Iteration 764, loss = 625397.39704369\n",
      "Iteration 765, loss = 624903.92824915\n",
      "Iteration 766, loss = 624428.77979848\n",
      "Iteration 767, loss = 623885.20980373\n",
      "Iteration 768, loss = 623386.62054528\n",
      "Iteration 769, loss = 622850.13752881\n",
      "Iteration 770, loss = 622350.62084084\n",
      "Iteration 771, loss = 621875.10462804\n",
      "Iteration 772, loss = 621403.34411054\n",
      "Iteration 773, loss = 620852.95727446\n",
      "Iteration 774, loss = 620330.07864373\n",
      "Iteration 775, loss = 619821.74416667\n",
      "Iteration 776, loss = 619322.48757332\n",
      "Iteration 777, loss = 618834.38101290\n",
      "Iteration 778, loss = 618326.62716073\n",
      "Iteration 779, loss = 617829.90336911\n",
      "Iteration 780, loss = 617321.30398995\n",
      "Iteration 781, loss = 616827.65940338\n",
      "Iteration 782, loss = 616315.70073673\n",
      "Iteration 783, loss = 615823.79965555\n",
      "Iteration 784, loss = 615315.58142166\n",
      "Iteration 785, loss = 614806.38644722\n",
      "Iteration 786, loss = 614323.41646074\n",
      "Iteration 787, loss = 613808.49654277\n",
      "Iteration 788, loss = 613315.10363310\n",
      "Iteration 789, loss = 612819.00888489\n",
      "Iteration 790, loss = 612304.94262298\n",
      "Iteration 791, loss = 611836.93039229\n",
      "Iteration 792, loss = 611378.01215728\n",
      "Iteration 793, loss = 610919.07770987\n",
      "Iteration 794, loss = 610399.52833416\n",
      "Iteration 795, loss = 609958.47654380\n",
      "Iteration 796, loss = 609570.59197874\n",
      "Iteration 797, loss = 608963.85196944\n",
      "Iteration 798, loss = 608558.97861119\n",
      "Iteration 799, loss = 608101.45925650\n",
      "Iteration 800, loss = 607531.23974743\n",
      "Iteration 801, loss = 607575.28713733\n",
      "Iteration 802, loss = 606846.46333711\n",
      "Iteration 803, loss = 606432.89787534\n",
      "Iteration 804, loss = 605654.81390785\n",
      "Iteration 805, loss = 605364.67751023\n",
      "Iteration 806, loss = 604797.81576488\n",
      "Iteration 807, loss = 604499.15819022\n",
      "Iteration 808, loss = 603881.89711296\n",
      "Iteration 809, loss = 603382.60450630\n",
      "Iteration 810, loss = 602844.40113497\n",
      "Iteration 811, loss = 602415.89501026\n",
      "Iteration 812, loss = 601953.94470248\n",
      "Iteration 813, loss = 601485.23923924\n",
      "Iteration 814, loss = 601027.46673598\n",
      "Iteration 815, loss = 600554.12488269\n",
      "Iteration 816, loss = 600080.60737656\n",
      "Iteration 817, loss = 599617.89598652\n",
      "Iteration 818, loss = 599151.85951280\n",
      "Iteration 819, loss = 598697.11605221\n",
      "Iteration 820, loss = 598199.03310618\n",
      "Iteration 821, loss = 597751.75680857\n",
      "Iteration 822, loss = 597269.51772438\n",
      "Iteration 823, loss = 596816.22852826\n",
      "Iteration 824, loss = 596341.41805258\n",
      "Iteration 825, loss = 595852.29770852\n",
      "Iteration 826, loss = 595373.19126846\n",
      "Iteration 827, loss = 594938.02519720\n",
      "Iteration 828, loss = 594442.93916527\n",
      "Iteration 829, loss = 593983.94931321\n",
      "Iteration 830, loss = 593479.75320123\n",
      "Iteration 831, loss = 593010.12944110\n",
      "Iteration 832, loss = 592530.26546405\n",
      "Iteration 833, loss = 592063.47537096\n",
      "Iteration 834, loss = 591587.33264071\n",
      "Iteration 835, loss = 591107.32978668\n",
      "Iteration 836, loss = 590683.68509047\n",
      "Iteration 837, loss = 590296.85463037\n",
      "Iteration 838, loss = 589763.76700747\n",
      "Iteration 839, loss = 589309.75607382\n",
      "Iteration 840, loss = 588730.50341550\n",
      "Iteration 841, loss = 588273.90646400\n",
      "Iteration 842, loss = 587789.03291632\n",
      "Iteration 843, loss = 587369.38974987\n",
      "Iteration 844, loss = 586904.99699617\n",
      "Iteration 845, loss = 586432.54201254\n",
      "Iteration 846, loss = 585987.52813723\n",
      "Iteration 847, loss = 585448.19544204\n",
      "Iteration 848, loss = 584976.15144624\n",
      "Iteration 849, loss = 584516.92518293\n",
      "Iteration 850, loss = 584067.46297555\n",
      "Iteration 851, loss = 583679.15473736\n",
      "Iteration 852, loss = 583219.62204733\n",
      "Iteration 853, loss = 582675.18632303\n",
      "Iteration 854, loss = 582329.77642344\n",
      "Iteration 855, loss = 581828.58976504\n",
      "Iteration 856, loss = 581357.37313429\n",
      "Iteration 857, loss = 581157.34118297\n",
      "Iteration 858, loss = 580599.22104114\n",
      "Iteration 859, loss = 580111.58235724\n",
      "Iteration 860, loss = 579905.71128859\n",
      "Iteration 861, loss = 579122.82316936\n",
      "Iteration 862, loss = 578664.03531062\n",
      "Iteration 863, loss = 578253.34468705\n",
      "Iteration 864, loss = 577687.39794376\n",
      "Iteration 865, loss = 577251.81238170\n",
      "Iteration 866, loss = 576796.54605872\n",
      "Iteration 867, loss = 576385.94520479\n",
      "Iteration 868, loss = 575886.16084366\n",
      "Iteration 869, loss = 575446.99900174\n",
      "Iteration 870, loss = 574982.95261202\n",
      "Iteration 871, loss = 574524.24374742\n",
      "Iteration 872, loss = 574081.89515190\n",
      "Iteration 873, loss = 573626.11624128\n",
      "Iteration 874, loss = 573188.88257740\n",
      "Iteration 875, loss = 572710.51389779\n",
      "Iteration 876, loss = 572240.31780388\n",
      "Iteration 877, loss = 571767.23944869\n",
      "Iteration 878, loss = 571287.47682001\n",
      "Iteration 879, loss = 570828.18226589\n",
      "Iteration 880, loss = 570372.72260951\n",
      "Iteration 881, loss = 569930.80890419\n",
      "Iteration 882, loss = 569430.24276497\n",
      "Iteration 883, loss = 568966.04052161\n",
      "Iteration 884, loss = 568525.32581178\n",
      "Iteration 885, loss = 568074.66371576\n",
      "Iteration 886, loss = 567638.78591897\n",
      "Iteration 887, loss = 567175.36535834\n",
      "Iteration 888, loss = 566700.10560844\n",
      "Iteration 889, loss = 566243.78002176\n",
      "Iteration 890, loss = 565846.65482097\n",
      "Iteration 891, loss = 565403.91498990\n",
      "Iteration 892, loss = 564928.69005494\n",
      "Iteration 893, loss = 564507.29833949\n",
      "Iteration 894, loss = 564040.37432831\n",
      "Iteration 895, loss = 563673.24623135\n",
      "Iteration 896, loss = 563138.46052929\n",
      "Iteration 897, loss = 562908.12429715\n",
      "Iteration 898, loss = 562628.30555694\n",
      "Iteration 899, loss = 562141.85957480\n",
      "Iteration 900, loss = 561655.42087960\n",
      "Iteration 901, loss = 561069.32003858\n",
      "Iteration 902, loss = 560602.69043616\n",
      "Iteration 903, loss = 560227.17971789\n",
      "Iteration 904, loss = 559773.81509043\n",
      "Iteration 905, loss = 559324.92856564\n",
      "Iteration 906, loss = 558881.98565192\n",
      "Iteration 907, loss = 558464.69950553\n",
      "Iteration 908, loss = 558042.61093354\n",
      "Iteration 909, loss = 557608.39166736\n",
      "Iteration 910, loss = 557171.85360901\n",
      "Iteration 911, loss = 556747.24680299\n",
      "Iteration 912, loss = 556332.67482665\n",
      "Iteration 913, loss = 555908.68266429\n",
      "Iteration 914, loss = 555480.82955640\n",
      "Iteration 915, loss = 555068.05834643\n",
      "Iteration 916, loss = 554650.32173722\n",
      "Iteration 917, loss = 554218.21692735\n",
      "Iteration 918, loss = 553822.27225089\n",
      "Iteration 919, loss = 553383.07122831\n",
      "Iteration 920, loss = 553005.45657243\n",
      "Iteration 921, loss = 552580.73616314\n",
      "Iteration 922, loss = 552186.80736127\n",
      "Iteration 923, loss = 551804.48732661\n",
      "Iteration 924, loss = 551362.72735028\n",
      "Iteration 925, loss = 550942.14711777\n",
      "Iteration 926, loss = 550574.55556185\n",
      "Iteration 927, loss = 550158.41873622\n",
      "Iteration 928, loss = 549766.21464467\n",
      "Iteration 929, loss = 549366.57483555\n",
      "Iteration 930, loss = 548973.11292098\n",
      "Iteration 931, loss = 548589.10611077\n",
      "Iteration 932, loss = 548195.83405014\n",
      "Iteration 933, loss = 547810.00770186\n",
      "Iteration 934, loss = 547424.64900049\n",
      "Iteration 935, loss = 547054.12639241\n",
      "Iteration 936, loss = 546713.38653206\n",
      "Iteration 937, loss = 546327.82027613\n",
      "Iteration 938, loss = 545955.75830573\n",
      "Iteration 939, loss = 545564.63946165\n",
      "Iteration 940, loss = 545188.23994704\n",
      "Iteration 941, loss = 544875.46594553\n",
      "Iteration 942, loss = 544462.53086638\n",
      "Iteration 943, loss = 544095.56475049\n",
      "Iteration 944, loss = 543750.00087819\n",
      "Iteration 945, loss = 543378.55325671\n",
      "Iteration 946, loss = 543023.64350929\n",
      "Iteration 947, loss = 542711.21131151\n",
      "Iteration 948, loss = 542336.01618983\n",
      "Iteration 949, loss = 541971.86061750\n",
      "Iteration 950, loss = 541644.73184601\n",
      "Iteration 951, loss = 541245.02938983\n",
      "Iteration 952, loss = 540904.32936611\n",
      "Iteration 953, loss = 540551.25066328\n",
      "Iteration 954, loss = 540206.71253676\n",
      "Iteration 955, loss = 539855.24061034\n",
      "Iteration 956, loss = 539509.09389542\n",
      "Iteration 957, loss = 539169.26376899\n",
      "Iteration 958, loss = 538835.10843125\n",
      "Iteration 959, loss = 538496.88128008\n",
      "Iteration 960, loss = 538172.27625111\n",
      "Iteration 961, loss = 537806.88833300\n",
      "Iteration 962, loss = 537460.95925131\n",
      "Iteration 963, loss = 537161.10580879\n",
      "Iteration 964, loss = 536801.94316244\n",
      "Iteration 965, loss = 536470.82771515\n",
      "Iteration 966, loss = 536128.46558948\n",
      "Iteration 967, loss = 535794.71704937\n",
      "Iteration 968, loss = 535467.15514465\n",
      "Iteration 969, loss = 535138.67920485\n",
      "Iteration 970, loss = 534838.71165002\n",
      "Iteration 971, loss = 534518.24393611\n",
      "Iteration 972, loss = 534181.80703505\n",
      "Iteration 973, loss = 533848.43055877\n",
      "Iteration 974, loss = 533508.61666797\n",
      "Iteration 975, loss = 533183.10475169\n",
      "Iteration 976, loss = 532864.30369728\n",
      "Iteration 977, loss = 532538.83738547\n",
      "Iteration 978, loss = 532240.51562781\n",
      "Iteration 979, loss = 531922.10333483\n",
      "Iteration 980, loss = 531596.47437328\n",
      "Iteration 981, loss = 531316.15536817\n",
      "Iteration 982, loss = 530953.35977651\n",
      "Iteration 983, loss = 530641.64719239\n",
      "Iteration 984, loss = 530342.29199768\n",
      "Iteration 985, loss = 530008.07535312\n",
      "Iteration 986, loss = 529709.00537588\n",
      "Iteration 987, loss = 529382.69753625\n",
      "Iteration 988, loss = 529076.08086748\n",
      "Iteration 989, loss = 528768.12731842\n",
      "Iteration 990, loss = 528449.60004240\n",
      "Iteration 991, loss = 528151.94755227\n",
      "Iteration 992, loss = 527837.63184952\n",
      "Iteration 993, loss = 527528.80765601\n",
      "Iteration 994, loss = 527221.25219514\n",
      "Iteration 995, loss = 526918.78928030\n",
      "Iteration 996, loss = 526621.34468705\n",
      "Iteration 997, loss = 526326.66479645\n",
      "Iteration 998, loss = 526030.82823063\n",
      "Iteration 999, loss = 525714.58354027\n",
      "Iteration 1000, loss = 525427.52660656\n",
      "Iteration 1001, loss = 525136.40726194\n",
      "Iteration 1002, loss = 524842.45003573\n",
      "Iteration 1003, loss = 524539.22246051\n",
      "Iteration 1004, loss = 524257.88605549\n",
      "Iteration 1005, loss = 523940.25697700\n",
      "Iteration 1006, loss = 523679.55821231\n",
      "Iteration 1007, loss = 523395.03133210\n",
      "Iteration 1008, loss = 523110.03499308\n",
      "Iteration 1009, loss = 522827.11400182\n",
      "Iteration 1010, loss = 522490.98898674\n",
      "Iteration 1011, loss = 522210.87374609\n",
      "Iteration 1012, loss = 521927.33217184\n",
      "Iteration 1013, loss = 521637.63079581\n",
      "Iteration 1014, loss = 521352.12594795\n",
      "Iteration 1015, loss = 521069.86103346\n",
      "Iteration 1016, loss = 520785.64518944\n",
      "Iteration 1017, loss = 520502.73935438\n",
      "Iteration 1018, loss = 520220.98600801\n",
      "Iteration 1019, loss = 519939.23564623\n",
      "Iteration 1020, loss = 519662.51264787\n",
      "Iteration 1021, loss = 519381.17647864\n",
      "Iteration 1022, loss = 519103.60803790\n",
      "Iteration 1023, loss = 518826.14664575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1024, loss = 518547.94110314\n",
      "Iteration 1025, loss = 518273.02945785\n",
      "Iteration 1026, loss = 517998.55796928\n",
      "Iteration 1027, loss = 517724.89821889\n",
      "Iteration 1028, loss = 517451.09206825\n",
      "Iteration 1029, loss = 517178.30340095\n",
      "Iteration 1030, loss = 516908.66548885\n",
      "Iteration 1031, loss = 516637.58144370\n",
      "Iteration 1032, loss = 516363.73504928\n",
      "Iteration 1033, loss = 516095.00499926\n",
      "Iteration 1034, loss = 515827.90545438\n",
      "Iteration 1035, loss = 515562.17750425\n",
      "Iteration 1036, loss = 515315.19282541\n",
      "Iteration 1037, loss = 515026.83166361\n",
      "Iteration 1038, loss = 514758.95586686\n",
      "Iteration 1039, loss = 514494.89424247\n",
      "Iteration 1040, loss = 514237.20699219\n",
      "Iteration 1041, loss = 513973.65558538\n",
      "Iteration 1042, loss = 513709.47777971\n",
      "Iteration 1043, loss = 513466.80890616\n",
      "Iteration 1044, loss = 513183.76173832\n",
      "Iteration 1045, loss = 512925.04124727\n",
      "Iteration 1046, loss = 512663.64125383\n",
      "Iteration 1047, loss = 512408.00341046\n",
      "Iteration 1048, loss = 512148.04968143\n",
      "Iteration 1049, loss = 511891.67718999\n",
      "Iteration 1050, loss = 511627.40119021\n",
      "Iteration 1051, loss = 511372.38257221\n",
      "Iteration 1052, loss = 511113.82285833\n",
      "Iteration 1053, loss = 510854.90713173\n",
      "Iteration 1054, loss = 510600.30029703\n",
      "Iteration 1055, loss = 510344.20307331\n",
      "Iteration 1056, loss = 510087.24823844\n",
      "Iteration 1057, loss = 509829.50727088\n",
      "Iteration 1058, loss = 509576.38163499\n",
      "Iteration 1059, loss = 509320.92140178\n",
      "Iteration 1060, loss = 509062.71813512\n",
      "Iteration 1061, loss = 508809.59766355\n",
      "Iteration 1062, loss = 508558.62801159\n",
      "Iteration 1063, loss = 508298.98791033\n",
      "Iteration 1064, loss = 508051.02348098\n",
      "Iteration 1065, loss = 507787.10444005\n",
      "Iteration 1066, loss = 507534.35365761\n",
      "Iteration 1067, loss = 507280.53777885\n",
      "Iteration 1068, loss = 507021.70620589\n",
      "Iteration 1069, loss = 506766.94955856\n",
      "Iteration 1070, loss = 506511.30862047\n",
      "Iteration 1071, loss = 506255.56412602\n",
      "Iteration 1072, loss = 505999.59045781\n",
      "Iteration 1073, loss = 505744.26238132\n",
      "Iteration 1074, loss = 505489.45571547\n",
      "Iteration 1075, loss = 505233.07167463\n",
      "Iteration 1076, loss = 504983.85664310\n",
      "Iteration 1077, loss = 504721.59570474\n",
      "Iteration 1078, loss = 504469.42937288\n",
      "Iteration 1079, loss = 504203.49098153\n",
      "Iteration 1080, loss = 503942.58348427\n",
      "Iteration 1081, loss = 503690.40762057\n",
      "Iteration 1082, loss = 503416.01570907\n",
      "Iteration 1083, loss = 503151.60381882\n",
      "Iteration 1084, loss = 502892.62671027\n",
      "Iteration 1085, loss = 502626.07897331\n",
      "Iteration 1086, loss = 502344.67465813\n",
      "Iteration 1087, loss = 502077.25797216\n",
      "Iteration 1088, loss = 501799.82757673\n",
      "Iteration 1089, loss = 501527.16723223\n",
      "Iteration 1090, loss = 501258.02209657\n",
      "Iteration 1091, loss = 501005.86401818\n",
      "Iteration 1092, loss = 500763.84717235\n",
      "Iteration 1093, loss = 500547.77676979\n",
      "Iteration 1094, loss = 500348.79708815\n",
      "Iteration 1095, loss = 500103.02032392\n",
      "Iteration 1096, loss = 499836.94182214\n",
      "Iteration 1097, loss = 499567.48357214\n",
      "Iteration 1098, loss = 499317.34465802\n",
      "Iteration 1099, loss = 499077.88683787\n",
      "Iteration 1100, loss = 498844.94049423\n",
      "Iteration 1101, loss = 498613.84405074\n",
      "Iteration 1102, loss = 498386.04892191\n",
      "Iteration 1103, loss = 498156.46653826\n",
      "Iteration 1104, loss = 497910.98683852\n",
      "Iteration 1105, loss = 497682.47056305\n",
      "Iteration 1106, loss = 497429.51326904\n",
      "Iteration 1107, loss = 497192.75934616\n",
      "Iteration 1108, loss = 496942.02797189\n",
      "Iteration 1109, loss = 496702.90299018\n",
      "Iteration 1110, loss = 496451.83456525\n",
      "Iteration 1111, loss = 496212.32277007\n",
      "Iteration 1112, loss = 495966.40572443\n",
      "Iteration 1113, loss = 495731.71838917\n",
      "Iteration 1114, loss = 495490.79042406\n",
      "Iteration 1115, loss = 495257.22930231\n",
      "Iteration 1116, loss = 495015.04634583\n",
      "Iteration 1117, loss = 494779.85356452\n",
      "Iteration 1118, loss = 494533.46356711\n",
      "Iteration 1119, loss = 494291.43017480\n",
      "Iteration 1120, loss = 494047.73947367\n",
      "Iteration 1121, loss = 493808.45268261\n",
      "Iteration 1122, loss = 493566.54273154\n",
      "Iteration 1123, loss = 493330.12914963\n",
      "Iteration 1124, loss = 493090.83038683\n",
      "Iteration 1125, loss = 492849.38564858\n",
      "Iteration 1126, loss = 492612.17595594\n",
      "Iteration 1127, loss = 492371.39529379\n",
      "Iteration 1128, loss = 492143.25113011\n",
      "Iteration 1129, loss = 491929.55545491\n",
      "Iteration 1130, loss = 491653.63949236\n",
      "Iteration 1131, loss = 491453.18357792\n",
      "Iteration 1132, loss = 491170.85793336\n",
      "Iteration 1133, loss = 490956.99834757\n",
      "Iteration 1134, loss = 490693.64178257\n",
      "Iteration 1135, loss = 490473.35369328\n",
      "Iteration 1136, loss = 490213.88267278\n",
      "Iteration 1137, loss = 489990.97346197\n",
      "Iteration 1138, loss = 489735.28896325\n",
      "Iteration 1139, loss = 489509.01949376\n",
      "Iteration 1140, loss = 489255.87793912\n",
      "Iteration 1141, loss = 489025.61902210\n",
      "Iteration 1142, loss = 488775.59054171\n",
      "Iteration 1143, loss = 488535.52222985\n",
      "Iteration 1144, loss = 488295.42035207\n",
      "Iteration 1145, loss = 488055.13350890\n",
      "Iteration 1146, loss = 487823.54686958\n",
      "Iteration 1147, loss = 487605.57199712\n",
      "Iteration 1148, loss = 487335.98187521\n",
      "Iteration 1149, loss = 487126.22319122\n",
      "Iteration 1150, loss = 486857.48086354\n",
      "Iteration 1151, loss = 486635.67609304\n",
      "Iteration 1152, loss = 486375.42421252\n",
      "Iteration 1153, loss = 486141.88574620\n",
      "Iteration 1154, loss = 485894.80121075\n",
      "Iteration 1155, loss = 485659.57131004\n",
      "Iteration 1156, loss = 485412.31328381\n",
      "Iteration 1157, loss = 485176.89171299\n",
      "Iteration 1158, loss = 484930.97089319\n",
      "Iteration 1159, loss = 484692.52781875\n",
      "Iteration 1160, loss = 484447.45896775\n",
      "Iteration 1161, loss = 484209.06188305\n",
      "Iteration 1162, loss = 483964.32880031\n",
      "Iteration 1163, loss = 483724.43790727\n",
      "Iteration 1164, loss = 483486.37578665\n",
      "Iteration 1165, loss = 483247.58440546\n",
      "Iteration 1166, loss = 482996.36358245\n",
      "Iteration 1167, loss = 482768.78288069\n",
      "Iteration 1168, loss = 482533.61462393\n",
      "Iteration 1169, loss = 482276.23159745\n",
      "Iteration 1170, loss = 482061.79793957\n",
      "Iteration 1171, loss = 481791.44102930\n",
      "Iteration 1172, loss = 481555.77610137\n",
      "Iteration 1173, loss = 481303.71764716\n",
      "Iteration 1174, loss = 481067.70198366\n",
      "Iteration 1175, loss = 480825.03691063\n",
      "Iteration 1176, loss = 480579.13382943\n",
      "Iteration 1177, loss = 480335.62114900\n",
      "Iteration 1178, loss = 480091.70957419\n",
      "Iteration 1179, loss = 479865.69396496\n",
      "Iteration 1180, loss = 479602.28686689\n",
      "Iteration 1181, loss = 479404.00232779\n",
      "Iteration 1182, loss = 479153.00158556\n",
      "Iteration 1183, loss = 478882.73866254\n",
      "Iteration 1184, loss = 478658.23051366\n",
      "Iteration 1185, loss = 478377.31621778\n",
      "Iteration 1186, loss = 478158.87068856\n",
      "Iteration 1187, loss = 477887.41508532\n",
      "Iteration 1188, loss = 477662.45321138\n",
      "Iteration 1189, loss = 477395.35490609\n",
      "Iteration 1190, loss = 477165.33482694\n",
      "Iteration 1191, loss = 476903.76401946\n",
      "Iteration 1192, loss = 476669.21145642\n",
      "Iteration 1193, loss = 476410.24416479\n",
      "Iteration 1194, loss = 476171.73761964\n",
      "Iteration 1195, loss = 475914.72408473\n",
      "Iteration 1196, loss = 475674.51191185\n",
      "Iteration 1197, loss = 475418.40240346\n",
      "Iteration 1198, loss = 475174.54792682\n",
      "Iteration 1199, loss = 474919.79851106\n",
      "Iteration 1200, loss = 474675.02483475\n",
      "Iteration 1201, loss = 474420.10819139\n",
      "Iteration 1202, loss = 474173.54006367\n",
      "Iteration 1203, loss = 473922.78321093\n",
      "Iteration 1204, loss = 473666.88274915\n",
      "Iteration 1205, loss = 473415.33703675\n",
      "Iteration 1206, loss = 473167.73768642\n",
      "Iteration 1207, loss = 472914.77615712\n",
      "Iteration 1208, loss = 472664.80739579\n",
      "Iteration 1209, loss = 472429.16143852\n",
      "Iteration 1210, loss = 472161.54425323\n",
      "Iteration 1211, loss = 471903.02277987\n",
      "Iteration 1212, loss = 471651.16154156\n",
      "Iteration 1213, loss = 471398.24779107\n",
      "Iteration 1214, loss = 471145.93242816\n",
      "Iteration 1215, loss = 470892.53730637\n",
      "Iteration 1216, loss = 470644.39374960\n",
      "Iteration 1217, loss = 470383.50924367\n",
      "Iteration 1218, loss = 470131.63367673\n",
      "Iteration 1219, loss = 469882.76483676\n",
      "Iteration 1220, loss = 469618.37585934\n",
      "Iteration 1221, loss = 469376.74802846\n",
      "Iteration 1222, loss = 469113.28792163\n",
      "Iteration 1223, loss = 468849.77088159\n",
      "Iteration 1224, loss = 468588.07605262\n",
      "Iteration 1225, loss = 468329.01513266\n",
      "Iteration 1226, loss = 468067.78308610\n",
      "Iteration 1227, loss = 467808.09593103\n",
      "Iteration 1228, loss = 467547.94278881\n",
      "Iteration 1229, loss = 467285.88777718\n",
      "Iteration 1230, loss = 467025.30923322\n",
      "Iteration 1231, loss = 466761.58114764\n",
      "Iteration 1232, loss = 466505.28383929\n",
      "Iteration 1233, loss = 466238.02188898\n",
      "Iteration 1234, loss = 465973.57497387\n",
      "Iteration 1235, loss = 465719.09911877\n",
      "Iteration 1236, loss = 465453.77904087\n",
      "Iteration 1237, loss = 465182.86349414\n",
      "Iteration 1238, loss = 464928.52695819\n",
      "Iteration 1239, loss = 464655.46587735\n",
      "Iteration 1240, loss = 464392.85064211\n",
      "Iteration 1241, loss = 464133.09052993\n",
      "Iteration 1242, loss = 463870.85073001\n",
      "Iteration 1243, loss = 463587.71333429\n",
      "Iteration 1244, loss = 463324.18041951\n",
      "Iteration 1245, loss = 463063.23127050\n",
      "Iteration 1246, loss = 462788.68550945\n",
      "Iteration 1247, loss = 462526.69612032\n",
      "Iteration 1248, loss = 462256.21936168\n",
      "Iteration 1249, loss = 461992.08949502\n",
      "Iteration 1250, loss = 461717.02169002\n",
      "Iteration 1251, loss = 461451.06710463\n",
      "Iteration 1252, loss = 461194.71227109\n",
      "Iteration 1253, loss = 460911.12038855\n",
      "Iteration 1254, loss = 460652.96398196\n",
      "Iteration 1255, loss = 460372.81541385\n",
      "Iteration 1256, loss = 460107.90390360\n",
      "Iteration 1257, loss = 459841.22711519\n",
      "Iteration 1258, loss = 459567.07191302\n",
      "Iteration 1259, loss = 459288.80433317\n",
      "Iteration 1260, loss = 459024.37080632\n",
      "Iteration 1261, loss = 458743.89258858\n",
      "Iteration 1262, loss = 458477.00472937\n",
      "Iteration 1263, loss = 458195.99172449\n",
      "Iteration 1264, loss = 457939.36533879\n",
      "Iteration 1265, loss = 457673.49476563\n",
      "Iteration 1266, loss = 457375.80261827\n",
      "Iteration 1267, loss = 457172.30643216\n",
      "Iteration 1268, loss = 456920.34351790\n",
      "Iteration 1269, loss = 456561.19618811\n",
      "Iteration 1270, loss = 456390.18017710\n",
      "Iteration 1271, loss = 456057.40783943\n",
      "Iteration 1272, loss = 455777.14116183\n",
      "Iteration 1273, loss = 455524.55020614\n",
      "Iteration 1274, loss = 455172.26502832\n",
      "Iteration 1275, loss = 454945.57843521\n",
      "Iteration 1276, loss = 454620.38989442\n",
      "Iteration 1277, loss = 454389.49949042\n",
      "Iteration 1278, loss = 454090.87815796\n",
      "Iteration 1279, loss = 453804.98538216\n",
      "Iteration 1280, loss = 453550.77069407\n",
      "Iteration 1281, loss = 453224.94974403\n",
      "Iteration 1282, loss = 452970.98641896\n",
      "Iteration 1283, loss = 452664.15002023\n",
      "Iteration 1284, loss = 452413.96173352\n",
      "Iteration 1285, loss = 452130.56989424\n",
      "Iteration 1286, loss = 451830.46535839\n",
      "Iteration 1287, loss = 451600.43717082\n",
      "Iteration 1288, loss = 451283.28463854\n",
      "Iteration 1289, loss = 450992.22881209\n",
      "Iteration 1290, loss = 450726.74654700\n",
      "Iteration 1291, loss = 450408.94853020\n",
      "Iteration 1292, loss = 450146.85444922\n",
      "Iteration 1293, loss = 449839.98864868\n",
      "Iteration 1294, loss = 449577.30095160\n",
      "Iteration 1295, loss = 449283.78206015\n",
      "Iteration 1296, loss = 448995.44300692\n",
      "Iteration 1297, loss = 448720.30301461\n",
      "Iteration 1298, loss = 448413.03246501\n",
      "Iteration 1299, loss = 448138.58474470\n",
      "Iteration 1300, loss = 447850.45808571\n",
      "Iteration 1301, loss = 447554.11206552\n",
      "Iteration 1302, loss = 447263.85261401\n",
      "Iteration 1303, loss = 446979.17403634\n",
      "Iteration 1304, loss = 446691.29090879\n",
      "Iteration 1305, loss = 446398.18123803\n",
      "Iteration 1306, loss = 446111.80119162\n",
      "Iteration 1307, loss = 445816.83298648\n",
      "Iteration 1308, loss = 445529.91373612\n",
      "Iteration 1309, loss = 445234.53071278\n",
      "Iteration 1310, loss = 444947.21803202\n",
      "Iteration 1311, loss = 444651.86535228\n",
      "Iteration 1312, loss = 444363.83565964\n",
      "Iteration 1313, loss = 444068.43449739\n",
      "Iteration 1314, loss = 443780.82762191\n",
      "Iteration 1315, loss = 443507.30367745\n",
      "Iteration 1316, loss = 443188.14070020\n",
      "Iteration 1317, loss = 442945.50980238\n",
      "Iteration 1318, loss = 442727.85966635\n",
      "Iteration 1319, loss = 442311.01456311\n",
      "Iteration 1320, loss = 442153.51210910\n",
      "Iteration 1321, loss = 441728.84758688\n",
      "Iteration 1322, loss = 441493.26180660\n",
      "Iteration 1323, loss = 441150.63434775\n",
      "Iteration 1324, loss = 440835.46636542\n",
      "Iteration 1325, loss = 440564.43243958\n",
      "Iteration 1326, loss = 440222.69926486\n",
      "Iteration 1327, loss = 440008.68139536\n",
      "Iteration 1328, loss = 439667.93210127\n",
      "Iteration 1329, loss = 439335.63706643\n",
      "Iteration 1330, loss = 439088.23524284\n",
      "Iteration 1331, loss = 438713.45075792\n",
      "Iteration 1332, loss = 438441.35789967\n",
      "Iteration 1333, loss = 438113.96610099\n",
      "Iteration 1334, loss = 437816.20448598\n",
      "Iteration 1335, loss = 437513.22733229\n",
      "Iteration 1336, loss = 437193.73890723\n",
      "Iteration 1337, loss = 436905.51014324\n",
      "Iteration 1338, loss = 436574.89259537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1339, loss = 436291.95343163\n",
      "Iteration 1340, loss = 435960.16727871\n",
      "Iteration 1341, loss = 435695.92714167\n",
      "Iteration 1342, loss = 435489.46474942\n",
      "Iteration 1343, loss = 435045.25028342\n",
      "Iteration 1344, loss = 434928.86841617\n",
      "Iteration 1345, loss = 434553.06905548\n",
      "Iteration 1346, loss = 434199.00139535\n",
      "Iteration 1347, loss = 433970.20774797\n",
      "Iteration 1348, loss = 433502.33029530\n",
      "Iteration 1349, loss = 433302.49725766\n",
      "Iteration 1350, loss = 432880.19649952\n",
      "Iteration 1351, loss = 432703.40972741\n",
      "Iteration 1352, loss = 432317.53685627\n",
      "Iteration 1353, loss = 432014.91789315\n",
      "Iteration 1354, loss = 431698.03305487\n",
      "Iteration 1355, loss = 431356.54193080\n",
      "Iteration 1356, loss = 431075.88452032\n",
      "Iteration 1357, loss = 430714.38409269\n",
      "Iteration 1358, loss = 430486.78862484\n",
      "Iteration 1359, loss = 430114.59074719\n",
      "Iteration 1360, loss = 429787.25197427\n",
      "Iteration 1361, loss = 429488.67032860\n",
      "Iteration 1362, loss = 429141.78657076\n",
      "Iteration 1363, loss = 428853.56999240\n",
      "Iteration 1364, loss = 428499.22114676\n",
      "Iteration 1365, loss = 428227.12904796\n",
      "Iteration 1366, loss = 427860.13449422\n",
      "Iteration 1367, loss = 427558.76903587\n",
      "Iteration 1368, loss = 427227.39952269\n",
      "Iteration 1369, loss = 426912.77963412\n",
      "Iteration 1370, loss = 426607.03125636\n",
      "Iteration 1371, loss = 426265.74194523\n",
      "Iteration 1372, loss = 425966.69607312\n",
      "Iteration 1373, loss = 425619.39203029\n",
      "Iteration 1374, loss = 425323.73007748\n",
      "Iteration 1375, loss = 424976.29015306\n",
      "Iteration 1376, loss = 424676.93484191\n",
      "Iteration 1377, loss = 424330.18235265\n",
      "Iteration 1378, loss = 424025.91141564\n",
      "Iteration 1379, loss = 423682.83509734\n",
      "Iteration 1380, loss = 423381.00583532\n",
      "Iteration 1381, loss = 423111.49065602\n",
      "Iteration 1382, loss = 422718.64398637\n",
      "Iteration 1383, loss = 422490.60744557\n",
      "Iteration 1384, loss = 422108.49177882\n",
      "Iteration 1385, loss = 421783.20578557\n",
      "Iteration 1386, loss = 421456.11989291\n",
      "Iteration 1387, loss = 421104.48781785\n",
      "Iteration 1388, loss = 420804.72266389\n",
      "Iteration 1389, loss = 420439.23209416\n",
      "Iteration 1390, loss = 420165.20661977\n",
      "Iteration 1391, loss = 419774.83211078\n",
      "Iteration 1392, loss = 419475.14409022\n",
      "Iteration 1393, loss = 419118.62791210\n",
      "Iteration 1394, loss = 418811.51438434\n",
      "Iteration 1395, loss = 418481.72266935\n",
      "Iteration 1396, loss = 418130.90868499\n",
      "Iteration 1397, loss = 417828.68667635\n",
      "Iteration 1398, loss = 417456.64128380\n",
      "Iteration 1399, loss = 417148.58982235\n",
      "Iteration 1400, loss = 416791.67100669\n",
      "Iteration 1401, loss = 416477.73847878\n",
      "Iteration 1402, loss = 416127.70459651\n",
      "Iteration 1403, loss = 415798.87800685\n",
      "Iteration 1404, loss = 415453.18251443\n",
      "Iteration 1405, loss = 415121.03989900\n",
      "Iteration 1406, loss = 414789.70300596\n",
      "Iteration 1407, loss = 414439.04450131\n",
      "Iteration 1408, loss = 414113.34276046\n",
      "Iteration 1409, loss = 413769.17464316\n",
      "Iteration 1410, loss = 413419.59521196\n",
      "Iteration 1411, loss = 413110.65266277\n",
      "Iteration 1412, loss = 412755.88862285\n",
      "Iteration 1413, loss = 412396.30761041\n",
      "Iteration 1414, loss = 412074.18599364\n",
      "Iteration 1415, loss = 411700.69299128\n",
      "Iteration 1416, loss = 411378.81996228\n",
      "Iteration 1417, loss = 411010.50337067\n",
      "Iteration 1418, loss = 410669.87313775\n",
      "Iteration 1419, loss = 410315.09331740\n",
      "Iteration 1420, loss = 409972.24326419\n",
      "Iteration 1421, loss = 409635.68193716\n",
      "Iteration 1422, loss = 409277.32749721\n",
      "Iteration 1423, loss = 408924.56795741\n",
      "Iteration 1424, loss = 408584.06185772\n",
      "Iteration 1425, loss = 408227.99730441\n",
      "Iteration 1426, loss = 407877.60755843\n",
      "Iteration 1427, loss = 407525.64022409\n",
      "Iteration 1428, loss = 407172.23236161\n",
      "Iteration 1429, loss = 406820.88539347\n",
      "Iteration 1430, loss = 406466.21887159\n",
      "Iteration 1431, loss = 406115.33059064\n",
      "Iteration 1432, loss = 405762.66852669\n",
      "Iteration 1433, loss = 405404.54739501\n",
      "Iteration 1434, loss = 405051.26512089\n",
      "Iteration 1435, loss = 404710.19440203\n",
      "Iteration 1436, loss = 404335.00169311\n",
      "Iteration 1437, loss = 403990.28689872\n",
      "Iteration 1438, loss = 403629.07258595\n",
      "Iteration 1439, loss = 403262.80822610\n",
      "Iteration 1440, loss = 402920.87204542\n",
      "Iteration 1441, loss = 402547.33303799\n",
      "Iteration 1442, loss = 402185.15107371\n",
      "Iteration 1443, loss = 401841.08290989\n",
      "Iteration 1444, loss = 401470.69283274\n",
      "Iteration 1445, loss = 401098.27326831\n",
      "Iteration 1446, loss = 400749.66030177\n",
      "Iteration 1447, loss = 400372.55966700\n",
      "Iteration 1448, loss = 400012.00639551\n",
      "Iteration 1449, loss = 399645.87877210\n",
      "Iteration 1450, loss = 399272.06323251\n",
      "Iteration 1451, loss = 398909.76942927\n",
      "Iteration 1452, loss = 398543.31157907\n",
      "Iteration 1453, loss = 398173.81631337\n",
      "Iteration 1454, loss = 397811.48383868\n",
      "Iteration 1455, loss = 397446.27070068\n",
      "Iteration 1456, loss = 397076.50390204\n",
      "Iteration 1457, loss = 396699.07068939\n",
      "Iteration 1458, loss = 396347.54202448\n",
      "Iteration 1459, loss = 395956.25071786\n",
      "Iteration 1460, loss = 395594.32315336\n",
      "Iteration 1461, loss = 395232.18471553\n",
      "Iteration 1462, loss = 394826.40370151\n",
      "Iteration 1463, loss = 394478.94425218\n",
      "Iteration 1464, loss = 394107.70639070\n",
      "Iteration 1465, loss = 393696.28734641\n",
      "Iteration 1466, loss = 393367.32604436\n",
      "Iteration 1467, loss = 393002.75641985\n",
      "Iteration 1468, loss = 392560.21072451\n",
      "Iteration 1469, loss = 392278.34876466\n",
      "Iteration 1470, loss = 391844.78476060\n",
      "Iteration 1471, loss = 391432.93108303\n",
      "Iteration 1472, loss = 391106.79780356\n",
      "Iteration 1473, loss = 390625.73826595\n",
      "Iteration 1474, loss = 390291.28621455\n",
      "Iteration 1475, loss = 389843.10434074\n",
      "Iteration 1476, loss = 389468.36439561\n",
      "Iteration 1477, loss = 389052.26929056\n",
      "Iteration 1478, loss = 388638.85451080\n",
      "Iteration 1479, loss = 388259.10110628\n",
      "Iteration 1480, loss = 387818.98509106\n",
      "Iteration 1481, loss = 387410.63062350\n",
      "Iteration 1482, loss = 387001.72550639\n",
      "Iteration 1483, loss = 386565.05776794\n",
      "Iteration 1484, loss = 386166.99691792\n",
      "Iteration 1485, loss = 385742.09324951\n",
      "Iteration 1486, loss = 385348.05678532\n",
      "Iteration 1487, loss = 384953.82348810\n",
      "Iteration 1488, loss = 384577.58231737\n",
      "Iteration 1489, loss = 384202.09343569\n",
      "Iteration 1490, loss = 383783.04548032\n",
      "Iteration 1491, loss = 383351.53129013\n",
      "Iteration 1492, loss = 382923.73105206\n",
      "Iteration 1493, loss = 382510.42048984\n",
      "Iteration 1494, loss = 382099.77040015\n",
      "Iteration 1495, loss = 381708.89730451\n",
      "Iteration 1496, loss = 381281.30015017\n",
      "Iteration 1497, loss = 380882.69861637\n",
      "Iteration 1498, loss = 380490.26121465\n",
      "Iteration 1499, loss = 380090.03577271\n",
      "Iteration 1500, loss = 379762.13878602\n",
      "Iteration 1501, loss = 379404.16873802\n",
      "Iteration 1502, loss = 378994.65028322\n",
      "Iteration 1503, loss = 378591.43381184\n",
      "Iteration 1504, loss = 378176.07206219\n",
      "Iteration 1505, loss = 377754.08058806\n",
      "Iteration 1506, loss = 377417.26336784\n",
      "Iteration 1507, loss = 377004.99579448\n",
      "Iteration 1508, loss = 376605.08015070\n",
      "Iteration 1509, loss = 376253.19392976\n",
      "Iteration 1510, loss = 375840.95506482\n",
      "Iteration 1511, loss = 375446.98339765\n",
      "Iteration 1512, loss = 375076.54253672\n",
      "Iteration 1513, loss = 374658.26776226\n",
      "Iteration 1514, loss = 374257.37125432\n",
      "Iteration 1515, loss = 373870.19897833\n",
      "Iteration 1516, loss = 373440.50079338\n",
      "Iteration 1517, loss = 373052.75283986\n",
      "Iteration 1518, loss = 372638.67446471\n",
      "Iteration 1519, loss = 372227.57811509\n",
      "Iteration 1520, loss = 371826.35247118\n",
      "Iteration 1521, loss = 371424.16567817\n",
      "Iteration 1522, loss = 371015.96304859\n",
      "Iteration 1523, loss = 370617.26546715\n",
      "Iteration 1524, loss = 370206.32702122\n",
      "Iteration 1525, loss = 369793.07334204\n",
      "Iteration 1526, loss = 369386.83852523\n",
      "Iteration 1527, loss = 368988.75650125\n",
      "Iteration 1528, loss = 368545.13468744\n",
      "Iteration 1529, loss = 368135.25096735\n",
      "Iteration 1530, loss = 367709.37481803\n",
      "Iteration 1531, loss = 367292.87987666\n",
      "Iteration 1532, loss = 366881.44495642\n",
      "Iteration 1533, loss = 366446.12462094\n",
      "Iteration 1534, loss = 366018.70751312\n",
      "Iteration 1535, loss = 365599.17318299\n",
      "Iteration 1536, loss = 365188.96377045\n",
      "Iteration 1537, loss = 364770.23246094\n",
      "Iteration 1538, loss = 364372.48468468\n",
      "Iteration 1539, loss = 364013.00141527\n",
      "Iteration 1540, loss = 363621.21316574\n",
      "Iteration 1541, loss = 363190.55506405\n",
      "Iteration 1542, loss = 362756.41368198\n",
      "Iteration 1543, loss = 362352.12198661\n",
      "Iteration 1544, loss = 361944.21042742\n",
      "Iteration 1545, loss = 361524.24857157\n",
      "Iteration 1546, loss = 361124.43197864\n",
      "Iteration 1547, loss = 360730.44932347\n",
      "Iteration 1548, loss = 360320.24225214\n",
      "Iteration 1549, loss = 359901.24593767\n",
      "Iteration 1550, loss = 359479.18437121\n",
      "Iteration 1551, loss = 359069.83133480\n",
      "Iteration 1552, loss = 358652.31390682\n",
      "Iteration 1553, loss = 358228.32134882\n",
      "Iteration 1554, loss = 357811.92372899\n",
      "Iteration 1555, loss = 357401.57363681\n",
      "Iteration 1556, loss = 356969.02466042\n",
      "Iteration 1557, loss = 356536.31051486\n",
      "Iteration 1558, loss = 356113.12317677\n",
      "Iteration 1559, loss = 355689.48974253\n",
      "Iteration 1560, loss = 355267.01286965\n",
      "Iteration 1561, loss = 354839.95634322\n",
      "Iteration 1562, loss = 354406.16550230\n",
      "Iteration 1563, loss = 353980.10702753\n",
      "Iteration 1564, loss = 353546.34923213\n",
      "Iteration 1565, loss = 353110.00443890\n",
      "Iteration 1566, loss = 352710.34100034\n",
      "Iteration 1567, loss = 352267.24165368\n",
      "Iteration 1568, loss = 351854.23167285\n",
      "Iteration 1569, loss = 351505.17551736\n",
      "Iteration 1570, loss = 351055.38193818\n",
      "Iteration 1571, loss = 350674.75672956\n",
      "Iteration 1572, loss = 350292.57859177\n",
      "Iteration 1573, loss = 349812.16451894\n",
      "Iteration 1574, loss = 349422.97721487\n",
      "Iteration 1575, loss = 349033.73876747\n",
      "Iteration 1576, loss = 348561.79300788\n",
      "Iteration 1577, loss = 348243.96272689\n",
      "Iteration 1578, loss = 347866.90934623\n",
      "Iteration 1579, loss = 347344.31944755\n",
      "Iteration 1580, loss = 347080.30558102\n",
      "Iteration 1581, loss = 346622.51181030\n",
      "Iteration 1582, loss = 346144.62516788\n",
      "Iteration 1583, loss = 345841.88831285\n",
      "Iteration 1584, loss = 345290.24664324\n",
      "Iteration 1585, loss = 344938.77014081\n",
      "Iteration 1586, loss = 344484.76683427\n",
      "Iteration 1587, loss = 344042.67513873\n",
      "Iteration 1588, loss = 343662.38281799\n",
      "Iteration 1589, loss = 343182.07107330\n",
      "Iteration 1590, loss = 342874.07867249\n",
      "Iteration 1591, loss = 342511.66130703\n",
      "Iteration 1592, loss = 341930.94613883\n",
      "Iteration 1593, loss = 341715.25097772\n",
      "Iteration 1594, loss = 341296.88255441\n",
      "Iteration 1595, loss = 340728.83117048\n",
      "Iteration 1596, loss = 340504.74529569\n",
      "Iteration 1597, loss = 339835.79718649\n",
      "Iteration 1598, loss = 339577.44116406\n",
      "Iteration 1599, loss = 339014.09612527\n",
      "Iteration 1600, loss = 338665.64556923\n",
      "Iteration 1601, loss = 338236.80708733\n",
      "Iteration 1602, loss = 337756.12195272\n",
      "Iteration 1603, loss = 337410.93837790\n",
      "Iteration 1604, loss = 336869.14705817\n",
      "Iteration 1605, loss = 336533.62959841\n",
      "Iteration 1606, loss = 336021.57167226\n",
      "Iteration 1607, loss = 335652.64718887\n",
      "Iteration 1608, loss = 335191.44080942\n",
      "Iteration 1609, loss = 334757.13223530\n",
      "Iteration 1610, loss = 334370.04858031\n",
      "Iteration 1611, loss = 333890.56258555\n",
      "Iteration 1612, loss = 333471.81968289\n",
      "Iteration 1613, loss = 333055.65351964\n",
      "Iteration 1614, loss = 332599.86615331\n",
      "Iteration 1615, loss = 332180.94227086\n",
      "Iteration 1616, loss = 331749.32881192\n",
      "Iteration 1617, loss = 331320.70241630\n",
      "Iteration 1618, loss = 330905.11118529\n",
      "Iteration 1619, loss = 330459.80004678\n",
      "Iteration 1620, loss = 330032.76442260\n",
      "Iteration 1621, loss = 329605.88973957\n",
      "Iteration 1622, loss = 329173.17916223\n",
      "Iteration 1623, loss = 328738.71364358\n",
      "Iteration 1624, loss = 328316.92302859\n",
      "Iteration 1625, loss = 327898.62775483\n",
      "Iteration 1626, loss = 327461.79159766\n",
      "Iteration 1627, loss = 327023.61922302\n",
      "Iteration 1628, loss = 326607.54762246\n",
      "Iteration 1629, loss = 326170.23186686\n",
      "Iteration 1630, loss = 325737.68381578\n",
      "Iteration 1631, loss = 325327.81467291\n",
      "Iteration 1632, loss = 324887.34900042\n",
      "Iteration 1633, loss = 324443.09658393\n",
      "Iteration 1634, loss = 324032.04720435\n",
      "Iteration 1635, loss = 323606.18028201\n",
      "Iteration 1636, loss = 323151.32313656\n",
      "Iteration 1637, loss = 322728.96761601\n",
      "Iteration 1638, loss = 322284.63426841\n",
      "Iteration 1639, loss = 321843.81209564\n",
      "Iteration 1640, loss = 321431.83260028\n",
      "Iteration 1641, loss = 321042.61532088\n",
      "Iteration 1642, loss = 320530.51452909\n",
      "Iteration 1643, loss = 320191.32833908\n",
      "Iteration 1644, loss = 319872.21008224\n",
      "Iteration 1645, loss = 319226.89517570\n",
      "Iteration 1646, loss = 319025.65356180\n",
      "Iteration 1647, loss = 318531.30188933\n",
      "Iteration 1648, loss = 317976.61694207\n",
      "Iteration 1649, loss = 317716.98296293\n",
      "Iteration 1650, loss = 317051.98881948\n",
      "Iteration 1651, loss = 316768.79755050\n",
      "Iteration 1652, loss = 316212.43178256\n",
      "Iteration 1653, loss = 315805.90425804\n",
      "Iteration 1654, loss = 315404.78273147\n",
      "Iteration 1655, loss = 314862.42334810\n",
      "Iteration 1656, loss = 314570.87666628\n",
      "Iteration 1657, loss = 314034.72244951\n",
      "Iteration 1658, loss = 313584.96556216\n",
      "Iteration 1659, loss = 313205.70801900\n",
      "Iteration 1660, loss = 312647.13466632\n",
      "Iteration 1661, loss = 312267.27876496\n",
      "Iteration 1662, loss = 311773.58684452\n",
      "Iteration 1663, loss = 311344.02071114\n",
      "Iteration 1664, loss = 310933.01148865\n",
      "Iteration 1665, loss = 310441.57767789\n",
      "Iteration 1666, loss = 310111.47426947\n",
      "Iteration 1667, loss = 309631.14389591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1668, loss = 309135.06326658\n",
      "Iteration 1669, loss = 308826.00007501\n",
      "Iteration 1670, loss = 308322.74645389\n",
      "Iteration 1671, loss = 307832.47412139\n",
      "Iteration 1672, loss = 307485.82704468\n",
      "Iteration 1673, loss = 306932.15889193\n",
      "Iteration 1674, loss = 306541.61968973\n",
      "Iteration 1675, loss = 306074.92333211\n",
      "Iteration 1676, loss = 305605.64925101\n",
      "Iteration 1677, loss = 305194.74698073\n",
      "Iteration 1678, loss = 304709.52476089\n",
      "Iteration 1679, loss = 304309.32332877\n",
      "Iteration 1680, loss = 303833.45974517\n",
      "Iteration 1681, loss = 303386.63230922\n",
      "Iteration 1682, loss = 302961.27447946\n",
      "Iteration 1683, loss = 302478.85406263\n",
      "Iteration 1684, loss = 302041.10587962\n",
      "Iteration 1685, loss = 301600.66795452\n",
      "Iteration 1686, loss = 301132.88522987\n",
      "Iteration 1687, loss = 300695.14320056\n",
      "Iteration 1688, loss = 300240.79559796\n",
      "Iteration 1689, loss = 299783.26689022\n",
      "Iteration 1690, loss = 299335.13094237\n",
      "Iteration 1691, loss = 298886.84746447\n",
      "Iteration 1692, loss = 298436.44107351\n",
      "Iteration 1693, loss = 297987.88009251\n",
      "Iteration 1694, loss = 297539.98511384\n",
      "Iteration 1695, loss = 297085.52790215\n",
      "Iteration 1696, loss = 296631.15993990\n",
      "Iteration 1697, loss = 296181.71762561\n",
      "Iteration 1698, loss = 295729.50814393\n",
      "Iteration 1699, loss = 295276.35424442\n",
      "Iteration 1700, loss = 294829.19588265\n",
      "Iteration 1701, loss = 294378.56559657\n",
      "Iteration 1702, loss = 293920.25562166\n",
      "Iteration 1703, loss = 293470.36890549\n",
      "Iteration 1704, loss = 293018.51866644\n",
      "Iteration 1705, loss = 292563.02818888\n",
      "Iteration 1706, loss = 292108.78943881\n",
      "Iteration 1707, loss = 291653.86553234\n",
      "Iteration 1708, loss = 291200.48189223\n",
      "Iteration 1709, loss = 290752.09989978\n",
      "Iteration 1710, loss = 290286.80022815\n",
      "Iteration 1711, loss = 289828.41644402\n",
      "Iteration 1712, loss = 289375.04306554\n",
      "Iteration 1713, loss = 288909.87027006\n",
      "Iteration 1714, loss = 288448.68497632\n",
      "Iteration 1715, loss = 287995.95727535\n",
      "Iteration 1716, loss = 287538.06886687\n",
      "Iteration 1717, loss = 287075.57716689\n",
      "Iteration 1718, loss = 286621.80387881\n",
      "Iteration 1719, loss = 286176.86706948\n",
      "Iteration 1720, loss = 285735.96838646\n",
      "Iteration 1721, loss = 285298.24573254\n",
      "Iteration 1722, loss = 284866.92009290\n",
      "Iteration 1723, loss = 284379.17106384\n",
      "Iteration 1724, loss = 283913.79171317\n",
      "Iteration 1725, loss = 283473.06451706\n",
      "Iteration 1726, loss = 283016.98355709\n",
      "Iteration 1727, loss = 282565.71685772\n",
      "Iteration 1728, loss = 282117.79302119\n",
      "Iteration 1729, loss = 281670.42977444\n",
      "Iteration 1730, loss = 281210.31037716\n",
      "Iteration 1731, loss = 280775.01447622\n",
      "Iteration 1732, loss = 280321.03950792\n",
      "Iteration 1733, loss = 279854.38326998\n",
      "Iteration 1734, loss = 279415.98776268\n",
      "Iteration 1735, loss = 278955.14298645\n",
      "Iteration 1736, loss = 278491.61439255\n",
      "Iteration 1737, loss = 278058.25601384\n",
      "Iteration 1738, loss = 277599.74423075\n",
      "Iteration 1739, loss = 277135.48355736\n",
      "Iteration 1740, loss = 276692.32939564\n",
      "Iteration 1741, loss = 276234.64959187\n",
      "Iteration 1742, loss = 275779.57200249\n",
      "Iteration 1743, loss = 275328.36932953\n",
      "Iteration 1744, loss = 274868.63942909\n",
      "Iteration 1745, loss = 274412.40168685\n",
      "Iteration 1746, loss = 273961.48727547\n",
      "Iteration 1747, loss = 273500.37182871\n",
      "Iteration 1748, loss = 273059.55194429\n",
      "Iteration 1749, loss = 272629.08401551\n",
      "Iteration 1750, loss = 272146.02424377\n",
      "Iteration 1751, loss = 271674.01614411\n",
      "Iteration 1752, loss = 271220.30758429\n",
      "Iteration 1753, loss = 270766.75471796\n",
      "Iteration 1754, loss = 270308.09273404\n",
      "Iteration 1755, loss = 269848.80834214\n",
      "Iteration 1756, loss = 269391.89550772\n",
      "Iteration 1757, loss = 268937.21995854\n",
      "Iteration 1758, loss = 268480.18453038\n",
      "Iteration 1759, loss = 268026.50765261\n",
      "Iteration 1760, loss = 267566.31223755\n",
      "Iteration 1761, loss = 267124.32132921\n",
      "Iteration 1762, loss = 266690.30494560\n",
      "Iteration 1763, loss = 266206.31092519\n",
      "Iteration 1764, loss = 265736.44648038\n",
      "Iteration 1765, loss = 265296.21146548\n",
      "Iteration 1766, loss = 264839.89912062\n",
      "Iteration 1767, loss = 264364.74025742\n",
      "Iteration 1768, loss = 263919.43707009\n",
      "Iteration 1769, loss = 263497.95910039\n",
      "Iteration 1770, loss = 263000.11373971\n",
      "Iteration 1771, loss = 262539.58414882\n",
      "Iteration 1772, loss = 262108.90319758\n",
      "Iteration 1773, loss = 261626.47315207\n",
      "Iteration 1774, loss = 261161.84943490\n",
      "Iteration 1775, loss = 260715.56074298\n",
      "Iteration 1776, loss = 260247.34453399\n",
      "Iteration 1777, loss = 259793.03881758\n",
      "Iteration 1778, loss = 259346.83166486\n",
      "Iteration 1779, loss = 258865.28067726\n",
      "Iteration 1780, loss = 258398.21514328\n",
      "Iteration 1781, loss = 257941.17890653\n",
      "Iteration 1782, loss = 257481.61778767\n",
      "Iteration 1783, loss = 257020.04780371\n",
      "Iteration 1784, loss = 256562.94713075\n",
      "Iteration 1785, loss = 256100.02021941\n",
      "Iteration 1786, loss = 255639.57497312\n",
      "Iteration 1787, loss = 255180.71392709\n",
      "Iteration 1788, loss = 254716.78637212\n",
      "Iteration 1789, loss = 254265.76860804\n",
      "Iteration 1790, loss = 253802.16647732\n",
      "Iteration 1791, loss = 253340.38409738\n",
      "Iteration 1792, loss = 252873.73573612\n",
      "Iteration 1793, loss = 252416.80217410\n",
      "Iteration 1794, loss = 251964.82827327\n",
      "Iteration 1795, loss = 251498.63218359\n",
      "Iteration 1796, loss = 251042.50863142\n",
      "Iteration 1797, loss = 250591.51983806\n",
      "Iteration 1798, loss = 250148.44635222\n",
      "Iteration 1799, loss = 249700.55134903\n",
      "Iteration 1800, loss = 249244.45603443\n",
      "Iteration 1801, loss = 248777.71013847\n",
      "Iteration 1802, loss = 248325.19057530\n",
      "Iteration 1803, loss = 247870.16601329\n",
      "Iteration 1804, loss = 247415.71713959\n",
      "Iteration 1805, loss = 246962.08701120\n",
      "Iteration 1806, loss = 246508.66475382\n",
      "Iteration 1807, loss = 246061.35868122\n",
      "Iteration 1808, loss = 245611.59883162\n",
      "Iteration 1809, loss = 245151.57090530\n",
      "Iteration 1810, loss = 244688.01868557\n",
      "Iteration 1811, loss = 244230.32371545\n",
      "Iteration 1812, loss = 243772.78382929\n",
      "Iteration 1813, loss = 243316.09551409\n",
      "Iteration 1814, loss = 242859.20031437\n",
      "Iteration 1815, loss = 242395.38910549\n",
      "Iteration 1816, loss = 241941.19693075\n",
      "Iteration 1817, loss = 241482.72304434\n",
      "Iteration 1818, loss = 241023.74678758\n",
      "Iteration 1819, loss = 240585.26648591\n",
      "Iteration 1820, loss = 240138.83917345\n",
      "Iteration 1821, loss = 239664.36943250\n",
      "Iteration 1822, loss = 239202.89603174\n",
      "Iteration 1823, loss = 238757.58547420\n",
      "Iteration 1824, loss = 238309.10473955\n",
      "Iteration 1825, loss = 237870.21911801\n",
      "Iteration 1826, loss = 237430.35179276\n",
      "Iteration 1827, loss = 236993.82198461\n",
      "Iteration 1828, loss = 236540.22508987\n",
      "Iteration 1829, loss = 236085.76358694\n",
      "Iteration 1830, loss = 235631.56474180\n",
      "Iteration 1831, loss = 235181.03102495\n",
      "Iteration 1832, loss = 234739.38289202\n",
      "Iteration 1833, loss = 234298.37855098\n",
      "Iteration 1834, loss = 233842.99322786\n",
      "Iteration 1835, loss = 233390.25714672\n",
      "Iteration 1836, loss = 232948.49824176\n",
      "Iteration 1837, loss = 232512.03036283\n",
      "Iteration 1838, loss = 232064.01504345\n",
      "Iteration 1839, loss = 231601.47169008\n",
      "Iteration 1840, loss = 231146.67731437\n",
      "Iteration 1841, loss = 230699.49067958\n",
      "Iteration 1842, loss = 230262.03481947\n",
      "Iteration 1843, loss = 229831.71936810\n",
      "Iteration 1844, loss = 229369.61217965\n",
      "Iteration 1845, loss = 228901.29553593\n",
      "Iteration 1846, loss = 228452.97523958\n",
      "Iteration 1847, loss = 228012.84602534\n",
      "Iteration 1848, loss = 227566.16392665\n",
      "Iteration 1849, loss = 227109.71203104\n",
      "Iteration 1850, loss = 226670.05667736\n",
      "Iteration 1851, loss = 226242.40495380\n",
      "Iteration 1852, loss = 225788.42322733\n",
      "Iteration 1853, loss = 225346.91648670\n",
      "Iteration 1854, loss = 224916.37569167\n",
      "Iteration 1855, loss = 224479.75129534\n",
      "Iteration 1856, loss = 224019.99367253\n",
      "Iteration 1857, loss = 223566.04333318\n",
      "Iteration 1858, loss = 223132.22830125\n",
      "Iteration 1859, loss = 222691.48451851\n",
      "Iteration 1860, loss = 222249.01953733\n",
      "Iteration 1861, loss = 221800.46231559\n",
      "Iteration 1862, loss = 221352.93943226\n",
      "Iteration 1863, loss = 220918.28362504\n",
      "Iteration 1864, loss = 220469.67421346\n",
      "Iteration 1865, loss = 220024.00140647\n",
      "Iteration 1866, loss = 219577.29297833\n",
      "Iteration 1867, loss = 219130.62909111\n",
      "Iteration 1868, loss = 218690.00709256\n",
      "Iteration 1869, loss = 218257.62578650\n",
      "Iteration 1870, loss = 217828.39346908\n",
      "Iteration 1871, loss = 217410.48561631\n",
      "Iteration 1872, loss = 216971.22589195\n",
      "Iteration 1873, loss = 216539.14653582\n",
      "Iteration 1874, loss = 216098.07581712\n",
      "Iteration 1875, loss = 215664.02542490\n",
      "Iteration 1876, loss = 215231.80765346\n",
      "Iteration 1877, loss = 214804.11077280\n",
      "Iteration 1878, loss = 214366.53657816\n",
      "Iteration 1879, loss = 213922.96839526\n",
      "Iteration 1880, loss = 213480.05810702\n",
      "Iteration 1881, loss = 213045.14910157\n",
      "Iteration 1882, loss = 212611.67823810\n",
      "Iteration 1883, loss = 212177.14146680\n",
      "Iteration 1884, loss = 211737.01439616\n",
      "Iteration 1885, loss = 211291.12292783\n",
      "Iteration 1886, loss = 210850.54293771\n",
      "Iteration 1887, loss = 210419.36316224\n",
      "Iteration 1888, loss = 209991.95355820\n",
      "Iteration 1889, loss = 209554.01348850\n",
      "Iteration 1890, loss = 209108.31286847\n",
      "Iteration 1891, loss = 208671.70284189\n",
      "Iteration 1892, loss = 208263.18228953\n",
      "Iteration 1893, loss = 207883.15150574\n",
      "Iteration 1894, loss = 207472.24426146\n",
      "Iteration 1895, loss = 207032.77427412\n",
      "Iteration 1896, loss = 206572.62984318\n",
      "Iteration 1897, loss = 206145.49912253\n",
      "Iteration 1898, loss = 205767.48685717\n",
      "Iteration 1899, loss = 205350.95613273\n",
      "Iteration 1900, loss = 204904.83127065\n",
      "Iteration 1901, loss = 204467.40838724\n",
      "Iteration 1902, loss = 204080.00689175\n",
      "Iteration 1903, loss = 203691.06429587\n",
      "Iteration 1904, loss = 203237.47398983\n",
      "Iteration 1905, loss = 202796.14806901\n",
      "Iteration 1906, loss = 202376.41562320\n",
      "Iteration 1907, loss = 201973.90278874\n",
      "Iteration 1908, loss = 201562.68496473\n",
      "Iteration 1909, loss = 201116.60477590\n",
      "Iteration 1910, loss = 200686.94637998\n",
      "Iteration 1911, loss = 200278.04611942\n",
      "Iteration 1912, loss = 199871.89608113\n",
      "Iteration 1913, loss = 199462.35026379\n",
      "Iteration 1914, loss = 199034.00262518\n",
      "Iteration 1915, loss = 198600.45971111\n",
      "Iteration 1916, loss = 198177.61369760\n",
      "Iteration 1917, loss = 197768.75598485\n",
      "Iteration 1918, loss = 197355.24455483\n",
      "Iteration 1919, loss = 196926.45797516\n",
      "Iteration 1920, loss = 196504.14244828\n",
      "Iteration 1921, loss = 196087.87893785\n",
      "Iteration 1922, loss = 195680.55691031\n",
      "Iteration 1923, loss = 195277.09028989\n",
      "Iteration 1924, loss = 194884.00743105\n",
      "Iteration 1925, loss = 194480.64625440\n",
      "Iteration 1926, loss = 194053.57332874\n",
      "Iteration 1927, loss = 193626.20317190\n",
      "Iteration 1928, loss = 193196.77813522\n",
      "Iteration 1929, loss = 192785.45309240\n",
      "Iteration 1930, loss = 192398.07017962\n",
      "Iteration 1931, loss = 191986.20383471\n",
      "Iteration 1932, loss = 191557.82808521\n",
      "Iteration 1933, loss = 191126.14769554\n",
      "Iteration 1934, loss = 190711.91239593\n",
      "Iteration 1935, loss = 190306.20163871\n",
      "Iteration 1936, loss = 189909.23472595\n",
      "Iteration 1937, loss = 189507.59826114\n",
      "Iteration 1938, loss = 189083.01194702\n",
      "Iteration 1939, loss = 188659.53859651\n",
      "Iteration 1940, loss = 188240.36859126\n",
      "Iteration 1941, loss = 187827.56341367\n",
      "Iteration 1942, loss = 187420.84078468\n",
      "Iteration 1943, loss = 187012.61689634\n",
      "Iteration 1944, loss = 186599.62656626\n",
      "Iteration 1945, loss = 186195.39262621\n",
      "Iteration 1946, loss = 185801.10930137\n",
      "Iteration 1947, loss = 185411.89127405\n",
      "Iteration 1948, loss = 185025.61533500\n",
      "Iteration 1949, loss = 184603.96357605\n",
      "Iteration 1950, loss = 184174.65715750\n",
      "Iteration 1951, loss = 183747.87547195\n",
      "Iteration 1952, loss = 183357.70759546\n",
      "Iteration 1953, loss = 182964.86443090\n",
      "Iteration 1954, loss = 182540.21036605\n",
      "Iteration 1955, loss = 182123.87980576\n",
      "Iteration 1956, loss = 181723.72160861\n",
      "Iteration 1957, loss = 181328.79409455\n",
      "Iteration 1958, loss = 180936.26542414\n",
      "Iteration 1959, loss = 180540.02661969\n",
      "Iteration 1960, loss = 180139.23156567\n",
      "Iteration 1961, loss = 179737.59944917\n",
      "Iteration 1962, loss = 179334.48422378\n",
      "Iteration 1963, loss = 178922.31373979\n",
      "Iteration 1964, loss = 178516.43230953\n",
      "Iteration 1965, loss = 178117.30191087\n",
      "Iteration 1966, loss = 177721.45283055\n",
      "Iteration 1967, loss = 177328.46143142\n",
      "Iteration 1968, loss = 176934.56071226\n",
      "Iteration 1969, loss = 176545.05404759\n",
      "Iteration 1970, loss = 176144.65809522\n",
      "Iteration 1971, loss = 175742.14938878\n",
      "Iteration 1972, loss = 175340.47346423\n",
      "Iteration 1973, loss = 174945.25316879\n",
      "Iteration 1974, loss = 174553.22092721\n",
      "Iteration 1975, loss = 174163.44940551\n",
      "Iteration 1976, loss = 173774.10564588\n",
      "Iteration 1977, loss = 173391.86784377\n",
      "Iteration 1978, loss = 173003.11388444\n",
      "Iteration 1979, loss = 172600.71888008\n",
      "Iteration 1980, loss = 172197.66853680\n",
      "Iteration 1981, loss = 171800.91622017\n",
      "Iteration 1982, loss = 171413.61180450\n",
      "Iteration 1983, loss = 171026.22943184\n",
      "Iteration 1984, loss = 170632.79208713\n",
      "Iteration 1985, loss = 170239.08070542\n",
      "Iteration 1986, loss = 169855.54550056\n",
      "Iteration 1987, loss = 169481.15881119\n",
      "Iteration 1988, loss = 169103.85305760\n",
      "Iteration 1989, loss = 168723.35419724\n",
      "Iteration 1990, loss = 168339.46794932\n",
      "Iteration 1991, loss = 167939.52061762\n",
      "Iteration 1992, loss = 167531.01827974\n",
      "Iteration 1993, loss = 167127.23605159\n",
      "Iteration 1994, loss = 166731.97028081\n",
      "Iteration 1995, loss = 166342.98356078\n",
      "Iteration 1996, loss = 165955.84366231\n",
      "Iteration 1997, loss = 165569.41246632\n",
      "Iteration 1998, loss = 165185.61029263\n",
      "Iteration 1999, loss = 164814.52893649\n",
      "Iteration 2000, loss = 164460.78111735\n",
      "Iteration 2001, loss = 164121.73843149\n",
      "Iteration 2002, loss = 163758.74834570\n",
      "Iteration 2003, loss = 163389.17501320\n",
      "Iteration 2004, loss = 162956.25520456\n",
      "Iteration 2005, loss = 162518.69565137\n",
      "Iteration 2006, loss = 162121.28514330\n",
      "Iteration 2007, loss = 161779.04923714\n",
      "Iteration 2008, loss = 161453.94042910\n",
      "Iteration 2009, loss = 161066.53280339\n",
      "Iteration 2010, loss = 160662.44726696\n",
      "Iteration 2011, loss = 160235.31384665\n",
      "Iteration 2012, loss = 159834.88798274\n",
      "Iteration 2013, loss = 159454.52525103\n",
      "Iteration 2014, loss = 159091.47274298\n",
      "Iteration 2015, loss = 158745.85824635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2016, loss = 158367.34651201\n",
      "Iteration 2017, loss = 157986.42980931\n",
      "Iteration 2018, loss = 157596.79989940\n",
      "Iteration 2019, loss = 157194.81879227\n",
      "Iteration 2020, loss = 156806.54283016\n",
      "Iteration 2021, loss = 156430.53990044\n",
      "Iteration 2022, loss = 156083.06293244\n",
      "Iteration 2023, loss = 155749.00290834\n",
      "Iteration 2024, loss = 155389.95755622\n",
      "Iteration 2025, loss = 154984.77756395\n",
      "Iteration 2026, loss = 154572.25995496\n",
      "Iteration 2027, loss = 154184.38840563\n",
      "Iteration 2028, loss = 153824.81805600\n",
      "Iteration 2029, loss = 153485.12991587\n",
      "Iteration 2030, loss = 153125.63535365\n",
      "Iteration 2031, loss = 152732.59378663\n",
      "Iteration 2032, loss = 152333.18022377\n",
      "Iteration 2033, loss = 151950.81598896\n",
      "Iteration 2034, loss = 151582.27943364\n",
      "Iteration 2035, loss = 151213.01062454\n",
      "Iteration 2036, loss = 150845.17003467\n",
      "Iteration 2037, loss = 150474.84534786\n",
      "Iteration 2038, loss = 150101.14076825\n",
      "Iteration 2039, loss = 149732.06716213\n",
      "Iteration 2040, loss = 149365.04290844\n",
      "Iteration 2041, loss = 148996.95114079\n",
      "Iteration 2042, loss = 148638.56930471\n",
      "Iteration 2043, loss = 148281.43557952\n",
      "Iteration 2044, loss = 147929.83643953\n",
      "Iteration 2045, loss = 147570.18275609\n",
      "Iteration 2046, loss = 147195.13765967\n",
      "Iteration 2047, loss = 146809.73095089\n",
      "Iteration 2048, loss = 146434.82870754\n",
      "Iteration 2049, loss = 146065.59344221\n",
      "Iteration 2050, loss = 145697.50508509\n",
      "Iteration 2051, loss = 145331.53212393\n",
      "Iteration 2052, loss = 144966.59370455\n",
      "Iteration 2053, loss = 144605.99912493\n",
      "Iteration 2054, loss = 144251.19932807\n",
      "Iteration 2055, loss = 143915.18309713\n",
      "Iteration 2056, loss = 143587.05154134\n",
      "Iteration 2057, loss = 143262.69133690\n",
      "Iteration 2058, loss = 142899.92250098\n",
      "Iteration 2059, loss = 142531.45179339\n",
      "Iteration 2060, loss = 142134.27896297\n",
      "Iteration 2061, loss = 141730.15330964\n",
      "Iteration 2062, loss = 141362.10619419\n",
      "Iteration 2063, loss = 141065.39648835\n",
      "Iteration 2064, loss = 140828.13633100\n",
      "Iteration 2065, loss = 140505.26471191\n",
      "Iteration 2066, loss = 140151.51637413\n",
      "Iteration 2067, loss = 139667.80161373\n",
      "Iteration 2068, loss = 139228.09795843\n",
      "Iteration 2069, loss = 138922.44149676\n",
      "Iteration 2070, loss = 138669.37299432\n",
      "Iteration 2071, loss = 138338.10340054\n",
      "Iteration 2072, loss = 137893.52925347\n",
      "Iteration 2073, loss = 137469.96019324\n",
      "Iteration 2074, loss = 137119.99946818\n",
      "Iteration 2075, loss = 136830.66161087\n",
      "Iteration 2076, loss = 136535.97754244\n",
      "Iteration 2077, loss = 136145.34336955\n",
      "Iteration 2078, loss = 135732.92536568\n",
      "Iteration 2079, loss = 135359.68751097\n",
      "Iteration 2080, loss = 135043.54705923\n",
      "Iteration 2081, loss = 134753.06592849\n",
      "Iteration 2082, loss = 134415.87175329\n",
      "Iteration 2083, loss = 134026.00504535\n",
      "Iteration 2084, loss = 133633.44202221\n",
      "Iteration 2085, loss = 133282.06056893\n",
      "Iteration 2086, loss = 132987.98704565\n",
      "Iteration 2087, loss = 132687.62053336\n",
      "Iteration 2088, loss = 132314.65729249\n",
      "Iteration 2089, loss = 131914.41149527\n",
      "Iteration 2090, loss = 131557.81307726\n",
      "Iteration 2091, loss = 131243.32083725\n",
      "Iteration 2092, loss = 130920.80319937\n",
      "Iteration 2093, loss = 130585.27214360\n",
      "Iteration 2094, loss = 130210.49375404\n",
      "Iteration 2095, loss = 129836.36147877\n",
      "Iteration 2096, loss = 129490.17492162\n",
      "Iteration 2097, loss = 129166.59554620\n",
      "Iteration 2098, loss = 128836.83026860\n",
      "Iteration 2099, loss = 128499.61338386\n",
      "Iteration 2100, loss = 128136.28111555\n",
      "Iteration 2101, loss = 127772.74163763\n",
      "Iteration 2102, loss = 127426.05584827\n",
      "Iteration 2103, loss = 127101.48960001\n",
      "Iteration 2104, loss = 126787.63926352\n",
      "Iteration 2105, loss = 126466.36229262\n",
      "Iteration 2106, loss = 126097.55539708\n",
      "Iteration 2107, loss = 125723.89666307\n",
      "Iteration 2108, loss = 125373.81319629\n",
      "Iteration 2109, loss = 125057.76458091\n",
      "Iteration 2110, loss = 124744.26005685\n",
      "Iteration 2111, loss = 124402.37109166\n",
      "Iteration 2112, loss = 124037.00758899\n",
      "Iteration 2113, loss = 123681.86178613\n",
      "Iteration 2114, loss = 123341.80884823\n",
      "Iteration 2115, loss = 123015.32451728\n",
      "Iteration 2116, loss = 122696.36998531\n",
      "Iteration 2117, loss = 122375.37003623\n",
      "Iteration 2118, loss = 122036.55754735\n",
      "Iteration 2119, loss = 121705.53858694\n",
      "Iteration 2120, loss = 121373.41942976\n",
      "Iteration 2121, loss = 121042.79165721\n",
      "Iteration 2122, loss = 120721.61127890\n",
      "Iteration 2123, loss = 120405.90045182\n",
      "Iteration 2124, loss = 120084.42313080\n",
      "Iteration 2125, loss = 119761.98431662\n",
      "Iteration 2126, loss = 119420.93229312\n",
      "Iteration 2127, loss = 119086.21045490\n",
      "Iteration 2128, loss = 118760.24928006\n",
      "Iteration 2129, loss = 118438.18900560\n",
      "Iteration 2130, loss = 118119.48968556\n",
      "Iteration 2131, loss = 117806.09187312\n",
      "Iteration 2132, loss = 117494.45589770\n",
      "Iteration 2133, loss = 117174.89547877\n",
      "Iteration 2134, loss = 116847.33190360\n",
      "Iteration 2135, loss = 116516.25651171\n",
      "Iteration 2136, loss = 116189.75091547\n",
      "Iteration 2137, loss = 115873.18910441\n",
      "Iteration 2138, loss = 115567.25024816\n",
      "Iteration 2139, loss = 115260.83399391\n",
      "Iteration 2140, loss = 114942.97305187\n",
      "Iteration 2141, loss = 114610.16564872\n",
      "Iteration 2142, loss = 114279.40219141\n",
      "Iteration 2143, loss = 113953.33990376\n",
      "Iteration 2144, loss = 113634.64354251\n",
      "Iteration 2145, loss = 113320.38118247\n",
      "Iteration 2146, loss = 113007.48406789\n",
      "Iteration 2147, loss = 112697.58299505\n",
      "Iteration 2148, loss = 112387.81636131\n",
      "Iteration 2149, loss = 112080.25685187\n",
      "Iteration 2150, loss = 111769.22360917\n",
      "Iteration 2151, loss = 111468.70137071\n",
      "Iteration 2152, loss = 111159.75285862\n",
      "Iteration 2153, loss = 110847.00800664\n",
      "Iteration 2154, loss = 110528.96689145\n",
      "Iteration 2155, loss = 110206.95921322\n",
      "Iteration 2156, loss = 109890.97442285\n",
      "Iteration 2157, loss = 109583.79963689\n",
      "Iteration 2158, loss = 109286.05447488\n",
      "Iteration 2159, loss = 108995.12927452\n",
      "Iteration 2160, loss = 108709.99460826\n",
      "Iteration 2161, loss = 108419.24169625\n",
      "Iteration 2162, loss = 108111.77739395\n",
      "Iteration 2163, loss = 107796.64564673\n",
      "Iteration 2164, loss = 107462.57028161\n",
      "Iteration 2165, loss = 107139.07716951\n",
      "Iteration 2166, loss = 106841.54113924\n",
      "Iteration 2167, loss = 106564.92192877\n",
      "Iteration 2168, loss = 106310.41673416\n",
      "Iteration 2169, loss = 106029.26838646\n",
      "Iteration 2170, loss = 105706.55674482\n",
      "Iteration 2171, loss = 105372.22776434\n",
      "Iteration 2172, loss = 105055.05303529\n",
      "Iteration 2173, loss = 104755.20288979\n",
      "Iteration 2174, loss = 104475.62444187\n",
      "Iteration 2175, loss = 104220.06495757\n",
      "Iteration 2176, loss = 103948.67647350\n",
      "Iteration 2177, loss = 103655.28915340\n",
      "Iteration 2178, loss = 103331.71465384\n",
      "Iteration 2179, loss = 103008.94160019\n",
      "Iteration 2180, loss = 102700.38767961\n",
      "Iteration 2181, loss = 102413.19486341\n",
      "Iteration 2182, loss = 102148.06538885\n",
      "Iteration 2183, loss = 101877.58373923\n",
      "Iteration 2184, loss = 101589.58880238\n",
      "Iteration 2185, loss = 101275.43760207\n",
      "Iteration 2186, loss = 100968.56894866\n",
      "Iteration 2187, loss = 100668.03807631\n",
      "Iteration 2188, loss = 100379.76724228\n",
      "Iteration 2189, loss = 100103.69394435\n",
      "Iteration 2190, loss = 99834.89890643\n",
      "Iteration 2191, loss = 99561.79103285\n",
      "Iteration 2192, loss = 99279.35955593\n",
      "Iteration 2193, loss = 98980.65451723\n",
      "Iteration 2194, loss = 98683.06778554\n",
      "Iteration 2195, loss = 98382.07295065\n",
      "Iteration 2196, loss = 98089.79922513\n",
      "Iteration 2197, loss = 97806.58061097\n",
      "Iteration 2198, loss = 97527.11904208\n",
      "Iteration 2199, loss = 97246.82806687\n",
      "Iteration 2200, loss = 96964.64540768\n",
      "Iteration 2201, loss = 96682.85738007\n",
      "Iteration 2202, loss = 96404.50251425\n",
      "Iteration 2203, loss = 96130.26800187\n",
      "Iteration 2204, loss = 95854.09916703\n",
      "Iteration 2205, loss = 95579.17971365\n",
      "Iteration 2206, loss = 95304.57037374\n",
      "Iteration 2207, loss = 95024.84423282\n",
      "Iteration 2208, loss = 94744.48107727\n",
      "Iteration 2209, loss = 94460.09066083\n",
      "Iteration 2210, loss = 94178.79072643\n",
      "Iteration 2211, loss = 93899.97644123\n",
      "Iteration 2212, loss = 93623.02111388\n",
      "Iteration 2213, loss = 93350.23147036\n",
      "Iteration 2214, loss = 93083.60563300\n",
      "Iteration 2215, loss = 92823.04061381\n",
      "Iteration 2216, loss = 92564.12130004\n",
      "Iteration 2217, loss = 92314.13480153\n",
      "Iteration 2218, loss = 92057.32036402\n",
      "Iteration 2219, loss = 91797.26631408\n",
      "Iteration 2220, loss = 91513.88592689\n",
      "Iteration 2221, loss = 91220.59436466\n",
      "Iteration 2222, loss = 90927.45345432\n",
      "Iteration 2223, loss = 90653.02106892\n",
      "Iteration 2224, loss = 90397.51871867\n",
      "Iteration 2225, loss = 90146.65157021\n",
      "Iteration 2226, loss = 89894.28090207\n",
      "Iteration 2227, loss = 89630.78801728\n",
      "Iteration 2228, loss = 89361.09549520\n",
      "Iteration 2229, loss = 89085.76285472\n",
      "Iteration 2230, loss = 88810.91223827\n",
      "Iteration 2231, loss = 88534.01641343\n",
      "Iteration 2232, loss = 88265.63119495\n",
      "Iteration 2233, loss = 88009.98054158\n",
      "Iteration 2234, loss = 87766.25959431\n",
      "Iteration 2235, loss = 87531.27184915\n",
      "Iteration 2236, loss = 87289.08817025\n",
      "Iteration 2237, loss = 87051.92260588\n",
      "Iteration 2238, loss = 86786.61948188\n",
      "Iteration 2239, loss = 86507.10783690\n",
      "Iteration 2240, loss = 86218.34592949\n",
      "Iteration 2241, loss = 85936.63718776\n",
      "Iteration 2242, loss = 85678.76259020\n",
      "Iteration 2243, loss = 85439.60719869\n",
      "Iteration 2244, loss = 85203.40012359\n",
      "Iteration 2245, loss = 84956.15060871\n",
      "Iteration 2246, loss = 84703.21596043\n",
      "Iteration 2247, loss = 84438.63250250\n",
      "Iteration 2248, loss = 84174.23565495\n",
      "Iteration 2249, loss = 83909.42199484\n",
      "Iteration 2250, loss = 83652.43728361\n",
      "Iteration 2251, loss = 83402.36534400\n",
      "Iteration 2252, loss = 83158.96347553\n",
      "Iteration 2253, loss = 82920.62839571\n",
      "Iteration 2254, loss = 82688.92624150\n",
      "Iteration 2255, loss = 82456.84426019\n",
      "Iteration 2256, loss = 82227.15074370\n",
      "Iteration 2257, loss = 81993.25507715\n",
      "Iteration 2258, loss = 81738.09869160\n",
      "Iteration 2259, loss = 81471.98121782\n",
      "Iteration 2260, loss = 81200.21946754\n",
      "Iteration 2261, loss = 80937.85089138\n",
      "Iteration 2262, loss = 80696.89314930\n",
      "Iteration 2263, loss = 80475.92801962\n",
      "Iteration 2264, loss = 80259.08447036\n",
      "Iteration 2265, loss = 80027.03966209\n",
      "Iteration 2266, loss = 79787.13610270\n",
      "Iteration 2267, loss = 79521.38268433\n",
      "Iteration 2268, loss = 79259.28148662\n",
      "Iteration 2269, loss = 79002.41882876\n",
      "Iteration 2270, loss = 78755.68113837\n",
      "Iteration 2271, loss = 78519.63703719\n",
      "Iteration 2272, loss = 78294.55523956\n",
      "Iteration 2273, loss = 78073.74057770\n",
      "Iteration 2274, loss = 77852.08199177\n",
      "Iteration 2275, loss = 77624.14882851\n",
      "Iteration 2276, loss = 77382.05129869\n",
      "Iteration 2277, loss = 77132.83713486\n",
      "Iteration 2278, loss = 76879.08010138\n",
      "Iteration 2279, loss = 76629.80725413\n",
      "Iteration 2280, loss = 76391.09784306\n",
      "Iteration 2281, loss = 76166.34031647\n",
      "Iteration 2282, loss = 75952.17416063\n",
      "Iteration 2283, loss = 75739.37371570\n",
      "Iteration 2284, loss = 75517.69646849\n",
      "Iteration 2285, loss = 75283.70579753\n",
      "Iteration 2286, loss = 75048.85195587\n",
      "Iteration 2287, loss = 74801.34193736\n",
      "Iteration 2288, loss = 74547.65123959\n",
      "Iteration 2289, loss = 74303.73188878\n",
      "Iteration 2290, loss = 74077.87288191\n",
      "Iteration 2291, loss = 73868.25860900\n",
      "Iteration 2292, loss = 73666.29317952\n",
      "Iteration 2293, loss = 73464.34109341\n",
      "Iteration 2294, loss = 73254.60625396\n",
      "Iteration 2295, loss = 73023.52323908\n",
      "Iteration 2296, loss = 72769.17920614\n",
      "Iteration 2297, loss = 72518.86038005\n",
      "Iteration 2298, loss = 72272.79657788\n",
      "Iteration 2299, loss = 72039.10249396\n",
      "Iteration 2300, loss = 71822.33464791\n",
      "Iteration 2301, loss = 71615.92092840\n",
      "Iteration 2302, loss = 71412.09331183\n",
      "Iteration 2303, loss = 71200.07865488\n",
      "Iteration 2304, loss = 70977.69487315\n",
      "Iteration 2305, loss = 70739.81338073\n",
      "Iteration 2306, loss = 70500.66276693\n",
      "Iteration 2307, loss = 70266.62573069\n",
      "Iteration 2308, loss = 70042.47665831\n",
      "Iteration 2309, loss = 69828.31261374\n",
      "Iteration 2310, loss = 69621.78667007\n",
      "Iteration 2311, loss = 69421.62751656\n",
      "Iteration 2312, loss = 69225.92393622\n",
      "Iteration 2313, loss = 69032.93305660\n",
      "Iteration 2314, loss = 68829.89284740\n",
      "Iteration 2315, loss = 68609.94947397\n",
      "Iteration 2316, loss = 68376.75368875\n",
      "Iteration 2317, loss = 68131.09808442\n",
      "Iteration 2318, loss = 67891.16335007\n",
      "Iteration 2319, loss = 67665.54330231\n",
      "Iteration 2320, loss = 67456.86702596\n",
      "Iteration 2321, loss = 67260.81914395\n",
      "Iteration 2322, loss = 67065.99642404\n",
      "Iteration 2323, loss = 66867.27819870\n",
      "Iteration 2324, loss = 66651.25253584\n",
      "Iteration 2325, loss = 66427.49122081\n",
      "Iteration 2326, loss = 66199.74927555\n",
      "Iteration 2327, loss = 65975.12118793\n",
      "Iteration 2328, loss = 65762.30282215\n",
      "Iteration 2329, loss = 65560.24757184\n",
      "Iteration 2330, loss = 65363.61236406\n",
      "Iteration 2331, loss = 65166.55481627\n",
      "Iteration 2332, loss = 64968.46074260\n",
      "Iteration 2333, loss = 64759.36297585\n",
      "Iteration 2334, loss = 64544.09690422\n",
      "Iteration 2335, loss = 64326.28013212\n",
      "Iteration 2336, loss = 64111.21142479\n",
      "Iteration 2337, loss = 63903.43762126\n",
      "Iteration 2338, loss = 63703.81919856\n",
      "Iteration 2339, loss = 63509.59978788\n",
      "Iteration 2340, loss = 63312.68325888\n",
      "Iteration 2341, loss = 63114.89840558\n",
      "Iteration 2342, loss = 62913.25329776\n",
      "Iteration 2343, loss = 62706.42008153\n",
      "Iteration 2344, loss = 62496.14434942\n",
      "Iteration 2345, loss = 62287.96995542\n",
      "Iteration 2346, loss = 62083.56472749\n",
      "Iteration 2347, loss = 61884.30931076\n",
      "Iteration 2348, loss = 61688.83048535\n",
      "Iteration 2349, loss = 61497.24947040\n",
      "Iteration 2350, loss = 61309.41721607\n",
      "Iteration 2351, loss = 61122.08517597\n",
      "Iteration 2352, loss = 60933.85218374\n",
      "Iteration 2353, loss = 60739.38816959\n",
      "Iteration 2354, loss = 60543.73638146\n",
      "Iteration 2355, loss = 60338.68218154\n",
      "Iteration 2356, loss = 60131.17499257\n",
      "Iteration 2357, loss = 59926.17729913\n",
      "Iteration 2358, loss = 59725.77594516\n",
      "Iteration 2359, loss = 59529.39666863\n",
      "Iteration 2360, loss = 59335.49702109\n",
      "Iteration 2361, loss = 59143.87262237\n",
      "Iteration 2362, loss = 58954.12467701\n",
      "Iteration 2363, loss = 58764.78820125\n",
      "Iteration 2364, loss = 58576.07861143\n",
      "Iteration 2365, loss = 58390.31823062\n",
      "Iteration 2366, loss = 58203.68804424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2367, loss = 58020.60122822\n",
      "Iteration 2368, loss = 57838.20595009\n",
      "Iteration 2369, loss = 57656.95221027\n",
      "Iteration 2370, loss = 57473.40125513\n",
      "Iteration 2371, loss = 57298.28086579\n",
      "Iteration 2372, loss = 57125.00025304\n",
      "Iteration 2373, loss = 56969.33389758\n",
      "Iteration 2374, loss = 56807.82056191\n",
      "Iteration 2375, loss = 56658.92860350\n",
      "Iteration 2376, loss = 56510.77060081\n",
      "Iteration 2377, loss = 56368.88190912\n",
      "Iteration 2378, loss = 56205.25877975\n",
      "Iteration 2379, loss = 56007.53437976\n",
      "Iteration 2380, loss = 55750.13229603\n",
      "Iteration 2381, loss = 55486.09484538\n",
      "Iteration 2382, loss = 55230.62100127\n",
      "Iteration 2383, loss = 55027.52593365\n",
      "Iteration 2384, loss = 54872.10483692\n",
      "Iteration 2385, loss = 54732.92304772\n",
      "Iteration 2386, loss = 54596.42731392\n",
      "Iteration 2387, loss = 54412.88851605\n",
      "Iteration 2388, loss = 54204.71838368\n",
      "Iteration 2389, loss = 53978.06620451\n",
      "Iteration 2390, loss = 53770.18768108\n",
      "Iteration 2391, loss = 53596.19404830\n",
      "Iteration 2392, loss = 53443.00736863\n",
      "Iteration 2393, loss = 53290.20687296\n",
      "Iteration 2394, loss = 53118.48753964\n",
      "Iteration 2395, loss = 52931.33984724\n",
      "Iteration 2396, loss = 52733.46106836\n",
      "Iteration 2397, loss = 52539.78342781\n",
      "Iteration 2398, loss = 52359.02625986\n",
      "Iteration 2399, loss = 52190.78715355\n",
      "Iteration 2400, loss = 52029.00946249\n",
      "Iteration 2401, loss = 51867.05830582\n",
      "Iteration 2402, loss = 51701.98405060\n",
      "Iteration 2403, loss = 51526.79867041\n",
      "Iteration 2404, loss = 51348.61656129\n",
      "Iteration 2405, loss = 51165.39589098\n",
      "Iteration 2406, loss = 50985.04243187\n",
      "Iteration 2407, loss = 50808.47073486\n",
      "Iteration 2408, loss = 50637.25699879\n",
      "Iteration 2409, loss = 50471.42357978\n",
      "Iteration 2410, loss = 50310.31608025\n",
      "Iteration 2411, loss = 50152.81357838\n",
      "Iteration 2412, loss = 49995.22842250\n",
      "Iteration 2413, loss = 49836.09066518\n",
      "Iteration 2414, loss = 49668.65816552\n",
      "Iteration 2415, loss = 49499.94788773\n",
      "Iteration 2416, loss = 49321.14933854\n",
      "Iteration 2417, loss = 49144.64156730\n",
      "Iteration 2418, loss = 48969.51863969\n",
      "Iteration 2419, loss = 48802.33696779\n",
      "Iteration 2420, loss = 48642.46628185\n",
      "Iteration 2421, loss = 48483.88634885\n",
      "Iteration 2422, loss = 48324.18894137\n",
      "Iteration 2423, loss = 48164.44718421\n",
      "Iteration 2424, loss = 48002.68996329\n",
      "Iteration 2425, loss = 47841.41954768\n",
      "Iteration 2426, loss = 47677.95666615\n",
      "Iteration 2427, loss = 47516.62634593\n",
      "Iteration 2428, loss = 47357.39445478\n",
      "Iteration 2429, loss = 47197.52899249\n",
      "Iteration 2430, loss = 47041.14917296\n",
      "Iteration 2431, loss = 46881.14076730\n",
      "Iteration 2432, loss = 46725.12006700\n",
      "Iteration 2433, loss = 46564.56104841\n",
      "Iteration 2434, loss = 46403.62816761\n",
      "Iteration 2435, loss = 46241.26803549\n",
      "Iteration 2436, loss = 46079.00494489\n",
      "Iteration 2437, loss = 45918.16508954\n",
      "Iteration 2438, loss = 45759.51553573\n",
      "Iteration 2439, loss = 45601.62367621\n",
      "Iteration 2440, loss = 45445.98833012\n",
      "Iteration 2441, loss = 45290.14551393\n",
      "Iteration 2442, loss = 45134.76023301\n",
      "Iteration 2443, loss = 44982.19530939\n",
      "Iteration 2444, loss = 44830.97074391\n",
      "Iteration 2445, loss = 44681.10794569\n",
      "Iteration 2446, loss = 44536.01503288\n",
      "Iteration 2447, loss = 44393.70441295\n",
      "Iteration 2448, loss = 44259.17166569\n",
      "Iteration 2449, loss = 44124.07536659\n",
      "Iteration 2450, loss = 43997.40172845\n",
      "Iteration 2451, loss = 43863.98983662\n",
      "Iteration 2452, loss = 43733.99893810\n",
      "Iteration 2453, loss = 43582.69409884\n",
      "Iteration 2454, loss = 43426.52873660\n",
      "Iteration 2455, loss = 43250.20279135\n",
      "Iteration 2456, loss = 43072.72933861\n",
      "Iteration 2457, loss = 42893.82353216\n",
      "Iteration 2458, loss = 42726.89690481\n",
      "Iteration 2459, loss = 42570.89241037\n",
      "Iteration 2460, loss = 42424.79209306\n",
      "Iteration 2461, loss = 42286.37629427\n",
      "Iteration 2462, loss = 42156.20639181\n",
      "Iteration 2463, loss = 42028.56269030\n",
      "Iteration 2464, loss = 41906.88666993\n",
      "Iteration 2465, loss = 41782.04439293\n",
      "Iteration 2466, loss = 41648.27077863\n",
      "Iteration 2467, loss = 41502.11395093\n",
      "Iteration 2468, loss = 41339.80773643\n",
      "Iteration 2469, loss = 41173.54368447\n",
      "Iteration 2470, loss = 41007.42292782\n",
      "Iteration 2471, loss = 40846.46907997\n",
      "Iteration 2472, loss = 40695.11480145\n",
      "Iteration 2473, loss = 40554.25232750\n",
      "Iteration 2474, loss = 40421.66256074\n",
      "Iteration 2475, loss = 40295.05295151\n",
      "Iteration 2476, loss = 40171.00017108\n",
      "Iteration 2477, loss = 40043.02629173\n",
      "Iteration 2478, loss = 39909.80549172\n",
      "Iteration 2479, loss = 39765.25364834\n",
      "Iteration 2480, loss = 39616.46566235\n",
      "Iteration 2481, loss = 39463.50324829\n",
      "Iteration 2482, loss = 39312.39468022\n",
      "Iteration 2483, loss = 39167.24722725\n",
      "Iteration 2484, loss = 39027.64711793\n",
      "Iteration 2485, loss = 38891.14581707\n",
      "Iteration 2486, loss = 38756.63305065\n",
      "Iteration 2487, loss = 38624.73794072\n",
      "Iteration 2488, loss = 38497.89074394\n",
      "Iteration 2489, loss = 38376.17215503\n",
      "Iteration 2490, loss = 38258.29607802\n",
      "Iteration 2491, loss = 38145.00953803\n",
      "Iteration 2492, loss = 38030.80898210\n",
      "Iteration 2493, loss = 37913.44009786\n",
      "Iteration 2494, loss = 37786.09546237\n",
      "Iteration 2495, loss = 37649.96484416\n",
      "Iteration 2496, loss = 37499.79909766\n",
      "Iteration 2497, loss = 37342.44442475\n",
      "Iteration 2498, loss = 37181.64846938\n",
      "Iteration 2499, loss = 37030.80112552\n",
      "Iteration 2500, loss = 36894.16368745\n",
      "Iteration 2501, loss = 36770.46164252\n",
      "Iteration 2502, loss = 36655.02969016\n",
      "Iteration 2503, loss = 36543.47908812\n",
      "Iteration 2504, loss = 36428.61215108\n",
      "Iteration 2505, loss = 36306.46604341\n",
      "Iteration 2506, loss = 36177.18381030\n",
      "Iteration 2507, loss = 36041.36958716\n",
      "Iteration 2508, loss = 35903.36830075\n",
      "Iteration 2509, loss = 35764.40224589\n",
      "Iteration 2510, loss = 35627.89805246\n",
      "Iteration 2511, loss = 35495.45386693\n",
      "Iteration 2512, loss = 35367.32697261\n",
      "Iteration 2513, loss = 35242.80419403\n",
      "Iteration 2514, loss = 35121.11695142\n",
      "Iteration 2515, loss = 35002.58975443\n",
      "Iteration 2516, loss = 34887.72021087\n",
      "Iteration 2517, loss = 34776.07208360\n",
      "Iteration 2518, loss = 34667.18519763\n",
      "Iteration 2519, loss = 34557.02092796\n",
      "Iteration 2520, loss = 34444.29766151\n",
      "Iteration 2521, loss = 34325.33650396\n",
      "Iteration 2522, loss = 34201.68664001\n",
      "Iteration 2523, loss = 34069.86941823\n",
      "Iteration 2524, loss = 33935.35638663\n",
      "Iteration 2525, loss = 33799.49755727\n",
      "Iteration 2526, loss = 33667.65136182\n",
      "Iteration 2527, loss = 33542.23981986\n",
      "Iteration 2528, loss = 33423.11290688\n",
      "Iteration 2529, loss = 33308.40300942\n",
      "Iteration 2530, loss = 33196.37906391\n",
      "Iteration 2531, loss = 33084.94901585\n",
      "Iteration 2532, loss = 32973.48242345\n",
      "Iteration 2533, loss = 32862.70566970\n",
      "Iteration 2534, loss = 32752.65961899\n",
      "Iteration 2535, loss = 32642.73569223\n",
      "Iteration 2536, loss = 32530.71387125\n",
      "Iteration 2537, loss = 32412.92807062\n",
      "Iteration 2538, loss = 32291.22349224\n",
      "Iteration 2539, loss = 32169.47457545\n",
      "Iteration 2540, loss = 32047.35166252\n",
      "Iteration 2541, loss = 31927.91747206\n",
      "Iteration 2542, loss = 31810.07401166\n",
      "Iteration 2543, loss = 31694.76736044\n",
      "Iteration 2544, loss = 31581.53120983\n",
      "Iteration 2545, loss = 31468.42245914\n",
      "Iteration 2546, loss = 31356.30449352\n",
      "Iteration 2547, loss = 31245.77697526\n",
      "Iteration 2548, loss = 31138.13596677\n",
      "Iteration 2549, loss = 31033.79102518\n",
      "Iteration 2550, loss = 30933.31700235\n",
      "Iteration 2551, loss = 30840.31696334\n",
      "Iteration 2552, loss = 30752.51588800\n",
      "Iteration 2553, loss = 30673.33479828\n",
      "Iteration 2554, loss = 30598.91185262\n",
      "Iteration 2555, loss = 30526.18678506\n",
      "Iteration 2556, loss = 30443.12643972\n",
      "Iteration 2557, loss = 30344.32841908\n",
      "Iteration 2558, loss = 30224.69284294\n",
      "Iteration 2559, loss = 30075.22976855\n",
      "Iteration 2560, loss = 29910.59653143\n",
      "Iteration 2561, loss = 29747.54838822\n",
      "Iteration 2562, loss = 29610.18368864\n",
      "Iteration 2563, loss = 29509.22195376\n",
      "Iteration 2564, loss = 29431.30364632\n",
      "Iteration 2565, loss = 29356.15761804\n",
      "Iteration 2566, loss = 29272.53636465\n",
      "Iteration 2567, loss = 29169.15582132\n",
      "Iteration 2568, loss = 29046.41791364\n",
      "Iteration 2569, loss = 28914.43962334\n",
      "Iteration 2570, loss = 28786.01213590\n",
      "Iteration 2571, loss = 28669.46327980\n",
      "Iteration 2572, loss = 28565.11485172\n",
      "Iteration 2573, loss = 28469.52385109\n",
      "Iteration 2574, loss = 28379.06849925\n",
      "Iteration 2575, loss = 28291.23059055\n",
      "Iteration 2576, loss = 28201.21446363\n",
      "Iteration 2577, loss = 28108.37365467\n",
      "Iteration 2578, loss = 28010.95123614\n",
      "Iteration 2579, loss = 27905.52475923\n",
      "Iteration 2580, loss = 27795.90802392\n",
      "Iteration 2581, loss = 27685.53892113\n",
      "Iteration 2582, loss = 27576.27211329\n",
      "Iteration 2583, loss = 27467.17900065\n",
      "Iteration 2584, loss = 27360.55991631\n",
      "Iteration 2585, loss = 27257.90964771\n",
      "Iteration 2586, loss = 27160.53205466\n",
      "Iteration 2587, loss = 27067.13073320\n",
      "Iteration 2588, loss = 26974.82355936\n",
      "Iteration 2589, loss = 26882.00781141\n",
      "Iteration 2590, loss = 26787.01847122\n",
      "Iteration 2591, loss = 26691.14241645\n",
      "Iteration 2592, loss = 26594.19782853\n",
      "Iteration 2593, loss = 26495.98506036\n",
      "Iteration 2594, loss = 26397.34189972\n",
      "Iteration 2595, loss = 26298.53680669\n",
      "Iteration 2596, loss = 26200.76963665\n",
      "Iteration 2597, loss = 26103.67484001\n",
      "Iteration 2598, loss = 26008.66078442\n",
      "Iteration 2599, loss = 25914.94837272\n",
      "Iteration 2600, loss = 25822.21800640\n",
      "Iteration 2601, loss = 25729.97952943\n",
      "Iteration 2602, loss = 25638.29610068\n",
      "Iteration 2603, loss = 25547.49100052\n",
      "Iteration 2604, loss = 25457.18691856\n",
      "Iteration 2605, loss = 25366.96931248\n",
      "Iteration 2606, loss = 25276.05508546\n",
      "Iteration 2607, loss = 25185.25762864\n",
      "Iteration 2608, loss = 25094.08344491\n",
      "Iteration 2609, loss = 25003.03981188\n",
      "Iteration 2610, loss = 24911.50308768\n",
      "Iteration 2611, loss = 24819.72770759\n",
      "Iteration 2612, loss = 24728.07641770\n",
      "Iteration 2613, loss = 24637.90835356\n",
      "Iteration 2614, loss = 24548.17530413\n",
      "Iteration 2615, loss = 24459.29695684\n",
      "Iteration 2616, loss = 24370.52041155\n",
      "Iteration 2617, loss = 24283.17662103\n",
      "Iteration 2618, loss = 24195.54542490\n",
      "Iteration 2619, loss = 24108.99983371\n",
      "Iteration 2620, loss = 24023.13146317\n",
      "Iteration 2621, loss = 23936.96785834\n",
      "Iteration 2622, loss = 23851.54929363\n",
      "Iteration 2623, loss = 23766.86358884\n",
      "Iteration 2624, loss = 23683.06829007\n",
      "Iteration 2625, loss = 23604.02887776\n",
      "Iteration 2626, loss = 23526.45304942\n",
      "Iteration 2627, loss = 23452.52056585\n",
      "Iteration 2628, loss = 23381.09146387\n",
      "Iteration 2629, loss = 23311.99219026\n",
      "Iteration 2630, loss = 23242.81573497\n",
      "Iteration 2631, loss = 23169.20237547\n",
      "Iteration 2632, loss = 23094.84243300\n",
      "Iteration 2633, loss = 23024.13845410\n",
      "Iteration 2634, loss = 22946.21999983\n",
      "Iteration 2635, loss = 22855.57373819\n",
      "Iteration 2636, loss = 22757.29637616\n",
      "Iteration 2637, loss = 22648.46747474\n",
      "Iteration 2638, loss = 22535.25858716\n",
      "Iteration 2639, loss = 22425.64027733\n",
      "Iteration 2640, loss = 22323.74174189\n",
      "Iteration 2641, loss = 22234.19875424\n",
      "Iteration 2642, loss = 22154.85682791\n",
      "Iteration 2643, loss = 22082.90681596\n",
      "Iteration 2644, loss = 22016.12996952\n",
      "Iteration 2645, loss = 21951.90030104\n",
      "Iteration 2646, loss = 21886.33478698\n",
      "Iteration 2647, loss = 21819.09488201\n",
      "Iteration 2648, loss = 21743.74060499\n",
      "Iteration 2649, loss = 21664.34253960\n",
      "Iteration 2650, loss = 21575.04508062\n",
      "Iteration 2651, loss = 21481.13595413\n",
      "Iteration 2652, loss = 21383.09216901\n",
      "Iteration 2653, loss = 21288.15556413\n",
      "Iteration 2654, loss = 21199.83887588\n",
      "Iteration 2655, loss = 21119.82741205\n",
      "Iteration 2656, loss = 21046.84249872\n",
      "Iteration 2657, loss = 20978.15149110\n",
      "Iteration 2658, loss = 20910.83411038\n",
      "Iteration 2659, loss = 20842.14261561\n",
      "Iteration 2660, loss = 20769.43377099\n",
      "Iteration 2661, loss = 20692.55495186\n",
      "Iteration 2662, loss = 20611.02890973\n",
      "Iteration 2663, loss = 20528.06491474\n",
      "Iteration 2664, loss = 20444.72785084\n",
      "Iteration 2665, loss = 20363.20559255\n",
      "Iteration 2666, loss = 20283.49277700\n",
      "Iteration 2667, loss = 20206.02369548\n",
      "Iteration 2668, loss = 20130.46106599\n",
      "Iteration 2669, loss = 20056.22565030\n",
      "Iteration 2670, loss = 19983.28155346\n",
      "Iteration 2671, loss = 19911.65752491\n",
      "Iteration 2672, loss = 19841.42487490\n",
      "Iteration 2673, loss = 19773.30998042\n",
      "Iteration 2674, loss = 19705.28506452\n",
      "Iteration 2675, loss = 19638.45879012\n",
      "Iteration 2676, loss = 19572.12229554\n",
      "Iteration 2677, loss = 19506.25152258\n",
      "Iteration 2678, loss = 19440.93318242\n",
      "Iteration 2679, loss = 19376.84587631\n",
      "Iteration 2680, loss = 19311.34394063\n",
      "Iteration 2681, loss = 19247.62165014\n",
      "Iteration 2682, loss = 19180.65206550\n",
      "Iteration 2683, loss = 19115.79022692\n",
      "Iteration 2684, loss = 19046.70175203\n",
      "Iteration 2685, loss = 18976.11606866\n",
      "Iteration 2686, loss = 18901.27845204\n",
      "Iteration 2687, loss = 18822.95324189\n",
      "Iteration 2688, loss = 18740.56874094\n",
      "Iteration 2689, loss = 18658.23052560\n",
      "Iteration 2690, loss = 18576.51190355\n",
      "Iteration 2691, loss = 18497.70196223\n",
      "Iteration 2692, loss = 18422.75340541\n",
      "Iteration 2693, loss = 18351.71505502\n",
      "Iteration 2694, loss = 18283.84881274\n",
      "Iteration 2695, loss = 18218.83300136\n",
      "Iteration 2696, loss = 18155.72152168\n",
      "Iteration 2697, loss = 18093.43394999\n",
      "Iteration 2698, loss = 18032.28721497\n",
      "Iteration 2699, loss = 17971.72528846\n",
      "Iteration 2700, loss = 17913.98087581\n",
      "Iteration 2701, loss = 17856.86429547\n",
      "Iteration 2702, loss = 17800.56997600\n",
      "Iteration 2703, loss = 17743.05541122\n",
      "Iteration 2704, loss = 17685.35977810\n",
      "Iteration 2705, loss = 17625.69822529\n",
      "Iteration 2706, loss = 17563.84349326\n",
      "Iteration 2707, loss = 17497.30648829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2708, loss = 17426.21626938\n",
      "Iteration 2709, loss = 17349.54805384\n",
      "Iteration 2710, loss = 17271.26450287\n",
      "Iteration 2711, loss = 17192.02869646\n",
      "Iteration 2712, loss = 17115.43442545\n",
      "Iteration 2713, loss = 17042.23119449\n",
      "Iteration 2714, loss = 16973.49968155\n",
      "Iteration 2715, loss = 16908.19188941\n",
      "Iteration 2716, loss = 16845.93028141\n",
      "Iteration 2717, loss = 16786.14615408\n",
      "Iteration 2718, loss = 16728.28839314\n",
      "Iteration 2719, loss = 16672.31757464\n",
      "Iteration 2720, loss = 16616.77733413\n",
      "Iteration 2721, loss = 16562.77537174\n",
      "Iteration 2722, loss = 16508.54621137\n",
      "Iteration 2723, loss = 16455.74820965\n",
      "Iteration 2724, loss = 16401.82845850\n",
      "Iteration 2725, loss = 16349.59271983\n",
      "Iteration 2726, loss = 16293.04935025\n",
      "Iteration 2727, loss = 16236.16538901\n",
      "Iteration 2728, loss = 16174.84255739\n",
      "Iteration 2729, loss = 16112.75183655\n",
      "Iteration 2730, loss = 16044.59624959\n",
      "Iteration 2731, loss = 15976.36398234\n",
      "Iteration 2732, loss = 15903.53408886\n",
      "Iteration 2733, loss = 15830.40761715\n",
      "Iteration 2734, loss = 15760.15480154\n",
      "Iteration 2735, loss = 15693.99210820\n",
      "Iteration 2736, loss = 15632.04489085\n",
      "Iteration 2737, loss = 15573.50012497\n",
      "Iteration 2738, loss = 15517.57694072\n",
      "Iteration 2739, loss = 15464.71412052\n",
      "Iteration 2740, loss = 15414.50450322\n",
      "Iteration 2741, loss = 15366.81396274\n",
      "Iteration 2742, loss = 15321.19859240\n",
      "Iteration 2743, loss = 15276.09387949\n",
      "Iteration 2744, loss = 15233.88052128\n",
      "Iteration 2745, loss = 15189.52420021\n",
      "Iteration 2746, loss = 15147.12545939\n",
      "Iteration 2747, loss = 15098.94050775\n",
      "Iteration 2748, loss = 15048.32773747\n",
      "Iteration 2749, loss = 14988.61189600\n",
      "Iteration 2750, loss = 14922.67789606\n",
      "Iteration 2751, loss = 14848.69275079\n",
      "Iteration 2752, loss = 14770.90317561\n",
      "Iteration 2753, loss = 14693.20660598\n",
      "Iteration 2754, loss = 14619.21716542\n",
      "Iteration 2755, loss = 14554.15065487\n",
      "Iteration 2756, loss = 14495.50165998\n",
      "Iteration 2757, loss = 14443.95056360\n",
      "Iteration 2758, loss = 14395.89060859\n",
      "Iteration 2759, loss = 14349.97393533\n",
      "Iteration 2760, loss = 14305.20089462\n",
      "Iteration 2761, loss = 14260.57462272\n",
      "Iteration 2762, loss = 14214.56394598\n",
      "Iteration 2763, loss = 14168.31554236\n",
      "Iteration 2764, loss = 14120.50730549\n",
      "Iteration 2765, loss = 14070.29405986\n",
      "Iteration 2766, loss = 14018.36721825\n",
      "Iteration 2767, loss = 13963.15186583\n",
      "Iteration 2768, loss = 13905.69519851\n",
      "Iteration 2769, loss = 13846.36016210\n",
      "Iteration 2770, loss = 13785.34303097\n",
      "Iteration 2771, loss = 13723.67154544\n",
      "Iteration 2772, loss = 13660.81566391\n",
      "Iteration 2773, loss = 13599.18785470\n",
      "Iteration 2774, loss = 13539.84083348\n",
      "Iteration 2775, loss = 13483.49950286\n",
      "Iteration 2776, loss = 13429.59587287\n",
      "Iteration 2777, loss = 13377.48527566\n",
      "Iteration 2778, loss = 13326.52454603\n",
      "Iteration 2779, loss = 13276.49366716\n",
      "Iteration 2780, loss = 13227.24741525\n",
      "Iteration 2781, loss = 13178.94900091\n",
      "Iteration 2782, loss = 13131.86501946\n",
      "Iteration 2783, loss = 13086.09212973\n",
      "Iteration 2784, loss = 13042.38608627\n",
      "Iteration 2785, loss = 13001.49454637\n",
      "Iteration 2786, loss = 12964.83524541\n",
      "Iteration 2787, loss = 12929.23714762\n",
      "Iteration 2788, loss = 12900.40773901\n",
      "Iteration 2789, loss = 12869.79790885\n",
      "Iteration 2790, loss = 12844.76253715\n",
      "Iteration 2791, loss = 12810.60861233\n",
      "Iteration 2792, loss = 12776.11323092\n",
      "Iteration 2793, loss = 12723.44116919\n",
      "Iteration 2794, loss = 12663.89481258\n",
      "Iteration 2795, loss = 12585.10670853\n",
      "Iteration 2796, loss = 12499.94261059\n",
      "Iteration 2797, loss = 12415.71820389\n",
      "Iteration 2798, loss = 12344.30117013\n",
      "Iteration 2799, loss = 12290.65624498\n",
      "Iteration 2800, loss = 12251.95023692\n",
      "Iteration 2801, loss = 12221.73426876\n",
      "Iteration 2802, loss = 12193.12557961\n",
      "Iteration 2803, loss = 12158.83515188\n",
      "Iteration 2804, loss = 12116.33040984\n",
      "Iteration 2805, loss = 12064.90510222\n",
      "Iteration 2806, loss = 12006.02688823\n",
      "Iteration 2807, loss = 11944.18235350\n",
      "Iteration 2808, loss = 11884.36156472\n",
      "Iteration 2809, loss = 11829.88679563\n",
      "Iteration 2810, loss = 11781.70026060\n",
      "Iteration 2811, loss = 11739.28223892\n",
      "Iteration 2812, loss = 11700.96378903\n",
      "Iteration 2813, loss = 11664.77682275\n",
      "Iteration 2814, loss = 11627.54696745\n",
      "Iteration 2815, loss = 11588.31498446\n",
      "Iteration 2816, loss = 11547.24668577\n",
      "Iteration 2817, loss = 11503.08859839\n",
      "Iteration 2818, loss = 11456.71256530\n",
      "Iteration 2819, loss = 11407.88374109\n",
      "Iteration 2820, loss = 11358.02972433\n",
      "Iteration 2821, loss = 11309.09710019\n",
      "Iteration 2822, loss = 11261.51673752\n",
      "Iteration 2823, loss = 11215.30820983\n",
      "Iteration 2824, loss = 11170.36568803\n",
      "Iteration 2825, loss = 11126.50105920\n",
      "Iteration 2826, loss = 11083.58137400\n",
      "Iteration 2827, loss = 11041.34652353\n",
      "Iteration 2828, loss = 10999.50198955\n",
      "Iteration 2829, loss = 10957.78385254\n",
      "Iteration 2830, loss = 10916.29647401\n",
      "Iteration 2831, loss = 10875.30614548\n",
      "Iteration 2832, loss = 10834.89718609\n",
      "Iteration 2833, loss = 10795.05102417\n",
      "Iteration 2834, loss = 10755.84603438\n",
      "Iteration 2835, loss = 10717.64842265\n",
      "Iteration 2836, loss = 10681.67871747\n",
      "Iteration 2837, loss = 10648.03010258\n",
      "Iteration 2838, loss = 10617.45421574\n",
      "Iteration 2839, loss = 10591.59434107\n",
      "Iteration 2840, loss = 10570.04936852\n",
      "Iteration 2841, loss = 10554.05927453\n",
      "Iteration 2842, loss = 10540.60747971\n",
      "Iteration 2843, loss = 10529.31539936\n",
      "Iteration 2844, loss = 10512.52115220\n",
      "Iteration 2845, loss = 10489.47971110\n",
      "Iteration 2846, loss = 10450.09141326\n",
      "Iteration 2847, loss = 10392.67474149\n",
      "Iteration 2848, loss = 10315.66346321\n",
      "Iteration 2849, loss = 10229.63232125\n",
      "Iteration 2850, loss = 10146.91729498\n",
      "Iteration 2851, loss = 10079.74304270\n",
      "Iteration 2852, loss = 10032.95736342\n",
      "Iteration 2853, loss = 10004.03244380\n",
      "Iteration 2854, loss = 9985.53929284\n",
      "Iteration 2855, loss = 9968.42559952\n",
      "Iteration 2856, loss = 9945.36274064\n",
      "Iteration 2857, loss = 9912.68692914\n",
      "Iteration 2858, loss = 9869.65087078\n",
      "Iteration 2859, loss = 9818.89203352\n",
      "Iteration 2860, loss = 9763.71410483\n",
      "Iteration 2861, loss = 9709.31594304\n",
      "Iteration 2862, loss = 9660.51483110\n",
      "Iteration 2863, loss = 9619.28248729\n",
      "Iteration 2864, loss = 9584.47548151\n",
      "Iteration 2865, loss = 9553.82650313\n",
      "Iteration 2866, loss = 9524.37594353\n",
      "Iteration 2867, loss = 9494.13212246\n",
      "Iteration 2868, loss = 9461.43257095\n",
      "Iteration 2869, loss = 9426.57552583\n",
      "Iteration 2870, loss = 9388.92250083\n",
      "Iteration 2871, loss = 9349.56044631\n",
      "Iteration 2872, loss = 9309.05447277\n",
      "Iteration 2873, loss = 9268.38089494\n",
      "Iteration 2874, loss = 9228.56048387\n",
      "Iteration 2875, loss = 9189.74859283\n",
      "Iteration 2876, loss = 9152.09943921\n",
      "Iteration 2877, loss = 9115.68988330\n",
      "Iteration 2878, loss = 9080.08613544\n",
      "Iteration 2879, loss = 9045.11327101\n",
      "Iteration 2880, loss = 9010.72609328\n",
      "Iteration 2881, loss = 8976.71174913\n",
      "Iteration 2882, loss = 8942.96016885\n",
      "Iteration 2883, loss = 8909.65117296\n",
      "Iteration 2884, loss = 8876.69773775\n",
      "Iteration 2885, loss = 8844.16756319\n",
      "Iteration 2886, loss = 8811.86991080\n",
      "Iteration 2887, loss = 8780.09222455\n",
      "Iteration 2888, loss = 8749.49544919\n",
      "Iteration 2889, loss = 8719.78900311\n",
      "Iteration 2890, loss = 8691.90173551\n",
      "Iteration 2891, loss = 8664.37981258\n",
      "Iteration 2892, loss = 8638.30738995\n",
      "Iteration 2893, loss = 8612.66308830\n",
      "Iteration 2894, loss = 8588.38625326\n",
      "Iteration 2895, loss = 8563.21022730\n",
      "Iteration 2896, loss = 8538.25826039\n",
      "Iteration 2897, loss = 8510.87408118\n",
      "Iteration 2898, loss = 8482.76073102\n",
      "Iteration 2899, loss = 8450.25496769\n",
      "Iteration 2900, loss = 8416.77788933\n",
      "Iteration 2901, loss = 8379.04210325\n",
      "Iteration 2902, loss = 8339.20186561\n",
      "Iteration 2903, loss = 8295.82837233\n",
      "Iteration 2904, loss = 8252.36927617\n",
      "Iteration 2905, loss = 8207.92967467\n",
      "Iteration 2906, loss = 8164.82486380\n",
      "Iteration 2907, loss = 8123.82442057\n",
      "Iteration 2908, loss = 8085.58116481\n",
      "Iteration 2909, loss = 8050.12175957\n",
      "Iteration 2910, loss = 8016.83651735\n",
      "Iteration 2911, loss = 7985.13179394\n",
      "Iteration 2912, loss = 7954.50554019\n",
      "Iteration 2913, loss = 7924.97157729\n",
      "Iteration 2914, loss = 7896.48295817\n",
      "Iteration 2915, loss = 7869.16532931\n",
      "Iteration 2916, loss = 7842.03468695\n",
      "Iteration 2917, loss = 7816.16808278\n",
      "Iteration 2918, loss = 7789.95743050\n",
      "Iteration 2919, loss = 7768.26957198\n",
      "Iteration 2920, loss = 7745.21488820\n",
      "Iteration 2921, loss = 7718.91778054\n",
      "Iteration 2922, loss = 7689.81738107\n",
      "Iteration 2923, loss = 7659.21859353\n",
      "Iteration 2924, loss = 7626.05034392\n",
      "Iteration 2925, loss = 7591.16179073\n",
      "Iteration 2926, loss = 7553.12731729\n",
      "Iteration 2927, loss = 7513.98389170\n",
      "Iteration 2928, loss = 7474.47737026\n",
      "Iteration 2929, loss = 7435.74390095\n",
      "Iteration 2930, loss = 7398.19903112\n",
      "Iteration 2931, loss = 7362.77855722\n",
      "Iteration 2932, loss = 7328.74937464\n",
      "Iteration 2933, loss = 7295.83150265\n",
      "Iteration 2934, loss = 7264.37724654\n",
      "Iteration 2935, loss = 7234.05266642\n",
      "Iteration 2936, loss = 7204.62552432\n",
      "Iteration 2937, loss = 7175.66062270\n",
      "Iteration 2938, loss = 7147.08977147\n",
      "Iteration 2939, loss = 7119.03453710\n",
      "Iteration 2940, loss = 7091.55929301\n",
      "Iteration 2941, loss = 7064.62374223\n",
      "Iteration 2942, loss = 7038.25205224\n",
      "Iteration 2943, loss = 7012.84106931\n",
      "Iteration 2944, loss = 6988.65083180\n",
      "Iteration 2945, loss = 6965.80938725\n",
      "Iteration 2946, loss = 6944.48240094\n",
      "Iteration 2947, loss = 6925.15350525\n",
      "Iteration 2948, loss = 6908.72310194\n",
      "Iteration 2949, loss = 6896.21676693\n",
      "Iteration 2950, loss = 6887.38297139\n",
      "Iteration 2951, loss = 6881.46532344\n",
      "Iteration 2952, loss = 6879.71861441\n",
      "Iteration 2953, loss = 6877.86268125\n",
      "Iteration 2954, loss = 6878.55297124\n",
      "Iteration 2955, loss = 6867.60264260\n",
      "Iteration 2956, loss = 6848.19825142\n",
      "Iteration 2957, loss = 6803.49399436\n",
      "Iteration 2958, loss = 6741.87396074\n",
      "Iteration 2959, loss = 6663.96780965\n",
      "Iteration 2960, loss = 6587.38528104\n",
      "Iteration 2961, loss = 6523.69938249\n",
      "Iteration 2962, loss = 6482.04452698\n",
      "Iteration 2963, loss = 6462.22266114\n",
      "Iteration 2964, loss = 6456.82103570\n",
      "Iteration 2965, loss = 6455.21424257\n",
      "Iteration 2966, loss = 6445.48698921\n",
      "Iteration 2967, loss = 6425.19019065\n",
      "Iteration 2968, loss = 6390.12956023\n",
      "Iteration 2969, loss = 6346.71823095\n",
      "Iteration 2970, loss = 6300.26696544\n",
      "Iteration 2971, loss = 6259.43199477\n",
      "Iteration 2972, loss = 6226.72219057\n",
      "Iteration 2973, loss = 6202.55854482\n",
      "Iteration 2974, loss = 6184.12823689\n",
      "Iteration 2975, loss = 6167.97179753\n",
      "Iteration 2976, loss = 6150.94781433\n",
      "Iteration 2977, loss = 6130.22367947\n",
      "Iteration 2978, loss = 6105.26369714\n",
      "Iteration 2979, loss = 6077.21989101\n",
      "Iteration 2980, loss = 6047.25699648\n",
      "Iteration 2981, loss = 6016.97596027\n",
      "Iteration 2982, loss = 5987.52091493\n",
      "Iteration 2983, loss = 5959.58941755\n",
      "Iteration 2984, loss = 5933.69357578\n",
      "Iteration 2985, loss = 5909.45113829\n",
      "Iteration 2986, loss = 5886.31183071\n",
      "Iteration 2987, loss = 5863.85012053\n",
      "Iteration 2988, loss = 5841.74053502\n",
      "Iteration 2989, loss = 5819.57162333\n",
      "Iteration 2990, loss = 5797.16815896\n",
      "Iteration 2991, loss = 5774.42468764\n",
      "Iteration 2992, loss = 5751.60854147\n",
      "Iteration 2993, loss = 5728.35390776\n",
      "Iteration 2994, loss = 5704.87339604\n",
      "Iteration 2995, loss = 5681.34973036\n",
      "Iteration 2996, loss = 5657.94475972\n",
      "Iteration 2997, loss = 5634.63771729\n",
      "Iteration 2998, loss = 5611.49283811\n",
      "Iteration 2999, loss = 5588.63787444\n",
      "Iteration 3000, loss = 5566.00348093\n",
      "Iteration 3001, loss = 5543.63298824\n",
      "Iteration 3002, loss = 5521.50278436\n",
      "Iteration 3003, loss = 5499.49060156\n",
      "Iteration 3004, loss = 5477.62734165\n",
      "Iteration 3005, loss = 5455.91978254\n",
      "Iteration 3006, loss = 5434.26961089\n",
      "Iteration 3007, loss = 5412.74756773\n",
      "Iteration 3008, loss = 5391.41445042\n",
      "Iteration 3009, loss = 5370.17761032\n",
      "Iteration 3010, loss = 5349.09217867\n",
      "Iteration 3011, loss = 5328.21511590\n",
      "Iteration 3012, loss = 5307.39163976\n",
      "Iteration 3013, loss = 5286.86051023\n",
      "Iteration 3014, loss = 5266.79351770\n",
      "Iteration 3015, loss = 5246.91933393\n",
      "Iteration 3016, loss = 5227.39232983\n",
      "Iteration 3017, loss = 5208.38235482\n",
      "Iteration 3018, loss = 5190.15809029\n",
      "Iteration 3019, loss = 5172.67631395\n",
      "Iteration 3020, loss = 5156.27763339\n",
      "Iteration 3021, loss = 5141.06982946\n",
      "Iteration 3022, loss = 5128.15976698\n",
      "Iteration 3023, loss = 5117.72979929\n",
      "Iteration 3024, loss = 5111.23799723\n",
      "Iteration 3025, loss = 5109.58792281\n",
      "Iteration 3026, loss = 5114.09276343\n",
      "Iteration 3027, loss = 5126.69609508\n",
      "Iteration 3028, loss = 5152.20463826\n",
      "Iteration 3029, loss = 5181.81770744\n",
      "Iteration 3030, loss = 5218.57033979\n",
      "Iteration 3031, loss = 5236.19525514\n",
      "Iteration 3032, loss = 5235.17762754\n",
      "Iteration 3033, loss = 5178.23329063\n",
      "Iteration 3034, loss = 5085.12531195\n",
      "Iteration 3035, loss = 4964.16649157\n",
      "Iteration 3036, loss = 4862.40261870\n",
      "Iteration 3037, loss = 4808.08317308\n",
      "Iteration 3038, loss = 4804.69118164\n",
      "Iteration 3039, loss = 4831.00666165\n",
      "Iteration 3040, loss = 4855.73820020\n",
      "Iteration 3041, loss = 4855.38426658\n",
      "Iteration 3042, loss = 4818.70518624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3043, loss = 4760.69909104\n",
      "Iteration 3044, loss = 4700.91345310\n",
      "Iteration 3045, loss = 4660.62640731\n",
      "Iteration 3046, loss = 4645.46160217\n",
      "Iteration 3047, loss = 4647.52283199\n",
      "Iteration 3048, loss = 4651.34032636\n",
      "Iteration 3049, loss = 4643.27187749\n",
      "Iteration 3050, loss = 4619.29150456\n",
      "Iteration 3051, loss = 4583.26775020\n",
      "Iteration 3052, loss = 4546.44388490\n",
      "Iteration 3053, loss = 4517.29369240\n",
      "Iteration 3054, loss = 4499.45789202\n",
      "Iteration 3055, loss = 4489.96709229\n",
      "Iteration 3056, loss = 4482.33470961\n",
      "Iteration 3057, loss = 4471.54042599\n",
      "Iteration 3058, loss = 4453.31854188\n",
      "Iteration 3059, loss = 4429.01813030\n",
      "Iteration 3060, loss = 4402.97237716\n",
      "Iteration 3061, loss = 4379.51686417\n",
      "Iteration 3062, loss = 4360.80077202\n",
      "Iteration 3063, loss = 4346.03355278\n",
      "Iteration 3064, loss = 4333.26215383\n",
      "Iteration 3065, loss = 4320.07788582\n",
      "Iteration 3066, loss = 4304.89103476\n",
      "Iteration 3067, loss = 4286.73441011\n",
      "Iteration 3068, loss = 4266.80801454\n",
      "Iteration 3069, loss = 4246.70001655\n",
      "Iteration 3070, loss = 4227.90357139\n",
      "Iteration 3071, loss = 4210.94776789\n",
      "Iteration 3072, loss = 4195.57557998\n",
      "Iteration 3073, loss = 4181.01119649\n",
      "Iteration 3074, loss = 4166.45881932\n",
      "Iteration 3075, loss = 4151.42674575\n",
      "Iteration 3076, loss = 4135.52540872\n",
      "Iteration 3077, loss = 4118.79974041\n",
      "Iteration 3078, loss = 4101.65174466\n",
      "Iteration 3079, loss = 4084.43356304\n",
      "Iteration 3080, loss = 4067.58842541\n",
      "Iteration 3081, loss = 4051.24525838\n",
      "Iteration 3082, loss = 4035.53774899\n",
      "Iteration 3083, loss = 4020.10191304\n",
      "Iteration 3084, loss = 4004.86144596\n",
      "Iteration 3085, loss = 3989.66768467\n",
      "Iteration 3086, loss = 3974.51318233\n",
      "Iteration 3087, loss = 3959.44227033\n",
      "Iteration 3088, loss = 3944.31564481\n",
      "Iteration 3089, loss = 3929.04545927\n",
      "Iteration 3090, loss = 3913.66498835\n",
      "Iteration 3091, loss = 3898.40581469\n",
      "Iteration 3092, loss = 3883.23262736\n",
      "Iteration 3093, loss = 3868.06824211\n",
      "Iteration 3094, loss = 3852.95156095\n",
      "Iteration 3095, loss = 3837.98734464\n",
      "Iteration 3096, loss = 3823.19452742\n",
      "Iteration 3097, loss = 3808.46912213\n",
      "Iteration 3098, loss = 3793.80519643\n",
      "Iteration 3099, loss = 3779.21909572\n",
      "Iteration 3100, loss = 3764.71106097\n",
      "Iteration 3101, loss = 3750.39343369\n",
      "Iteration 3102, loss = 3736.03274613\n",
      "Iteration 3103, loss = 3721.76208166\n",
      "Iteration 3104, loss = 3707.46959114\n",
      "Iteration 3105, loss = 3693.27043436\n",
      "Iteration 3106, loss = 3679.13557664\n",
      "Iteration 3107, loss = 3665.09713664\n",
      "Iteration 3108, loss = 3651.07659006\n",
      "Iteration 3109, loss = 3637.10846981\n",
      "Iteration 3110, loss = 3623.19818817\n",
      "Iteration 3111, loss = 3609.35936946\n",
      "Iteration 3112, loss = 3595.61086327\n",
      "Iteration 3113, loss = 3581.89053327\n",
      "Iteration 3114, loss = 3568.23150009\n",
      "Iteration 3115, loss = 3554.68222140\n",
      "Iteration 3116, loss = 3541.22731911\n",
      "Iteration 3117, loss = 3527.91027776\n",
      "Iteration 3118, loss = 3514.65578378\n",
      "Iteration 3119, loss = 3501.61851091\n",
      "Iteration 3120, loss = 3488.67241079\n",
      "Iteration 3121, loss = 3475.95372315\n",
      "Iteration 3122, loss = 3463.53181695\n",
      "Iteration 3123, loss = 3451.71081012\n",
      "Iteration 3124, loss = 3440.51027336\n",
      "Iteration 3125, loss = 3430.07158722\n",
      "Iteration 3126, loss = 3420.79572328\n",
      "Iteration 3127, loss = 3413.26347431\n",
      "Iteration 3128, loss = 3408.69650476\n",
      "Iteration 3129, loss = 3408.43142628\n",
      "Iteration 3130, loss = 3413.90133787\n",
      "Iteration 3131, loss = 3429.17679239\n",
      "Iteration 3132, loss = 3455.00270235\n",
      "Iteration 3133, loss = 3498.53736417\n",
      "Iteration 3134, loss = 3553.80644946\n",
      "Iteration 3135, loss = 3624.49121659\n",
      "Iteration 3136, loss = 3680.34692724\n",
      "Iteration 3137, loss = 3712.47450711\n",
      "Iteration 3138, loss = 3665.54435099\n",
      "Iteration 3139, loss = 3553.80018609\n",
      "Iteration 3140, loss = 3393.91020521\n",
      "Iteration 3141, loss = 3262.39449179\n",
      "Iteration 3142, loss = 3209.51630122\n",
      "Iteration 3143, loss = 3236.38662251\n",
      "Iteration 3144, loss = 3298.25402074\n",
      "Iteration 3145, loss = 3339.15927752\n",
      "Iteration 3146, loss = 3327.09604050\n",
      "Iteration 3147, loss = 3260.94985347\n",
      "Iteration 3148, loss = 3181.33884546\n",
      "Iteration 3149, loss = 3129.72096720\n",
      "Iteration 3150, loss = 3123.34210089\n",
      "Iteration 3151, loss = 3146.25306490\n",
      "Iteration 3152, loss = 3166.84636152\n",
      "Iteration 3153, loss = 3161.74226599\n",
      "Iteration 3154, loss = 3127.44276392\n",
      "Iteration 3155, loss = 3082.86540709\n",
      "Iteration 3156, loss = 3049.28323037\n",
      "Iteration 3157, loss = 3037.30816054\n",
      "Iteration 3158, loss = 3041.57539819\n",
      "Iteration 3159, loss = 3047.41175594\n",
      "Iteration 3160, loss = 3042.59632129\n",
      "Iteration 3161, loss = 3023.05352110\n",
      "Iteration 3162, loss = 2996.43120836\n",
      "Iteration 3163, loss = 2972.30301749\n",
      "Iteration 3164, loss = 2957.63159267\n",
      "Iteration 3165, loss = 2951.94589109\n",
      "Iteration 3166, loss = 2949.63248607\n",
      "Iteration 3167, loss = 2944.19590334\n",
      "Iteration 3168, loss = 2931.93038291\n",
      "Iteration 3169, loss = 2914.65358365\n",
      "Iteration 3170, loss = 2896.76041934\n",
      "Iteration 3171, loss = 2882.39385753\n",
      "Iteration 3172, loss = 2872.76267629\n",
      "Iteration 3173, loss = 2866.00488816\n",
      "Iteration 3174, loss = 2859.04374531\n",
      "Iteration 3175, loss = 2849.43951772\n",
      "Iteration 3176, loss = 2837.01203804\n",
      "Iteration 3177, loss = 2823.40521761\n",
      "Iteration 3178, loss = 2810.11812735\n",
      "Iteration 3179, loss = 2798.71478984\n",
      "Iteration 3180, loss = 2789.08101289\n",
      "Iteration 3181, loss = 2780.45395013\n",
      "Iteration 3182, loss = 2771.82847772\n",
      "Iteration 3183, loss = 2762.44915383\n",
      "Iteration 3184, loss = 2752.05890353\n",
      "Iteration 3185, loss = 2740.80197383\n",
      "Iteration 3186, loss = 2729.34208914\n",
      "Iteration 3187, loss = 2718.15464817\n",
      "Iteration 3188, loss = 2707.71034289\n",
      "Iteration 3189, loss = 2697.99632655\n",
      "Iteration 3190, loss = 2688.72968908\n",
      "Iteration 3191, loss = 2679.53201327\n",
      "Iteration 3192, loss = 2670.09380077\n",
      "Iteration 3193, loss = 2660.32400258\n",
      "Iteration 3194, loss = 2650.21531576\n",
      "Iteration 3195, loss = 2639.95585889\n",
      "Iteration 3196, loss = 2629.86852825\n",
      "Iteration 3197, loss = 2619.95356762\n",
      "Iteration 3198, loss = 2610.48051064\n",
      "Iteration 3199, loss = 2601.25652465\n",
      "Iteration 3200, loss = 2592.11451978\n",
      "Iteration 3201, loss = 2582.92939432\n",
      "Iteration 3202, loss = 2573.63085634\n",
      "Iteration 3203, loss = 2564.20363045\n",
      "Iteration 3204, loss = 2554.79212304\n",
      "Iteration 3205, loss = 2545.37881963\n",
      "Iteration 3206, loss = 2535.97863387\n",
      "Iteration 3207, loss = 2526.57774954\n",
      "Iteration 3208, loss = 2517.38535892\n",
      "Iteration 3209, loss = 2508.13482348\n",
      "Iteration 3210, loss = 2499.08664872\n",
      "Iteration 3211, loss = 2490.06909845\n",
      "Iteration 3212, loss = 2481.08225423\n",
      "Iteration 3213, loss = 2472.17574398\n",
      "Iteration 3214, loss = 2463.31204329\n",
      "Iteration 3215, loss = 2454.48556137\n",
      "Iteration 3216, loss = 2445.65461953\n",
      "Iteration 3217, loss = 2436.85724530\n",
      "Iteration 3218, loss = 2428.18887390\n",
      "Iteration 3219, loss = 2419.35301962\n",
      "Iteration 3220, loss = 2410.72547831\n",
      "Iteration 3221, loss = 2402.11326852\n",
      "Iteration 3222, loss = 2393.48130143\n",
      "Iteration 3223, loss = 2384.86432639\n",
      "Iteration 3224, loss = 2376.32312213\n",
      "Iteration 3225, loss = 2367.88866975\n",
      "Iteration 3226, loss = 2359.51357096\n",
      "Iteration 3227, loss = 2351.12384442\n",
      "Iteration 3228, loss = 2342.77738374\n",
      "Iteration 3229, loss = 2334.47913826\n",
      "Iteration 3230, loss = 2326.27549288\n",
      "Iteration 3231, loss = 2318.11653764\n",
      "Iteration 3232, loss = 2310.07956541\n",
      "Iteration 3233, loss = 2302.00715871\n",
      "Iteration 3234, loss = 2293.89926178\n",
      "Iteration 3235, loss = 2285.85921900\n",
      "Iteration 3236, loss = 2277.94889937\n",
      "Iteration 3237, loss = 2270.31253216\n",
      "Iteration 3238, loss = 2262.72964558\n",
      "Iteration 3239, loss = 2255.20243415\n",
      "Iteration 3240, loss = 2247.71895614\n",
      "Iteration 3241, loss = 2240.35163613\n",
      "Iteration 3242, loss = 2233.15134272\n",
      "Iteration 3243, loss = 2226.53266345\n",
      "Iteration 3244, loss = 2220.06890210\n",
      "Iteration 3245, loss = 2213.79209203\n",
      "Iteration 3246, loss = 2207.82862182\n",
      "Iteration 3247, loss = 2202.49810099\n",
      "Iteration 3248, loss = 2198.04065508\n",
      "Iteration 3249, loss = 2195.02175361\n",
      "Iteration 3250, loss = 2193.39664648\n",
      "Iteration 3251, loss = 2193.56546258\n",
      "Iteration 3252, loss = 2195.94098881\n",
      "Iteration 3253, loss = 2201.30464258\n",
      "Iteration 3254, loss = 2208.84261995\n",
      "Iteration 3255, loss = 2222.45629860\n",
      "Iteration 3256, loss = 2238.03338132\n",
      "Iteration 3257, loss = 2259.61146844\n",
      "Iteration 3258, loss = 2278.83359430\n",
      "Iteration 3259, loss = 2298.05451108\n",
      "Iteration 3260, loss = 2301.27431932\n",
      "Iteration 3261, loss = 2295.12345489\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#folosim MLP regressor pentru predictii\n",
    "#MLP Regressor pentru NN Multy Layer\n",
    "regr = MLPRegressor(solver='adam', hidden_layer_sizes=(200,100), max_iter=10000, verbose = 'true',activation='relu')\n",
    "\n",
    "#Antrenam modelul folosind setul de train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Facem predictii folosind setul de test\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-60,  -5,  -5,   0]),\n",
       " array([-31,   7,   4,   0]),\n",
       " array([742,  -7, 151,  10]),\n",
       " array([7976,  426,  323,   21]),\n",
       " array([-59,  -5,  -5,   0]),\n",
       " array([2872,   97,  241,   13]),\n",
       " array([7657,  405,  318,   20]),\n",
       " array([6062,  302,  292,   18]),\n",
       " array([10527,   590,   364,    24]),\n",
       " array([-25,  10,   9,   0]),\n",
       " array([-42,   2,   0,   0]),\n",
       " array([-22,  12,  11,   0]),\n",
       " array([-67, -12,  -9,   0]),\n",
       " array([2234,   55,  231,   12]),\n",
       " array([-54,  -2,  -3,   0]),\n",
       " array([-70, -12,  -9,   0]),\n",
       " array([6700,  343,  302,   19]),\n",
       " array([-69, -12,  -9,   0]),\n",
       " array([-49,   0,  -2,   0]),\n",
       " array([-58,  -4,  -5,   0]),\n",
       " array([-68, -12,  -9,   0])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertim datele din float in int\n",
    "result_int = []\n",
    "for x in y_pred:\n",
    "    result_int.append(x.astype(int))\n",
    "\n",
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Folosim diferite scalere pentru a puteam face operatii de normalizare, standardizare si scalare\n",
    "std_scaler = StandardScaler() \n",
    "std_scaler2 = StandardScaler()\n",
    "minMaxScaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxScaler.fit(X_train)  \n",
    "X_train = minMaxScaler.transform(X_train)  \n",
    "\n",
    "#Normalizam si scalam setul de train\n",
    "std_scaler.fit(X_train)  \n",
    "X_train = std_scaler.transform(X_train) \n",
    "std_scaler2.fit(X_train)  \n",
    "X_train = std_scaler2.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizam si scalam setul de test\n",
    "minMaxScaler.fit(X_test) \n",
    "X_test = minMaxScaler.transform(X_test)  \n",
    "std_scaler.fit(X_test) \n",
    "X_test = std_scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalam si standardizam datele de test\n",
    "std_scaler2.fit(X_test) \n",
    "X_test = std_scaler2.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1835595.19163764\n",
      "Iteration 2, loss = 1835543.57389179\n",
      "Iteration 3, loss = 1835493.18193466\n",
      "Iteration 4, loss = 1835443.96044343\n",
      "Iteration 5, loss = 1835396.15659576\n",
      "Iteration 6, loss = 1835353.21879957\n",
      "Iteration 7, loss = 1835312.25028738\n",
      "Iteration 8, loss = 1835271.99964443\n",
      "Iteration 9, loss = 1835230.61751008\n",
      "Iteration 10, loss = 1835188.88974233\n",
      "Iteration 11, loss = 1835147.41810403\n",
      "Iteration 12, loss = 1835105.55712800\n",
      "Iteration 13, loss = 1835063.04985237\n",
      "Iteration 14, loss = 1835019.18716525\n",
      "Iteration 15, loss = 1834973.68727514\n",
      "Iteration 16, loss = 1834926.36886312\n",
      "Iteration 17, loss = 1834876.86238443\n",
      "Iteration 18, loss = 1834825.29482847\n",
      "Iteration 19, loss = 1834771.75491448\n",
      "Iteration 20, loss = 1834716.18819223\n",
      "Iteration 21, loss = 1834658.43353300\n",
      "Iteration 22, loss = 1834598.38433547\n",
      "Iteration 23, loss = 1834535.92485222\n",
      "Iteration 24, loss = 1834470.91832159\n",
      "Iteration 25, loss = 1834403.21961062\n",
      "Iteration 26, loss = 1834332.71685032\n",
      "Iteration 27, loss = 1834259.27861355\n",
      "Iteration 28, loss = 1834182.70923902\n",
      "Iteration 29, loss = 1834102.82694226\n",
      "Iteration 30, loss = 1834019.46455336\n",
      "Iteration 31, loss = 1833932.48478456\n",
      "Iteration 32, loss = 1833841.68852855\n",
      "Iteration 33, loss = 1833746.91299442\n",
      "Iteration 34, loss = 1833647.95769585\n",
      "Iteration 35, loss = 1833544.63761419\n",
      "Iteration 36, loss = 1833436.87714690\n",
      "Iteration 37, loss = 1833324.47572661\n",
      "Iteration 38, loss = 1833207.21672846\n",
      "Iteration 39, loss = 1833084.97610880\n",
      "Iteration 40, loss = 1832957.17495972\n",
      "Iteration 41, loss = 1832823.75887418\n",
      "Iteration 42, loss = 1832684.50100138\n",
      "Iteration 43, loss = 1832539.30970129\n",
      "Iteration 44, loss = 1832388.04274678\n",
      "Iteration 45, loss = 1832230.55425567\n",
      "Iteration 46, loss = 1832066.62185152\n",
      "Iteration 47, loss = 1831896.03363907\n",
      "Iteration 48, loss = 1831718.51165125\n",
      "Iteration 49, loss = 1831533.73729607\n",
      "Iteration 50, loss = 1831341.59744058\n",
      "Iteration 51, loss = 1831141.81989459\n",
      "Iteration 52, loss = 1830934.19419842\n",
      "Iteration 53, loss = 1830718.45909858\n",
      "Iteration 54, loss = 1830494.37816584\n",
      "Iteration 55, loss = 1830261.73239820\n",
      "Iteration 56, loss = 1830020.33234304\n",
      "Iteration 57, loss = 1829769.91934719\n",
      "Iteration 58, loss = 1829510.31981100\n",
      "Iteration 59, loss = 1829241.29143955\n",
      "Iteration 60, loss = 1828962.69679691\n",
      "Iteration 61, loss = 1828674.35012179\n",
      "Iteration 62, loss = 1828376.05745633\n",
      "Iteration 63, loss = 1828067.51564160\n",
      "Iteration 64, loss = 1827748.49691917\n",
      "Iteration 65, loss = 1827418.86104384\n",
      "Iteration 66, loss = 1827078.40357770\n",
      "Iteration 67, loss = 1826726.90049510\n",
      "Iteration 68, loss = 1826364.11897751\n",
      "Iteration 69, loss = 1825989.82355199\n",
      "Iteration 70, loss = 1825603.79705444\n",
      "Iteration 71, loss = 1825205.80418389\n",
      "Iteration 72, loss = 1824795.60983457\n",
      "Iteration 73, loss = 1824372.96921102\n",
      "Iteration 74, loss = 1823936.77744263\n",
      "Iteration 75, loss = 1823486.83265405\n",
      "Iteration 76, loss = 1823023.02637026\n",
      "Iteration 77, loss = 1822545.32223492\n",
      "Iteration 78, loss = 1822053.54804138\n",
      "Iteration 79, loss = 1821547.48566261\n",
      "Iteration 80, loss = 1821026.90761419\n",
      "Iteration 81, loss = 1820491.55760923\n",
      "Iteration 82, loss = 1819941.15370593\n",
      "Iteration 83, loss = 1819375.47593664\n",
      "Iteration 84, loss = 1818794.17883510\n",
      "Iteration 85, loss = 1818197.15637098\n",
      "Iteration 86, loss = 1817584.18674854\n",
      "Iteration 87, loss = 1816954.96445420\n",
      "Iteration 88, loss = 1816309.21487256\n",
      "Iteration 89, loss = 1815646.69491735\n",
      "Iteration 90, loss = 1814967.12175774\n",
      "Iteration 91, loss = 1814270.32226001\n",
      "Iteration 92, loss = 1813555.95339424\n",
      "Iteration 93, loss = 1812823.71712177\n",
      "Iteration 94, loss = 1812073.52977085\n",
      "Iteration 95, loss = 1811305.21156882\n",
      "Iteration 96, loss = 1810518.52753112\n",
      "Iteration 97, loss = 1809713.24517760\n",
      "Iteration 98, loss = 1808889.13440956\n",
      "Iteration 99, loss = 1808045.96670767\n",
      "Iteration 100, loss = 1807183.50995636\n",
      "Iteration 101, loss = 1806301.54040435\n",
      "Iteration 102, loss = 1805399.83190971\n",
      "Iteration 103, loss = 1804478.15637027\n",
      "Iteration 104, loss = 1803536.29980275\n",
      "Iteration 105, loss = 1802574.04076917\n",
      "Iteration 106, loss = 1801591.15960749\n",
      "Iteration 107, loss = 1800587.44141428\n",
      "Iteration 108, loss = 1799562.66883294\n",
      "Iteration 109, loss = 1798516.63503375\n",
      "Iteration 110, loss = 1797449.10308288\n",
      "Iteration 111, loss = 1796359.88701539\n",
      "Iteration 112, loss = 1795248.77330820\n",
      "Iteration 113, loss = 1794115.55655267\n",
      "Iteration 114, loss = 1792960.04825881\n",
      "Iteration 115, loss = 1791782.04401588\n",
      "Iteration 116, loss = 1790581.32352069\n",
      "Iteration 117, loss = 1789357.72551849\n",
      "Iteration 118, loss = 1788111.02300214\n",
      "Iteration 119, loss = 1786840.96348262\n",
      "Iteration 120, loss = 1785547.34104948\n",
      "Iteration 121, loss = 1784229.95268435\n",
      "Iteration 122, loss = 1782888.61429499\n",
      "Iteration 123, loss = 1781523.02593327\n",
      "Iteration 124, loss = 1780133.19836739\n",
      "Iteration 125, loss = 1778719.01830072\n",
      "Iteration 126, loss = 1777280.32722564\n",
      "Iteration 127, loss = 1775816.97086347\n",
      "Iteration 128, loss = 1774328.79215327\n",
      "Iteration 129, loss = 1772815.65153034\n",
      "Iteration 130, loss = 1771277.41768648\n",
      "Iteration 131, loss = 1769713.93529341\n",
      "Iteration 132, loss = 1768125.07034175\n",
      "Iteration 133, loss = 1766510.70792730\n",
      "Iteration 134, loss = 1764870.72888845\n",
      "Iteration 135, loss = 1763204.98563401\n",
      "Iteration 136, loss = 1761513.36101017\n",
      "Iteration 137, loss = 1759795.76674062\n",
      "Iteration 138, loss = 1758052.08754665\n",
      "Iteration 139, loss = 1756282.20215117\n",
      "Iteration 140, loss = 1754486.01209301\n",
      "Iteration 141, loss = 1752663.38738728\n",
      "Iteration 142, loss = 1750814.29263603\n",
      "Iteration 143, loss = 1748938.63087574\n",
      "Iteration 144, loss = 1747036.28859630\n",
      "Iteration 145, loss = 1745107.18917533\n",
      "Iteration 146, loss = 1743151.29224734\n",
      "Iteration 147, loss = 1741168.50598439\n",
      "Iteration 148, loss = 1739158.77878277\n",
      "Iteration 149, loss = 1737122.01093293\n",
      "Iteration 150, loss = 1735058.19565306\n",
      "Iteration 151, loss = 1732967.28078048\n",
      "Iteration 152, loss = 1730849.20443801\n",
      "Iteration 153, loss = 1728703.98558748\n",
      "Iteration 154, loss = 1726531.45342381\n",
      "Iteration 155, loss = 1724331.62691658\n",
      "Iteration 156, loss = 1722104.45469515\n",
      "Iteration 157, loss = 1719849.94056742\n",
      "Iteration 158, loss = 1717568.08275662\n",
      "Iteration 159, loss = 1715258.81742447\n",
      "Iteration 160, loss = 1712922.17105247\n",
      "Iteration 161, loss = 1710558.01547340\n",
      "Iteration 162, loss = 1708166.58665647\n",
      "Iteration 163, loss = 1705747.66072801\n",
      "Iteration 164, loss = 1703301.39243688\n",
      "Iteration 165, loss = 1700827.64592107\n",
      "Iteration 166, loss = 1698326.39115717\n",
      "Iteration 167, loss = 1695797.73935154\n",
      "Iteration 168, loss = 1693241.69210766\n",
      "Iteration 169, loss = 1690658.25130098\n",
      "Iteration 170, loss = 1688047.32467322\n",
      "Iteration 171, loss = 1685408.96149857\n",
      "Iteration 172, loss = 1682743.21163058\n",
      "Iteration 173, loss = 1680050.06857324\n",
      "Iteration 174, loss = 1677329.52157952\n",
      "Iteration 175, loss = 1674581.55401065\n",
      "Iteration 176, loss = 1671806.27120890\n",
      "Iteration 177, loss = 1669003.70914315\n",
      "Iteration 178, loss = 1666173.75151732\n",
      "Iteration 179, loss = 1663316.26652729\n",
      "Iteration 180, loss = 1660431.43774598\n",
      "Iteration 181, loss = 1657519.21747528\n",
      "Iteration 182, loss = 1654579.60894295\n",
      "Iteration 183, loss = 1651612.53926642\n",
      "Iteration 184, loss = 1648617.99456913\n",
      "Iteration 185, loss = 1645595.96615150\n",
      "Iteration 186, loss = 1642546.44486748\n",
      "Iteration 187, loss = 1639469.25543156\n",
      "Iteration 188, loss = 1636364.55275610\n",
      "Iteration 189, loss = 1633232.22170030\n",
      "Iteration 190, loss = 1630072.18613833\n",
      "Iteration 191, loss = 1626884.39429623\n",
      "Iteration 192, loss = 1623668.71278670\n",
      "Iteration 193, loss = 1620425.04405758\n",
      "Iteration 194, loss = 1617154.97017227\n",
      "Iteration 195, loss = 1613853.58472586\n",
      "Iteration 196, loss = 1610525.72417536\n",
      "Iteration 197, loss = 1607169.66072938\n",
      "Iteration 198, loss = 1603785.35002315\n",
      "Iteration 199, loss = 1600372.63260323\n",
      "Iteration 200, loss = 1596931.53211552\n",
      "Iteration 201, loss = 1593461.85965609\n",
      "Iteration 202, loss = 1589963.68312399\n",
      "Iteration 203, loss = 1586436.48317205\n",
      "Iteration 204, loss = 1582880.37502519\n",
      "Iteration 205, loss = 1579295.30983693\n",
      "Iteration 206, loss = 1575681.11681012\n",
      "Iteration 207, loss = 1572037.80433055\n",
      "Iteration 208, loss = 1568364.88492246\n",
      "Iteration 209, loss = 1564662.56851856\n",
      "Iteration 210, loss = 1560930.97745471\n",
      "Iteration 211, loss = 1557169.77055873\n",
      "Iteration 212, loss = 1553378.62326347\n",
      "Iteration 213, loss = 1549557.86233007\n",
      "Iteration 214, loss = 1545707.71216692\n",
      "Iteration 215, loss = 1541827.32168524\n",
      "Iteration 216, loss = 1537916.99174355\n",
      "Iteration 217, loss = 1533976.80494314\n",
      "Iteration 218, loss = 1530006.98622506\n",
      "Iteration 219, loss = 1526007.25977312\n",
      "Iteration 220, loss = 1521978.14618228\n",
      "Iteration 221, loss = 1517919.59474277\n",
      "Iteration 222, loss = 1513831.50802941\n",
      "Iteration 223, loss = 1509714.10166412\n",
      "Iteration 224, loss = 1505567.13872556\n",
      "Iteration 225, loss = 1501390.42377198\n",
      "Iteration 226, loss = 1497184.08108181\n",
      "Iteration 227, loss = 1492948.38306758\n",
      "Iteration 228, loss = 1488683.43566160\n",
      "Iteration 229, loss = 1484389.24326661\n",
      "Iteration 230, loss = 1480066.06261525\n",
      "Iteration 231, loss = 1475713.69692203\n",
      "Iteration 232, loss = 1471332.41754449\n",
      "Iteration 233, loss = 1466922.72764367\n",
      "Iteration 234, loss = 1462484.09183691\n",
      "Iteration 235, loss = 1458017.38933557\n",
      "Iteration 236, loss = 1453522.21096323\n",
      "Iteration 237, loss = 1448999.48553288\n",
      "Iteration 238, loss = 1444448.99945801\n",
      "Iteration 239, loss = 1439870.70333989\n",
      "Iteration 240, loss = 1435265.89190998\n",
      "Iteration 241, loss = 1430634.20542352\n",
      "Iteration 242, loss = 1425974.99225551\n",
      "Iteration 243, loss = 1421289.32267219\n",
      "Iteration 244, loss = 1416577.13426894\n",
      "Iteration 245, loss = 1411838.02282182\n",
      "Iteration 246, loss = 1407072.76772486\n",
      "Iteration 247, loss = 1402281.22641670\n",
      "Iteration 248, loss = 1397463.41355938\n",
      "Iteration 249, loss = 1392619.84695019\n",
      "Iteration 250, loss = 1387750.56739900\n",
      "Iteration 251, loss = 1382855.49471327\n",
      "Iteration 252, loss = 1377934.95324055\n",
      "Iteration 253, loss = 1372989.49216631\n",
      "Iteration 254, loss = 1368019.34537345\n",
      "Iteration 255, loss = 1363024.34052963\n",
      "Iteration 256, loss = 1358004.75314809\n",
      "Iteration 257, loss = 1352961.08704608\n",
      "Iteration 258, loss = 1347894.15578658\n",
      "Iteration 259, loss = 1342803.52471651\n",
      "Iteration 260, loss = 1337689.60681414\n",
      "Iteration 261, loss = 1332552.76323677\n",
      "Iteration 262, loss = 1327393.53775219\n",
      "Iteration 263, loss = 1322211.74518902\n",
      "Iteration 264, loss = 1317008.21595017\n",
      "Iteration 265, loss = 1311782.90700846\n",
      "Iteration 266, loss = 1306536.37191462\n",
      "Iteration 267, loss = 1301268.39085327\n",
      "Iteration 268, loss = 1295979.01964791\n",
      "Iteration 269, loss = 1290669.11222535\n",
      "Iteration 270, loss = 1285338.68880191\n",
      "Iteration 271, loss = 1279987.75338274\n",
      "Iteration 272, loss = 1274617.40965222\n",
      "Iteration 273, loss = 1269227.89505570\n",
      "Iteration 274, loss = 1263819.53852280\n",
      "Iteration 275, loss = 1258392.25055438\n",
      "Iteration 276, loss = 1252947.07512899\n",
      "Iteration 277, loss = 1247484.38963869\n",
      "Iteration 278, loss = 1242004.48065203\n",
      "Iteration 279, loss = 1236507.11537073\n",
      "Iteration 280, loss = 1230993.20032694\n",
      "Iteration 281, loss = 1225463.52584928\n",
      "Iteration 282, loss = 1219918.07875287\n",
      "Iteration 283, loss = 1214356.89716314\n",
      "Iteration 284, loss = 1208780.88334372\n",
      "Iteration 285, loss = 1203190.95267396\n",
      "Iteration 286, loss = 1197587.87380153\n",
      "Iteration 287, loss = 1191972.24363905\n",
      "Iteration 288, loss = 1186344.27754140\n",
      "Iteration 289, loss = 1180704.68016737\n",
      "Iteration 290, loss = 1175053.26223754\n",
      "Iteration 291, loss = 1169390.93305797\n",
      "Iteration 292, loss = 1163717.35700769\n",
      "Iteration 293, loss = 1158033.54976815\n",
      "Iteration 294, loss = 1152340.26105591\n",
      "Iteration 295, loss = 1146637.82828219\n",
      "Iteration 296, loss = 1140926.35078825\n",
      "Iteration 297, loss = 1135206.51861586\n",
      "Iteration 298, loss = 1129479.09247411\n",
      "Iteration 299, loss = 1123744.68462450\n",
      "Iteration 300, loss = 1118002.91332734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 301, loss = 1112255.52625150\n",
      "Iteration 302, loss = 1106501.22923062\n",
      "Iteration 303, loss = 1100732.32584993\n",
      "Iteration 304, loss = 1094955.77232877\n",
      "Iteration 305, loss = 1089172.54409462\n",
      "Iteration 306, loss = 1083384.09987434\n",
      "Iteration 307, loss = 1077589.95050496\n",
      "Iteration 308, loss = 1071791.90327662\n",
      "Iteration 309, loss = 1065989.63469143\n",
      "Iteration 310, loss = 1060184.81566336\n",
      "Iteration 311, loss = 1054377.23230747\n",
      "Iteration 312, loss = 1048567.58940631\n",
      "Iteration 313, loss = 1042756.76912827\n",
      "Iteration 314, loss = 1036944.99715757\n",
      "Iteration 315, loss = 1031132.24598683\n",
      "Iteration 316, loss = 1025320.95287720\n",
      "Iteration 317, loss = 1019508.68377788\n",
      "Iteration 318, loss = 1013698.66839541\n",
      "Iteration 319, loss = 1007891.81145355\n",
      "Iteration 320, loss = 1002087.19759884\n",
      "Iteration 321, loss = 996287.21092259\n",
      "Iteration 322, loss = 990490.83708192\n",
      "Iteration 323, loss = 984698.85733389\n",
      "Iteration 324, loss = 978910.52872664\n",
      "Iteration 325, loss = 973127.82483428\n",
      "Iteration 326, loss = 967350.63354928\n",
      "Iteration 327, loss = 961578.35424994\n",
      "Iteration 328, loss = 955815.45835560\n",
      "Iteration 329, loss = 950061.20848571\n",
      "Iteration 330, loss = 944316.84635962\n",
      "Iteration 331, loss = 938579.01709471\n",
      "Iteration 332, loss = 932853.33910087\n",
      "Iteration 333, loss = 927136.95903215\n",
      "Iteration 334, loss = 921430.14386277\n",
      "Iteration 335, loss = 915734.75483489\n",
      "Iteration 336, loss = 910048.87480696\n",
      "Iteration 337, loss = 904374.89431214\n",
      "Iteration 338, loss = 898713.39464726\n",
      "Iteration 339, loss = 893062.27251691\n",
      "Iteration 340, loss = 887425.30496382\n",
      "Iteration 341, loss = 881803.21960505\n",
      "Iteration 342, loss = 876196.43407430\n",
      "Iteration 343, loss = 870605.21593859\n",
      "Iteration 344, loss = 865029.64512879\n",
      "Iteration 345, loss = 859470.75687807\n",
      "Iteration 346, loss = 853936.43598914\n",
      "Iteration 347, loss = 848403.82713240\n",
      "Iteration 348, loss = 842896.00279323\n",
      "Iteration 349, loss = 837405.26806791\n",
      "Iteration 350, loss = 831931.75661785\n",
      "Iteration 351, loss = 826476.05309746\n",
      "Iteration 352, loss = 821040.04906926\n",
      "Iteration 353, loss = 815625.26335252\n",
      "Iteration 354, loss = 810231.28364462\n",
      "Iteration 355, loss = 804858.77734153\n",
      "Iteration 356, loss = 799507.09535879\n",
      "Iteration 357, loss = 794176.04066702\n",
      "Iteration 358, loss = 788867.00911562\n",
      "Iteration 359, loss = 783577.08949504\n",
      "Iteration 360, loss = 778312.33190470\n",
      "Iteration 361, loss = 773068.93677420\n",
      "Iteration 362, loss = 767849.92601742\n",
      "Iteration 363, loss = 762650.50771502\n",
      "Iteration 364, loss = 757479.95706630\n",
      "Iteration 365, loss = 752332.94963658\n",
      "Iteration 366, loss = 747212.97971525\n",
      "Iteration 367, loss = 742120.00317359\n",
      "Iteration 368, loss = 737049.80011311\n",
      "Iteration 369, loss = 732004.93112075\n",
      "Iteration 370, loss = 726989.07108395\n",
      "Iteration 371, loss = 721995.69372124\n",
      "Iteration 372, loss = 717028.09163004\n",
      "Iteration 373, loss = 712088.35687942\n",
      "Iteration 374, loss = 707176.06582678\n",
      "Iteration 375, loss = 702280.78185063\n",
      "Iteration 376, loss = 697417.08743475\n",
      "Iteration 377, loss = 692574.10436546\n",
      "Iteration 378, loss = 687756.65592697\n",
      "Iteration 379, loss = 682960.64397796\n",
      "Iteration 380, loss = 678190.69319213\n",
      "Iteration 381, loss = 673454.98149936\n",
      "Iteration 382, loss = 668755.65138567\n",
      "Iteration 383, loss = 664085.04468845\n",
      "Iteration 384, loss = 659440.02936636\n",
      "Iteration 385, loss = 654822.59499229\n",
      "Iteration 386, loss = 650233.90652965\n",
      "Iteration 387, loss = 645666.03737192\n",
      "Iteration 388, loss = 641133.44938333\n",
      "Iteration 389, loss = 636619.02986622\n",
      "Iteration 390, loss = 632133.06487976\n",
      "Iteration 391, loss = 627688.46669246\n",
      "Iteration 392, loss = 623280.75078523\n",
      "Iteration 393, loss = 618899.20320783\n",
      "Iteration 394, loss = 614543.97807354\n",
      "Iteration 395, loss = 610221.33942405\n",
      "Iteration 396, loss = 605932.86958275\n",
      "Iteration 397, loss = 601665.17643912\n",
      "Iteration 398, loss = 597435.25008370\n",
      "Iteration 399, loss = 593233.42119140\n",
      "Iteration 400, loss = 589064.53493470\n",
      "Iteration 401, loss = 584927.61342405\n",
      "Iteration 402, loss = 580818.06023241\n",
      "Iteration 403, loss = 576749.07249584\n",
      "Iteration 404, loss = 572706.18657305\n",
      "Iteration 405, loss = 568703.72683372\n",
      "Iteration 406, loss = 564728.67733603\n",
      "Iteration 407, loss = 560787.78133190\n",
      "Iteration 408, loss = 556887.98225467\n",
      "Iteration 409, loss = 553010.36353608\n",
      "Iteration 410, loss = 549173.18921116\n",
      "Iteration 411, loss = 545373.82909245\n",
      "Iteration 412, loss = 541599.34012435\n",
      "Iteration 413, loss = 537864.53466072\n",
      "Iteration 414, loss = 534161.35582935\n",
      "Iteration 415, loss = 530489.62016726\n",
      "Iteration 416, loss = 526845.60173535\n",
      "Iteration 417, loss = 523237.91262527\n",
      "Iteration 418, loss = 519653.25217723\n",
      "Iteration 419, loss = 516096.26026282\n",
      "Iteration 420, loss = 512567.95962701\n",
      "Iteration 421, loss = 509059.43742019\n",
      "Iteration 422, loss = 505574.02106544\n",
      "Iteration 423, loss = 502111.46377409\n",
      "Iteration 424, loss = 498675.94517205\n",
      "Iteration 425, loss = 495250.40847568\n",
      "Iteration 426, loss = 491853.14106358\n",
      "Iteration 427, loss = 488479.97100319\n",
      "Iteration 428, loss = 485137.73704301\n",
      "Iteration 429, loss = 481846.55263733\n",
      "Iteration 430, loss = 478599.20908003\n",
      "Iteration 431, loss = 475388.97265349\n",
      "Iteration 432, loss = 472219.74395388\n",
      "Iteration 433, loss = 469085.89552960\n",
      "Iteration 434, loss = 465976.97683081\n",
      "Iteration 435, loss = 462888.63492817\n",
      "Iteration 436, loss = 459822.30695381\n",
      "Iteration 437, loss = 456780.11647177\n",
      "Iteration 438, loss = 453764.88569248\n",
      "Iteration 439, loss = 450778.70707730\n",
      "Iteration 440, loss = 447822.40708742\n",
      "Iteration 441, loss = 444894.84138160\n",
      "Iteration 442, loss = 442001.48414052\n",
      "Iteration 443, loss = 439139.09717234\n",
      "Iteration 444, loss = 436308.31700001\n",
      "Iteration 445, loss = 433509.13803630\n",
      "Iteration 446, loss = 430740.52804743\n",
      "Iteration 447, loss = 427999.86058365\n",
      "Iteration 448, loss = 425290.87604323\n",
      "Iteration 449, loss = 422608.74061175\n",
      "Iteration 450, loss = 419954.17831504\n",
      "Iteration 451, loss = 417327.71052121\n",
      "Iteration 452, loss = 414725.89891090\n",
      "Iteration 453, loss = 412150.15963729\n",
      "Iteration 454, loss = 409599.36299200\n",
      "Iteration 455, loss = 407070.48780561\n",
      "Iteration 456, loss = 404569.93052362\n",
      "Iteration 457, loss = 402089.10595474\n",
      "Iteration 458, loss = 399634.05984864\n",
      "Iteration 459, loss = 397208.95244891\n",
      "Iteration 460, loss = 394806.74951964\n",
      "Iteration 461, loss = 392437.43089307\n",
      "Iteration 462, loss = 390095.62252575\n",
      "Iteration 463, loss = 387774.69550104\n",
      "Iteration 464, loss = 385478.22223574\n",
      "Iteration 465, loss = 383204.55278268\n",
      "Iteration 466, loss = 380950.11968753\n",
      "Iteration 467, loss = 378719.64293713\n",
      "Iteration 468, loss = 376511.18287364\n",
      "Iteration 469, loss = 374324.84999455\n",
      "Iteration 470, loss = 372159.71168217\n",
      "Iteration 471, loss = 370023.68863674\n",
      "Iteration 472, loss = 367907.37436142\n",
      "Iteration 473, loss = 365809.27778831\n",
      "Iteration 474, loss = 363732.63795580\n",
      "Iteration 475, loss = 361677.12257718\n",
      "Iteration 476, loss = 359641.07783800\n",
      "Iteration 477, loss = 357627.74233949\n",
      "Iteration 478, loss = 355638.06688760\n",
      "Iteration 479, loss = 353667.12714973\n",
      "Iteration 480, loss = 351716.81852277\n",
      "Iteration 481, loss = 349789.56663308\n",
      "Iteration 482, loss = 347880.50964228\n",
      "Iteration 483, loss = 345990.57621057\n",
      "Iteration 484, loss = 344121.81885977\n",
      "Iteration 485, loss = 342270.07199702\n",
      "Iteration 486, loss = 340436.33809875\n",
      "Iteration 487, loss = 338621.05832814\n",
      "Iteration 488, loss = 336823.53596474\n",
      "Iteration 489, loss = 335039.76723168\n",
      "Iteration 490, loss = 333272.66816125\n",
      "Iteration 491, loss = 331524.26926045\n",
      "Iteration 492, loss = 329787.12420626\n",
      "Iteration 493, loss = 328062.23460997\n",
      "Iteration 494, loss = 326355.18605810\n",
      "Iteration 495, loss = 324658.09954578\n",
      "Iteration 496, loss = 322975.83426653\n",
      "Iteration 497, loss = 321314.77196720\n",
      "Iteration 498, loss = 319674.39948076\n",
      "Iteration 499, loss = 318052.17432622\n",
      "Iteration 500, loss = 316443.83482757\n",
      "Iteration 501, loss = 314849.62219387\n",
      "Iteration 502, loss = 313266.76594799\n",
      "Iteration 503, loss = 311696.77783559\n",
      "Iteration 504, loss = 310141.31300710\n",
      "Iteration 505, loss = 308597.86203344\n",
      "Iteration 506, loss = 307069.03312259\n",
      "Iteration 507, loss = 305554.02555890\n",
      "Iteration 508, loss = 304051.64810597\n",
      "Iteration 509, loss = 302562.31586275\n",
      "Iteration 510, loss = 301086.75913298\n",
      "Iteration 511, loss = 299620.81069792\n",
      "Iteration 512, loss = 298169.43077024\n",
      "Iteration 513, loss = 296728.95124592\n",
      "Iteration 514, loss = 295298.19313877\n",
      "Iteration 515, loss = 293878.24121530\n",
      "Iteration 516, loss = 292469.47673323\n",
      "Iteration 517, loss = 291069.78546828\n",
      "Iteration 518, loss = 289681.58352094\n",
      "Iteration 519, loss = 288302.02695207\n",
      "Iteration 520, loss = 286932.65409833\n",
      "Iteration 521, loss = 285579.84000109\n",
      "Iteration 522, loss = 284236.04513774\n",
      "Iteration 523, loss = 282901.75343459\n",
      "Iteration 524, loss = 281577.73226611\n",
      "Iteration 525, loss = 280263.79706543\n",
      "Iteration 526, loss = 278957.45825099\n",
      "Iteration 527, loss = 277661.54786575\n",
      "Iteration 528, loss = 276375.53077294\n",
      "Iteration 529, loss = 275096.92738829\n",
      "Iteration 530, loss = 273828.76050816\n",
      "Iteration 531, loss = 272571.19957148\n",
      "Iteration 532, loss = 271324.14023967\n",
      "Iteration 533, loss = 270083.87445590\n",
      "Iteration 534, loss = 268854.61584734\n",
      "Iteration 535, loss = 267634.72674607\n",
      "Iteration 536, loss = 266424.29711133\n",
      "Iteration 537, loss = 265220.68054583\n",
      "Iteration 538, loss = 264023.85303153\n",
      "Iteration 539, loss = 262837.66922664\n",
      "Iteration 540, loss = 261657.69100289\n",
      "Iteration 541, loss = 260482.58258527\n",
      "Iteration 542, loss = 259318.10731282\n",
      "Iteration 543, loss = 258159.76925257\n",
      "Iteration 544, loss = 257008.56208625\n",
      "Iteration 545, loss = 255863.50945595\n",
      "Iteration 546, loss = 254724.67618155\n",
      "Iteration 547, loss = 253592.69159458\n",
      "Iteration 548, loss = 252466.49830990\n",
      "Iteration 549, loss = 251345.46335541\n",
      "Iteration 550, loss = 250230.08735582\n",
      "Iteration 551, loss = 249118.98272812\n",
      "Iteration 552, loss = 248012.37782673\n",
      "Iteration 553, loss = 246914.10638829\n",
      "Iteration 554, loss = 245822.98079288\n",
      "Iteration 555, loss = 244736.43121460\n",
      "Iteration 556, loss = 243663.51946301\n",
      "Iteration 557, loss = 242597.85712617\n",
      "Iteration 558, loss = 241535.73082537\n",
      "Iteration 559, loss = 240479.35171145\n",
      "Iteration 560, loss = 239428.36249416\n",
      "Iteration 561, loss = 238378.78581291\n",
      "Iteration 562, loss = 237335.04530450\n",
      "Iteration 563, loss = 236298.51260612\n",
      "Iteration 564, loss = 235267.48438261\n",
      "Iteration 565, loss = 234242.09152325\n",
      "Iteration 566, loss = 233220.50640710\n",
      "Iteration 567, loss = 232208.30358236\n",
      "Iteration 568, loss = 231200.64787639\n",
      "Iteration 569, loss = 230197.57482310\n",
      "Iteration 570, loss = 229201.94234187\n",
      "Iteration 571, loss = 228212.72009055\n",
      "Iteration 572, loss = 227226.46528731\n",
      "Iteration 573, loss = 226245.23502031\n",
      "Iteration 574, loss = 225268.66713460\n",
      "Iteration 575, loss = 224296.12188500\n",
      "Iteration 576, loss = 223327.36757344\n",
      "Iteration 577, loss = 222365.13141489\n",
      "Iteration 578, loss = 221407.30727536\n",
      "Iteration 579, loss = 220453.79874093\n",
      "Iteration 580, loss = 219506.19604544\n",
      "Iteration 581, loss = 218564.16471308\n",
      "Iteration 582, loss = 217627.03266608\n",
      "Iteration 583, loss = 216692.89307072\n",
      "Iteration 584, loss = 215764.62083848\n",
      "Iteration 585, loss = 214842.02179753\n",
      "Iteration 586, loss = 213922.68355365\n",
      "Iteration 587, loss = 213006.86445754\n",
      "Iteration 588, loss = 212096.41075117\n",
      "Iteration 589, loss = 211190.24595436\n",
      "Iteration 590, loss = 210286.29656797\n",
      "Iteration 591, loss = 209387.59748720\n",
      "Iteration 592, loss = 208492.01376621\n",
      "Iteration 593, loss = 207600.67771980\n",
      "Iteration 594, loss = 206712.96050447\n",
      "Iteration 595, loss = 205828.05632637\n",
      "Iteration 596, loss = 204948.57080676\n",
      "Iteration 597, loss = 204072.25109507\n",
      "Iteration 598, loss = 203199.23445683\n",
      "Iteration 599, loss = 202331.28222858\n",
      "Iteration 600, loss = 201465.02246865\n",
      "Iteration 601, loss = 200603.40395077\n",
      "Iteration 602, loss = 199745.40911799\n",
      "Iteration 603, loss = 198891.08595605\n",
      "Iteration 604, loss = 198040.41950291\n",
      "Iteration 605, loss = 197191.36206334\n",
      "Iteration 606, loss = 196346.62096183\n",
      "Iteration 607, loss = 195507.20567418\n",
      "Iteration 608, loss = 194669.39547002\n",
      "Iteration 609, loss = 193836.70779549\n",
      "Iteration 610, loss = 193007.17029135\n",
      "Iteration 611, loss = 192181.52917442\n",
      "Iteration 612, loss = 191359.55549794\n",
      "Iteration 613, loss = 190541.17173886\n",
      "Iteration 614, loss = 189725.41825798\n",
      "Iteration 615, loss = 188913.60956043\n",
      "Iteration 616, loss = 188105.12591143\n",
      "Iteration 617, loss = 187299.55708806\n",
      "Iteration 618, loss = 186499.75908156\n",
      "Iteration 619, loss = 185701.28864159\n",
      "Iteration 620, loss = 184906.42917398\n",
      "Iteration 621, loss = 184116.56663289\n",
      "Iteration 622, loss = 183328.41670547\n",
      "Iteration 623, loss = 182545.40248170\n",
      "Iteration 624, loss = 181766.75960655\n",
      "Iteration 625, loss = 180988.96934422\n",
      "Iteration 626, loss = 180216.15929865\n",
      "Iteration 627, loss = 179446.82072684\n",
      "Iteration 628, loss = 178680.50175474\n",
      "Iteration 629, loss = 177916.67506442\n",
      "Iteration 630, loss = 177155.99878448\n",
      "Iteration 631, loss = 176399.97197389\n",
      "Iteration 632, loss = 175647.90638391\n",
      "Iteration 633, loss = 174900.41237292\n",
      "Iteration 634, loss = 174154.82264866\n",
      "Iteration 635, loss = 173411.70950555\n",
      "Iteration 636, loss = 172674.42986909\n",
      "Iteration 637, loss = 171939.56013576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 638, loss = 171208.37481049\n",
      "Iteration 639, loss = 170480.09334879\n",
      "Iteration 640, loss = 169754.01007729\n",
      "Iteration 641, loss = 169031.77796217\n",
      "Iteration 642, loss = 168312.41070590\n",
      "Iteration 643, loss = 167595.51965717\n",
      "Iteration 644, loss = 166881.39283955\n",
      "Iteration 645, loss = 166169.43669257\n",
      "Iteration 646, loss = 165461.48367116\n",
      "Iteration 647, loss = 164756.72098510\n",
      "Iteration 648, loss = 164055.77884167\n",
      "Iteration 649, loss = 163358.03434726\n",
      "Iteration 650, loss = 162660.92766221\n",
      "Iteration 651, loss = 161967.03660139\n",
      "Iteration 652, loss = 161275.84741067\n",
      "Iteration 653, loss = 160587.88928965\n",
      "Iteration 654, loss = 159903.97491566\n",
      "Iteration 655, loss = 159221.63947151\n",
      "Iteration 656, loss = 158541.16132346\n",
      "Iteration 657, loss = 157863.81385648\n",
      "Iteration 658, loss = 157190.19708625\n",
      "Iteration 659, loss = 156520.48484844\n",
      "Iteration 660, loss = 155854.63508139\n",
      "Iteration 661, loss = 155193.07592131\n",
      "Iteration 662, loss = 154535.43035464\n",
      "Iteration 663, loss = 153878.89175593\n",
      "Iteration 664, loss = 153224.19521524\n",
      "Iteration 665, loss = 152573.47270146\n",
      "Iteration 666, loss = 151923.62571980\n",
      "Iteration 667, loss = 151276.10444914\n",
      "Iteration 668, loss = 150633.62625921\n",
      "Iteration 669, loss = 149994.03565432\n",
      "Iteration 670, loss = 149355.81543481\n",
      "Iteration 671, loss = 148719.59068387\n",
      "Iteration 672, loss = 148086.92967086\n",
      "Iteration 673, loss = 147456.34598546\n",
      "Iteration 674, loss = 146827.66554080\n",
      "Iteration 675, loss = 146202.62667683\n",
      "Iteration 676, loss = 145579.69493686\n",
      "Iteration 677, loss = 144959.62551585\n",
      "Iteration 678, loss = 144342.23004890\n",
      "Iteration 679, loss = 143727.17733135\n",
      "Iteration 680, loss = 143113.58916303\n",
      "Iteration 681, loss = 142502.06102328\n",
      "Iteration 682, loss = 141893.37326393\n",
      "Iteration 683, loss = 141286.83147532\n",
      "Iteration 684, loss = 140682.96264083\n",
      "Iteration 685, loss = 140082.64514763\n",
      "Iteration 686, loss = 139484.55322870\n",
      "Iteration 687, loss = 138889.29847783\n",
      "Iteration 688, loss = 138296.47925943\n",
      "Iteration 689, loss = 137706.55603081\n",
      "Iteration 690, loss = 137119.15610316\n",
      "Iteration 691, loss = 136534.91029913\n",
      "Iteration 692, loss = 135951.92568229\n",
      "Iteration 693, loss = 135371.41884908\n",
      "Iteration 694, loss = 134792.66344189\n",
      "Iteration 695, loss = 134217.86513127\n",
      "Iteration 696, loss = 133644.88474991\n",
      "Iteration 697, loss = 133072.67209591\n",
      "Iteration 698, loss = 132503.73346355\n",
      "Iteration 699, loss = 131937.64894004\n",
      "Iteration 700, loss = 131373.46830924\n",
      "Iteration 701, loss = 130811.75419935\n",
      "Iteration 702, loss = 130252.31180912\n",
      "Iteration 703, loss = 129695.03117959\n",
      "Iteration 704, loss = 129140.47368108\n",
      "Iteration 705, loss = 128588.65995237\n",
      "Iteration 706, loss = 128038.43861186\n",
      "Iteration 707, loss = 127490.20251287\n",
      "Iteration 708, loss = 126944.63737490\n",
      "Iteration 709, loss = 126400.95735126\n",
      "Iteration 710, loss = 125859.99968360\n",
      "Iteration 711, loss = 125321.24708589\n",
      "Iteration 712, loss = 124784.20465306\n",
      "Iteration 713, loss = 124249.38960471\n",
      "Iteration 714, loss = 123717.75221657\n",
      "Iteration 715, loss = 123188.92898083\n",
      "Iteration 716, loss = 122665.23760029\n",
      "Iteration 717, loss = 122142.71965339\n",
      "Iteration 718, loss = 121622.73696591\n",
      "Iteration 719, loss = 121106.58761069\n",
      "Iteration 720, loss = 120591.76281772\n",
      "Iteration 721, loss = 120078.20273127\n",
      "Iteration 722, loss = 119567.33054343\n",
      "Iteration 723, loss = 119059.13253604\n",
      "Iteration 724, loss = 118552.96840898\n",
      "Iteration 725, loss = 118049.46564773\n",
      "Iteration 726, loss = 117548.67198305\n",
      "Iteration 727, loss = 117049.63332857\n",
      "Iteration 728, loss = 116552.93516457\n",
      "Iteration 729, loss = 116058.79212001\n",
      "Iteration 730, loss = 115567.08981610\n",
      "Iteration 731, loss = 115076.61655114\n",
      "Iteration 732, loss = 114588.73928130\n",
      "Iteration 733, loss = 114103.13046917\n",
      "Iteration 734, loss = 113619.74752816\n",
      "Iteration 735, loss = 113137.68478356\n",
      "Iteration 736, loss = 112658.19019471\n",
      "Iteration 737, loss = 112179.92959464\n",
      "Iteration 738, loss = 111704.24014435\n",
      "Iteration 739, loss = 111229.72784693\n",
      "Iteration 740, loss = 110756.94742638\n",
      "Iteration 741, loss = 110285.90559642\n",
      "Iteration 742, loss = 109818.50898386\n",
      "Iteration 743, loss = 109354.20843824\n",
      "Iteration 744, loss = 108890.72037447\n",
      "Iteration 745, loss = 108429.61076134\n",
      "Iteration 746, loss = 107971.59938588\n",
      "Iteration 747, loss = 107516.68752461\n",
      "Iteration 748, loss = 107063.84970963\n",
      "Iteration 749, loss = 106612.99655056\n",
      "Iteration 750, loss = 106163.80618093\n",
      "Iteration 751, loss = 105716.37546163\n",
      "Iteration 752, loss = 105271.72551696\n",
      "Iteration 753, loss = 104829.34696367\n",
      "Iteration 754, loss = 104388.43288282\n",
      "Iteration 755, loss = 103949.63578120\n",
      "Iteration 756, loss = 103513.44863386\n",
      "Iteration 757, loss = 103079.27810704\n",
      "Iteration 758, loss = 102646.65659203\n",
      "Iteration 759, loss = 102215.84456904\n",
      "Iteration 760, loss = 101786.74659833\n",
      "Iteration 761, loss = 101359.19592802\n",
      "Iteration 762, loss = 100933.12361693\n",
      "Iteration 763, loss = 100508.79514376\n",
      "Iteration 764, loss = 100086.40805964\n",
      "Iteration 765, loss = 99666.77277010\n",
      "Iteration 766, loss = 99247.66237676\n",
      "Iteration 767, loss = 98830.20612114\n",
      "Iteration 768, loss = 98414.93053455\n",
      "Iteration 769, loss = 98000.58385835\n",
      "Iteration 770, loss = 97586.76012239\n",
      "Iteration 771, loss = 97175.13958775\n",
      "Iteration 772, loss = 96766.57418261\n",
      "Iteration 773, loss = 96359.79316857\n",
      "Iteration 774, loss = 95957.36497198\n",
      "Iteration 775, loss = 95556.89895332\n",
      "Iteration 776, loss = 95157.99343185\n",
      "Iteration 777, loss = 94759.45580918\n",
      "Iteration 778, loss = 94363.39018095\n",
      "Iteration 779, loss = 93968.92762096\n",
      "Iteration 780, loss = 93575.78286426\n",
      "Iteration 781, loss = 93184.44038485\n",
      "Iteration 782, loss = 92795.22044240\n",
      "Iteration 783, loss = 92406.97016276\n",
      "Iteration 784, loss = 92020.25615992\n",
      "Iteration 785, loss = 91636.03354860\n",
      "Iteration 786, loss = 91254.34059070\n",
      "Iteration 787, loss = 90873.52207379\n",
      "Iteration 788, loss = 90493.82820659\n",
      "Iteration 789, loss = 90115.80449939\n",
      "Iteration 790, loss = 89740.47742186\n",
      "Iteration 791, loss = 89366.75207535\n",
      "Iteration 792, loss = 88993.74076384\n",
      "Iteration 793, loss = 88622.37194168\n",
      "Iteration 794, loss = 88253.24565123\n",
      "Iteration 795, loss = 87885.49225987\n",
      "Iteration 796, loss = 87517.92869637\n",
      "Iteration 797, loss = 87152.47907602\n",
      "Iteration 798, loss = 86790.03208220\n",
      "Iteration 799, loss = 86428.14185409\n",
      "Iteration 800, loss = 86067.13196416\n",
      "Iteration 801, loss = 85707.13307368\n",
      "Iteration 802, loss = 85348.94332518\n",
      "Iteration 803, loss = 84992.21984231\n",
      "Iteration 804, loss = 84638.29928290\n",
      "Iteration 805, loss = 84286.22928054\n",
      "Iteration 806, loss = 83935.76998960\n",
      "Iteration 807, loss = 83587.96746996\n",
      "Iteration 808, loss = 83241.72993605\n",
      "Iteration 809, loss = 82896.14972847\n",
      "Iteration 810, loss = 82552.70678065\n",
      "Iteration 811, loss = 82211.15935059\n",
      "Iteration 812, loss = 81871.10331757\n",
      "Iteration 813, loss = 81532.24364396\n",
      "Iteration 814, loss = 81194.70325928\n",
      "Iteration 815, loss = 80859.03893069\n",
      "Iteration 816, loss = 80524.46147849\n",
      "Iteration 817, loss = 80191.69011427\n",
      "Iteration 818, loss = 79860.04120844\n",
      "Iteration 819, loss = 79530.89521075\n",
      "Iteration 820, loss = 79202.92367248\n",
      "Iteration 821, loss = 78876.23383350\n",
      "Iteration 822, loss = 78551.17102907\n",
      "Iteration 823, loss = 78227.30622739\n",
      "Iteration 824, loss = 77905.85769699\n",
      "Iteration 825, loss = 77585.10010711\n",
      "Iteration 826, loss = 77265.26689156\n",
      "Iteration 827, loss = 76947.28574140\n",
      "Iteration 828, loss = 76630.76850903\n",
      "Iteration 829, loss = 76314.69075092\n",
      "Iteration 830, loss = 76000.24813583\n",
      "Iteration 831, loss = 75686.87564414\n",
      "Iteration 832, loss = 75375.27689119\n",
      "Iteration 833, loss = 75064.14691394\n",
      "Iteration 834, loss = 74754.62389203\n",
      "Iteration 835, loss = 74446.29047918\n",
      "Iteration 836, loss = 74137.98843447\n",
      "Iteration 837, loss = 73831.05475102\n",
      "Iteration 838, loss = 73525.54957568\n",
      "Iteration 839, loss = 73221.74541731\n",
      "Iteration 840, loss = 72921.85452739\n",
      "Iteration 841, loss = 72624.13062698\n",
      "Iteration 842, loss = 72328.14630863\n",
      "Iteration 843, loss = 72033.75222178\n",
      "Iteration 844, loss = 71739.75044766\n",
      "Iteration 845, loss = 71446.49886834\n",
      "Iteration 846, loss = 71154.66353321\n",
      "Iteration 847, loss = 70864.21592650\n",
      "Iteration 848, loss = 70574.68694208\n",
      "Iteration 849, loss = 70286.54276039\n",
      "Iteration 850, loss = 70000.44267415\n",
      "Iteration 851, loss = 69714.40270169\n",
      "Iteration 852, loss = 69429.71219709\n",
      "Iteration 853, loss = 69146.98927582\n",
      "Iteration 854, loss = 68865.55688331\n",
      "Iteration 855, loss = 68585.26275182\n",
      "Iteration 856, loss = 68306.78083036\n",
      "Iteration 857, loss = 68029.65041563\n",
      "Iteration 858, loss = 67753.52448920\n",
      "Iteration 859, loss = 67478.42106252\n",
      "Iteration 860, loss = 67204.83091617\n",
      "Iteration 861, loss = 66933.07833793\n",
      "Iteration 862, loss = 66661.76686112\n",
      "Iteration 863, loss = 66391.81904334\n",
      "Iteration 864, loss = 66122.60728421\n",
      "Iteration 865, loss = 65854.00781970\n",
      "Iteration 866, loss = 65586.99646415\n",
      "Iteration 867, loss = 65321.02037717\n",
      "Iteration 868, loss = 65055.77903852\n",
      "Iteration 869, loss = 64790.88592924\n",
      "Iteration 870, loss = 64527.96332761\n",
      "Iteration 871, loss = 64266.15232467\n",
      "Iteration 872, loss = 64004.22129984\n",
      "Iteration 873, loss = 63743.33365720\n",
      "Iteration 874, loss = 63483.59120996\n",
      "Iteration 875, loss = 63226.12728106\n",
      "Iteration 876, loss = 62970.91869292\n",
      "Iteration 877, loss = 62717.18224164\n",
      "Iteration 878, loss = 62465.52907034\n",
      "Iteration 879, loss = 62214.46690416\n",
      "Iteration 880, loss = 61965.28278181\n",
      "Iteration 881, loss = 61717.24680835\n",
      "Iteration 882, loss = 61470.12829479\n",
      "Iteration 883, loss = 61223.85047569\n",
      "Iteration 884, loss = 60978.45806838\n",
      "Iteration 885, loss = 60734.20819616\n",
      "Iteration 886, loss = 60490.65139617\n",
      "Iteration 887, loss = 60248.38937194\n",
      "Iteration 888, loss = 60007.43595030\n",
      "Iteration 889, loss = 59767.39945463\n",
      "Iteration 890, loss = 59529.01273665\n",
      "Iteration 891, loss = 59291.62843993\n",
      "Iteration 892, loss = 59055.00296392\n",
      "Iteration 893, loss = 58819.66250594\n",
      "Iteration 894, loss = 58585.42431829\n",
      "Iteration 895, loss = 58352.38837062\n",
      "Iteration 896, loss = 58120.70907732\n",
      "Iteration 897, loss = 57889.84971704\n",
      "Iteration 898, loss = 57660.08631817\n",
      "Iteration 899, loss = 57431.25344333\n",
      "Iteration 900, loss = 57203.54472866\n",
      "Iteration 901, loss = 56977.11752237\n",
      "Iteration 902, loss = 56751.09828656\n",
      "Iteration 903, loss = 56526.22195566\n",
      "Iteration 904, loss = 56302.07706401\n",
      "Iteration 905, loss = 56078.47635137\n",
      "Iteration 906, loss = 55855.46821670\n",
      "Iteration 907, loss = 55633.15928622\n",
      "Iteration 908, loss = 55411.53396252\n",
      "Iteration 909, loss = 55190.54243948\n",
      "Iteration 910, loss = 54970.52219211\n",
      "Iteration 911, loss = 54750.98468065\n",
      "Iteration 912, loss = 54532.54119359\n",
      "Iteration 913, loss = 54314.80211126\n",
      "Iteration 914, loss = 54098.97551918\n",
      "Iteration 915, loss = 53883.61347188\n",
      "Iteration 916, loss = 53671.32972725\n",
      "Iteration 917, loss = 53462.06297227\n",
      "Iteration 918, loss = 53253.26879389\n",
      "Iteration 919, loss = 53045.55248738\n",
      "Iteration 920, loss = 52838.17917569\n",
      "Iteration 921, loss = 52631.47334130\n",
      "Iteration 922, loss = 52425.43321935\n",
      "Iteration 923, loss = 52220.61653826\n",
      "Iteration 924, loss = 52016.47891421\n",
      "Iteration 925, loss = 51813.40210228\n",
      "Iteration 926, loss = 51610.90740753\n",
      "Iteration 927, loss = 51409.56387012\n",
      "Iteration 928, loss = 51209.01235285\n",
      "Iteration 929, loss = 51009.64083386\n",
      "Iteration 930, loss = 50811.21301734\n",
      "Iteration 931, loss = 50613.68795233\n",
      "Iteration 932, loss = 50417.38092152\n",
      "Iteration 933, loss = 50221.83030022\n",
      "Iteration 934, loss = 50027.27357280\n",
      "Iteration 935, loss = 49833.63221590\n",
      "Iteration 936, loss = 49640.86878353\n",
      "Iteration 937, loss = 49448.74519943\n",
      "Iteration 938, loss = 49257.45983889\n",
      "Iteration 939, loss = 49066.87210090\n",
      "Iteration 940, loss = 48877.29399840\n",
      "Iteration 941, loss = 48688.50320437\n",
      "Iteration 942, loss = 48500.27758976\n",
      "Iteration 943, loss = 48312.85951866\n",
      "Iteration 944, loss = 48126.13943408\n",
      "Iteration 945, loss = 47939.83446209\n",
      "Iteration 946, loss = 47754.34982713\n",
      "Iteration 947, loss = 47569.40817995\n",
      "Iteration 948, loss = 47384.98274981\n",
      "Iteration 949, loss = 47201.06349726\n",
      "Iteration 950, loss = 47017.66355544\n",
      "Iteration 951, loss = 46834.77803998\n",
      "Iteration 952, loss = 46652.35494679\n",
      "Iteration 953, loss = 46470.17286298\n",
      "Iteration 954, loss = 46288.42724842\n",
      "Iteration 955, loss = 46107.29788026\n",
      "Iteration 956, loss = 45926.69220274\n",
      "Iteration 957, loss = 45746.68369320\n",
      "Iteration 958, loss = 45567.28665785\n",
      "Iteration 959, loss = 45388.41339743\n",
      "Iteration 960, loss = 45210.16927576\n",
      "Iteration 961, loss = 45032.31943216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 962, loss = 44854.67385152\n",
      "Iteration 963, loss = 44677.53636074\n",
      "Iteration 964, loss = 44500.76351639\n",
      "Iteration 965, loss = 44324.34289246\n",
      "Iteration 966, loss = 44148.34820869\n",
      "Iteration 967, loss = 43972.50684787\n",
      "Iteration 968, loss = 43797.17866512\n",
      "Iteration 969, loss = 43623.58496577\n",
      "Iteration 970, loss = 43450.64843023\n",
      "Iteration 971, loss = 43279.42558491\n",
      "Iteration 972, loss = 43110.07418830\n",
      "Iteration 973, loss = 42941.88931735\n",
      "Iteration 974, loss = 42774.26276030\n",
      "Iteration 975, loss = 42608.04902522\n",
      "Iteration 976, loss = 42442.21199698\n",
      "Iteration 977, loss = 42277.58082112\n",
      "Iteration 978, loss = 42113.78486798\n",
      "Iteration 979, loss = 41950.28556964\n",
      "Iteration 980, loss = 41787.00932665\n",
      "Iteration 981, loss = 41624.18366479\n",
      "Iteration 982, loss = 41461.93310783\n",
      "Iteration 983, loss = 41300.35796352\n",
      "Iteration 984, loss = 41139.60169026\n",
      "Iteration 985, loss = 40979.65848373\n",
      "Iteration 986, loss = 40820.37256270\n",
      "Iteration 987, loss = 40661.96169156\n",
      "Iteration 988, loss = 40504.00466305\n",
      "Iteration 989, loss = 40347.06077482\n",
      "Iteration 990, loss = 40190.96531575\n",
      "Iteration 991, loss = 40035.13861934\n",
      "Iteration 992, loss = 39880.28726314\n",
      "Iteration 993, loss = 39726.30717325\n",
      "Iteration 994, loss = 39573.16055790\n",
      "Iteration 995, loss = 39420.45100497\n",
      "Iteration 996, loss = 39268.49210545\n",
      "Iteration 997, loss = 39117.04394650\n",
      "Iteration 998, loss = 38966.01520097\n",
      "Iteration 999, loss = 38815.21763879\n",
      "Iteration 1000, loss = 38664.91199146\n",
      "Iteration 1001, loss = 38515.12422544\n",
      "Iteration 1002, loss = 38365.80155457\n",
      "Iteration 1003, loss = 38216.65795455\n",
      "Iteration 1004, loss = 38067.63824886\n",
      "Iteration 1005, loss = 37918.94053545\n",
      "Iteration 1006, loss = 37770.58289743\n",
      "Iteration 1007, loss = 37622.62006141\n",
      "Iteration 1008, loss = 37474.98093517\n",
      "Iteration 1009, loss = 37327.80237410\n",
      "Iteration 1010, loss = 37180.94693987\n",
      "Iteration 1011, loss = 37034.39898310\n",
      "Iteration 1012, loss = 36888.20573151\n",
      "Iteration 1013, loss = 36741.89596422\n",
      "Iteration 1014, loss = 36595.78315390\n",
      "Iteration 1015, loss = 36450.86228018\n",
      "Iteration 1016, loss = 36307.65981554\n",
      "Iteration 1017, loss = 36166.39446928\n",
      "Iteration 1018, loss = 36026.01833222\n",
      "Iteration 1019, loss = 35885.61644919\n",
      "Iteration 1020, loss = 35746.07099031\n",
      "Iteration 1021, loss = 35606.57840698\n",
      "Iteration 1022, loss = 35467.27541229\n",
      "Iteration 1023, loss = 35328.37602266\n",
      "Iteration 1024, loss = 35190.02863366\n",
      "Iteration 1025, loss = 35052.13784555\n",
      "Iteration 1026, loss = 34914.78557392\n",
      "Iteration 1027, loss = 34778.00707118\n",
      "Iteration 1028, loss = 34641.75282658\n",
      "Iteration 1029, loss = 34506.08173371\n",
      "Iteration 1030, loss = 34371.20439099\n",
      "Iteration 1031, loss = 34236.94908555\n",
      "Iteration 1032, loss = 34103.34645666\n",
      "Iteration 1033, loss = 33970.49620885\n",
      "Iteration 1034, loss = 33838.29884180\n",
      "Iteration 1035, loss = 33706.63334942\n",
      "Iteration 1036, loss = 33575.53972301\n",
      "Iteration 1037, loss = 33445.15207414\n",
      "Iteration 1038, loss = 33315.33344974\n",
      "Iteration 1039, loss = 33186.14438866\n",
      "Iteration 1040, loss = 33057.60981049\n",
      "Iteration 1041, loss = 32929.46490934\n",
      "Iteration 1042, loss = 32801.74243270\n",
      "Iteration 1043, loss = 32674.63210306\n",
      "Iteration 1044, loss = 32547.62074280\n",
      "Iteration 1045, loss = 32420.93201814\n",
      "Iteration 1046, loss = 32294.40769300\n",
      "Iteration 1047, loss = 32168.34798649\n",
      "Iteration 1048, loss = 32042.91720470\n",
      "Iteration 1049, loss = 31917.82212354\n",
      "Iteration 1050, loss = 31793.06913098\n",
      "Iteration 1051, loss = 31668.61557428\n",
      "Iteration 1052, loss = 31544.45855678\n",
      "Iteration 1053, loss = 31420.40035525\n",
      "Iteration 1054, loss = 31296.47081462\n",
      "Iteration 1055, loss = 31172.81953134\n",
      "Iteration 1056, loss = 31049.56137655\n",
      "Iteration 1057, loss = 30926.68923314\n",
      "Iteration 1058, loss = 30803.87341844\n",
      "Iteration 1059, loss = 30681.50880937\n",
      "Iteration 1060, loss = 30559.27089550\n",
      "Iteration 1061, loss = 30437.16685773\n",
      "Iteration 1062, loss = 30315.41589348\n",
      "Iteration 1063, loss = 30193.95567972\n",
      "Iteration 1064, loss = 30072.88431414\n",
      "Iteration 1065, loss = 29952.47460300\n",
      "Iteration 1066, loss = 29834.62207301\n",
      "Iteration 1067, loss = 29717.01908180\n",
      "Iteration 1068, loss = 29600.82894748\n",
      "Iteration 1069, loss = 29484.78775786\n",
      "Iteration 1070, loss = 29369.54446648\n",
      "Iteration 1071, loss = 29254.17393495\n",
      "Iteration 1072, loss = 29139.15250043\n",
      "Iteration 1073, loss = 29025.27105711\n",
      "Iteration 1074, loss = 28911.38711872\n",
      "Iteration 1075, loss = 28797.51004325\n",
      "Iteration 1076, loss = 28684.18473126\n",
      "Iteration 1077, loss = 28570.99835231\n",
      "Iteration 1078, loss = 28458.18645364\n",
      "Iteration 1079, loss = 28345.80436984\n",
      "Iteration 1080, loss = 28234.40236066\n",
      "Iteration 1081, loss = 28123.67479963\n",
      "Iteration 1082, loss = 28013.54678520\n",
      "Iteration 1083, loss = 27904.11952447\n",
      "Iteration 1084, loss = 27795.17221052\n",
      "Iteration 1085, loss = 27687.07730055\n",
      "Iteration 1086, loss = 27579.32073985\n",
      "Iteration 1087, loss = 27472.41837682\n",
      "Iteration 1088, loss = 27366.49780196\n",
      "Iteration 1089, loss = 27261.08584490\n",
      "Iteration 1090, loss = 27156.03796698\n",
      "Iteration 1091, loss = 27051.50992370\n",
      "Iteration 1092, loss = 26947.33030292\n",
      "Iteration 1093, loss = 26843.46433192\n",
      "Iteration 1094, loss = 26740.22093170\n",
      "Iteration 1095, loss = 26637.46966967\n",
      "Iteration 1096, loss = 26535.45246059\n",
      "Iteration 1097, loss = 26433.83788663\n",
      "Iteration 1098, loss = 26332.39289588\n",
      "Iteration 1099, loss = 26231.40402205\n",
      "Iteration 1100, loss = 26131.07453576\n",
      "Iteration 1101, loss = 26031.17606071\n",
      "Iteration 1102, loss = 25931.57382696\n",
      "Iteration 1103, loss = 25832.13240885\n",
      "Iteration 1104, loss = 25733.08551336\n",
      "Iteration 1105, loss = 25634.37285956\n",
      "Iteration 1106, loss = 25536.07865202\n",
      "Iteration 1107, loss = 25438.23786341\n",
      "Iteration 1108, loss = 25340.64313736\n",
      "Iteration 1109, loss = 25243.27454682\n",
      "Iteration 1110, loss = 25146.26001427\n",
      "Iteration 1111, loss = 25049.73364600\n",
      "Iteration 1112, loss = 24953.55708528\n",
      "Iteration 1113, loss = 24857.62892226\n",
      "Iteration 1114, loss = 24761.94842618\n",
      "Iteration 1115, loss = 24666.61911346\n",
      "Iteration 1116, loss = 24571.30776893\n",
      "Iteration 1117, loss = 24476.44067450\n",
      "Iteration 1118, loss = 24382.01870697\n",
      "Iteration 1119, loss = 24287.68540508\n",
      "Iteration 1120, loss = 24193.61045433\n",
      "Iteration 1121, loss = 24099.95472244\n",
      "Iteration 1122, loss = 24006.56347723\n",
      "Iteration 1123, loss = 23913.59118662\n",
      "Iteration 1124, loss = 23820.96356600\n",
      "Iteration 1125, loss = 23728.46515847\n",
      "Iteration 1126, loss = 23636.36671776\n",
      "Iteration 1127, loss = 23545.11506655\n",
      "Iteration 1128, loss = 23454.21012962\n",
      "Iteration 1129, loss = 23363.51193442\n",
      "Iteration 1130, loss = 23273.24914610\n",
      "Iteration 1131, loss = 23183.78753556\n",
      "Iteration 1132, loss = 23094.67143782\n",
      "Iteration 1133, loss = 23006.27163349\n",
      "Iteration 1134, loss = 22918.86020175\n",
      "Iteration 1135, loss = 22831.06043988\n",
      "Iteration 1136, loss = 22743.77311092\n",
      "Iteration 1137, loss = 22657.40938427\n",
      "Iteration 1138, loss = 22571.06426331\n",
      "Iteration 1139, loss = 22485.01415149\n",
      "Iteration 1140, loss = 22399.05233463\n",
      "Iteration 1141, loss = 22313.45764283\n",
      "Iteration 1142, loss = 22228.34281092\n",
      "Iteration 1143, loss = 22143.62278461\n",
      "Iteration 1144, loss = 22059.41817210\n",
      "Iteration 1145, loss = 21975.97612121\n",
      "Iteration 1146, loss = 21893.01050632\n",
      "Iteration 1147, loss = 21810.51393128\n",
      "Iteration 1148, loss = 21728.71880685\n",
      "Iteration 1149, loss = 21647.16731496\n",
      "Iteration 1150, loss = 21566.37508608\n",
      "Iteration 1151, loss = 21486.16559646\n",
      "Iteration 1152, loss = 21406.55398428\n",
      "Iteration 1153, loss = 21327.29116142\n",
      "Iteration 1154, loss = 21248.29433918\n",
      "Iteration 1155, loss = 21169.60057773\n",
      "Iteration 1156, loss = 21091.30397097\n",
      "Iteration 1157, loss = 21013.39936576\n",
      "Iteration 1158, loss = 20935.94975894\n",
      "Iteration 1159, loss = 20858.89088667\n",
      "Iteration 1160, loss = 20782.21845288\n",
      "Iteration 1161, loss = 20705.89092764\n",
      "Iteration 1162, loss = 20629.76881113\n",
      "Iteration 1163, loss = 20554.12246215\n",
      "Iteration 1164, loss = 20478.84155351\n",
      "Iteration 1165, loss = 20403.80424142\n",
      "Iteration 1166, loss = 20328.96082927\n",
      "Iteration 1167, loss = 20254.31849679\n",
      "Iteration 1168, loss = 20179.84832344\n",
      "Iteration 1169, loss = 20105.47675682\n",
      "Iteration 1170, loss = 20031.43695584\n",
      "Iteration 1171, loss = 19957.55522938\n",
      "Iteration 1172, loss = 19884.01526009\n",
      "Iteration 1173, loss = 19810.77014964\n",
      "Iteration 1174, loss = 19737.78747362\n",
      "Iteration 1175, loss = 19665.15358169\n",
      "Iteration 1176, loss = 19592.70469435\n",
      "Iteration 1177, loss = 19520.33818267\n",
      "Iteration 1178, loss = 19448.08688305\n",
      "Iteration 1179, loss = 19376.18260781\n",
      "Iteration 1180, loss = 19304.39126447\n",
      "Iteration 1181, loss = 19232.83367685\n",
      "Iteration 1182, loss = 19161.24934412\n",
      "Iteration 1183, loss = 19090.00629918\n",
      "Iteration 1184, loss = 19018.85391278\n",
      "Iteration 1185, loss = 18947.86652684\n",
      "Iteration 1186, loss = 18877.16265874\n",
      "Iteration 1187, loss = 18806.67048329\n",
      "Iteration 1188, loss = 18736.29971250\n",
      "Iteration 1189, loss = 18666.23654084\n",
      "Iteration 1190, loss = 18596.42825277\n",
      "Iteration 1191, loss = 18526.81689498\n",
      "Iteration 1192, loss = 18457.60235508\n",
      "Iteration 1193, loss = 18388.62494707\n",
      "Iteration 1194, loss = 18319.75164563\n",
      "Iteration 1195, loss = 18251.01038690\n",
      "Iteration 1196, loss = 18183.12224817\n",
      "Iteration 1197, loss = 18116.66519713\n",
      "Iteration 1198, loss = 18050.77006690\n",
      "Iteration 1199, loss = 17985.18285522\n",
      "Iteration 1200, loss = 17919.64288611\n",
      "Iteration 1201, loss = 17853.90504006\n",
      "Iteration 1202, loss = 17788.14308415\n",
      "Iteration 1203, loss = 17722.71343435\n",
      "Iteration 1204, loss = 17657.39168868\n",
      "Iteration 1205, loss = 17592.22302692\n",
      "Iteration 1206, loss = 17527.31703933\n",
      "Iteration 1207, loss = 17462.75721207\n",
      "Iteration 1208, loss = 17398.51546884\n",
      "Iteration 1209, loss = 17334.64125019\n",
      "Iteration 1210, loss = 17271.08938508\n",
      "Iteration 1211, loss = 17208.18486221\n",
      "Iteration 1212, loss = 17145.65996302\n",
      "Iteration 1213, loss = 17083.55847732\n",
      "Iteration 1214, loss = 17021.70655711\n",
      "Iteration 1215, loss = 16960.41602575\n",
      "Iteration 1216, loss = 16899.43681833\n",
      "Iteration 1217, loss = 16838.86820548\n",
      "Iteration 1218, loss = 16778.74105898\n",
      "Iteration 1219, loss = 16719.01798968\n",
      "Iteration 1220, loss = 16659.61592334\n",
      "Iteration 1221, loss = 16600.67780288\n",
      "Iteration 1222, loss = 16542.05606014\n",
      "Iteration 1223, loss = 16483.57688476\n",
      "Iteration 1224, loss = 16425.31715084\n",
      "Iteration 1225, loss = 16367.36366179\n",
      "Iteration 1226, loss = 16309.58553363\n",
      "Iteration 1227, loss = 16251.98426060\n",
      "Iteration 1228, loss = 16194.67133400\n",
      "Iteration 1229, loss = 16137.62182633\n",
      "Iteration 1230, loss = 16080.79090171\n",
      "Iteration 1231, loss = 16024.23550600\n",
      "Iteration 1232, loss = 15967.84840546\n",
      "Iteration 1233, loss = 15911.75760024\n",
      "Iteration 1234, loss = 15855.92657668\n",
      "Iteration 1235, loss = 15800.19055138\n",
      "Iteration 1236, loss = 15744.69033272\n",
      "Iteration 1237, loss = 15689.21161927\n",
      "Iteration 1238, loss = 15633.88974507\n",
      "Iteration 1239, loss = 15578.65252272\n",
      "Iteration 1240, loss = 15523.53432186\n",
      "Iteration 1241, loss = 15468.52151952\n",
      "Iteration 1242, loss = 15413.62774725\n",
      "Iteration 1243, loss = 15358.85732413\n",
      "Iteration 1244, loss = 15304.26670588\n",
      "Iteration 1245, loss = 15249.85945138\n",
      "Iteration 1246, loss = 15195.53460736\n",
      "Iteration 1247, loss = 15141.17921137\n",
      "Iteration 1248, loss = 15086.82174474\n",
      "Iteration 1249, loss = 15032.73502137\n",
      "Iteration 1250, loss = 14978.86358764\n",
      "Iteration 1251, loss = 14925.11201572\n",
      "Iteration 1252, loss = 14871.51908693\n",
      "Iteration 1253, loss = 14818.19440794\n",
      "Iteration 1254, loss = 14765.14727645\n",
      "Iteration 1255, loss = 14712.18902665\n",
      "Iteration 1256, loss = 14659.25975861\n",
      "Iteration 1257, loss = 14606.49894382\n",
      "Iteration 1258, loss = 14553.86030888\n",
      "Iteration 1259, loss = 14501.35088067\n",
      "Iteration 1260, loss = 14448.88291041\n",
      "Iteration 1261, loss = 14396.42373777\n",
      "Iteration 1262, loss = 14344.15343136\n",
      "Iteration 1263, loss = 14291.96969269\n",
      "Iteration 1264, loss = 14240.00386626\n",
      "Iteration 1265, loss = 14188.21862442\n",
      "Iteration 1266, loss = 14136.55814729\n",
      "Iteration 1267, loss = 14085.14686965\n",
      "Iteration 1268, loss = 14034.03768865\n",
      "Iteration 1269, loss = 13983.08750675\n",
      "Iteration 1270, loss = 13932.32952754\n",
      "Iteration 1271, loss = 13881.52341934\n",
      "Iteration 1272, loss = 13830.78762203\n",
      "Iteration 1273, loss = 13780.05285785\n",
      "Iteration 1274, loss = 13729.40215593\n",
      "Iteration 1275, loss = 13678.99321022\n",
      "Iteration 1276, loss = 13628.70005527\n",
      "Iteration 1277, loss = 13578.45252222\n",
      "Iteration 1278, loss = 13528.30237434\n",
      "Iteration 1279, loss = 13478.33835725\n",
      "Iteration 1280, loss = 13428.58392864\n",
      "Iteration 1281, loss = 13378.89135957\n",
      "Iteration 1282, loss = 13329.35213882\n",
      "Iteration 1283, loss = 13279.88691513\n",
      "Iteration 1284, loss = 13230.55163843\n",
      "Iteration 1285, loss = 13181.37105720\n",
      "Iteration 1286, loss = 13132.33325277\n",
      "Iteration 1287, loss = 13083.47531906\n",
      "Iteration 1288, loss = 13034.79881398\n",
      "Iteration 1289, loss = 12986.31476621\n",
      "Iteration 1290, loss = 12937.90333542\n",
      "Iteration 1291, loss = 12889.66872780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1292, loss = 12841.67192828\n",
      "Iteration 1293, loss = 12793.89973934\n",
      "Iteration 1294, loss = 12746.29406312\n",
      "Iteration 1295, loss = 12698.88006890\n",
      "Iteration 1296, loss = 12651.85446860\n",
      "Iteration 1297, loss = 12605.19952169\n",
      "Iteration 1298, loss = 12558.77305103\n",
      "Iteration 1299, loss = 12512.77268151\n",
      "Iteration 1300, loss = 12467.06084984\n",
      "Iteration 1301, loss = 12421.64534648\n",
      "Iteration 1302, loss = 12376.18281184\n",
      "Iteration 1303, loss = 12330.85352687\n",
      "Iteration 1304, loss = 12285.49790129\n",
      "Iteration 1305, loss = 12240.97079754\n",
      "Iteration 1306, loss = 12196.67427712\n",
      "Iteration 1307, loss = 12152.48251200\n",
      "Iteration 1308, loss = 12108.52532423\n",
      "Iteration 1309, loss = 12064.99403003\n",
      "Iteration 1310, loss = 12021.85602510\n",
      "Iteration 1311, loss = 11978.81286135\n",
      "Iteration 1312, loss = 11935.85147043\n",
      "Iteration 1313, loss = 11893.13984249\n",
      "Iteration 1314, loss = 11850.49877695\n",
      "Iteration 1315, loss = 11808.23341036\n",
      "Iteration 1316, loss = 11766.47272459\n",
      "Iteration 1317, loss = 11724.87840360\n",
      "Iteration 1318, loss = 11683.57514768\n",
      "Iteration 1319, loss = 11642.47513869\n",
      "Iteration 1320, loss = 11601.76747194\n",
      "Iteration 1321, loss = 11561.22266974\n",
      "Iteration 1322, loss = 11520.83878192\n",
      "Iteration 1323, loss = 11480.62159657\n",
      "Iteration 1324, loss = 11440.72550752\n",
      "Iteration 1325, loss = 11401.01682619\n",
      "Iteration 1326, loss = 11361.39305178\n",
      "Iteration 1327, loss = 11321.88937221\n",
      "Iteration 1328, loss = 11282.49996235\n",
      "Iteration 1329, loss = 11243.37895000\n",
      "Iteration 1330, loss = 11204.41863576\n",
      "Iteration 1331, loss = 11165.64573147\n",
      "Iteration 1332, loss = 11127.03997728\n",
      "Iteration 1333, loss = 11088.58349453\n",
      "Iteration 1334, loss = 11050.35333490\n",
      "Iteration 1335, loss = 11012.24934410\n",
      "Iteration 1336, loss = 10974.19755172\n",
      "Iteration 1337, loss = 10936.21585078\n",
      "Iteration 1338, loss = 10898.33486428\n",
      "Iteration 1339, loss = 10860.63075952\n",
      "Iteration 1340, loss = 10823.04135380\n",
      "Iteration 1341, loss = 10785.56719954\n",
      "Iteration 1342, loss = 10748.26330442\n",
      "Iteration 1343, loss = 10711.13279105\n",
      "Iteration 1344, loss = 10674.07068060\n",
      "Iteration 1345, loss = 10637.14445413\n",
      "Iteration 1346, loss = 10600.30340852\n",
      "Iteration 1347, loss = 10563.58908064\n",
      "Iteration 1348, loss = 10526.97874852\n",
      "Iteration 1349, loss = 10490.48731204\n",
      "Iteration 1350, loss = 10454.13563010\n",
      "Iteration 1351, loss = 10417.88059202\n",
      "Iteration 1352, loss = 10381.67595384\n",
      "Iteration 1353, loss = 10345.62336358\n",
      "Iteration 1354, loss = 10309.70693032\n",
      "Iteration 1355, loss = 10273.90161382\n",
      "Iteration 1356, loss = 10238.14995674\n",
      "Iteration 1357, loss = 10202.51085992\n",
      "Iteration 1358, loss = 10166.85601506\n",
      "Iteration 1359, loss = 10131.28878145\n",
      "Iteration 1360, loss = 10095.87163197\n",
      "Iteration 1361, loss = 10060.58911193\n",
      "Iteration 1362, loss = 10025.31788777\n",
      "Iteration 1363, loss = 9990.08035894\n",
      "Iteration 1364, loss = 9954.85413754\n",
      "Iteration 1365, loss = 9919.70379351\n",
      "Iteration 1366, loss = 9884.68973829\n",
      "Iteration 1367, loss = 9849.76606832\n",
      "Iteration 1368, loss = 9814.91307222\n",
      "Iteration 1369, loss = 9780.19125757\n",
      "Iteration 1370, loss = 9745.50249619\n",
      "Iteration 1371, loss = 9710.85303442\n",
      "Iteration 1372, loss = 9676.35117771\n",
      "Iteration 1373, loss = 9641.95499460\n",
      "Iteration 1374, loss = 9607.61052726\n",
      "Iteration 1375, loss = 9573.38711464\n",
      "Iteration 1376, loss = 9539.29711725\n",
      "Iteration 1377, loss = 9505.31714307\n",
      "Iteration 1378, loss = 9471.39297817\n",
      "Iteration 1379, loss = 9437.61204384\n",
      "Iteration 1380, loss = 9403.96095804\n",
      "Iteration 1381, loss = 9370.45893484\n",
      "Iteration 1382, loss = 9337.10634505\n",
      "Iteration 1383, loss = 9303.89268807\n",
      "Iteration 1384, loss = 9270.73964081\n",
      "Iteration 1385, loss = 9237.73882762\n",
      "Iteration 1386, loss = 9204.88306621\n",
      "Iteration 1387, loss = 9172.18829728\n",
      "Iteration 1388, loss = 9139.61777565\n",
      "Iteration 1389, loss = 9107.24953118\n",
      "Iteration 1390, loss = 9075.04872784\n",
      "Iteration 1391, loss = 9042.99303636\n",
      "Iteration 1392, loss = 9011.11973812\n",
      "Iteration 1393, loss = 8979.33686471\n",
      "Iteration 1394, loss = 8947.66070684\n",
      "Iteration 1395, loss = 8916.14659275\n",
      "Iteration 1396, loss = 8884.71669417\n",
      "Iteration 1397, loss = 8853.40896749\n",
      "Iteration 1398, loss = 8822.24594534\n",
      "Iteration 1399, loss = 8791.12419640\n",
      "Iteration 1400, loss = 8760.10441116\n",
      "Iteration 1401, loss = 8729.13325050\n",
      "Iteration 1402, loss = 8698.27172237\n",
      "Iteration 1403, loss = 8667.50090896\n",
      "Iteration 1404, loss = 8636.93350719\n",
      "Iteration 1405, loss = 8606.46948019\n",
      "Iteration 1406, loss = 8576.11190245\n",
      "Iteration 1407, loss = 8545.91605336\n",
      "Iteration 1408, loss = 8515.84852031\n",
      "Iteration 1409, loss = 8485.95065673\n",
      "Iteration 1410, loss = 8456.18132064\n",
      "Iteration 1411, loss = 8426.55916410\n",
      "Iteration 1412, loss = 8397.10412605\n",
      "Iteration 1413, loss = 8367.86885849\n",
      "Iteration 1414, loss = 8338.76780527\n",
      "Iteration 1415, loss = 8309.81413777\n",
      "Iteration 1416, loss = 8280.86546207\n",
      "Iteration 1417, loss = 8252.04896782\n",
      "Iteration 1418, loss = 8223.33375149\n",
      "Iteration 1419, loss = 8194.74265680\n",
      "Iteration 1420, loss = 8166.22803973\n",
      "Iteration 1421, loss = 8137.80640963\n",
      "Iteration 1422, loss = 8109.49519495\n",
      "Iteration 1423, loss = 8081.24123369\n",
      "Iteration 1424, loss = 8053.09751952\n",
      "Iteration 1425, loss = 8025.13790885\n",
      "Iteration 1426, loss = 7997.32874471\n",
      "Iteration 1427, loss = 7969.60967368\n",
      "Iteration 1428, loss = 7941.90164739\n",
      "Iteration 1429, loss = 7914.31660690\n",
      "Iteration 1430, loss = 7886.94617762\n",
      "Iteration 1431, loss = 7859.72560157\n",
      "Iteration 1432, loss = 7832.66715808\n",
      "Iteration 1433, loss = 7805.61781151\n",
      "Iteration 1434, loss = 7778.68036760\n",
      "Iteration 1435, loss = 7751.86007939\n",
      "Iteration 1436, loss = 7725.11653003\n",
      "Iteration 1437, loss = 7698.49210761\n",
      "Iteration 1438, loss = 7671.91046166\n",
      "Iteration 1439, loss = 7645.37625711\n",
      "Iteration 1440, loss = 7618.97447913\n",
      "Iteration 1441, loss = 7592.65898740\n",
      "Iteration 1442, loss = 7566.42314995\n",
      "Iteration 1443, loss = 7540.42336858\n",
      "Iteration 1444, loss = 7514.69651906\n",
      "Iteration 1445, loss = 7488.96096204\n",
      "Iteration 1446, loss = 7463.28252993\n",
      "Iteration 1447, loss = 7437.74265212\n",
      "Iteration 1448, loss = 7412.36862790\n",
      "Iteration 1449, loss = 7387.17562224\n",
      "Iteration 1450, loss = 7362.55256694\n",
      "Iteration 1451, loss = 7337.82426410\n",
      "Iteration 1452, loss = 7313.07496976\n",
      "Iteration 1453, loss = 7288.35692031\n",
      "Iteration 1454, loss = 7263.64788582\n",
      "Iteration 1455, loss = 7238.94798123\n",
      "Iteration 1456, loss = 7214.40734184\n",
      "Iteration 1457, loss = 7190.06517014\n",
      "Iteration 1458, loss = 7165.69814070\n",
      "Iteration 1459, loss = 7141.53055373\n",
      "Iteration 1460, loss = 7117.58544922\n",
      "Iteration 1461, loss = 7093.71728276\n",
      "Iteration 1462, loss = 7070.04914973\n",
      "Iteration 1463, loss = 7046.36324740\n",
      "Iteration 1464, loss = 7022.69351765\n",
      "Iteration 1465, loss = 6999.45454061\n",
      "Iteration 1466, loss = 6976.29688270\n",
      "Iteration 1467, loss = 6953.14045344\n",
      "Iteration 1468, loss = 6930.01643230\n",
      "Iteration 1469, loss = 6907.04307809\n",
      "Iteration 1470, loss = 6884.19471517\n",
      "Iteration 1471, loss = 6861.30668793\n",
      "Iteration 1472, loss = 6838.43797753\n",
      "Iteration 1473, loss = 6815.69201623\n",
      "Iteration 1474, loss = 6793.09692599\n",
      "Iteration 1475, loss = 6770.57665367\n",
      "Iteration 1476, loss = 6748.08319623\n",
      "Iteration 1477, loss = 6725.71299015\n",
      "Iteration 1478, loss = 6703.45748029\n",
      "Iteration 1479, loss = 6681.21116176\n",
      "Iteration 1480, loss = 6659.03756035\n",
      "Iteration 1481, loss = 6636.98750355\n",
      "Iteration 1482, loss = 6615.02425867\n",
      "Iteration 1483, loss = 6593.14820413\n",
      "Iteration 1484, loss = 6571.45762079\n",
      "Iteration 1485, loss = 6549.81921185\n",
      "Iteration 1486, loss = 6528.26488855\n",
      "Iteration 1487, loss = 6506.84238727\n",
      "Iteration 1488, loss = 6485.60199977\n",
      "Iteration 1489, loss = 6464.52476589\n",
      "Iteration 1490, loss = 6443.54919653\n",
      "Iteration 1491, loss = 6422.68016382\n",
      "Iteration 1492, loss = 6401.94516321\n",
      "Iteration 1493, loss = 6381.31438096\n",
      "Iteration 1494, loss = 6360.81605631\n",
      "Iteration 1495, loss = 6340.38306099\n",
      "Iteration 1496, loss = 6320.17892794\n",
      "Iteration 1497, loss = 6300.08953832\n",
      "Iteration 1498, loss = 6280.08009712\n",
      "Iteration 1499, loss = 6260.11306262\n",
      "Iteration 1500, loss = 6240.18084505\n",
      "Iteration 1501, loss = 6220.33567425\n",
      "Iteration 1502, loss = 6200.58304930\n",
      "Iteration 1503, loss = 6180.88898739\n",
      "Iteration 1504, loss = 6161.29475918\n",
      "Iteration 1505, loss = 6141.73991630\n",
      "Iteration 1506, loss = 6122.23268748\n",
      "Iteration 1507, loss = 6102.86125453\n",
      "Iteration 1508, loss = 6083.56527114\n",
      "Iteration 1509, loss = 6064.37525100\n",
      "Iteration 1510, loss = 6045.26010073\n",
      "Iteration 1511, loss = 6026.23162272\n",
      "Iteration 1512, loss = 6007.29166644\n",
      "Iteration 1513, loss = 5988.42497258\n",
      "Iteration 1514, loss = 5969.60841955\n",
      "Iteration 1515, loss = 5950.89544157\n",
      "Iteration 1516, loss = 5932.37826033\n",
      "Iteration 1517, loss = 5913.93031408\n",
      "Iteration 1518, loss = 5895.53303623\n",
      "Iteration 1519, loss = 5877.22601831\n",
      "Iteration 1520, loss = 5859.01648682\n",
      "Iteration 1521, loss = 5840.87563254\n",
      "Iteration 1522, loss = 5822.77721781\n",
      "Iteration 1523, loss = 5804.75371571\n",
      "Iteration 1524, loss = 5786.85089900\n",
      "Iteration 1525, loss = 5769.00986054\n",
      "Iteration 1526, loss = 5751.27494209\n",
      "Iteration 1527, loss = 5733.64003397\n",
      "Iteration 1528, loss = 5716.05122980\n",
      "Iteration 1529, loss = 5698.54732461\n",
      "Iteration 1530, loss = 5681.14823946\n",
      "Iteration 1531, loss = 5663.83381216\n",
      "Iteration 1532, loss = 5646.53154086\n",
      "Iteration 1533, loss = 5629.34124445\n",
      "Iteration 1534, loss = 5612.23826927\n",
      "Iteration 1535, loss = 5595.17385456\n",
      "Iteration 1536, loss = 5578.15947393\n",
      "Iteration 1537, loss = 5561.20271824\n",
      "Iteration 1538, loss = 5544.26656114\n",
      "Iteration 1539, loss = 5527.37557663\n",
      "Iteration 1540, loss = 5510.62219094\n",
      "Iteration 1541, loss = 5493.93023827\n",
      "Iteration 1542, loss = 5477.32619179\n",
      "Iteration 1543, loss = 5460.80119337\n",
      "Iteration 1544, loss = 5444.33049344\n",
      "Iteration 1545, loss = 5427.94917465\n",
      "Iteration 1546, loss = 5411.69500535\n",
      "Iteration 1547, loss = 5395.46542630\n",
      "Iteration 1548, loss = 5379.32106367\n",
      "Iteration 1549, loss = 5363.22818627\n",
      "Iteration 1550, loss = 5347.14836790\n",
      "Iteration 1551, loss = 5331.12075554\n",
      "Iteration 1552, loss = 5315.23014104\n",
      "Iteration 1553, loss = 5299.41160290\n",
      "Iteration 1554, loss = 5283.64174032\n",
      "Iteration 1555, loss = 5267.87516996\n",
      "Iteration 1556, loss = 5252.15377475\n",
      "Iteration 1557, loss = 5236.46537964\n",
      "Iteration 1558, loss = 5220.83762261\n",
      "Iteration 1559, loss = 5205.26390627\n",
      "Iteration 1560, loss = 5189.77998049\n",
      "Iteration 1561, loss = 5174.40970270\n",
      "Iteration 1562, loss = 5159.08461641\n",
      "Iteration 1563, loss = 5143.91180009\n",
      "Iteration 1564, loss = 5128.81067654\n",
      "Iteration 1565, loss = 5113.69259219\n",
      "Iteration 1566, loss = 5098.60386129\n",
      "Iteration 1567, loss = 5083.58027485\n",
      "Iteration 1568, loss = 5068.51186050\n",
      "Iteration 1569, loss = 5053.51478638\n",
      "Iteration 1570, loss = 5038.51781244\n",
      "Iteration 1571, loss = 5023.68033017\n",
      "Iteration 1572, loss = 5009.02368268\n",
      "Iteration 1573, loss = 4994.33838299\n",
      "Iteration 1574, loss = 4979.66411951\n",
      "Iteration 1575, loss = 4965.02766386\n",
      "Iteration 1576, loss = 4950.49087447\n",
      "Iteration 1577, loss = 4935.95022673\n",
      "Iteration 1578, loss = 4921.49152273\n",
      "Iteration 1579, loss = 4907.00896420\n",
      "Iteration 1580, loss = 4892.60501103\n",
      "Iteration 1581, loss = 4878.38768632\n",
      "Iteration 1582, loss = 4864.27493316\n",
      "Iteration 1583, loss = 4850.14178046\n",
      "Iteration 1584, loss = 4836.01676051\n",
      "Iteration 1585, loss = 4821.90900737\n",
      "Iteration 1586, loss = 4807.79497080\n",
      "Iteration 1587, loss = 4793.84495571\n",
      "Iteration 1588, loss = 4780.05915321\n",
      "Iteration 1589, loss = 4766.27576666\n",
      "Iteration 1590, loss = 4752.47952471\n",
      "Iteration 1591, loss = 4738.75072364\n",
      "Iteration 1592, loss = 4725.11753538\n",
      "Iteration 1593, loss = 4711.48453233\n",
      "Iteration 1594, loss = 4697.85870841\n",
      "Iteration 1595, loss = 4684.35489527\n",
      "Iteration 1596, loss = 4670.90193835\n",
      "Iteration 1597, loss = 4657.44421093\n",
      "Iteration 1598, loss = 4644.01699501\n",
      "Iteration 1599, loss = 4630.65903788\n",
      "Iteration 1600, loss = 4617.32654191\n",
      "Iteration 1601, loss = 4604.05203588\n",
      "Iteration 1602, loss = 4590.86431883\n",
      "Iteration 1603, loss = 4577.72252442\n",
      "Iteration 1604, loss = 4564.61613808\n",
      "Iteration 1605, loss = 4551.61146810\n",
      "Iteration 1606, loss = 4538.65924313\n",
      "Iteration 1607, loss = 4525.78479330\n",
      "Iteration 1608, loss = 4512.92903139\n",
      "Iteration 1609, loss = 4500.14318649\n",
      "Iteration 1610, loss = 4487.43250114\n",
      "Iteration 1611, loss = 4474.77646194\n",
      "Iteration 1612, loss = 4462.16314146\n",
      "Iteration 1613, loss = 4449.60982565\n",
      "Iteration 1614, loss = 4437.11454683\n",
      "Iteration 1615, loss = 4424.70273288\n",
      "Iteration 1616, loss = 4412.38394129\n",
      "Iteration 1617, loss = 4400.11116349\n",
      "Iteration 1618, loss = 4387.88647635\n",
      "Iteration 1619, loss = 4375.69704880\n",
      "Iteration 1620, loss = 4363.57915274\n",
      "Iteration 1621, loss = 4351.51318999\n",
      "Iteration 1622, loss = 4339.45890292\n",
      "Iteration 1623, loss = 4327.44609923\n",
      "Iteration 1624, loss = 4315.47396536\n",
      "Iteration 1625, loss = 4303.53632344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1626, loss = 4291.64798741\n",
      "Iteration 1627, loss = 4279.81201057\n",
      "Iteration 1628, loss = 4268.06401849\n",
      "Iteration 1629, loss = 4256.36608189\n",
      "Iteration 1630, loss = 4244.72843633\n",
      "Iteration 1631, loss = 4233.07995243\n",
      "Iteration 1632, loss = 4221.47843810\n",
      "Iteration 1633, loss = 4209.92496091\n",
      "Iteration 1634, loss = 4198.39736078\n",
      "Iteration 1635, loss = 4186.89536782\n",
      "Iteration 1636, loss = 4175.43651384\n",
      "Iteration 1637, loss = 4164.01835551\n",
      "Iteration 1638, loss = 4152.64094544\n",
      "Iteration 1639, loss = 4141.26665934\n",
      "Iteration 1640, loss = 4129.94414255\n",
      "Iteration 1641, loss = 4118.66939315\n",
      "Iteration 1642, loss = 4107.44368320\n",
      "Iteration 1643, loss = 4096.25669540\n",
      "Iteration 1644, loss = 4085.11262392\n",
      "Iteration 1645, loss = 4074.02006914\n",
      "Iteration 1646, loss = 4062.95945243\n",
      "Iteration 1647, loss = 4051.92477271\n",
      "Iteration 1648, loss = 4040.92902952\n",
      "Iteration 1649, loss = 4030.00179268\n",
      "Iteration 1650, loss = 4019.09727435\n",
      "Iteration 1651, loss = 4008.23288068\n",
      "Iteration 1652, loss = 3997.37620562\n",
      "Iteration 1653, loss = 3986.55635130\n",
      "Iteration 1654, loss = 3975.78202353\n",
      "Iteration 1655, loss = 3965.04155430\n",
      "Iteration 1656, loss = 3954.35756762\n",
      "Iteration 1657, loss = 3943.70356390\n",
      "Iteration 1658, loss = 3933.10125137\n",
      "Iteration 1659, loss = 3922.54310487\n",
      "Iteration 1660, loss = 3912.05209072\n",
      "Iteration 1661, loss = 3901.59277797\n",
      "Iteration 1662, loss = 3891.18182055\n",
      "Iteration 1663, loss = 3880.83403818\n",
      "Iteration 1664, loss = 3870.53967378\n",
      "Iteration 1665, loss = 3860.34772611\n",
      "Iteration 1666, loss = 3850.18725778\n",
      "Iteration 1667, loss = 3840.04541746\n",
      "Iteration 1668, loss = 3829.95203006\n",
      "Iteration 1669, loss = 3819.91477895\n",
      "Iteration 1670, loss = 3809.91353840\n",
      "Iteration 1671, loss = 3799.96202417\n",
      "Iteration 1672, loss = 3790.05844975\n",
      "Iteration 1673, loss = 3780.20585718\n",
      "Iteration 1674, loss = 3770.40834344\n",
      "Iteration 1675, loss = 3760.66189726\n",
      "Iteration 1676, loss = 3750.89485978\n",
      "Iteration 1677, loss = 3741.17129099\n",
      "Iteration 1678, loss = 3731.49719183\n",
      "Iteration 1679, loss = 3721.86742129\n",
      "Iteration 1680, loss = 3712.27075654\n",
      "Iteration 1681, loss = 3702.72440244\n",
      "Iteration 1682, loss = 3693.22946975\n",
      "Iteration 1683, loss = 3683.75056030\n",
      "Iteration 1684, loss = 3674.30342077\n",
      "Iteration 1685, loss = 3664.87905224\n",
      "Iteration 1686, loss = 3655.46860684\n",
      "Iteration 1687, loss = 3646.10125330\n",
      "Iteration 1688, loss = 3636.77559304\n",
      "Iteration 1689, loss = 3627.49084027\n",
      "Iteration 1690, loss = 3618.25045044\n",
      "Iteration 1691, loss = 3609.04848374\n",
      "Iteration 1692, loss = 3599.89330180\n",
      "Iteration 1693, loss = 3590.78174933\n",
      "Iteration 1694, loss = 3581.72240597\n",
      "Iteration 1695, loss = 3572.71862439\n",
      "Iteration 1696, loss = 3563.75055792\n",
      "Iteration 1697, loss = 3554.82202703\n",
      "Iteration 1698, loss = 3545.93137204\n",
      "Iteration 1699, loss = 3537.08478721\n",
      "Iteration 1700, loss = 3528.28540883\n",
      "Iteration 1701, loss = 3519.53358321\n",
      "Iteration 1702, loss = 3510.82941967\n",
      "Iteration 1703, loss = 3502.16899671\n",
      "Iteration 1704, loss = 3493.55426850\n",
      "Iteration 1705, loss = 3484.99163203\n",
      "Iteration 1706, loss = 3476.45099255\n",
      "Iteration 1707, loss = 3467.92733830\n",
      "Iteration 1708, loss = 3459.44549552\n",
      "Iteration 1709, loss = 3450.97644012\n",
      "Iteration 1710, loss = 3442.53702953\n",
      "Iteration 1711, loss = 3434.12729704\n",
      "Iteration 1712, loss = 3425.75533365\n",
      "Iteration 1713, loss = 3417.41476130\n",
      "Iteration 1714, loss = 3409.06389009\n",
      "Iteration 1715, loss = 3400.73148491\n",
      "Iteration 1716, loss = 3392.43864586\n",
      "Iteration 1717, loss = 3384.17798117\n",
      "Iteration 1718, loss = 3375.94567441\n",
      "Iteration 1719, loss = 3367.75339459\n",
      "Iteration 1720, loss = 3359.60647752\n",
      "Iteration 1721, loss = 3351.49782395\n",
      "Iteration 1722, loss = 3343.44538448\n",
      "Iteration 1723, loss = 3335.42635502\n",
      "Iteration 1724, loss = 3327.40759179\n",
      "Iteration 1725, loss = 3319.43232884\n",
      "Iteration 1726, loss = 3311.49301208\n",
      "Iteration 1727, loss = 3303.58726112\n",
      "Iteration 1728, loss = 3295.72769024\n",
      "Iteration 1729, loss = 3287.93513278\n",
      "Iteration 1730, loss = 3280.17461459\n",
      "Iteration 1731, loss = 3272.44396647\n",
      "Iteration 1732, loss = 3264.74230775\n",
      "Iteration 1733, loss = 3257.07425447\n",
      "Iteration 1734, loss = 3249.40613998\n",
      "Iteration 1735, loss = 3241.75699056\n",
      "Iteration 1736, loss = 3234.10167540\n",
      "Iteration 1737, loss = 3226.47476915\n",
      "Iteration 1738, loss = 3218.86015967\n",
      "Iteration 1739, loss = 3211.26219400\n",
      "Iteration 1740, loss = 3203.69420381\n",
      "Iteration 1741, loss = 3196.12734817\n",
      "Iteration 1742, loss = 3188.57866090\n",
      "Iteration 1743, loss = 3181.03180823\n",
      "Iteration 1744, loss = 3173.47799044\n",
      "Iteration 1745, loss = 3165.94429499\n",
      "Iteration 1746, loss = 3158.43508307\n",
      "Iteration 1747, loss = 3150.91344423\n",
      "Iteration 1748, loss = 3143.39619228\n",
      "Iteration 1749, loss = 3135.88835956\n",
      "Iteration 1750, loss = 3128.40460142\n",
      "Iteration 1751, loss = 3120.92469458\n",
      "Iteration 1752, loss = 3113.42382064\n",
      "Iteration 1753, loss = 3105.92460492\n",
      "Iteration 1754, loss = 3098.44088427\n",
      "Iteration 1755, loss = 3090.96041552\n",
      "Iteration 1756, loss = 3083.50094548\n",
      "Iteration 1757, loss = 3076.06421254\n",
      "Iteration 1758, loss = 3068.65149244\n",
      "Iteration 1759, loss = 3061.26341267\n",
      "Iteration 1760, loss = 3053.89997501\n",
      "Iteration 1761, loss = 3046.56306587\n",
      "Iteration 1762, loss = 3039.24417106\n",
      "Iteration 1763, loss = 3031.93180879\n",
      "Iteration 1764, loss = 3024.63129474\n",
      "Iteration 1765, loss = 3017.34209018\n",
      "Iteration 1766, loss = 3010.05466789\n",
      "Iteration 1767, loss = 3002.78550356\n",
      "Iteration 1768, loss = 2995.53975883\n",
      "Iteration 1769, loss = 2988.29772471\n",
      "Iteration 1770, loss = 2981.07048343\n",
      "Iteration 1771, loss = 2973.86678816\n",
      "Iteration 1772, loss = 2966.68752850\n",
      "Iteration 1773, loss = 2959.53312316\n",
      "Iteration 1774, loss = 2952.40442750\n",
      "Iteration 1775, loss = 2945.30243666\n",
      "Iteration 1776, loss = 2938.22757845\n",
      "Iteration 1777, loss = 2931.18022179\n",
      "Iteration 1778, loss = 2924.16067123\n",
      "Iteration 1779, loss = 2917.16851958\n",
      "Iteration 1780, loss = 2910.20440264\n",
      "Iteration 1781, loss = 2903.26872960\n",
      "Iteration 1782, loss = 2896.36170045\n",
      "Iteration 1783, loss = 2889.48348181\n",
      "Iteration 1784, loss = 2882.63420357\n",
      "Iteration 1785, loss = 2875.81460973\n",
      "Iteration 1786, loss = 2868.99509626\n",
      "Iteration 1787, loss = 2862.19979099\n",
      "Iteration 1788, loss = 2855.43094914\n",
      "Iteration 1789, loss = 2848.68808016\n",
      "Iteration 1790, loss = 2841.97187871\n",
      "Iteration 1791, loss = 2835.26807451\n",
      "Iteration 1792, loss = 2828.57251063\n",
      "Iteration 1793, loss = 2821.90125707\n",
      "Iteration 1794, loss = 2815.25503931\n",
      "Iteration 1795, loss = 2808.63379109\n",
      "Iteration 1796, loss = 2802.03840002\n",
      "Iteration 1797, loss = 2795.45869322\n",
      "Iteration 1798, loss = 2788.88061814\n",
      "Iteration 1799, loss = 2782.32290324\n",
      "Iteration 1800, loss = 2775.75961158\n",
      "Iteration 1801, loss = 2769.20227635\n",
      "Iteration 1802, loss = 2762.64448920\n",
      "Iteration 1803, loss = 2756.10614852\n",
      "Iteration 1804, loss = 2749.58818433\n",
      "Iteration 1805, loss = 2743.06889075\n",
      "Iteration 1806, loss = 2736.56847611\n",
      "Iteration 1807, loss = 2730.08820929\n",
      "Iteration 1808, loss = 2723.62891184\n",
      "Iteration 1809, loss = 2717.17611619\n",
      "Iteration 1810, loss = 2710.73068882\n",
      "Iteration 1811, loss = 2704.30548604\n",
      "Iteration 1812, loss = 2697.88100218\n",
      "Iteration 1813, loss = 2691.47364523\n",
      "Iteration 1814, loss = 2685.08624383\n",
      "Iteration 1815, loss = 2678.71960058\n",
      "Iteration 1816, loss = 2672.37441212\n",
      "Iteration 1817, loss = 2666.05128290\n",
      "Iteration 1818, loss = 2659.75076004\n",
      "Iteration 1819, loss = 2653.47344877\n",
      "Iteration 1820, loss = 2647.21961921\n",
      "Iteration 1821, loss = 2640.98976650\n",
      "Iteration 1822, loss = 2634.78378996\n",
      "Iteration 1823, loss = 2628.60214684\n",
      "Iteration 1824, loss = 2622.41954075\n",
      "Iteration 1825, loss = 2616.25595256\n",
      "Iteration 1826, loss = 2610.11457357\n",
      "Iteration 1827, loss = 2603.99590396\n",
      "Iteration 1828, loss = 2597.91291481\n",
      "Iteration 1829, loss = 2591.84145805\n",
      "Iteration 1830, loss = 2585.78685405\n",
      "Iteration 1831, loss = 2579.75417098\n",
      "Iteration 1832, loss = 2573.74375845\n",
      "Iteration 1833, loss = 2567.75582586\n",
      "Iteration 1834, loss = 2561.79054465\n",
      "Iteration 1835, loss = 2555.84809039\n",
      "Iteration 1836, loss = 2549.92884166\n",
      "Iteration 1837, loss = 2544.01807273\n",
      "Iteration 1838, loss = 2538.12586432\n",
      "Iteration 1839, loss = 2532.26547782\n",
      "Iteration 1840, loss = 2526.42737226\n",
      "Iteration 1841, loss = 2520.61168985\n",
      "Iteration 1842, loss = 2514.81854206\n",
      "Iteration 1843, loss = 2509.04808964\n",
      "Iteration 1844, loss = 2503.30057367\n",
      "Iteration 1845, loss = 2497.57629193\n",
      "Iteration 1846, loss = 2491.87552598\n",
      "Iteration 1847, loss = 2486.19851020\n",
      "Iteration 1848, loss = 2480.54539898\n",
      "Iteration 1849, loss = 2474.91151812\n",
      "Iteration 1850, loss = 2469.34103911\n",
      "Iteration 1851, loss = 2463.80911926\n",
      "Iteration 1852, loss = 2458.29739981\n",
      "Iteration 1853, loss = 2452.80615076\n",
      "Iteration 1854, loss = 2447.33469708\n",
      "Iteration 1855, loss = 2441.88146670\n",
      "Iteration 1856, loss = 2436.44525614\n",
      "Iteration 1857, loss = 2431.02713071\n",
      "Iteration 1858, loss = 2425.63122630\n",
      "Iteration 1859, loss = 2420.26173110\n",
      "Iteration 1860, loss = 2414.89585427\n",
      "Iteration 1861, loss = 2409.55123648\n",
      "Iteration 1862, loss = 2404.22820776\n",
      "Iteration 1863, loss = 2398.92399643\n",
      "Iteration 1864, loss = 2393.63935976\n",
      "Iteration 1865, loss = 2388.38150525\n",
      "Iteration 1866, loss = 2383.14725739\n",
      "Iteration 1867, loss = 2377.93855853\n",
      "Iteration 1868, loss = 2372.75491902\n",
      "Iteration 1869, loss = 2367.59418664\n",
      "Iteration 1870, loss = 2362.45436115\n",
      "Iteration 1871, loss = 2357.31144698\n",
      "Iteration 1872, loss = 2352.18383627\n",
      "Iteration 1873, loss = 2347.07717726\n",
      "Iteration 1874, loss = 2341.99130624\n",
      "Iteration 1875, loss = 2336.91532725\n",
      "Iteration 1876, loss = 2331.85389921\n",
      "Iteration 1877, loss = 2326.78723665\n",
      "Iteration 1878, loss = 2321.73699232\n",
      "Iteration 1879, loss = 2316.70440439\n",
      "Iteration 1880, loss = 2311.69081129\n",
      "Iteration 1881, loss = 2306.69676147\n",
      "Iteration 1882, loss = 2301.72213673\n",
      "Iteration 1883, loss = 2296.76660390\n",
      "Iteration 1884, loss = 2291.83007031\n",
      "Iteration 1885, loss = 2286.91283556\n",
      "Iteration 1886, loss = 2282.01541386\n",
      "Iteration 1887, loss = 2277.12110555\n",
      "Iteration 1888, loss = 2272.23311871\n",
      "Iteration 1889, loss = 2267.34084893\n",
      "Iteration 1890, loss = 2262.46395200\n",
      "Iteration 1891, loss = 2257.60283176\n",
      "Iteration 1892, loss = 2252.75803840\n",
      "Iteration 1893, loss = 2247.93052877\n",
      "Iteration 1894, loss = 2243.11966974\n",
      "Iteration 1895, loss = 2238.32658358\n",
      "Iteration 1896, loss = 2233.55107824\n",
      "Iteration 1897, loss = 2228.79335299\n",
      "Iteration 1898, loss = 2224.05688713\n",
      "Iteration 1899, loss = 2219.33949427\n",
      "Iteration 1900, loss = 2214.64047028\n",
      "Iteration 1901, loss = 2209.95237950\n",
      "Iteration 1902, loss = 2205.26262105\n",
      "Iteration 1903, loss = 2200.58384512\n",
      "Iteration 1904, loss = 2195.90344970\n",
      "Iteration 1905, loss = 2191.21717955\n",
      "Iteration 1906, loss = 2186.54097469\n",
      "Iteration 1907, loss = 2181.87769951\n",
      "Iteration 1908, loss = 2177.22807135\n",
      "Iteration 1909, loss = 2172.59236014\n",
      "Iteration 1910, loss = 2167.97133178\n",
      "Iteration 1911, loss = 2163.37018392\n",
      "Iteration 1912, loss = 2158.77185016\n",
      "Iteration 1913, loss = 2154.18727611\n",
      "Iteration 1914, loss = 2149.61698885\n",
      "Iteration 1915, loss = 2145.06140413\n",
      "Iteration 1916, loss = 2140.52084177\n",
      "Iteration 1917, loss = 2135.98420375\n",
      "Iteration 1918, loss = 2131.42868607\n",
      "Iteration 1919, loss = 2126.87969314\n",
      "Iteration 1920, loss = 2122.34235287\n",
      "Iteration 1921, loss = 2117.81732592\n",
      "Iteration 1922, loss = 2113.28836134\n",
      "Iteration 1923, loss = 2108.76184958\n",
      "Iteration 1924, loss = 2104.24407289\n",
      "Iteration 1925, loss = 2099.73805497\n",
      "Iteration 1926, loss = 2095.24436843\n",
      "Iteration 1927, loss = 2090.76533581\n",
      "Iteration 1928, loss = 2086.30077388\n",
      "Iteration 1929, loss = 2081.84924646\n",
      "Iteration 1930, loss = 2077.41111275\n",
      "Iteration 1931, loss = 2072.98689600\n",
      "Iteration 1932, loss = 2068.57696406\n",
      "Iteration 1933, loss = 2064.18163328\n",
      "Iteration 1934, loss = 2059.80313746\n",
      "Iteration 1935, loss = 2055.47951902\n",
      "Iteration 1936, loss = 2051.17057835\n",
      "Iteration 1937, loss = 2046.84720087\n",
      "Iteration 1938, loss = 2042.52808698\n",
      "Iteration 1939, loss = 2038.19480941\n",
      "Iteration 1940, loss = 2033.85713445\n",
      "Iteration 1941, loss = 2029.51858820\n",
      "Iteration 1942, loss = 2025.19136787\n",
      "Iteration 1943, loss = 2020.85531606\n",
      "Iteration 1944, loss = 2016.52634318\n",
      "Iteration 1945, loss = 2012.20801413\n",
      "Iteration 1946, loss = 2007.90138333\n",
      "Iteration 1947, loss = 2003.60694629\n",
      "Iteration 1948, loss = 1999.32698052\n",
      "Iteration 1949, loss = 1995.06149928\n",
      "Iteration 1950, loss = 1990.81008124\n",
      "Iteration 1951, loss = 1986.57309630\n",
      "Iteration 1952, loss = 1982.35085720\n",
      "Iteration 1953, loss = 1978.14700375\n",
      "Iteration 1954, loss = 1973.95986885\n",
      "Iteration 1955, loss = 1969.78734672\n",
      "Iteration 1956, loss = 1965.63004749\n",
      "Iteration 1957, loss = 1961.48868815\n",
      "Iteration 1958, loss = 1957.36216436\n",
      "Iteration 1959, loss = 1953.25078457\n",
      "Iteration 1960, loss = 1949.15581308\n",
      "Iteration 1961, loss = 1945.07642614\n",
      "Iteration 1962, loss = 1941.01302934\n",
      "Iteration 1963, loss = 1936.96509056\n",
      "Iteration 1964, loss = 1932.93447501\n",
      "Iteration 1965, loss = 1928.92169410\n",
      "Iteration 1966, loss = 1924.92169306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1967, loss = 1920.92287796\n",
      "Iteration 1968, loss = 1916.93817605\n",
      "Iteration 1969, loss = 1912.96736572\n",
      "Iteration 1970, loss = 1909.01020385\n",
      "Iteration 1971, loss = 1905.06737384\n",
      "Iteration 1972, loss = 1901.13849941\n",
      "Iteration 1973, loss = 1897.22335835\n",
      "Iteration 1974, loss = 1893.32229407\n",
      "Iteration 1975, loss = 1889.43041504\n",
      "Iteration 1976, loss = 1885.54415690\n",
      "Iteration 1977, loss = 1881.67061792\n",
      "Iteration 1978, loss = 1877.80936367\n",
      "Iteration 1979, loss = 1873.96105871\n",
      "Iteration 1980, loss = 1870.12541926\n",
      "Iteration 1981, loss = 1866.30379286\n",
      "Iteration 1982, loss = 1862.49750457\n",
      "Iteration 1983, loss = 1858.70704915\n",
      "Iteration 1984, loss = 1854.92221909\n",
      "Iteration 1985, loss = 1851.13321280\n",
      "Iteration 1986, loss = 1847.35526926\n",
      "Iteration 1987, loss = 1843.59047203\n",
      "Iteration 1988, loss = 1839.85244131\n",
      "Iteration 1989, loss = 1836.13062844\n",
      "Iteration 1990, loss = 1832.41528393\n",
      "Iteration 1991, loss = 1828.71013614\n",
      "Iteration 1992, loss = 1825.01436381\n",
      "Iteration 1993, loss = 1821.32807625\n",
      "Iteration 1994, loss = 1817.65161709\n",
      "Iteration 1995, loss = 1813.98780608\n",
      "Iteration 1996, loss = 1810.35066553\n",
      "Iteration 1997, loss = 1806.72498931\n",
      "Iteration 1998, loss = 1803.11184166\n",
      "Iteration 1999, loss = 1799.51207273\n",
      "Iteration 2000, loss = 1795.92275938\n",
      "Iteration 2001, loss = 1792.32789759\n",
      "Iteration 2002, loss = 1788.73989428\n",
      "Iteration 2003, loss = 1785.16447657\n",
      "Iteration 2004, loss = 1781.60406844\n",
      "Iteration 2005, loss = 1778.05334103\n",
      "Iteration 2006, loss = 1774.51133600\n",
      "Iteration 2007, loss = 1770.98388400\n",
      "Iteration 2008, loss = 1767.47020636\n",
      "Iteration 2009, loss = 1763.96737547\n",
      "Iteration 2010, loss = 1760.46355240\n",
      "Iteration 2011, loss = 1756.96331571\n",
      "Iteration 2012, loss = 1753.47677637\n",
      "Iteration 2013, loss = 1750.00046351\n",
      "Iteration 2014, loss = 1746.53188420\n",
      "Iteration 2015, loss = 1743.07061486\n",
      "Iteration 2016, loss = 1739.60181200\n",
      "Iteration 2017, loss = 1736.13301813\n",
      "Iteration 2018, loss = 1732.67028681\n",
      "Iteration 2019, loss = 1729.21463439\n",
      "Iteration 2020, loss = 1725.76813089\n",
      "Iteration 2021, loss = 1722.32893335\n",
      "Iteration 2022, loss = 1718.89767187\n",
      "Iteration 2023, loss = 1715.47714155\n",
      "Iteration 2024, loss = 1712.06583549\n",
      "Iteration 2025, loss = 1708.67658434\n",
      "Iteration 2026, loss = 1705.29926968\n",
      "Iteration 2027, loss = 1701.92906251\n",
      "Iteration 2028, loss = 1698.56468336\n",
      "Iteration 2029, loss = 1695.21246631\n",
      "Iteration 2030, loss = 1691.87107147\n",
      "Iteration 2031, loss = 1688.54081432\n",
      "Iteration 2032, loss = 1685.22581777\n",
      "Iteration 2033, loss = 1681.92812123\n",
      "Iteration 2034, loss = 1678.64539869\n",
      "Iteration 2035, loss = 1675.37810782\n",
      "Iteration 2036, loss = 1672.12195707\n",
      "Iteration 2037, loss = 1668.87913708\n",
      "Iteration 2038, loss = 1665.64648205\n",
      "Iteration 2039, loss = 1662.42261028\n",
      "Iteration 2040, loss = 1659.20893546\n",
      "Iteration 2041, loss = 1656.00538550\n",
      "Iteration 2042, loss = 1652.81634773\n",
      "Iteration 2043, loss = 1649.64447366\n",
      "Iteration 2044, loss = 1646.48389733\n",
      "Iteration 2045, loss = 1643.33227158\n",
      "Iteration 2046, loss = 1640.18978842\n",
      "Iteration 2047, loss = 1637.06725633\n",
      "Iteration 2048, loss = 1633.98441793\n",
      "Iteration 2049, loss = 1630.90430225\n",
      "Iteration 2050, loss = 1627.82632008\n",
      "Iteration 2051, loss = 1624.76438771\n",
      "Iteration 2052, loss = 1621.70837317\n",
      "Iteration 2053, loss = 1618.64532148\n",
      "Iteration 2054, loss = 1615.57531215\n",
      "Iteration 2055, loss = 1612.50743255\n",
      "Iteration 2056, loss = 1609.44666631\n",
      "Iteration 2057, loss = 1606.40247479\n",
      "Iteration 2058, loss = 1603.36234318\n",
      "Iteration 2059, loss = 1600.33141012\n",
      "Iteration 2060, loss = 1597.30995040\n",
      "Iteration 2061, loss = 1594.29997097\n",
      "Iteration 2062, loss = 1591.29449196\n",
      "Iteration 2063, loss = 1588.29552212\n",
      "Iteration 2064, loss = 1585.30603579\n",
      "Iteration 2065, loss = 1582.33022982\n",
      "Iteration 2066, loss = 1579.36329434\n",
      "Iteration 2067, loss = 1576.41287197\n",
      "Iteration 2068, loss = 1573.47407044\n",
      "Iteration 2069, loss = 1570.54419165\n",
      "Iteration 2070, loss = 1567.62375778\n",
      "Iteration 2071, loss = 1564.72276627\n",
      "Iteration 2072, loss = 1561.83384785\n",
      "Iteration 2073, loss = 1558.95647270\n",
      "Iteration 2074, loss = 1556.09021313\n",
      "Iteration 2075, loss = 1553.22973945\n",
      "Iteration 2076, loss = 1550.37961614\n",
      "Iteration 2077, loss = 1547.53764831\n",
      "Iteration 2078, loss = 1544.70565766\n",
      "Iteration 2079, loss = 1541.89391951\n",
      "Iteration 2080, loss = 1539.09013652\n",
      "Iteration 2081, loss = 1536.29753251\n",
      "Iteration 2082, loss = 1533.51967952\n",
      "Iteration 2083, loss = 1530.75263894\n",
      "Iteration 2084, loss = 1527.99445552\n",
      "Iteration 2085, loss = 1525.24290365\n",
      "Iteration 2086, loss = 1522.50527232\n",
      "Iteration 2087, loss = 1519.78074667\n",
      "Iteration 2088, loss = 1517.06300141\n",
      "Iteration 2089, loss = 1514.35319523\n",
      "Iteration 2090, loss = 1511.65684579\n",
      "Iteration 2091, loss = 1508.97471050\n",
      "Iteration 2092, loss = 1506.30392088\n",
      "Iteration 2093, loss = 1503.64154027\n",
      "Iteration 2094, loss = 1500.98738435\n",
      "Iteration 2095, loss = 1498.32888909\n",
      "Iteration 2096, loss = 1495.67844592\n",
      "Iteration 2097, loss = 1493.03291647\n",
      "Iteration 2098, loss = 1490.39551445\n",
      "Iteration 2099, loss = 1487.76992761\n",
      "Iteration 2100, loss = 1485.14460136\n",
      "Iteration 2101, loss = 1482.53860446\n",
      "Iteration 2102, loss = 1479.94101095\n",
      "Iteration 2103, loss = 1477.35293380\n",
      "Iteration 2104, loss = 1474.77179340\n",
      "Iteration 2105, loss = 1472.19728957\n",
      "Iteration 2106, loss = 1469.63543761\n",
      "Iteration 2107, loss = 1467.07795011\n",
      "Iteration 2108, loss = 1464.52828566\n",
      "Iteration 2109, loss = 1461.99013190\n",
      "Iteration 2110, loss = 1459.46230408\n",
      "Iteration 2111, loss = 1456.94467749\n",
      "Iteration 2112, loss = 1454.43325461\n",
      "Iteration 2113, loss = 1451.92233014\n",
      "Iteration 2114, loss = 1449.40963836\n",
      "Iteration 2115, loss = 1446.89685558\n",
      "Iteration 2116, loss = 1444.37351411\n",
      "Iteration 2117, loss = 1441.85324627\n",
      "Iteration 2118, loss = 1439.33647248\n",
      "Iteration 2119, loss = 1436.81979503\n",
      "Iteration 2120, loss = 1434.30853736\n",
      "Iteration 2121, loss = 1431.80195831\n",
      "Iteration 2122, loss = 1429.30117472\n",
      "Iteration 2123, loss = 1426.80688684\n",
      "Iteration 2124, loss = 1424.31939335\n",
      "Iteration 2125, loss = 1421.83819602\n",
      "Iteration 2126, loss = 1419.36364451\n",
      "Iteration 2127, loss = 1416.89558830\n",
      "Iteration 2128, loss = 1414.43483980\n",
      "Iteration 2129, loss = 1411.98101213\n",
      "Iteration 2130, loss = 1409.53426535\n",
      "Iteration 2131, loss = 1407.09515535\n",
      "Iteration 2132, loss = 1404.66302428\n",
      "Iteration 2133, loss = 1402.23829825\n",
      "Iteration 2134, loss = 1399.82139810\n",
      "Iteration 2135, loss = 1397.40223789\n",
      "Iteration 2136, loss = 1394.98834079\n",
      "Iteration 2137, loss = 1392.56801771\n",
      "Iteration 2138, loss = 1390.15048262\n",
      "Iteration 2139, loss = 1387.73750474\n",
      "Iteration 2140, loss = 1385.33043008\n",
      "Iteration 2141, loss = 1382.92808244\n",
      "Iteration 2142, loss = 1380.53100123\n",
      "Iteration 2143, loss = 1378.13388602\n",
      "Iteration 2144, loss = 1375.74259421\n",
      "Iteration 2145, loss = 1373.35692920\n",
      "Iteration 2146, loss = 1370.97737159\n",
      "Iteration 2147, loss = 1368.60403300\n",
      "Iteration 2148, loss = 1366.23706859\n",
      "Iteration 2149, loss = 1363.87670379\n",
      "Iteration 2150, loss = 1361.52267750\n",
      "Iteration 2151, loss = 1359.17552809\n",
      "Iteration 2152, loss = 1356.83495421\n",
      "Iteration 2153, loss = 1354.50140214\n",
      "Iteration 2154, loss = 1352.17489895\n",
      "Iteration 2155, loss = 1349.85549438\n",
      "Iteration 2156, loss = 1347.54338374\n",
      "Iteration 2157, loss = 1345.24491924\n",
      "Iteration 2158, loss = 1342.96601590\n",
      "Iteration 2159, loss = 1340.69638668\n",
      "Iteration 2160, loss = 1338.43466000\n",
      "Iteration 2161, loss = 1336.18176084\n",
      "Iteration 2162, loss = 1333.93740524\n",
      "Iteration 2163, loss = 1331.68636196\n",
      "Iteration 2164, loss = 1329.42597039\n",
      "Iteration 2165, loss = 1327.16807456\n",
      "Iteration 2166, loss = 1324.91324387\n",
      "Iteration 2167, loss = 1322.66179044\n",
      "Iteration 2168, loss = 1320.41434724\n",
      "Iteration 2169, loss = 1318.16245076\n",
      "Iteration 2170, loss = 1315.91078036\n",
      "Iteration 2171, loss = 1313.66449552\n",
      "Iteration 2172, loss = 1311.42468837\n",
      "Iteration 2173, loss = 1309.18988546\n",
      "Iteration 2174, loss = 1306.96069023\n",
      "Iteration 2175, loss = 1304.73724038\n",
      "Iteration 2176, loss = 1302.51837917\n",
      "Iteration 2177, loss = 1300.30414959\n",
      "Iteration 2178, loss = 1298.09537767\n",
      "Iteration 2179, loss = 1295.89275972\n",
      "Iteration 2180, loss = 1293.69688679\n",
      "Iteration 2181, loss = 1291.50801331\n",
      "Iteration 2182, loss = 1289.32605421\n",
      "Iteration 2183, loss = 1287.15488316\n",
      "Iteration 2184, loss = 1284.99562083\n",
      "Iteration 2185, loss = 1282.84251332\n",
      "Iteration 2186, loss = 1280.69408057\n",
      "Iteration 2187, loss = 1278.53684623\n",
      "Iteration 2188, loss = 1276.38467425\n",
      "Iteration 2189, loss = 1274.23809281\n",
      "Iteration 2190, loss = 1272.09732962\n",
      "Iteration 2191, loss = 1269.96278803\n",
      "Iteration 2192, loss = 1267.83387181\n",
      "Iteration 2193, loss = 1265.70931607\n",
      "Iteration 2194, loss = 1263.57577112\n",
      "Iteration 2195, loss = 1261.44668946\n",
      "Iteration 2196, loss = 1259.32250583\n",
      "Iteration 2197, loss = 1257.20326936\n",
      "Iteration 2198, loss = 1255.08030575\n",
      "Iteration 2199, loss = 1252.95792982\n",
      "Iteration 2200, loss = 1250.82774174\n",
      "Iteration 2201, loss = 1248.70088093\n",
      "Iteration 2202, loss = 1246.57775837\n",
      "Iteration 2203, loss = 1244.45872124\n",
      "Iteration 2204, loss = 1242.34407196\n",
      "Iteration 2205, loss = 1240.23408271\n",
      "Iteration 2206, loss = 1238.12900625\n",
      "Iteration 2207, loss = 1236.02911640\n",
      "Iteration 2208, loss = 1233.93457232\n",
      "Iteration 2209, loss = 1231.84556315\n",
      "Iteration 2210, loss = 1229.76225699\n",
      "Iteration 2211, loss = 1227.68479852\n",
      "Iteration 2212, loss = 1225.61330942\n",
      "Iteration 2213, loss = 1223.54789058\n",
      "Iteration 2214, loss = 1221.48862502\n",
      "Iteration 2215, loss = 1219.43558199\n",
      "Iteration 2216, loss = 1217.38882097\n",
      "Iteration 2217, loss = 1215.34839458\n",
      "Iteration 2218, loss = 1213.31435015\n",
      "Iteration 2219, loss = 1211.28673134\n",
      "Iteration 2220, loss = 1209.26557889\n",
      "Iteration 2221, loss = 1207.25092985\n",
      "Iteration 2222, loss = 1205.24281561\n",
      "Iteration 2223, loss = 1203.24126133\n",
      "Iteration 2224, loss = 1201.24629439\n",
      "Iteration 2225, loss = 1199.25791628\n",
      "Iteration 2226, loss = 1197.27613241\n",
      "Iteration 2227, loss = 1195.30126396\n",
      "Iteration 2228, loss = 1193.33250884\n",
      "Iteration 2229, loss = 1191.37045335\n",
      "Iteration 2230, loss = 1189.41507062\n",
      "Iteration 2231, loss = 1187.46624411\n",
      "Iteration 2232, loss = 1185.52398735\n",
      "Iteration 2233, loss = 1183.58829379\n",
      "Iteration 2234, loss = 1181.66387621\n",
      "Iteration 2235, loss = 1179.76245718\n",
      "Iteration 2236, loss = 1177.86621616\n",
      "Iteration 2237, loss = 1175.97544277\n",
      "Iteration 2238, loss = 1174.09040218\n",
      "Iteration 2239, loss = 1172.21128056\n",
      "Iteration 2240, loss = 1170.33830160\n",
      "Iteration 2241, loss = 1168.47169458\n",
      "Iteration 2242, loss = 1166.61162472\n",
      "Iteration 2243, loss = 1164.75821062\n",
      "Iteration 2244, loss = 1162.91152916\n",
      "Iteration 2245, loss = 1161.07201208\n",
      "Iteration 2246, loss = 1159.23923072\n",
      "Iteration 2247, loss = 1157.41302927\n",
      "Iteration 2248, loss = 1155.59372764\n",
      "Iteration 2249, loss = 1153.78155206\n",
      "Iteration 2250, loss = 1151.97615744\n",
      "Iteration 2251, loss = 1150.17750539\n",
      "Iteration 2252, loss = 1148.38569982\n",
      "Iteration 2253, loss = 1146.60054689\n",
      "Iteration 2254, loss = 1144.82143034\n",
      "Iteration 2255, loss = 1143.04858145\n",
      "Iteration 2256, loss = 1141.27329495\n",
      "Iteration 2257, loss = 1139.50279082\n",
      "Iteration 2258, loss = 1137.73833624\n",
      "Iteration 2259, loss = 1135.98037149\n",
      "Iteration 2260, loss = 1134.22835516\n",
      "Iteration 2261, loss = 1132.48226009\n",
      "Iteration 2262, loss = 1130.74201652\n",
      "Iteration 2263, loss = 1129.00756293\n",
      "Iteration 2264, loss = 1127.27877414\n",
      "Iteration 2265, loss = 1125.55576205\n",
      "Iteration 2266, loss = 1123.83833440\n",
      "Iteration 2267, loss = 1122.12720069\n",
      "Iteration 2268, loss = 1120.42169987\n",
      "Iteration 2269, loss = 1118.72497933\n",
      "Iteration 2270, loss = 1117.03440990\n",
      "Iteration 2271, loss = 1115.34885297\n",
      "Iteration 2272, loss = 1113.66892075\n",
      "Iteration 2273, loss = 1111.99438486\n",
      "Iteration 2274, loss = 1110.32527169\n",
      "Iteration 2275, loss = 1108.66135990\n",
      "Iteration 2276, loss = 1107.00293159\n",
      "Iteration 2277, loss = 1105.34993002\n",
      "Iteration 2278, loss = 1103.70251157\n",
      "Iteration 2279, loss = 1102.06055892\n",
      "Iteration 2280, loss = 1100.42405751\n",
      "Iteration 2281, loss = 1098.79290799\n",
      "Iteration 2282, loss = 1097.16730051\n",
      "Iteration 2283, loss = 1095.54815164\n",
      "Iteration 2284, loss = 1093.93470575\n",
      "Iteration 2285, loss = 1092.32627206\n",
      "Iteration 2286, loss = 1090.72280305\n",
      "Iteration 2287, loss = 1089.12404357\n",
      "Iteration 2288, loss = 1087.52997516\n",
      "Iteration 2289, loss = 1085.94026754\n",
      "Iteration 2290, loss = 1084.35541256\n",
      "Iteration 2291, loss = 1082.77533995\n",
      "Iteration 2292, loss = 1081.20027784\n",
      "Iteration 2293, loss = 1079.63036352\n",
      "Iteration 2294, loss = 1078.06695340\n",
      "Iteration 2295, loss = 1076.50885357\n",
      "Iteration 2296, loss = 1074.95606312\n",
      "Iteration 2297, loss = 1073.40829198\n",
      "Iteration 2298, loss = 1071.86558124\n",
      "Iteration 2299, loss = 1070.32814658\n",
      "Iteration 2300, loss = 1068.79543499\n",
      "Iteration 2301, loss = 1067.26723885\n",
      "Iteration 2302, loss = 1065.74390233\n",
      "Iteration 2303, loss = 1064.22516954\n",
      "Iteration 2304, loss = 1062.71120814\n",
      "Iteration 2305, loss = 1061.20171312\n",
      "Iteration 2306, loss = 1059.69716957\n",
      "Iteration 2307, loss = 1058.19770133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2308, loss = 1056.70291192\n",
      "Iteration 2309, loss = 1055.21321761\n",
      "Iteration 2310, loss = 1053.73229467\n",
      "Iteration 2311, loss = 1052.26101822\n",
      "Iteration 2312, loss = 1050.79490364\n",
      "Iteration 2313, loss = 1049.33409752\n",
      "Iteration 2314, loss = 1047.87851571\n",
      "Iteration 2315, loss = 1046.42759219\n",
      "Iteration 2316, loss = 1044.98185825\n",
      "Iteration 2317, loss = 1043.54092583\n",
      "Iteration 2318, loss = 1042.10452999\n",
      "Iteration 2319, loss = 1040.67319562\n",
      "Iteration 2320, loss = 1039.24649124\n",
      "Iteration 2321, loss = 1037.82472796\n",
      "Iteration 2322, loss = 1036.40741273\n",
      "Iteration 2323, loss = 1034.99428426\n",
      "Iteration 2324, loss = 1033.58627777\n",
      "Iteration 2325, loss = 1032.18278005\n",
      "Iteration 2326, loss = 1030.78374341\n",
      "Iteration 2327, loss = 1029.38921996\n",
      "Iteration 2328, loss = 1027.99912141\n",
      "Iteration 2329, loss = 1026.61333887\n",
      "Iteration 2330, loss = 1025.23335327\n",
      "Iteration 2331, loss = 1023.85860655\n",
      "Iteration 2332, loss = 1022.48366004\n",
      "Iteration 2333, loss = 1021.09420971\n",
      "Iteration 2334, loss = 1019.70659283\n",
      "Iteration 2335, loss = 1018.32105048\n",
      "Iteration 2336, loss = 1016.93785467\n",
      "Iteration 2337, loss = 1015.55731569\n",
      "Iteration 2338, loss = 1014.17958311\n",
      "Iteration 2339, loss = 1012.80466060\n",
      "Iteration 2340, loss = 1011.43467164\n",
      "Iteration 2341, loss = 1010.06748526\n",
      "Iteration 2342, loss = 1008.70316984\n",
      "Iteration 2343, loss = 1007.34188296\n",
      "Iteration 2344, loss = 1005.98431736\n",
      "Iteration 2345, loss = 1004.63005471\n",
      "Iteration 2346, loss = 1003.27927932\n",
      "Iteration 2347, loss = 1001.93226031\n",
      "Iteration 2348, loss = 1000.58963866\n",
      "Iteration 2349, loss = 999.25037417\n",
      "Iteration 2350, loss = 997.91448856\n",
      "Iteration 2351, loss = 996.58303936\n",
      "Iteration 2352, loss = 995.25528992\n",
      "Iteration 2353, loss = 993.93116159\n",
      "Iteration 2354, loss = 992.61081713\n",
      "Iteration 2355, loss = 991.29450016\n",
      "Iteration 2356, loss = 989.98202777\n",
      "Iteration 2357, loss = 988.67367439\n",
      "Iteration 2358, loss = 987.36894947\n",
      "Iteration 2359, loss = 986.06835612\n",
      "Iteration 2360, loss = 984.77173221\n",
      "Iteration 2361, loss = 983.47903159\n",
      "Iteration 2362, loss = 982.19007180\n",
      "Iteration 2363, loss = 980.90119890\n",
      "Iteration 2364, loss = 979.61547769\n",
      "Iteration 2365, loss = 978.33294474\n",
      "Iteration 2366, loss = 977.05326491\n",
      "Iteration 2367, loss = 975.77703960\n",
      "Iteration 2368, loss = 974.50520384\n",
      "Iteration 2369, loss = 973.23724374\n",
      "Iteration 2370, loss = 971.97284313\n",
      "Iteration 2371, loss = 970.71207995\n",
      "Iteration 2372, loss = 969.45498344\n",
      "Iteration 2373, loss = 968.20218283\n",
      "Iteration 2374, loss = 966.95268780\n",
      "Iteration 2375, loss = 965.70693862\n",
      "Iteration 2376, loss = 964.46381772\n",
      "Iteration 2377, loss = 963.22303568\n",
      "Iteration 2378, loss = 961.98486108\n",
      "Iteration 2379, loss = 960.74922471\n",
      "Iteration 2380, loss = 959.51750825\n",
      "Iteration 2381, loss = 958.29038422\n",
      "Iteration 2382, loss = 957.06751514\n",
      "Iteration 2383, loss = 955.84917077\n",
      "Iteration 2384, loss = 954.63546640\n",
      "Iteration 2385, loss = 953.42587369\n",
      "Iteration 2386, loss = 952.21970325\n",
      "Iteration 2387, loss = 951.01738583\n",
      "Iteration 2388, loss = 949.81865081\n",
      "Iteration 2389, loss = 948.62279339\n",
      "Iteration 2390, loss = 947.43012306\n",
      "Iteration 2391, loss = 946.24088231\n",
      "Iteration 2392, loss = 945.05630916\n",
      "Iteration 2393, loss = 943.87544165\n",
      "Iteration 2394, loss = 942.69822200\n",
      "Iteration 2395, loss = 941.52470934\n",
      "Iteration 2396, loss = 940.35513518\n",
      "Iteration 2397, loss = 939.18936950\n",
      "Iteration 2398, loss = 938.02740714\n",
      "Iteration 2399, loss = 936.86591569\n",
      "Iteration 2400, loss = 935.70638151\n",
      "Iteration 2401, loss = 934.54994870\n",
      "Iteration 2402, loss = 933.39660803\n",
      "Iteration 2403, loss = 932.24631457\n",
      "Iteration 2404, loss = 931.09526585\n",
      "Iteration 2405, loss = 929.94207861\n",
      "Iteration 2406, loss = 928.79138599\n",
      "Iteration 2407, loss = 927.64301925\n",
      "Iteration 2408, loss = 926.49753761\n",
      "Iteration 2409, loss = 925.35466286\n",
      "Iteration 2410, loss = 924.21421589\n",
      "Iteration 2411, loss = 923.07646104\n",
      "Iteration 2412, loss = 921.94204842\n",
      "Iteration 2413, loss = 920.81035987\n",
      "Iteration 2414, loss = 919.68153051\n",
      "Iteration 2415, loss = 918.55587102\n",
      "Iteration 2416, loss = 917.43339966\n",
      "Iteration 2417, loss = 916.31406085\n",
      "Iteration 2418, loss = 915.19774482\n",
      "Iteration 2419, loss = 914.08467076\n",
      "Iteration 2420, loss = 912.97458016\n",
      "Iteration 2421, loss = 911.86789354\n",
      "Iteration 2422, loss = 910.76434708\n",
      "Iteration 2423, loss = 909.66381278\n",
      "Iteration 2424, loss = 908.56644936\n",
      "Iteration 2425, loss = 907.47236449\n",
      "Iteration 2426, loss = 906.38171505\n",
      "Iteration 2427, loss = 905.29419133\n",
      "Iteration 2428, loss = 904.21059036\n",
      "Iteration 2429, loss = 903.13038517\n",
      "Iteration 2430, loss = 902.05340473\n",
      "Iteration 2431, loss = 900.97945134\n",
      "Iteration 2432, loss = 899.90868403\n",
      "Iteration 2433, loss = 898.84129377\n",
      "Iteration 2434, loss = 897.77684039\n",
      "Iteration 2435, loss = 896.71548041\n",
      "Iteration 2436, loss = 895.65739599\n",
      "Iteration 2437, loss = 894.60269687\n",
      "Iteration 2438, loss = 893.55087096\n",
      "Iteration 2439, loss = 892.50190750\n",
      "Iteration 2440, loss = 891.45648883\n",
      "Iteration 2441, loss = 890.41418201\n",
      "Iteration 2442, loss = 889.37561596\n",
      "Iteration 2443, loss = 888.33986015\n",
      "Iteration 2444, loss = 887.30705162\n",
      "Iteration 2445, loss = 886.27765268\n",
      "Iteration 2446, loss = 885.25144955\n",
      "Iteration 2447, loss = 884.22797071\n",
      "Iteration 2448, loss = 883.20791639\n",
      "Iteration 2449, loss = 882.19085795\n",
      "Iteration 2450, loss = 881.17661777\n",
      "Iteration 2451, loss = 880.16606746\n",
      "Iteration 2452, loss = 879.15832551\n",
      "Iteration 2453, loss = 878.15369196\n",
      "Iteration 2454, loss = 877.15179496\n",
      "Iteration 2455, loss = 876.15318072\n",
      "Iteration 2456, loss = 875.15744796\n",
      "Iteration 2457, loss = 874.16526595\n",
      "Iteration 2458, loss = 873.17585127\n",
      "Iteration 2459, loss = 872.18911270\n",
      "Iteration 2460, loss = 871.21008072\n",
      "Iteration 2461, loss = 870.23497273\n",
      "Iteration 2462, loss = 869.26249449\n",
      "Iteration 2463, loss = 868.29268484\n",
      "Iteration 2464, loss = 867.32567428\n",
      "Iteration 2465, loss = 866.36129316\n",
      "Iteration 2466, loss = 865.39969732\n",
      "Iteration 2467, loss = 864.44135500\n",
      "Iteration 2468, loss = 863.48601001\n",
      "Iteration 2469, loss = 862.53326067\n",
      "Iteration 2470, loss = 861.58345293\n",
      "Iteration 2471, loss = 860.63759465\n",
      "Iteration 2472, loss = 859.69446774\n",
      "Iteration 2473, loss = 858.75426826\n",
      "Iteration 2474, loss = 857.81665406\n",
      "Iteration 2475, loss = 856.88201826\n",
      "Iteration 2476, loss = 855.95056664\n",
      "Iteration 2477, loss = 855.02175472\n",
      "Iteration 2478, loss = 854.09557132\n",
      "Iteration 2479, loss = 853.17236747\n",
      "Iteration 2480, loss = 852.25301368\n",
      "Iteration 2481, loss = 851.33652951\n",
      "Iteration 2482, loss = 850.42279650\n",
      "Iteration 2483, loss = 849.51174690\n",
      "Iteration 2484, loss = 848.60385409\n",
      "Iteration 2485, loss = 847.69909788\n",
      "Iteration 2486, loss = 846.79775645\n",
      "Iteration 2487, loss = 845.89949852\n",
      "Iteration 2488, loss = 845.00410457\n",
      "Iteration 2489, loss = 844.11085966\n",
      "Iteration 2490, loss = 843.20884714\n",
      "Iteration 2491, loss = 842.30173377\n",
      "Iteration 2492, loss = 841.39366024\n",
      "Iteration 2493, loss = 840.48516126\n",
      "Iteration 2494, loss = 839.57751643\n",
      "Iteration 2495, loss = 838.68986049\n",
      "Iteration 2496, loss = 837.80632458\n",
      "Iteration 2497, loss = 836.92746306\n",
      "Iteration 2498, loss = 836.05266548\n",
      "Iteration 2499, loss = 835.18073644\n",
      "Iteration 2500, loss = 834.31070733\n",
      "Iteration 2501, loss = 833.44231192\n",
      "Iteration 2502, loss = 832.57522893\n",
      "Iteration 2503, loss = 831.70974012\n",
      "Iteration 2504, loss = 830.84654971\n",
      "Iteration 2505, loss = 829.98680023\n",
      "Iteration 2506, loss = 829.13006030\n",
      "Iteration 2507, loss = 828.27634415\n",
      "Iteration 2508, loss = 827.42567115\n",
      "Iteration 2509, loss = 826.57724944\n",
      "Iteration 2510, loss = 825.73057207\n",
      "Iteration 2511, loss = 824.88584497\n",
      "Iteration 2512, loss = 824.04320397\n",
      "Iteration 2513, loss = 823.20277617\n",
      "Iteration 2514, loss = 822.36514233\n",
      "Iteration 2515, loss = 821.53040558\n",
      "Iteration 2516, loss = 820.69808945\n",
      "Iteration 2517, loss = 819.86839893\n",
      "Iteration 2518, loss = 819.04073638\n",
      "Iteration 2519, loss = 818.21529619\n",
      "Iteration 2520, loss = 817.39215987\n",
      "Iteration 2521, loss = 816.57115814\n",
      "Iteration 2522, loss = 815.75209525\n",
      "Iteration 2523, loss = 814.93550642\n",
      "Iteration 2524, loss = 814.12143035\n",
      "Iteration 2525, loss = 813.31015297\n",
      "Iteration 2526, loss = 812.50118804\n",
      "Iteration 2527, loss = 811.69410118\n",
      "Iteration 2528, loss = 810.88922504\n",
      "Iteration 2529, loss = 810.08651860\n",
      "Iteration 2530, loss = 809.28603393\n",
      "Iteration 2531, loss = 808.48791992\n",
      "Iteration 2532, loss = 807.69202112\n",
      "Iteration 2533, loss = 806.89828595\n",
      "Iteration 2534, loss = 806.10665229\n",
      "Iteration 2535, loss = 805.31750272\n",
      "Iteration 2536, loss = 804.53040196\n",
      "Iteration 2537, loss = 803.74567548\n",
      "Iteration 2538, loss = 802.96321947\n",
      "Iteration 2539, loss = 802.18265402\n",
      "Iteration 2540, loss = 801.40424397\n",
      "Iteration 2541, loss = 800.62805430\n",
      "Iteration 2542, loss = 799.85402331\n",
      "Iteration 2543, loss = 799.08204703\n",
      "Iteration 2544, loss = 798.31238334\n",
      "Iteration 2545, loss = 797.54499170\n",
      "Iteration 2546, loss = 796.77959534\n",
      "Iteration 2547, loss = 796.01618108\n",
      "Iteration 2548, loss = 795.25459424\n",
      "Iteration 2549, loss = 794.49581726\n",
      "Iteration 2550, loss = 793.73909283\n",
      "Iteration 2551, loss = 792.98421612\n",
      "Iteration 2552, loss = 792.23120551\n",
      "Iteration 2553, loss = 791.48024989\n",
      "Iteration 2554, loss = 790.73130870\n",
      "Iteration 2555, loss = 789.98480044\n",
      "Iteration 2556, loss = 789.23682875\n",
      "Iteration 2557, loss = 788.48921753\n",
      "Iteration 2558, loss = 787.74270887\n",
      "Iteration 2559, loss = 786.99764108\n",
      "Iteration 2560, loss = 786.25396839\n",
      "Iteration 2561, loss = 785.51239484\n",
      "Iteration 2562, loss = 784.77260797\n",
      "Iteration 2563, loss = 784.03443350\n",
      "Iteration 2564, loss = 783.29773918\n",
      "Iteration 2565, loss = 782.56265784\n",
      "Iteration 2566, loss = 781.82949644\n",
      "Iteration 2567, loss = 781.09846400\n",
      "Iteration 2568, loss = 780.36901144\n",
      "Iteration 2569, loss = 779.64157389\n",
      "Iteration 2570, loss = 778.91579280\n",
      "Iteration 2571, loss = 778.19169105\n",
      "Iteration 2572, loss = 777.46968166\n",
      "Iteration 2573, loss = 776.74969504\n",
      "Iteration 2574, loss = 776.03171364\n",
      "Iteration 2575, loss = 775.31559534\n",
      "Iteration 2576, loss = 774.60122945\n",
      "Iteration 2577, loss = 773.88860191\n",
      "Iteration 2578, loss = 773.17833997\n",
      "Iteration 2579, loss = 772.46979292\n",
      "Iteration 2580, loss = 771.76283672\n",
      "Iteration 2581, loss = 771.05655197\n",
      "Iteration 2582, loss = 770.35144956\n",
      "Iteration 2583, loss = 769.64839880\n",
      "Iteration 2584, loss = 768.94710406\n",
      "Iteration 2585, loss = 768.24758877\n",
      "Iteration 2586, loss = 767.54985537\n",
      "Iteration 2587, loss = 766.85368469\n",
      "Iteration 2588, loss = 766.15952036\n",
      "Iteration 2589, loss = 765.46721473\n",
      "Iteration 2590, loss = 764.77661515\n",
      "Iteration 2591, loss = 764.08779676\n",
      "Iteration 2592, loss = 763.40065677\n",
      "Iteration 2593, loss = 762.71536224\n",
      "Iteration 2594, loss = 762.03215088\n",
      "Iteration 2595, loss = 761.35056866\n",
      "Iteration 2596, loss = 760.67071898\n",
      "Iteration 2597, loss = 759.99266620\n",
      "Iteration 2598, loss = 759.31641807\n",
      "Iteration 2599, loss = 758.64183153\n",
      "Iteration 2600, loss = 757.96919946\n",
      "Iteration 2601, loss = 757.29834794\n",
      "Iteration 2602, loss = 756.62389537\n",
      "Iteration 2603, loss = 755.94897102\n",
      "Iteration 2604, loss = 755.27561353\n",
      "Iteration 2605, loss = 754.60312193\n",
      "Iteration 2606, loss = 753.93157469\n",
      "Iteration 2607, loss = 753.26169442\n",
      "Iteration 2608, loss = 752.59331394\n",
      "Iteration 2609, loss = 751.92626053\n",
      "Iteration 2610, loss = 751.26057293\n",
      "Iteration 2611, loss = 750.59635573\n",
      "Iteration 2612, loss = 749.93363832\n",
      "Iteration 2613, loss = 749.27227493\n",
      "Iteration 2614, loss = 748.61246624\n",
      "Iteration 2615, loss = 747.95378282\n",
      "Iteration 2616, loss = 747.29636120\n",
      "Iteration 2617, loss = 746.63989195\n",
      "Iteration 2618, loss = 745.98461743\n",
      "Iteration 2619, loss = 745.33064445\n",
      "Iteration 2620, loss = 744.67763678\n",
      "Iteration 2621, loss = 744.02247145\n",
      "Iteration 2622, loss = 743.36866528\n",
      "Iteration 2623, loss = 742.71658000\n",
      "Iteration 2624, loss = 742.06609743\n",
      "Iteration 2625, loss = 741.41753001\n",
      "Iteration 2626, loss = 740.77014922\n",
      "Iteration 2627, loss = 740.12428475\n",
      "Iteration 2628, loss = 739.48004712\n",
      "Iteration 2629, loss = 738.83716009\n",
      "Iteration 2630, loss = 738.19535336\n",
      "Iteration 2631, loss = 737.55490083\n",
      "Iteration 2632, loss = 736.91587808\n",
      "Iteration 2633, loss = 736.27831043\n",
      "Iteration 2634, loss = 735.64216603\n",
      "Iteration 2635, loss = 735.00793709\n",
      "Iteration 2636, loss = 734.37530824\n",
      "Iteration 2637, loss = 733.74440314\n",
      "Iteration 2638, loss = 733.11503624\n",
      "Iteration 2639, loss = 732.48759045\n",
      "Iteration 2640, loss = 731.86163523\n",
      "Iteration 2641, loss = 731.23697496\n",
      "Iteration 2642, loss = 730.61416006\n",
      "Iteration 2643, loss = 729.99319270\n",
      "Iteration 2644, loss = 729.37370824\n",
      "Iteration 2645, loss = 728.75561473\n",
      "Iteration 2646, loss = 728.13922947\n",
      "Iteration 2647, loss = 727.52443445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2648, loss = 726.91133397\n",
      "Iteration 2649, loss = 726.30009088\n",
      "Iteration 2650, loss = 725.69019192\n",
      "Iteration 2651, loss = 725.08210028\n",
      "Iteration 2652, loss = 724.47584343\n",
      "Iteration 2653, loss = 723.87103711\n",
      "Iteration 2654, loss = 723.26767407\n",
      "Iteration 2655, loss = 722.66602040\n",
      "Iteration 2656, loss = 722.06625039\n",
      "Iteration 2657, loss = 721.46798302\n",
      "Iteration 2658, loss = 720.87115405\n",
      "Iteration 2659, loss = 720.27611630\n",
      "Iteration 2660, loss = 719.68244103\n",
      "Iteration 2661, loss = 719.09062475\n",
      "Iteration 2662, loss = 718.50037859\n",
      "Iteration 2663, loss = 717.91162027\n",
      "Iteration 2664, loss = 717.32451836\n",
      "Iteration 2665, loss = 716.73510479\n",
      "Iteration 2666, loss = 716.14455771\n",
      "Iteration 2667, loss = 715.55470330\n",
      "Iteration 2668, loss = 714.96576209\n",
      "Iteration 2669, loss = 714.37800878\n",
      "Iteration 2670, loss = 713.79134636\n",
      "Iteration 2671, loss = 713.20574931\n",
      "Iteration 2672, loss = 712.62130775\n",
      "Iteration 2673, loss = 712.03825720\n",
      "Iteration 2674, loss = 711.45620058\n",
      "Iteration 2675, loss = 710.87559937\n",
      "Iteration 2676, loss = 710.29617110\n",
      "Iteration 2677, loss = 709.71813097\n",
      "Iteration 2678, loss = 709.14138219\n",
      "Iteration 2679, loss = 708.56086357\n",
      "Iteration 2680, loss = 707.97992690\n",
      "Iteration 2681, loss = 707.39943926\n",
      "Iteration 2682, loss = 706.81971132\n",
      "Iteration 2683, loss = 706.24091402\n",
      "Iteration 2684, loss = 705.66300965\n",
      "Iteration 2685, loss = 705.08612392\n",
      "Iteration 2686, loss = 704.51019372\n",
      "Iteration 2687, loss = 703.93524993\n",
      "Iteration 2688, loss = 703.36153745\n",
      "Iteration 2689, loss = 702.78903573\n",
      "Iteration 2690, loss = 702.21786968\n",
      "Iteration 2691, loss = 701.64789222\n",
      "Iteration 2692, loss = 701.07913879\n",
      "Iteration 2693, loss = 700.51174860\n",
      "Iteration 2694, loss = 699.94585864\n",
      "Iteration 2695, loss = 699.38144372\n",
      "Iteration 2696, loss = 698.81860543\n",
      "Iteration 2697, loss = 698.25729942\n",
      "Iteration 2698, loss = 697.69766282\n",
      "Iteration 2699, loss = 697.13990101\n",
      "Iteration 2700, loss = 696.58369973\n",
      "Iteration 2701, loss = 696.02905005\n",
      "Iteration 2702, loss = 695.47571507\n",
      "Iteration 2703, loss = 694.92313683\n",
      "Iteration 2704, loss = 694.37089488\n",
      "Iteration 2705, loss = 693.81856234\n",
      "Iteration 2706, loss = 693.26583134\n",
      "Iteration 2707, loss = 692.71372613\n",
      "Iteration 2708, loss = 692.16307268\n",
      "Iteration 2709, loss = 691.61512224\n",
      "Iteration 2710, loss = 691.07035521\n",
      "Iteration 2711, loss = 690.52850104\n",
      "Iteration 2712, loss = 689.98886159\n",
      "Iteration 2713, loss = 689.45042124\n",
      "Iteration 2714, loss = 688.91313812\n",
      "Iteration 2715, loss = 688.37643703\n",
      "Iteration 2716, loss = 687.84013184\n",
      "Iteration 2717, loss = 687.30452927\n",
      "Iteration 2718, loss = 686.77087818\n",
      "Iteration 2719, loss = 686.23937192\n",
      "Iteration 2720, loss = 685.70989041\n",
      "Iteration 2721, loss = 685.18216215\n",
      "Iteration 2722, loss = 684.65574255\n",
      "Iteration 2723, loss = 684.13045374\n",
      "Iteration 2724, loss = 683.60645772\n",
      "Iteration 2725, loss = 683.08349862\n",
      "Iteration 2726, loss = 682.56205186\n",
      "Iteration 2727, loss = 682.04173725\n",
      "Iteration 2728, loss = 681.52281159\n",
      "Iteration 2729, loss = 681.00561129\n",
      "Iteration 2730, loss = 680.49025247\n",
      "Iteration 2731, loss = 679.97627029\n",
      "Iteration 2732, loss = 679.46349273\n",
      "Iteration 2733, loss = 678.95216679\n",
      "Iteration 2734, loss = 678.44210239\n",
      "Iteration 2735, loss = 677.93310633\n",
      "Iteration 2736, loss = 677.42561292\n",
      "Iteration 2737, loss = 676.91940989\n",
      "Iteration 2738, loss = 676.41455026\n",
      "Iteration 2739, loss = 675.91133560\n",
      "Iteration 2740, loss = 675.40970043\n",
      "Iteration 2741, loss = 674.90824908\n",
      "Iteration 2742, loss = 674.40501101\n",
      "Iteration 2743, loss = 673.90091390\n",
      "Iteration 2744, loss = 673.39793896\n",
      "Iteration 2745, loss = 672.89549552\n",
      "Iteration 2746, loss = 672.39377842\n",
      "Iteration 2747, loss = 671.89296272\n",
      "Iteration 2748, loss = 671.39333721\n",
      "Iteration 2749, loss = 670.89472983\n",
      "Iteration 2750, loss = 670.39713264\n",
      "Iteration 2751, loss = 669.90059527\n",
      "Iteration 2752, loss = 669.40516874\n",
      "Iteration 2753, loss = 668.91099255\n",
      "Iteration 2754, loss = 668.41756532\n",
      "Iteration 2755, loss = 667.92533006\n",
      "Iteration 2756, loss = 667.43442114\n",
      "Iteration 2757, loss = 666.94463456\n",
      "Iteration 2758, loss = 666.45581543\n",
      "Iteration 2759, loss = 665.96841146\n",
      "Iteration 2760, loss = 665.48230244\n",
      "Iteration 2761, loss = 664.99720399\n",
      "Iteration 2762, loss = 664.51329380\n",
      "Iteration 2763, loss = 664.03071391\n",
      "Iteration 2764, loss = 663.54929666\n",
      "Iteration 2765, loss = 663.06891642\n",
      "Iteration 2766, loss = 662.58948291\n",
      "Iteration 2767, loss = 662.11097522\n",
      "Iteration 2768, loss = 661.63357728\n",
      "Iteration 2769, loss = 661.15737844\n",
      "Iteration 2770, loss = 660.68262429\n",
      "Iteration 2771, loss = 660.20890499\n",
      "Iteration 2772, loss = 659.73630906\n",
      "Iteration 2773, loss = 659.26485147\n",
      "Iteration 2774, loss = 658.79448620\n",
      "Iteration 2775, loss = 658.32557664\n",
      "Iteration 2776, loss = 657.85786606\n",
      "Iteration 2777, loss = 657.39135126\n",
      "Iteration 2778, loss = 656.92585498\n",
      "Iteration 2779, loss = 656.46184309\n",
      "Iteration 2780, loss = 655.99897608\n",
      "Iteration 2781, loss = 655.53726605\n",
      "Iteration 2782, loss = 655.07653631\n",
      "Iteration 2783, loss = 654.61701163\n",
      "Iteration 2784, loss = 654.15784757\n",
      "Iteration 2785, loss = 653.69760214\n",
      "Iteration 2786, loss = 653.23723299\n",
      "Iteration 2787, loss = 652.77696399\n",
      "Iteration 2788, loss = 652.31654021\n",
      "Iteration 2789, loss = 651.85639536\n",
      "Iteration 2790, loss = 651.39685930\n",
      "Iteration 2791, loss = 650.93781782\n",
      "Iteration 2792, loss = 650.47925573\n",
      "Iteration 2793, loss = 650.02131173\n",
      "Iteration 2794, loss = 649.56409971\n",
      "Iteration 2795, loss = 649.10753981\n",
      "Iteration 2796, loss = 648.65185983\n",
      "Iteration 2797, loss = 648.19704426\n",
      "Iteration 2798, loss = 647.74253316\n",
      "Iteration 2799, loss = 647.28681814\n",
      "Iteration 2800, loss = 646.83184755\n",
      "Iteration 2801, loss = 646.37755426\n",
      "Iteration 2802, loss = 645.92402579\n",
      "Iteration 2803, loss = 645.47133338\n",
      "Iteration 2804, loss = 645.01947495\n",
      "Iteration 2805, loss = 644.56860039\n",
      "Iteration 2806, loss = 644.11574147\n",
      "Iteration 2807, loss = 643.66167237\n",
      "Iteration 2808, loss = 643.20816107\n",
      "Iteration 2809, loss = 642.75483150\n",
      "Iteration 2810, loss = 642.30192646\n",
      "Iteration 2811, loss = 641.84992075\n",
      "Iteration 2812, loss = 641.39852158\n",
      "Iteration 2813, loss = 640.94789891\n",
      "Iteration 2814, loss = 640.49805147\n",
      "Iteration 2815, loss = 640.04907527\n",
      "Iteration 2816, loss = 639.60115887\n",
      "Iteration 2817, loss = 639.15408296\n",
      "Iteration 2818, loss = 638.70787965\n",
      "Iteration 2819, loss = 638.26317563\n",
      "Iteration 2820, loss = 637.81954526\n",
      "Iteration 2821, loss = 637.37678421\n",
      "Iteration 2822, loss = 636.93524728\n",
      "Iteration 2823, loss = 636.49490751\n",
      "Iteration 2824, loss = 636.05554566\n",
      "Iteration 2825, loss = 635.61680846\n",
      "Iteration 2826, loss = 635.17857059\n",
      "Iteration 2827, loss = 634.74068599\n",
      "Iteration 2828, loss = 634.30287558\n",
      "Iteration 2829, loss = 633.86555255\n",
      "Iteration 2830, loss = 633.41269123\n",
      "Iteration 2831, loss = 632.95528319\n",
      "Iteration 2832, loss = 632.49608418\n",
      "Iteration 2833, loss = 632.03530918\n",
      "Iteration 2834, loss = 631.57354823\n",
      "Iteration 2835, loss = 631.11078604\n",
      "Iteration 2836, loss = 630.64725593\n",
      "Iteration 2837, loss = 630.18263883\n",
      "Iteration 2838, loss = 629.71697195\n",
      "Iteration 2839, loss = 629.25043323\n",
      "Iteration 2840, loss = 628.78316411\n",
      "Iteration 2841, loss = 628.31553145\n",
      "Iteration 2842, loss = 627.84779717\n",
      "Iteration 2843, loss = 627.38025591\n",
      "Iteration 2844, loss = 626.91309522\n",
      "Iteration 2845, loss = 626.44642677\n",
      "Iteration 2846, loss = 625.98044810\n",
      "Iteration 2847, loss = 625.51485132\n",
      "Iteration 2848, loss = 625.04990720\n",
      "Iteration 2849, loss = 624.58557201\n",
      "Iteration 2850, loss = 624.12173855\n",
      "Iteration 2851, loss = 623.65853271\n",
      "Iteration 2852, loss = 623.19608394\n",
      "Iteration 2853, loss = 622.73470304\n",
      "Iteration 2854, loss = 622.27427489\n",
      "Iteration 2855, loss = 621.81496813\n",
      "Iteration 2856, loss = 621.35641878\n",
      "Iteration 2857, loss = 620.89909926\n",
      "Iteration 2858, loss = 620.44291269\n",
      "Iteration 2859, loss = 619.98771196\n",
      "Iteration 2860, loss = 619.53364948\n",
      "Iteration 2861, loss = 619.08076442\n",
      "Iteration 2862, loss = 618.62891517\n",
      "Iteration 2863, loss = 618.17929615\n",
      "Iteration 2864, loss = 617.73057714\n",
      "Iteration 2865, loss = 617.28312044\n",
      "Iteration 2866, loss = 616.83680456\n",
      "Iteration 2867, loss = 616.39170364\n",
      "Iteration 2868, loss = 615.94778726\n",
      "Iteration 2869, loss = 615.50507480\n",
      "Iteration 2870, loss = 615.06360590\n",
      "Iteration 2871, loss = 614.63934504\n",
      "Iteration 2872, loss = 614.22998421\n",
      "Iteration 2873, loss = 613.82305396\n",
      "Iteration 2874, loss = 613.41839563\n",
      "Iteration 2875, loss = 613.01592543\n",
      "Iteration 2876, loss = 612.61546026\n",
      "Iteration 2877, loss = 612.21700286\n",
      "Iteration 2878, loss = 611.82037383\n",
      "Iteration 2879, loss = 611.42547191\n",
      "Iteration 2880, loss = 611.03222187\n",
      "Iteration 2881, loss = 610.64056886\n",
      "Iteration 2882, loss = 610.25048621\n",
      "Iteration 2883, loss = 609.86215073\n",
      "Iteration 2884, loss = 609.47509098\n",
      "Iteration 2885, loss = 609.08926036\n",
      "Iteration 2886, loss = 608.70496631\n",
      "Iteration 2887, loss = 608.32192872\n",
      "Iteration 2888, loss = 607.93997910\n",
      "Iteration 2889, loss = 607.55799374\n",
      "Iteration 2890, loss = 607.17702019\n",
      "Iteration 2891, loss = 606.79698545\n",
      "Iteration 2892, loss = 606.41782837\n",
      "Iteration 2893, loss = 606.03984314\n",
      "Iteration 2894, loss = 605.66287556\n",
      "Iteration 2895, loss = 605.28693607\n",
      "Iteration 2896, loss = 604.91206996\n",
      "Iteration 2897, loss = 604.53852771\n",
      "Iteration 2898, loss = 604.16559028\n",
      "Iteration 2899, loss = 603.79388802\n",
      "Iteration 2900, loss = 603.42954904\n",
      "Iteration 2901, loss = 603.07646457\n",
      "Iteration 2902, loss = 602.72400008\n",
      "Iteration 2903, loss = 602.37227183\n",
      "Iteration 2904, loss = 602.02121943\n",
      "Iteration 2905, loss = 601.67091351\n",
      "Iteration 2906, loss = 601.32156474\n",
      "Iteration 2907, loss = 600.97326014\n",
      "Iteration 2908, loss = 600.62556205\n",
      "Iteration 2909, loss = 600.27892556\n",
      "Iteration 2910, loss = 599.93289626\n",
      "Iteration 2911, loss = 599.58790330\n",
      "Iteration 2912, loss = 599.24392243\n",
      "Iteration 2913, loss = 598.90085299\n",
      "Iteration 2914, loss = 598.55879565\n",
      "Iteration 2915, loss = 598.21768363\n",
      "Iteration 2916, loss = 597.87760795\n",
      "Iteration 2917, loss = 597.53880586\n",
      "Iteration 2918, loss = 597.20111535\n",
      "Iteration 2919, loss = 596.86422618\n",
      "Iteration 2920, loss = 596.52814050\n",
      "Iteration 2921, loss = 596.19274166\n",
      "Iteration 2922, loss = 595.85785128\n",
      "Iteration 2923, loss = 595.52314215\n",
      "Iteration 2924, loss = 595.18818938\n",
      "Iteration 2925, loss = 594.85131846\n",
      "Iteration 2926, loss = 594.51390410\n",
      "Iteration 2927, loss = 594.17694692\n",
      "Iteration 2928, loss = 593.84065144\n",
      "Iteration 2929, loss = 593.50367563\n",
      "Iteration 2930, loss = 593.16722457\n",
      "Iteration 2931, loss = 592.83198997\n",
      "Iteration 2932, loss = 592.49793410\n",
      "Iteration 2933, loss = 592.16281937\n",
      "Iteration 2934, loss = 591.82749737\n",
      "Iteration 2935, loss = 591.49223070\n",
      "Iteration 2936, loss = 591.15716420\n",
      "Iteration 2937, loss = 590.82226416\n",
      "Iteration 2938, loss = 590.48769186\n",
      "Iteration 2939, loss = 590.15372698\n",
      "Iteration 2940, loss = 589.82079759\n",
      "Iteration 2941, loss = 589.48875895\n",
      "Iteration 2942, loss = 589.15764438\n",
      "Iteration 2943, loss = 588.82759697\n",
      "Iteration 2944, loss = 588.49828033\n",
      "Iteration 2945, loss = 588.16987798\n",
      "Iteration 2946, loss = 587.84237529\n",
      "Iteration 2947, loss = 587.51549758\n",
      "Iteration 2948, loss = 587.18932610\n",
      "Iteration 2949, loss = 586.86373315\n",
      "Iteration 2950, loss = 586.53912969\n",
      "Iteration 2951, loss = 586.21550925\n",
      "Iteration 2952, loss = 585.89268574\n",
      "Iteration 2953, loss = 585.57094370\n",
      "Iteration 2954, loss = 585.25011497\n",
      "Iteration 2955, loss = 584.93019939\n",
      "Iteration 2956, loss = 584.61137777\n",
      "Iteration 2957, loss = 584.29320223\n",
      "Iteration 2958, loss = 583.97596200\n",
      "Iteration 2959, loss = 583.65968027\n",
      "Iteration 2960, loss = 583.34417779\n",
      "Iteration 2961, loss = 583.02949757\n",
      "Iteration 2962, loss = 582.71551990\n",
      "Iteration 2963, loss = 582.40259697\n",
      "Iteration 2964, loss = 582.09041653\n",
      "Iteration 2965, loss = 581.77905730\n",
      "Iteration 2966, loss = 581.46852163\n",
      "Iteration 2967, loss = 581.15903966\n",
      "Iteration 2968, loss = 580.85042006\n",
      "Iteration 2969, loss = 580.54254749\n",
      "Iteration 2970, loss = 580.23523120\n",
      "Iteration 2971, loss = 579.92913979\n",
      "Iteration 2972, loss = 579.62369235\n",
      "Iteration 2973, loss = 579.31901573\n",
      "Iteration 2974, loss = 579.01534277\n",
      "Iteration 2975, loss = 578.71239652\n",
      "Iteration 2976, loss = 578.41004912\n",
      "Iteration 2977, loss = 578.10857278\n",
      "Iteration 2978, loss = 577.80782133\n",
      "Iteration 2979, loss = 577.50785545\n",
      "Iteration 2980, loss = 577.20880876\n",
      "Iteration 2981, loss = 576.91076957\n",
      "Iteration 2982, loss = 576.61321416\n",
      "Iteration 2983, loss = 576.31595891\n",
      "Iteration 2984, loss = 576.01666191\n",
      "Iteration 2985, loss = 575.71758430\n",
      "Iteration 2986, loss = 575.41867446\n",
      "Iteration 2987, loss = 575.12026392\n",
      "Iteration 2988, loss = 574.82227418\n",
      "Iteration 2989, loss = 574.52497589\n",
      "Iteration 2990, loss = 574.22786484\n",
      "Iteration 2991, loss = 573.93139058\n",
      "Iteration 2992, loss = 573.63543183\n",
      "Iteration 2993, loss = 573.34007068\n",
      "Iteration 2994, loss = 573.04560153\n",
      "Iteration 2995, loss = 572.75149381\n",
      "Iteration 2996, loss = 572.45795594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2997, loss = 572.16510367\n",
      "Iteration 2998, loss = 571.87303923\n",
      "Iteration 2999, loss = 571.58158455\n",
      "Iteration 3000, loss = 571.29074039\n",
      "Iteration 3001, loss = 571.00065322\n",
      "Iteration 3002, loss = 570.71116307\n",
      "Iteration 3003, loss = 570.42240443\n",
      "Iteration 3004, loss = 570.13388642\n",
      "Iteration 3005, loss = 569.84552632\n",
      "Iteration 3006, loss = 569.55796605\n",
      "Iteration 3007, loss = 569.27095316\n",
      "Iteration 3008, loss = 568.98429864\n",
      "Iteration 3009, loss = 568.69834106\n",
      "Iteration 3010, loss = 568.41284951\n",
      "Iteration 3011, loss = 568.12748838\n",
      "Iteration 3012, loss = 567.84131355\n",
      "Iteration 3013, loss = 567.55551265\n",
      "Iteration 3014, loss = 567.27051721\n",
      "Iteration 3015, loss = 566.98627341\n",
      "Iteration 3016, loss = 566.70262014\n",
      "Iteration 3017, loss = 566.41956636\n",
      "Iteration 3018, loss = 566.13764253\n",
      "Iteration 3019, loss = 565.85677922\n",
      "Iteration 3020, loss = 565.57709035\n",
      "Iteration 3021, loss = 565.29839715\n",
      "Iteration 3022, loss = 565.02061106\n",
      "Iteration 3023, loss = 564.74325399\n",
      "Iteration 3024, loss = 564.46551465\n",
      "Iteration 3025, loss = 564.18665526\n",
      "Iteration 3026, loss = 563.90591598\n",
      "Iteration 3027, loss = 563.62345953\n",
      "Iteration 3028, loss = 563.34113744\n",
      "Iteration 3029, loss = 563.06058832\n",
      "Iteration 3030, loss = 562.78328332\n",
      "Iteration 3031, loss = 562.50880740\n",
      "Iteration 3032, loss = 562.23657710\n",
      "Iteration 3033, loss = 561.96493786\n",
      "Iteration 3034, loss = 561.69266786\n",
      "Iteration 3035, loss = 561.41963290\n",
      "Iteration 3036, loss = 561.14600250\n",
      "Iteration 3037, loss = 560.87310071\n",
      "Iteration 3038, loss = 560.60198352\n",
      "Iteration 3039, loss = 560.33208876\n",
      "Iteration 3040, loss = 560.06347162\n",
      "Iteration 3041, loss = 559.79600734\n",
      "Iteration 3042, loss = 559.52875427\n",
      "Iteration 3043, loss = 559.26131580\n",
      "Iteration 3044, loss = 558.99419027\n",
      "Iteration 3045, loss = 558.72762979\n",
      "Iteration 3046, loss = 558.46187180\n",
      "Iteration 3047, loss = 558.19761201\n",
      "Iteration 3048, loss = 557.93442177\n",
      "Iteration 3049, loss = 557.67202438\n",
      "Iteration 3050, loss = 557.41024941\n",
      "Iteration 3051, loss = 557.14851704\n",
      "Iteration 3052, loss = 556.88750232\n",
      "Iteration 3053, loss = 556.62694540\n",
      "Iteration 3054, loss = 556.36667093\n",
      "Iteration 3055, loss = 556.10740204\n",
      "Iteration 3056, loss = 555.84916428\n",
      "Iteration 3057, loss = 555.59161455\n",
      "Iteration 3058, loss = 555.33516034\n",
      "Iteration 3059, loss = 555.07887943\n",
      "Iteration 3060, loss = 554.82291889\n",
      "Iteration 3061, loss = 554.56802609\n",
      "Iteration 3062, loss = 554.31350279\n",
      "Iteration 3063, loss = 554.05948178\n",
      "Iteration 3064, loss = 553.80640548\n",
      "Iteration 3065, loss = 553.55387927\n",
      "Iteration 3066, loss = 553.30188830\n",
      "Iteration 3067, loss = 553.05056101\n",
      "Iteration 3068, loss = 552.80007945\n",
      "Iteration 3069, loss = 552.55022404\n",
      "Iteration 3070, loss = 552.30089050\n",
      "Iteration 3071, loss = 552.05203328\n",
      "Iteration 3072, loss = 551.80384887\n",
      "Iteration 3073, loss = 551.55634914\n",
      "Iteration 3074, loss = 551.30955860\n",
      "Iteration 3075, loss = 551.06361253\n",
      "Iteration 3076, loss = 550.81788771\n",
      "Iteration 3077, loss = 550.57248540\n",
      "Iteration 3078, loss = 550.32837496\n",
      "Iteration 3079, loss = 550.08439174\n",
      "Iteration 3080, loss = 549.83851562\n",
      "Iteration 3081, loss = 549.59289765\n",
      "Iteration 3082, loss = 549.34766442\n",
      "Iteration 3083, loss = 549.10190544\n",
      "Iteration 3084, loss = 548.85594962\n",
      "Iteration 3085, loss = 548.61025282\n",
      "Iteration 3086, loss = 548.36459121\n",
      "Iteration 3087, loss = 548.11916892\n",
      "Iteration 3088, loss = 547.87436995\n",
      "Iteration 3089, loss = 547.62976630\n",
      "Iteration 3090, loss = 547.38568909\n",
      "Iteration 3091, loss = 547.14184455\n",
      "Iteration 3092, loss = 546.90013539\n",
      "Iteration 3093, loss = 546.66062101\n",
      "Iteration 3094, loss = 546.42162596\n",
      "Iteration 3095, loss = 546.18286056\n",
      "Iteration 3096, loss = 545.94462471\n",
      "Iteration 3097, loss = 545.70694261\n",
      "Iteration 3098, loss = 545.46941037\n",
      "Iteration 3099, loss = 545.23133282\n",
      "Iteration 3100, loss = 544.99260145\n",
      "Iteration 3101, loss = 544.74933092\n",
      "Iteration 3102, loss = 544.50470927\n",
      "Iteration 3103, loss = 544.25987990\n",
      "Iteration 3104, loss = 544.01467962\n",
      "Iteration 3105, loss = 543.76924081\n",
      "Iteration 3106, loss = 543.52369455\n",
      "Iteration 3107, loss = 543.27842580\n",
      "Iteration 3108, loss = 543.03296632\n",
      "Iteration 3109, loss = 542.78747441\n",
      "Iteration 3110, loss = 542.54236661\n",
      "Iteration 3111, loss = 542.29743644\n",
      "Iteration 3112, loss = 542.05277666\n",
      "Iteration 3113, loss = 541.80706005\n",
      "Iteration 3114, loss = 541.56115931\n",
      "Iteration 3115, loss = 541.31518401\n",
      "Iteration 3116, loss = 541.06950141\n",
      "Iteration 3117, loss = 540.82421815\n",
      "Iteration 3118, loss = 540.57918760\n",
      "Iteration 3119, loss = 540.33460518\n",
      "Iteration 3120, loss = 540.09049215\n",
      "Iteration 3121, loss = 539.84654288\n",
      "Iteration 3122, loss = 539.60313608\n",
      "Iteration 3123, loss = 539.36031846\n",
      "Iteration 3124, loss = 539.11787273\n",
      "Iteration 3125, loss = 538.87603218\n",
      "Iteration 3126, loss = 538.63469740\n",
      "Iteration 3127, loss = 538.39379623\n",
      "Iteration 3128, loss = 538.15337596\n",
      "Iteration 3129, loss = 537.91358628\n",
      "Iteration 3130, loss = 537.67424103\n",
      "Iteration 3131, loss = 537.43570707\n",
      "Iteration 3132, loss = 537.19758098\n",
      "Iteration 3133, loss = 536.96036429\n",
      "Iteration 3134, loss = 536.72345179\n",
      "Iteration 3135, loss = 536.48702497\n",
      "Iteration 3136, loss = 536.25133717\n",
      "Iteration 3137, loss = 536.01625831\n",
      "Iteration 3138, loss = 535.78213031\n",
      "Iteration 3139, loss = 535.54825094\n",
      "Iteration 3140, loss = 535.31473119\n",
      "Iteration 3141, loss = 535.08223907\n",
      "Iteration 3142, loss = 534.85035301\n",
      "Iteration 3143, loss = 534.61927060\n",
      "Iteration 3144, loss = 534.38971146\n",
      "Iteration 3145, loss = 534.16000919\n",
      "Iteration 3146, loss = 533.93121778\n",
      "Iteration 3147, loss = 533.70362024\n",
      "Iteration 3148, loss = 533.47611113\n",
      "Iteration 3149, loss = 533.24957682\n",
      "Iteration 3150, loss = 533.02344575\n",
      "Iteration 3151, loss = 532.79768879\n",
      "Iteration 3152, loss = 532.57280158\n",
      "Iteration 3153, loss = 532.34806194\n",
      "Iteration 3154, loss = 532.12396835\n",
      "Iteration 3155, loss = 531.90075947\n",
      "Iteration 3156, loss = 531.67911577\n",
      "Iteration 3157, loss = 531.45882857\n",
      "Iteration 3158, loss = 531.23992963\n",
      "Iteration 3159, loss = 531.02183651\n",
      "Iteration 3160, loss = 530.80433335\n",
      "Iteration 3161, loss = 530.58647866\n",
      "Iteration 3162, loss = 530.36746976\n",
      "Iteration 3163, loss = 530.14681295\n",
      "Iteration 3164, loss = 529.92497274\n",
      "Iteration 3165, loss = 529.70242104\n",
      "Iteration 3166, loss = 529.48271358\n",
      "Iteration 3167, loss = 529.26483332\n",
      "Iteration 3168, loss = 529.04933501\n",
      "Iteration 3169, loss = 528.83528750\n",
      "Iteration 3170, loss = 528.62334123\n",
      "Iteration 3171, loss = 528.41174436\n",
      "Iteration 3172, loss = 528.19914300\n",
      "Iteration 3173, loss = 527.98559277\n",
      "Iteration 3174, loss = 527.77258829\n",
      "Iteration 3175, loss = 527.55952771\n",
      "Iteration 3176, loss = 527.34790435\n",
      "Iteration 3177, loss = 527.13856502\n",
      "Iteration 3178, loss = 526.93037148\n",
      "Iteration 3179, loss = 526.72307769\n",
      "Iteration 3180, loss = 526.51596094\n",
      "Iteration 3181, loss = 526.31002534\n",
      "Iteration 3182, loss = 526.10441525\n",
      "Iteration 3183, loss = 525.89905605\n",
      "Iteration 3184, loss = 525.69280845\n",
      "Iteration 3185, loss = 525.48357919\n",
      "Iteration 3186, loss = 525.27462101\n",
      "Iteration 3187, loss = 525.06776950\n",
      "Iteration 3188, loss = 524.86422676\n",
      "Iteration 3189, loss = 524.66288808\n",
      "Iteration 3190, loss = 524.46127170\n",
      "Iteration 3191, loss = 524.25674578\n",
      "Iteration 3192, loss = 524.05195677\n",
      "Iteration 3193, loss = 523.84941997\n",
      "Iteration 3194, loss = 523.64953887\n",
      "Iteration 3195, loss = 523.45028958\n",
      "Iteration 3196, loss = 523.24989201\n",
      "Iteration 3197, loss = 523.04907546\n",
      "Iteration 3198, loss = 522.84909723\n",
      "Iteration 3199, loss = 522.65083559\n",
      "Iteration 3200, loss = 522.45379363\n",
      "Iteration 3201, loss = 522.25614003\n",
      "Iteration 3202, loss = 522.05819707\n",
      "Iteration 3203, loss = 521.86135846\n",
      "Iteration 3204, loss = 521.66597335\n",
      "Iteration 3205, loss = 521.47116284\n",
      "Iteration 3206, loss = 521.27647219\n",
      "Iteration 3207, loss = 521.08241044\n",
      "Iteration 3208, loss = 520.88823565\n",
      "Iteration 3209, loss = 520.69483542\n",
      "Iteration 3210, loss = 520.50275199\n",
      "Iteration 3211, loss = 520.31042038\n",
      "Iteration 3212, loss = 520.11842630\n",
      "Iteration 3213, loss = 519.92702566\n",
      "Iteration 3214, loss = 519.73640431\n",
      "Iteration 3215, loss = 519.54665683\n",
      "Iteration 3216, loss = 519.35691479\n",
      "Iteration 3217, loss = 519.16776244\n",
      "Iteration 3218, loss = 518.97921870\n",
      "Iteration 3219, loss = 518.79123757\n",
      "Iteration 3220, loss = 518.60349549\n",
      "Iteration 3221, loss = 518.41520783\n",
      "Iteration 3222, loss = 518.22702369\n",
      "Iteration 3223, loss = 518.04002525\n",
      "Iteration 3224, loss = 517.85280469\n",
      "Iteration 3225, loss = 517.66621786\n",
      "Iteration 3226, loss = 517.47998365\n",
      "Iteration 3227, loss = 517.29417132\n",
      "Iteration 3228, loss = 517.10912283\n",
      "Iteration 3229, loss = 516.92399601\n",
      "Iteration 3230, loss = 516.73971578\n",
      "Iteration 3231, loss = 516.55636995\n",
      "Iteration 3232, loss = 516.37282597\n",
      "Iteration 3233, loss = 516.18881797\n",
      "Iteration 3234, loss = 516.00445948\n",
      "Iteration 3235, loss = 515.81962133\n",
      "Iteration 3236, loss = 515.63417272\n",
      "Iteration 3237, loss = 515.44879000\n",
      "Iteration 3238, loss = 515.26403330\n",
      "Iteration 3239, loss = 515.07926880\n",
      "Iteration 3240, loss = 514.89512390\n",
      "Iteration 3241, loss = 514.71103337\n",
      "Iteration 3242, loss = 514.52760039\n",
      "Iteration 3243, loss = 514.34416755\n",
      "Iteration 3244, loss = 514.16117473\n",
      "Iteration 3245, loss = 513.97848898\n",
      "Iteration 3246, loss = 513.79586546\n",
      "Iteration 3247, loss = 513.61473610\n",
      "Iteration 3248, loss = 513.43307525\n",
      "Iteration 3249, loss = 513.25139031\n",
      "Iteration 3250, loss = 513.07140424\n",
      "Iteration 3251, loss = 512.89142432\n",
      "Iteration 3252, loss = 512.71192353\n",
      "Iteration 3253, loss = 512.53256423\n",
      "Iteration 3254, loss = 512.35340258\n",
      "Iteration 3255, loss = 512.17471703\n",
      "Iteration 3256, loss = 511.99655282\n",
      "Iteration 3257, loss = 511.81883741\n",
      "Iteration 3258, loss = 511.64144826\n",
      "Iteration 3259, loss = 511.46503139\n",
      "Iteration 3260, loss = 511.28857498\n",
      "Iteration 3261, loss = 511.11289298\n",
      "Iteration 3262, loss = 510.93753408\n",
      "Iteration 3263, loss = 510.76237853\n",
      "Iteration 3264, loss = 510.58848546\n",
      "Iteration 3265, loss = 510.41430264\n",
      "Iteration 3266, loss = 510.24067401\n",
      "Iteration 3267, loss = 510.06771288\n",
      "Iteration 3268, loss = 509.89529155\n",
      "Iteration 3269, loss = 509.72326912\n",
      "Iteration 3270, loss = 509.55098501\n",
      "Iteration 3271, loss = 509.37777389\n",
      "Iteration 3272, loss = 509.20511672\n",
      "Iteration 3273, loss = 509.03271429\n",
      "Iteration 3274, loss = 508.86032178\n",
      "Iteration 3275, loss = 508.68855995\n",
      "Iteration 3276, loss = 508.51700541\n",
      "Iteration 3277, loss = 508.34565163\n",
      "Iteration 3278, loss = 508.17428531\n",
      "Iteration 3279, loss = 508.00340470\n",
      "Iteration 3280, loss = 507.83277838\n",
      "Iteration 3281, loss = 507.66263731\n",
      "Iteration 3282, loss = 507.49313565\n",
      "Iteration 3283, loss = 507.32375031\n",
      "Iteration 3284, loss = 507.15475239\n",
      "Iteration 3285, loss = 506.98656435\n",
      "Iteration 3286, loss = 506.81826716\n",
      "Iteration 3287, loss = 506.65055209\n",
      "Iteration 3288, loss = 506.48366858\n",
      "Iteration 3289, loss = 506.31725707\n",
      "Iteration 3290, loss = 506.15181944\n",
      "Iteration 3291, loss = 505.98671238\n",
      "Iteration 3292, loss = 505.82192514\n",
      "Iteration 3293, loss = 505.65853104\n",
      "Iteration 3294, loss = 505.49637773\n",
      "Iteration 3295, loss = 505.33468458\n",
      "Iteration 3296, loss = 505.17284699\n",
      "Iteration 3297, loss = 505.01164582\n",
      "Iteration 3298, loss = 504.85132643\n",
      "Iteration 3299, loss = 504.69087225\n",
      "Iteration 3300, loss = 504.53037405\n",
      "Iteration 3301, loss = 504.36906080\n",
      "Iteration 3302, loss = 504.20575746\n",
      "Iteration 3303, loss = 504.04090471\n",
      "Iteration 3304, loss = 503.87460723\n",
      "Iteration 3305, loss = 503.70980833\n",
      "Iteration 3306, loss = 503.54771408\n",
      "Iteration 3307, loss = 503.38804421\n",
      "Iteration 3308, loss = 503.23140210\n",
      "Iteration 3309, loss = 503.07677061\n",
      "Iteration 3310, loss = 502.92111642\n",
      "Iteration 3311, loss = 502.76347429\n",
      "Iteration 3312, loss = 502.60405200\n",
      "Iteration 3313, loss = 502.44464697\n",
      "Iteration 3314, loss = 502.28681669\n",
      "Iteration 3315, loss = 502.13117927\n",
      "Iteration 3316, loss = 501.97743392\n",
      "Iteration 3317, loss = 501.82458067\n",
      "Iteration 3318, loss = 501.67122975\n",
      "Iteration 3319, loss = 501.51721423\n",
      "Iteration 3320, loss = 501.36286126\n",
      "Iteration 3321, loss = 501.20859294\n",
      "Iteration 3322, loss = 501.05563216\n",
      "Iteration 3323, loss = 500.90374187\n",
      "Iteration 3324, loss = 500.75114840\n",
      "Iteration 3325, loss = 500.59915063\n",
      "Iteration 3326, loss = 500.44687382\n",
      "Iteration 3327, loss = 500.29348316\n",
      "Iteration 3328, loss = 500.14060058\n",
      "Iteration 3329, loss = 499.98857186\n",
      "Iteration 3330, loss = 499.83680830\n",
      "Iteration 3331, loss = 499.68563789\n",
      "Iteration 3332, loss = 499.53462452\n",
      "Iteration 3333, loss = 499.38450447\n",
      "Iteration 3334, loss = 499.23471071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3335, loss = 499.08443580\n",
      "Iteration 3336, loss = 498.93447232\n",
      "Iteration 3337, loss = 498.78463319\n",
      "Iteration 3338, loss = 498.63566017\n",
      "Iteration 3339, loss = 498.48724103\n",
      "Iteration 3340, loss = 498.33879880\n",
      "Iteration 3341, loss = 498.19101207\n",
      "Iteration 3342, loss = 498.04386865\n",
      "Iteration 3343, loss = 497.89677006\n",
      "Iteration 3344, loss = 497.74963500\n",
      "Iteration 3345, loss = 497.60315723\n",
      "Iteration 3346, loss = 497.45705350\n",
      "Iteration 3347, loss = 497.31152640\n",
      "Iteration 3348, loss = 497.16591981\n",
      "Iteration 3349, loss = 497.02128073\n",
      "Iteration 3350, loss = 496.87705997\n",
      "Iteration 3351, loss = 496.73282376\n",
      "Iteration 3352, loss = 496.58903468\n",
      "Iteration 3353, loss = 496.44569192\n",
      "Iteration 3354, loss = 496.30249562\n",
      "Iteration 3355, loss = 496.15979866\n",
      "Iteration 3356, loss = 496.01738676\n",
      "Iteration 3357, loss = 495.87566658\n",
      "Iteration 3358, loss = 495.73400087\n",
      "Iteration 3359, loss = 495.59278424\n",
      "Iteration 3360, loss = 495.45187611\n",
      "Iteration 3361, loss = 495.31133229\n",
      "Iteration 3362, loss = 495.17161834\n",
      "Iteration 3363, loss = 495.03240329\n",
      "Iteration 3364, loss = 494.89360695\n",
      "Iteration 3365, loss = 494.75506242\n",
      "Iteration 3366, loss = 494.61525398\n",
      "Iteration 3367, loss = 494.47407251\n",
      "Iteration 3368, loss = 494.33242794\n",
      "Iteration 3369, loss = 494.19036806\n",
      "Iteration 3370, loss = 494.04782921\n",
      "Iteration 3371, loss = 493.90536418\n",
      "Iteration 3372, loss = 493.76420500\n",
      "Iteration 3373, loss = 493.62230195\n",
      "Iteration 3374, loss = 493.48062766\n",
      "Iteration 3375, loss = 493.33870914\n",
      "Iteration 3376, loss = 493.19733351\n",
      "Iteration 3377, loss = 493.05574491\n",
      "Iteration 3378, loss = 492.91415706\n",
      "Iteration 3379, loss = 492.77337870\n",
      "Iteration 3380, loss = 492.63240852\n",
      "Iteration 3381, loss = 492.49162933\n",
      "Iteration 3382, loss = 492.35121615\n",
      "Iteration 3383, loss = 492.21028590\n",
      "Iteration 3384, loss = 492.06993022\n",
      "Iteration 3385, loss = 491.92995439\n",
      "Iteration 3386, loss = 491.79080673\n",
      "Iteration 3387, loss = 491.65137812\n",
      "Iteration 3388, loss = 491.51218615\n",
      "Iteration 3389, loss = 491.37368390\n",
      "Iteration 3390, loss = 491.23503671\n",
      "Iteration 3391, loss = 491.09624352\n",
      "Iteration 3392, loss = 490.95795590\n",
      "Iteration 3393, loss = 490.82054479\n",
      "Iteration 3394, loss = 490.68336548\n",
      "Iteration 3395, loss = 490.54632572\n",
      "Iteration 3396, loss = 490.40943436\n",
      "Iteration 3397, loss = 490.27278180\n",
      "Iteration 3398, loss = 490.13711310\n",
      "Iteration 3399, loss = 490.00186356\n",
      "Iteration 3400, loss = 489.86627142\n",
      "Iteration 3401, loss = 489.73075340\n",
      "Iteration 3402, loss = 489.59555182\n",
      "Iteration 3403, loss = 489.46129414\n",
      "Iteration 3404, loss = 489.32740549\n",
      "Iteration 3405, loss = 489.19281198\n",
      "Iteration 3406, loss = 489.05782333\n",
      "Iteration 3407, loss = 488.92366544\n",
      "Iteration 3408, loss = 488.78978343\n",
      "Iteration 3409, loss = 488.65600898\n",
      "Iteration 3410, loss = 488.52195606\n",
      "Iteration 3411, loss = 488.38852625\n",
      "Iteration 3412, loss = 488.25664273\n",
      "Iteration 3413, loss = 488.12505770\n",
      "Iteration 3414, loss = 487.99335102\n",
      "Iteration 3415, loss = 487.86184157\n",
      "Iteration 3416, loss = 487.73099838\n",
      "Iteration 3417, loss = 487.59977927\n",
      "Iteration 3418, loss = 487.46931378\n",
      "Iteration 3419, loss = 487.33897485\n",
      "Iteration 3420, loss = 487.20836347\n",
      "Iteration 3421, loss = 487.07828002\n",
      "Iteration 3422, loss = 486.94838147\n",
      "Iteration 3423, loss = 486.81820665\n",
      "Iteration 3424, loss = 486.68890070\n",
      "Iteration 3425, loss = 486.56098769\n",
      "Iteration 3426, loss = 486.43240746\n",
      "Iteration 3427, loss = 486.30407454\n",
      "Iteration 3428, loss = 486.17592739\n",
      "Iteration 3429, loss = 486.04801809\n",
      "Iteration 3430, loss = 485.92084739\n",
      "Iteration 3431, loss = 485.79396043\n",
      "Iteration 3432, loss = 485.66698795\n",
      "Iteration 3433, loss = 485.54011045\n",
      "Iteration 3434, loss = 485.41421054\n",
      "Iteration 3435, loss = 485.28843415\n",
      "Iteration 3436, loss = 485.16283958\n",
      "Iteration 3437, loss = 485.03682608\n",
      "Iteration 3438, loss = 484.91212710\n",
      "Iteration 3439, loss = 484.78817701\n",
      "Iteration 3440, loss = 484.66388547\n",
      "Iteration 3441, loss = 484.53951916\n",
      "Iteration 3442, loss = 484.41614214\n",
      "Iteration 3443, loss = 484.29370050\n",
      "Iteration 3444, loss = 484.17098749\n",
      "Iteration 3445, loss = 484.04905121\n",
      "Iteration 3446, loss = 483.92786846\n",
      "Iteration 3447, loss = 483.80731695\n",
      "Iteration 3448, loss = 483.68803407\n",
      "Iteration 3449, loss = 483.57038443\n",
      "Iteration 3450, loss = 483.45376127\n",
      "Iteration 3451, loss = 483.33691323\n",
      "Iteration 3452, loss = 483.21947931\n",
      "Iteration 3453, loss = 483.10056306\n",
      "Iteration 3454, loss = 482.97804589\n",
      "Iteration 3455, loss = 482.85182349\n",
      "Iteration 3456, loss = 482.72472060\n",
      "Iteration 3457, loss = 482.59937761\n",
      "Iteration 3458, loss = 482.47843180\n",
      "Iteration 3459, loss = 482.36150930\n",
      "Iteration 3460, loss = 482.24634421\n",
      "Iteration 3461, loss = 482.13110149\n",
      "Iteration 3462, loss = 482.01313357\n",
      "Iteration 3463, loss = 481.89289300\n",
      "Iteration 3464, loss = 481.77242254\n",
      "Iteration 3465, loss = 481.65373252\n",
      "Iteration 3466, loss = 481.53747784\n",
      "Iteration 3467, loss = 481.42281133\n",
      "Iteration 3468, loss = 481.30905661\n",
      "Iteration 3469, loss = 481.19421465\n",
      "Iteration 3470, loss = 481.07805666\n",
      "Iteration 3471, loss = 480.96108388\n",
      "Iteration 3472, loss = 480.84533965\n",
      "Iteration 3473, loss = 480.73091715\n",
      "Iteration 3474, loss = 480.61758946\n",
      "Iteration 3475, loss = 480.50450947\n",
      "Iteration 3476, loss = 480.39209763\n",
      "Iteration 3477, loss = 480.27918407\n",
      "Iteration 3478, loss = 480.16483773\n",
      "Iteration 3479, loss = 480.04992360\n",
      "Iteration 3480, loss = 479.93580469\n",
      "Iteration 3481, loss = 479.82198179\n",
      "Iteration 3482, loss = 479.70855737\n",
      "Iteration 3483, loss = 479.59537789\n",
      "Iteration 3484, loss = 479.48241874\n",
      "Iteration 3485, loss = 479.36982661\n",
      "Iteration 3486, loss = 479.25753946\n",
      "Iteration 3487, loss = 479.14536305\n",
      "Iteration 3488, loss = 479.03436866\n",
      "Iteration 3489, loss = 478.92285998\n",
      "Iteration 3490, loss = 478.81125439\n",
      "Iteration 3491, loss = 478.70039219\n",
      "Iteration 3492, loss = 478.58932494\n",
      "Iteration 3493, loss = 478.47861285\n",
      "Iteration 3494, loss = 478.36813891\n",
      "Iteration 3495, loss = 478.25788558\n",
      "Iteration 3496, loss = 478.14822766\n",
      "Iteration 3497, loss = 478.03887633\n",
      "Iteration 3498, loss = 477.92944731\n",
      "Iteration 3499, loss = 477.82055261\n",
      "Iteration 3500, loss = 477.71243729\n",
      "Iteration 3501, loss = 477.60395846\n",
      "Iteration 3502, loss = 477.49550813\n",
      "Iteration 3503, loss = 477.38802108\n",
      "Iteration 3504, loss = 477.28058171\n",
      "Iteration 3505, loss = 477.17337124\n",
      "Iteration 3506, loss = 477.06658044\n",
      "Iteration 3507, loss = 476.95965342\n",
      "Iteration 3508, loss = 476.85315609\n",
      "Iteration 3509, loss = 476.74658106\n",
      "Iteration 3510, loss = 476.64043216\n",
      "Iteration 3511, loss = 476.53486343\n",
      "Iteration 3512, loss = 476.42929558\n",
      "Iteration 3513, loss = 476.32374234\n",
      "Iteration 3514, loss = 476.21897289\n",
      "Iteration 3515, loss = 476.11424833\n",
      "Iteration 3516, loss = 476.00968789\n",
      "Iteration 3517, loss = 475.90544972\n",
      "Iteration 3518, loss = 475.80182047\n",
      "Iteration 3519, loss = 475.69804032\n",
      "Iteration 3520, loss = 475.59469688\n",
      "Iteration 3521, loss = 475.49172547\n",
      "Iteration 3522, loss = 475.38860165\n",
      "Iteration 3523, loss = 475.28589517\n",
      "Iteration 3524, loss = 475.18412970\n",
      "Iteration 3525, loss = 475.08227584\n",
      "Iteration 3526, loss = 474.98055856\n",
      "Iteration 3527, loss = 474.87932093\n",
      "Iteration 3528, loss = 474.77843155\n",
      "Iteration 3529, loss = 474.67788010\n",
      "Iteration 3530, loss = 474.57716091\n",
      "Iteration 3531, loss = 474.47696558\n",
      "Iteration 3532, loss = 474.37704937\n",
      "Iteration 3533, loss = 474.27744915\n",
      "Iteration 3534, loss = 474.17785854\n",
      "Iteration 3535, loss = 474.07838221\n",
      "Iteration 3536, loss = 473.97914983\n",
      "Iteration 3537, loss = 473.88052162\n",
      "Iteration 3538, loss = 473.78216899\n",
      "Iteration 3539, loss = 473.68370897\n",
      "Iteration 3540, loss = 473.58566793\n",
      "Iteration 3541, loss = 473.48775131\n",
      "Iteration 3542, loss = 473.39046521\n",
      "Iteration 3543, loss = 473.29322559\n",
      "Iteration 3544, loss = 473.19595112\n",
      "Iteration 3545, loss = 473.09896379\n",
      "Iteration 3546, loss = 473.00244577\n",
      "Iteration 3547, loss = 472.90497413\n",
      "Iteration 3548, loss = 472.80743083\n",
      "Iteration 3549, loss = 472.70993401\n",
      "Iteration 3550, loss = 472.61372867\n",
      "Iteration 3551, loss = 472.51828455\n",
      "Iteration 3552, loss = 472.42238289\n",
      "Iteration 3553, loss = 472.32690560\n",
      "Iteration 3554, loss = 472.23139260\n",
      "Iteration 3555, loss = 472.13599827\n",
      "Iteration 3556, loss = 472.04048958\n",
      "Iteration 3557, loss = 471.94503355\n",
      "Iteration 3558, loss = 471.85000174\n",
      "Iteration 3559, loss = 471.75530261\n",
      "Iteration 3560, loss = 471.65989398\n",
      "Iteration 3561, loss = 471.56504105\n",
      "Iteration 3562, loss = 471.47048142\n",
      "Iteration 3563, loss = 471.37607191\n",
      "Iteration 3564, loss = 471.28161679\n",
      "Iteration 3565, loss = 471.18721831\n",
      "Iteration 3566, loss = 471.09290628\n",
      "Iteration 3567, loss = 470.99884414\n",
      "Iteration 3568, loss = 470.90514331\n",
      "Iteration 3569, loss = 470.81154332\n",
      "Iteration 3570, loss = 470.71812814\n",
      "Iteration 3571, loss = 470.62488516\n",
      "Iteration 3572, loss = 470.53204620\n",
      "Iteration 3573, loss = 470.43944573\n",
      "Iteration 3574, loss = 470.34687004\n",
      "Iteration 3575, loss = 470.25455339\n",
      "Iteration 3576, loss = 470.16269178\n",
      "Iteration 3577, loss = 470.07135129\n",
      "Iteration 3578, loss = 469.98025889\n",
      "Iteration 3579, loss = 469.88939773\n",
      "Iteration 3580, loss = 469.79905769\n",
      "Iteration 3581, loss = 469.70937719\n",
      "Iteration 3582, loss = 469.61924427\n",
      "Iteration 3583, loss = 469.52818034\n",
      "Iteration 3584, loss = 469.43617349\n",
      "Iteration 3585, loss = 469.34297709\n",
      "Iteration 3586, loss = 469.24930779\n",
      "Iteration 3587, loss = 469.15569332\n",
      "Iteration 3588, loss = 469.06323206\n",
      "Iteration 3589, loss = 468.97199341\n",
      "Iteration 3590, loss = 468.88166207\n",
      "Iteration 3591, loss = 468.79138430\n",
      "Iteration 3592, loss = 468.70076042\n",
      "Iteration 3593, loss = 468.60960767\n",
      "Iteration 3594, loss = 468.51848577\n",
      "Iteration 3595, loss = 468.42776631\n",
      "Iteration 3596, loss = 468.33724412\n",
      "Iteration 3597, loss = 468.24647383\n",
      "Iteration 3598, loss = 468.15512314\n",
      "Iteration 3599, loss = 468.06292249\n",
      "Iteration 3600, loss = 467.97004580\n",
      "Iteration 3601, loss = 467.87725629\n",
      "Iteration 3602, loss = 467.78504952\n",
      "Iteration 3603, loss = 467.69387267\n",
      "Iteration 3604, loss = 467.60353814\n",
      "Iteration 3605, loss = 467.51378111\n",
      "Iteration 3606, loss = 467.42439644\n",
      "Iteration 3607, loss = 467.33535015\n",
      "Iteration 3608, loss = 467.24621851\n",
      "Iteration 3609, loss = 467.15706961\n",
      "Iteration 3610, loss = 467.06857804\n",
      "Iteration 3611, loss = 466.97957890\n",
      "Iteration 3612, loss = 466.89036812\n",
      "Iteration 3613, loss = 466.80139553\n",
      "Iteration 3614, loss = 466.71275173\n",
      "Iteration 3615, loss = 466.62409783\n",
      "Iteration 3616, loss = 466.53554604\n",
      "Iteration 3617, loss = 466.44784664\n",
      "Iteration 3618, loss = 466.36038657\n",
      "Iteration 3619, loss = 466.27325200\n",
      "Iteration 3620, loss = 466.18632042\n",
      "Iteration 3621, loss = 466.09907147\n",
      "Iteration 3622, loss = 466.01231823\n",
      "Iteration 3623, loss = 465.92554503\n",
      "Iteration 3624, loss = 465.83916822\n",
      "Iteration 3625, loss = 465.75307395\n",
      "Iteration 3626, loss = 465.66689614\n",
      "Iteration 3627, loss = 465.58084560\n",
      "Iteration 3628, loss = 465.49482212\n",
      "Iteration 3629, loss = 465.40909589\n",
      "Iteration 3630, loss = 465.32382475\n",
      "Iteration 3631, loss = 465.23869755\n",
      "Iteration 3632, loss = 465.15372584\n",
      "Iteration 3633, loss = 465.06865277\n",
      "Iteration 3634, loss = 464.98430492\n",
      "Iteration 3635, loss = 464.90011064\n",
      "Iteration 3636, loss = 464.81613254\n",
      "Iteration 3637, loss = 464.73193987\n",
      "Iteration 3638, loss = 464.64804274\n",
      "Iteration 3639, loss = 464.56434629\n",
      "Iteration 3640, loss = 464.48068814\n",
      "Iteration 3641, loss = 464.39729619\n",
      "Iteration 3642, loss = 464.31436662\n",
      "Iteration 3643, loss = 464.23157674\n",
      "Iteration 3644, loss = 464.14861731\n",
      "Iteration 3645, loss = 464.06609682\n",
      "Iteration 3646, loss = 463.98388300\n",
      "Iteration 3647, loss = 463.90171734\n",
      "Iteration 3648, loss = 463.81981322\n",
      "Iteration 3649, loss = 463.73793988\n",
      "Iteration 3650, loss = 463.65611163\n",
      "Iteration 3651, loss = 463.57483123\n",
      "Iteration 3652, loss = 463.49358599\n",
      "Iteration 3653, loss = 463.41261919\n",
      "Iteration 3654, loss = 463.33170340\n",
      "Iteration 3655, loss = 463.25081386\n",
      "Iteration 3656, loss = 463.17006729\n",
      "Iteration 3657, loss = 463.08995855\n",
      "Iteration 3658, loss = 463.01001975\n",
      "Iteration 3659, loss = 462.92998885\n",
      "Iteration 3660, loss = 462.84975602\n",
      "Iteration 3661, loss = 462.77032761\n",
      "Iteration 3662, loss = 462.69111162\n",
      "Iteration 3663, loss = 462.61194171\n",
      "Iteration 3664, loss = 462.53260936\n",
      "Iteration 3665, loss = 462.45343101\n",
      "Iteration 3666, loss = 462.37439760\n",
      "Iteration 3667, loss = 462.29567497\n",
      "Iteration 3668, loss = 462.21780735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3669, loss = 462.13985550\n",
      "Iteration 3670, loss = 462.06176181\n",
      "Iteration 3671, loss = 461.98353454\n",
      "Iteration 3672, loss = 461.90560877\n",
      "Iteration 3673, loss = 461.82831130\n",
      "Iteration 3674, loss = 461.75113210\n",
      "Iteration 3675, loss = 461.67407315\n",
      "Iteration 3676, loss = 461.59684437\n",
      "Iteration 3677, loss = 461.51930309\n",
      "Iteration 3678, loss = 461.44172631\n",
      "Iteration 3679, loss = 461.36356702\n",
      "Iteration 3680, loss = 461.28462209\n",
      "Iteration 3681, loss = 461.20542705\n",
      "Iteration 3682, loss = 461.12629432\n",
      "Iteration 3683, loss = 461.04786553\n",
      "Iteration 3684, loss = 460.96981566\n",
      "Iteration 3685, loss = 460.89216032\n",
      "Iteration 3686, loss = 460.81579619\n",
      "Iteration 3687, loss = 460.73965423\n",
      "Iteration 3688, loss = 460.66331731\n",
      "Iteration 3689, loss = 460.58702724\n",
      "Iteration 3690, loss = 460.51105862\n",
      "Iteration 3691, loss = 460.43441467\n",
      "Iteration 3692, loss = 460.35799556\n",
      "Iteration 3693, loss = 460.28220514\n",
      "Iteration 3694, loss = 460.20638583\n",
      "Iteration 3695, loss = 460.13061765\n",
      "Iteration 3696, loss = 460.05514277\n",
      "Iteration 3697, loss = 459.98006420\n",
      "Iteration 3698, loss = 459.90510227\n",
      "Iteration 3699, loss = 459.83044117\n",
      "Iteration 3700, loss = 459.75568306\n",
      "Iteration 3701, loss = 459.68101117\n",
      "Iteration 3702, loss = 459.60680366\n",
      "Iteration 3703, loss = 459.53289335\n",
      "Iteration 3704, loss = 459.45888830\n",
      "Iteration 3705, loss = 459.38505126\n",
      "Iteration 3706, loss = 459.31126385\n",
      "Iteration 3707, loss = 459.23746184\n",
      "Iteration 3708, loss = 459.16466639\n",
      "Iteration 3709, loss = 459.09154376\n",
      "Iteration 3710, loss = 459.01820416\n",
      "Iteration 3711, loss = 458.94488889\n",
      "Iteration 3712, loss = 458.87239490\n",
      "Iteration 3713, loss = 458.79991732\n",
      "Iteration 3714, loss = 458.72767297\n",
      "Iteration 3715, loss = 458.65554730\n",
      "Iteration 3716, loss = 458.58341472\n",
      "Iteration 3717, loss = 458.51137752\n",
      "Iteration 3718, loss = 458.43956697\n",
      "Iteration 3719, loss = 458.36814225\n",
      "Iteration 3720, loss = 458.29699675\n",
      "Iteration 3721, loss = 458.22581127\n",
      "Iteration 3722, loss = 458.15441107\n",
      "Iteration 3723, loss = 458.08363894\n",
      "Iteration 3724, loss = 458.01296105\n",
      "Iteration 3725, loss = 457.94226048\n",
      "Iteration 3726, loss = 457.87197024\n",
      "Iteration 3727, loss = 457.80145230\n",
      "Iteration 3728, loss = 457.73097156\n",
      "Iteration 3729, loss = 457.66104779\n",
      "Iteration 3730, loss = 457.59112240\n",
      "Iteration 3731, loss = 457.52153953\n",
      "Iteration 3732, loss = 457.45189126\n",
      "Iteration 3733, loss = 457.38231179\n",
      "Iteration 3734, loss = 457.31297774\n",
      "Iteration 3735, loss = 457.24406635\n",
      "Iteration 3736, loss = 457.17482115\n",
      "Iteration 3737, loss = 457.10563510\n",
      "Iteration 3738, loss = 457.03705880\n",
      "Iteration 3739, loss = 456.96831158\n",
      "Iteration 3740, loss = 456.89976763\n",
      "Iteration 3741, loss = 456.83134513\n",
      "Iteration 3742, loss = 456.76329777\n",
      "Iteration 3743, loss = 456.69514802\n",
      "Iteration 3744, loss = 456.62722007\n",
      "Iteration 3745, loss = 456.55948309\n",
      "Iteration 3746, loss = 456.49187603\n",
      "Iteration 3747, loss = 456.42455087\n",
      "Iteration 3748, loss = 456.35712060\n",
      "Iteration 3749, loss = 456.29008627\n",
      "Iteration 3750, loss = 456.22341951\n",
      "Iteration 3751, loss = 456.15690675\n",
      "Iteration 3752, loss = 456.09047972\n",
      "Iteration 3753, loss = 456.02418163\n",
      "Iteration 3754, loss = 455.95823650\n",
      "Iteration 3755, loss = 455.89265157\n",
      "Iteration 3756, loss = 455.82692809\n",
      "Iteration 3757, loss = 455.76190670\n",
      "Iteration 3758, loss = 455.69713516\n",
      "Iteration 3759, loss = 455.63212900\n",
      "Iteration 3760, loss = 455.56719048\n",
      "Iteration 3761, loss = 455.50140696\n",
      "Iteration 3762, loss = 455.43463557\n",
      "Iteration 3763, loss = 455.36677626\n",
      "Iteration 3764, loss = 455.29810141\n",
      "Iteration 3765, loss = 455.22872490\n",
      "Iteration 3766, loss = 455.15999954\n",
      "Iteration 3767, loss = 455.09203159\n",
      "Iteration 3768, loss = 455.02536898\n",
      "Iteration 3769, loss = 454.96035781\n",
      "Iteration 3770, loss = 454.89599666\n",
      "Iteration 3771, loss = 454.83193938\n",
      "Iteration 3772, loss = 454.76803181\n",
      "Iteration 3773, loss = 454.70404262\n",
      "Iteration 3774, loss = 454.63892408\n",
      "Iteration 3775, loss = 454.57277236\n",
      "Iteration 3776, loss = 454.50678512\n",
      "Iteration 3777, loss = 454.44107990\n",
      "Iteration 3778, loss = 454.37555212\n",
      "Iteration 3779, loss = 454.31027092\n",
      "Iteration 3780, loss = 454.24576012\n",
      "Iteration 3781, loss = 454.18125577\n",
      "Iteration 3782, loss = 454.11687268\n",
      "Iteration 3783, loss = 454.05219779\n",
      "Iteration 3784, loss = 453.98750278\n",
      "Iteration 3785, loss = 453.92249572\n",
      "Iteration 3786, loss = 453.85801332\n",
      "Iteration 3787, loss = 453.79360512\n",
      "Iteration 3788, loss = 453.72901191\n",
      "Iteration 3789, loss = 453.66504466\n",
      "Iteration 3790, loss = 453.60145698\n",
      "Iteration 3791, loss = 453.53760412\n",
      "Iteration 3792, loss = 453.47407684\n",
      "Iteration 3793, loss = 453.41076594\n",
      "Iteration 3794, loss = 453.34748215\n",
      "Iteration 3795, loss = 453.28414919\n",
      "Iteration 3796, loss = 453.22108012\n",
      "Iteration 3797, loss = 453.15775550\n",
      "Iteration 3798, loss = 453.09517422\n",
      "Iteration 3799, loss = 453.03190068\n",
      "Iteration 3800, loss = 452.96937157\n",
      "Iteration 3801, loss = 452.90695420\n",
      "Iteration 3802, loss = 452.84442071\n",
      "Iteration 3803, loss = 452.78187726\n",
      "Iteration 3804, loss = 452.71962096\n",
      "Iteration 3805, loss = 452.65788447\n",
      "Iteration 3806, loss = 452.59577309\n",
      "Iteration 3807, loss = 452.53358351\n",
      "Iteration 3808, loss = 452.47177672\n",
      "Iteration 3809, loss = 452.41061902\n",
      "Iteration 3810, loss = 452.34868435\n",
      "Iteration 3811, loss = 452.28725844\n",
      "Iteration 3812, loss = 452.22595811\n",
      "Iteration 3813, loss = 452.16467231\n",
      "Iteration 3814, loss = 452.10346833\n",
      "Iteration 3815, loss = 452.04266963\n",
      "Iteration 3816, loss = 451.98156532\n",
      "Iteration 3817, loss = 451.92105083\n",
      "Iteration 3818, loss = 451.86027858\n",
      "Iteration 3819, loss = 451.79966188\n",
      "Iteration 3820, loss = 451.73948058\n",
      "Iteration 3821, loss = 451.67947435\n",
      "Iteration 3822, loss = 451.61863188\n",
      "Iteration 3823, loss = 451.55846179\n",
      "Iteration 3824, loss = 451.49852479\n",
      "Iteration 3825, loss = 451.43882231\n",
      "Iteration 3826, loss = 451.37867284\n",
      "Iteration 3827, loss = 451.31905369\n",
      "Iteration 3828, loss = 451.25949815\n",
      "Iteration 3829, loss = 451.19996077\n",
      "Iteration 3830, loss = 451.14050177\n",
      "Iteration 3831, loss = 451.08149951\n",
      "Iteration 3832, loss = 451.02260197\n",
      "Iteration 3833, loss = 450.96327495\n",
      "Iteration 3834, loss = 450.90474185\n",
      "Iteration 3835, loss = 450.84617243\n",
      "Iteration 3836, loss = 450.78767834\n",
      "Iteration 3837, loss = 450.72910788\n",
      "Iteration 3838, loss = 450.67045963\n",
      "Iteration 3839, loss = 450.61206899\n",
      "Iteration 3840, loss = 450.55418283\n",
      "Iteration 3841, loss = 450.49603232\n",
      "Iteration 3842, loss = 450.43789203\n",
      "Iteration 3843, loss = 450.38030383\n",
      "Iteration 3844, loss = 450.32256416\n",
      "Iteration 3845, loss = 450.26484446\n",
      "Iteration 3846, loss = 450.20779154\n",
      "Iteration 3847, loss = 450.14564547\n",
      "Iteration 3848, loss = 450.07058323\n",
      "Iteration 3849, loss = 449.98618573\n",
      "Iteration 3850, loss = 449.89399170\n",
      "Iteration 3851, loss = 449.79558603\n",
      "Iteration 3852, loss = 449.69101194\n",
      "Iteration 3853, loss = 449.58256857\n",
      "Iteration 3854, loss = 449.46970025\n",
      "Iteration 3855, loss = 449.35407897\n",
      "Iteration 3856, loss = 449.23655562\n",
      "Iteration 3857, loss = 449.11742738\n",
      "Iteration 3858, loss = 448.99790632\n",
      "Iteration 3859, loss = 448.87671849\n",
      "Iteration 3860, loss = 448.75457268\n",
      "Iteration 3861, loss = 448.63112556\n",
      "Iteration 3862, loss = 448.50541151\n",
      "Iteration 3863, loss = 448.37681346\n",
      "Iteration 3864, loss = 448.24457263\n",
      "Iteration 3865, loss = 448.10905704\n",
      "Iteration 3866, loss = 447.97181264\n",
      "Iteration 3867, loss = 447.83521289\n",
      "Iteration 3868, loss = 447.70043295\n",
      "Iteration 3869, loss = 447.56791569\n",
      "Iteration 3870, loss = 447.43662911\n",
      "Iteration 3871, loss = 447.30603398\n",
      "Iteration 3872, loss = 447.17474634\n",
      "Iteration 3873, loss = 447.04264941\n",
      "Iteration 3874, loss = 446.91000193\n",
      "Iteration 3875, loss = 446.77759983\n",
      "Iteration 3876, loss = 446.64599324\n",
      "Iteration 3877, loss = 446.51611567\n",
      "Iteration 3878, loss = 446.38656452\n",
      "Iteration 3879, loss = 446.21941766\n",
      "Iteration 3880, loss = 445.99779670\n",
      "Iteration 3881, loss = 445.76185258\n",
      "Iteration 3882, loss = 445.51353776\n",
      "Iteration 3883, loss = 445.25526234\n",
      "Iteration 3884, loss = 444.98902085\n",
      "Iteration 3885, loss = 444.71627976\n",
      "Iteration 3886, loss = 444.43819083\n",
      "Iteration 3887, loss = 444.15554043\n",
      "Iteration 3888, loss = 443.86909358\n",
      "Iteration 3889, loss = 443.57947952\n",
      "Iteration 3890, loss = 443.28701081\n",
      "Iteration 3891, loss = 442.99219357\n",
      "Iteration 3892, loss = 442.69563357\n",
      "Iteration 3893, loss = 442.39837526\n",
      "Iteration 3894, loss = 442.09993020\n",
      "Iteration 3895, loss = 441.80107248\n",
      "Iteration 3896, loss = 441.50282225\n",
      "Iteration 3897, loss = 441.24727858\n",
      "Iteration 3898, loss = 441.02800665\n",
      "Iteration 3899, loss = 440.81871376\n",
      "Iteration 3900, loss = 440.61526935\n",
      "Iteration 3901, loss = 440.41721701\n",
      "Iteration 3902, loss = 440.22421488\n",
      "Iteration 3903, loss = 440.03563323\n",
      "Iteration 3904, loss = 439.85113546\n",
      "Iteration 3905, loss = 439.67048775\n",
      "Iteration 3906, loss = 439.49306535\n",
      "Iteration 3907, loss = 439.31877359\n",
      "Iteration 3908, loss = 439.14787936\n",
      "Iteration 3909, loss = 438.97891786\n",
      "Iteration 3910, loss = 438.81288591\n",
      "Iteration 3911, loss = 438.64940657\n",
      "Iteration 3912, loss = 438.48835145\n",
      "Iteration 3913, loss = 438.32941181\n",
      "Iteration 3914, loss = 438.17273431\n",
      "Iteration 3915, loss = 438.01807991\n",
      "Iteration 3916, loss = 437.86535708\n",
      "Iteration 3917, loss = 437.71458067\n",
      "Iteration 3918, loss = 437.70050520\n",
      "Iteration 3919, loss = 437.68823855\n",
      "Iteration 3920, loss = 437.66391168\n",
      "Iteration 3921, loss = 437.62924486\n",
      "Iteration 3922, loss = 437.58580489\n",
      "Iteration 3923, loss = 437.53520388\n",
      "Iteration 3924, loss = 437.47860388\n",
      "Iteration 3925, loss = 437.41674472\n",
      "Iteration 3926, loss = 437.35025586\n",
      "Iteration 3927, loss = 437.27948620\n",
      "Iteration 3928, loss = 437.20457941\n",
      "Iteration 3929, loss = 437.12586342\n",
      "Iteration 3930, loss = 437.04335787\n",
      "Iteration 3931, loss = 436.95760040\n",
      "Iteration 3932, loss = 436.86881968\n",
      "Iteration 3933, loss = 436.77746599\n",
      "Iteration 3934, loss = 436.68436487\n",
      "Iteration 3935, loss = 436.58977865\n",
      "Iteration 3936, loss = 436.49424750\n",
      "Iteration 3937, loss = 436.39831977\n",
      "Iteration 3938, loss = 436.32389688\n",
      "Iteration 3939, loss = 436.28509524\n",
      "Iteration 3940, loss = 436.23518336\n",
      "Iteration 3941, loss = 436.17574467\n",
      "Iteration 3942, loss = 436.10867849\n",
      "Iteration 3943, loss = 436.03469124\n",
      "Iteration 3944, loss = 435.95462973\n",
      "Iteration 3945, loss = 435.86904416\n",
      "Iteration 3946, loss = 435.82521791\n",
      "Iteration 3947, loss = 435.77750734\n",
      "Iteration 3948, loss = 435.72121164\n",
      "Iteration 3949, loss = 435.65743218\n",
      "Iteration 3950, loss = 435.58747671\n",
      "Iteration 3951, loss = 435.51744999\n",
      "Iteration 3952, loss = 435.44826480\n",
      "Iteration 3953, loss = 435.37818512\n",
      "Iteration 3954, loss = 435.32268253\n",
      "Iteration 3955, loss = 435.28175275\n",
      "Iteration 3956, loss = 435.22935384\n",
      "Iteration 3957, loss = 435.16585211\n",
      "Iteration 3958, loss = 435.09728607\n",
      "Iteration 3959, loss = 435.04944940\n",
      "Iteration 3960, loss = 434.99749294\n",
      "Iteration 3961, loss = 434.94125162\n",
      "Iteration 3962, loss = 434.88233842\n",
      "Iteration 3963, loss = 434.83254519\n",
      "Iteration 3964, loss = 434.78208050\n",
      "Iteration 3965, loss = 434.72348699\n",
      "Iteration 3966, loss = 434.67083960\n",
      "Iteration 3967, loss = 434.61401968\n",
      "Iteration 3968, loss = 434.56987494\n",
      "Iteration 3969, loss = 434.51601089\n",
      "Iteration 3970, loss = 434.46050747\n",
      "Iteration 3971, loss = 434.41131424\n",
      "Iteration 3972, loss = 434.35851204\n",
      "Iteration 3973, loss = 434.30259146\n",
      "Iteration 3974, loss = 434.26212285\n",
      "Iteration 3975, loss = 434.21121909\n",
      "Iteration 3976, loss = 434.15016881\n",
      "Iteration 3977, loss = 434.10574665\n",
      "Iteration 3978, loss = 434.06015277\n",
      "Iteration 3979, loss = 434.01063550\n",
      "Iteration 3980, loss = 433.95835158\n",
      "Iteration 3981, loss = 433.90256370\n",
      "Iteration 3982, loss = 433.84382781\n",
      "Iteration 3983, loss = 433.80494073\n",
      "Iteration 3984, loss = 433.76056739\n",
      "Iteration 3985, loss = 433.70468859\n",
      "Iteration 3986, loss = 433.63984867\n",
      "Iteration 3987, loss = 433.60104987\n",
      "Iteration 3988, loss = 433.56012361\n",
      "Iteration 3989, loss = 433.51612447\n",
      "Iteration 3990, loss = 433.46835689\n",
      "Iteration 3991, loss = 433.41773834\n",
      "Iteration 3992, loss = 433.36432532\n",
      "Iteration 3993, loss = 433.30580247\n",
      "Iteration 3994, loss = 433.24675608\n",
      "Iteration 3995, loss = 433.19720472\n",
      "Iteration 3996, loss = 433.13433934\n",
      "Iteration 3997, loss = 433.07968791\n",
      "Iteration 3998, loss = 433.02927956\n",
      "Iteration 3999, loss = 432.97815420\n",
      "Iteration 4000, loss = 432.92657924\n",
      "Iteration 4001, loss = 432.87421781\n",
      "Iteration 4002, loss = 432.82631504\n",
      "Iteration 4003, loss = 432.77757506\n",
      "Iteration 4004, loss = 432.72185554\n",
      "Iteration 4005, loss = 432.67074302\n",
      "Iteration 4006, loss = 432.61543558\n",
      "Iteration 4007, loss = 432.56190265\n",
      "Iteration 4008, loss = 432.50857954\n",
      "Iteration 4009, loss = 432.45767650\n",
      "Iteration 4010, loss = 432.41256435\n",
      "Iteration 4011, loss = 432.36406387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4012, loss = 432.31296926\n",
      "Iteration 4013, loss = 432.25858030\n",
      "Iteration 4014, loss = 432.21980975\n",
      "Iteration 4015, loss = 432.16905385\n",
      "Iteration 4016, loss = 432.10673506\n",
      "Iteration 4017, loss = 432.06580703\n",
      "Iteration 4018, loss = 432.02248587\n",
      "Iteration 4019, loss = 431.97642808\n",
      "Iteration 4020, loss = 431.92682660\n",
      "Iteration 4021, loss = 431.87471618\n",
      "Iteration 4022, loss = 431.82052486\n",
      "Iteration 4023, loss = 431.76411362\n",
      "Iteration 4024, loss = 431.71907651\n",
      "Iteration 4025, loss = 431.67491997\n",
      "Iteration 4026, loss = 431.61858525\n",
      "Iteration 4027, loss = 431.56653985\n",
      "Iteration 4028, loss = 431.52252557\n",
      "Iteration 4029, loss = 431.47580991\n",
      "Iteration 4030, loss = 431.42637492\n",
      "Iteration 4031, loss = 431.37465565\n",
      "Iteration 4032, loss = 431.32121014\n",
      "Iteration 4033, loss = 431.28018155\n",
      "Iteration 4034, loss = 431.23352908\n",
      "Iteration 4035, loss = 431.17485939\n",
      "Iteration 4036, loss = 431.13275888\n",
      "Iteration 4037, loss = 431.09097386\n",
      "Iteration 4038, loss = 431.04586146\n",
      "Iteration 4039, loss = 430.99846158\n",
      "Iteration 4040, loss = 430.94879517\n",
      "Iteration 4041, loss = 430.89702730\n",
      "Iteration 4042, loss = 430.84337027\n",
      "Iteration 4043, loss = 430.79584987\n",
      "Iteration 4044, loss = 430.75128755\n",
      "Iteration 4045, loss = 430.69575509\n",
      "Iteration 4046, loss = 430.65669078\n",
      "Iteration 4047, loss = 430.61366843\n",
      "Iteration 4048, loss = 430.56910173\n",
      "Iteration 4049, loss = 430.52243495\n",
      "Iteration 4050, loss = 430.47363396\n",
      "Iteration 4051, loss = 430.42266907\n",
      "Iteration 4052, loss = 430.37053086\n",
      "Iteration 4053, loss = 430.32635030\n",
      "Iteration 4054, loss = 430.28340284\n",
      "Iteration 4055, loss = 430.22755588\n",
      "Iteration 4056, loss = 430.19113742\n",
      "Iteration 4057, loss = 430.15069736\n",
      "Iteration 4058, loss = 430.10793169\n",
      "Iteration 4059, loss = 430.06320582\n",
      "Iteration 4060, loss = 430.01674685\n",
      "Iteration 4061, loss = 429.96843835\n",
      "Iteration 4062, loss = 429.91843510\n",
      "Iteration 4063, loss = 429.86673083\n",
      "Iteration 4064, loss = 429.84122292\n",
      "Iteration 4065, loss = 429.80127320\n",
      "Iteration 4066, loss = 429.74943240\n",
      "Iteration 4067, loss = 429.69134162\n",
      "Iteration 4068, loss = 429.65175116\n",
      "Iteration 4069, loss = 429.60936232\n",
      "Iteration 4070, loss = 429.56616358\n",
      "Iteration 4071, loss = 429.52094942\n",
      "Iteration 4072, loss = 429.47406805\n",
      "Iteration 4073, loss = 429.42598947\n",
      "Iteration 4074, loss = 429.39179059\n",
      "Iteration 4075, loss = 429.34828607\n",
      "Iteration 4076, loss = 429.29265075\n",
      "Iteration 4077, loss = 429.25204486\n",
      "Iteration 4078, loss = 429.20883068\n",
      "Iteration 4079, loss = 429.16302581\n",
      "Iteration 4080, loss = 429.12439783\n",
      "Iteration 4081, loss = 429.07676804\n",
      "Iteration 4082, loss = 429.03360294\n",
      "Iteration 4083, loss = 428.99360982\n",
      "Iteration 4084, loss = 428.94856348\n",
      "Iteration 4085, loss = 428.90704466\n",
      "Iteration 4086, loss = 428.86320631\n",
      "Iteration 4087, loss = 428.81808887\n",
      "Iteration 4088, loss = 428.78258805\n",
      "Iteration 4089, loss = 428.73636225\n",
      "Iteration 4090, loss = 428.69448528\n",
      "Iteration 4091, loss = 428.65497609\n",
      "Iteration 4092, loss = 428.61351989\n",
      "Iteration 4093, loss = 428.57129173\n",
      "Iteration 4094, loss = 428.52734412\n",
      "Iteration 4095, loss = 428.48182153\n",
      "Iteration 4096, loss = 428.43519451\n",
      "Iteration 4097, loss = 428.39389102\n",
      "Iteration 4098, loss = 428.35138268\n",
      "Iteration 4099, loss = 428.31161000\n",
      "Iteration 4100, loss = 428.27126079\n",
      "Iteration 4101, loss = 428.23041864\n",
      "Iteration 4102, loss = 428.18816429\n",
      "Iteration 4103, loss = 428.14296355\n",
      "Iteration 4104, loss = 428.10926404\n",
      "Iteration 4105, loss = 428.06531714\n",
      "Iteration 4106, loss = 428.02182287\n",
      "Iteration 4107, loss = 427.98398769\n",
      "Iteration 4108, loss = 427.94477933\n",
      "Iteration 4109, loss = 427.90409526\n",
      "Iteration 4110, loss = 427.86318140\n",
      "Iteration 4111, loss = 427.82121850\n",
      "Iteration 4112, loss = 427.77753428\n",
      "Iteration 4113, loss = 427.75288541\n",
      "Iteration 4114, loss = 427.71409407\n",
      "Iteration 4115, loss = 427.66120962\n",
      "Iteration 4116, loss = 427.62524226\n",
      "Iteration 4117, loss = 427.58527847\n",
      "Iteration 4118, loss = 427.54241095\n",
      "Iteration 4119, loss = 427.49608148\n",
      "Iteration 4120, loss = 427.45427853\n",
      "Iteration 4121, loss = 427.40724172\n",
      "Iteration 4122, loss = 427.36494983\n",
      "Iteration 4123, loss = 427.32368681\n",
      "Iteration 4124, loss = 427.28854035\n",
      "Iteration 4125, loss = 427.25315741\n",
      "Iteration 4126, loss = 427.21403539\n",
      "Iteration 4127, loss = 427.17188874\n",
      "Iteration 4128, loss = 427.12958643\n",
      "Iteration 4129, loss = 427.08549884\n",
      "Iteration 4130, loss = 427.04395120\n",
      "Iteration 4131, loss = 427.00362008\n",
      "Iteration 4132, loss = 426.96280889\n",
      "Iteration 4133, loss = 426.92742974\n",
      "Iteration 4134, loss = 426.88474748\n",
      "Iteration 4135, loss = 426.84656325\n",
      "Iteration 4136, loss = 426.80611828\n",
      "Iteration 4137, loss = 426.76471790\n",
      "Iteration 4138, loss = 426.73212260\n",
      "Iteration 4139, loss = 426.68611076\n",
      "Iteration 4140, loss = 426.64672171\n",
      "Iteration 4141, loss = 426.60682962\n",
      "Iteration 4142, loss = 426.57199564\n",
      "Iteration 4143, loss = 426.52881833\n",
      "Iteration 4144, loss = 426.49115595\n",
      "Iteration 4145, loss = 426.45193487\n",
      "Iteration 4146, loss = 426.41210259\n",
      "Iteration 4147, loss = 426.37125785\n",
      "Iteration 4148, loss = 426.33487691\n",
      "Iteration 4149, loss = 426.29763230\n",
      "Iteration 4150, loss = 426.25850704\n",
      "Iteration 4151, loss = 426.21893637\n",
      "Iteration 4152, loss = 426.18038380\n",
      "Iteration 4153, loss = 426.14137784\n",
      "Iteration 4154, loss = 426.10323195\n",
      "Iteration 4155, loss = 426.06444635\n",
      "Iteration 4156, loss = 426.02535623\n",
      "Iteration 4157, loss = 425.98896489\n",
      "Iteration 4158, loss = 425.94877356\n",
      "Iteration 4159, loss = 425.91179132\n",
      "Iteration 4160, loss = 425.87367070\n",
      "Iteration 4161, loss = 425.83456315\n",
      "Iteration 4162, loss = 425.79977313\n",
      "Iteration 4163, loss = 425.75767987\n",
      "Iteration 4164, loss = 425.72006190\n",
      "Iteration 4165, loss = 425.68321308\n",
      "Iteration 4166, loss = 425.64481480\n",
      "Iteration 4167, loss = 425.60796562\n",
      "Iteration 4168, loss = 425.56876430\n",
      "Iteration 4169, loss = 425.53324172\n",
      "Iteration 4170, loss = 425.49595060\n",
      "Iteration 4171, loss = 425.45755715\n",
      "Iteration 4172, loss = 425.41835282\n",
      "Iteration 4173, loss = 425.38934497\n",
      "Iteration 4174, loss = 425.34373735\n",
      "Iteration 4175, loss = 425.30904493\n",
      "Iteration 4176, loss = 425.27532102\n",
      "Iteration 4177, loss = 425.24132735\n",
      "Iteration 4178, loss = 425.20511006\n",
      "Iteration 4179, loss = 425.16787278\n",
      "Iteration 4180, loss = 425.12973401\n",
      "Iteration 4181, loss = 425.09006215\n",
      "Iteration 4182, loss = 425.04938281\n",
      "Iteration 4183, loss = 425.00859077\n",
      "Iteration 4184, loss = 424.96721535\n",
      "Iteration 4185, loss = 424.92967757\n",
      "Iteration 4186, loss = 424.89027627\n",
      "Iteration 4187, loss = 424.85529666\n",
      "Iteration 4188, loss = 424.81898472\n",
      "Iteration 4189, loss = 424.78357426\n",
      "Iteration 4190, loss = 424.74744982\n",
      "Iteration 4191, loss = 424.70987958\n",
      "Iteration 4192, loss = 424.67100838\n",
      "Iteration 4193, loss = 424.63168775\n",
      "Iteration 4194, loss = 424.59167156\n",
      "Iteration 4195, loss = 424.55112810\n",
      "Iteration 4196, loss = 424.51856143\n",
      "Iteration 4197, loss = 424.47699388\n",
      "Iteration 4198, loss = 424.44139469\n",
      "Iteration 4199, loss = 424.40635411\n",
      "Iteration 4200, loss = 424.37116962\n",
      "Iteration 4201, loss = 424.33544715\n",
      "Iteration 4202, loss = 424.29887780\n",
      "Iteration 4203, loss = 424.26109030\n",
      "Iteration 4204, loss = 424.22194520\n",
      "Iteration 4205, loss = 424.18365650\n",
      "Iteration 4206, loss = 424.14406087\n",
      "Iteration 4207, loss = 424.10521699\n",
      "Iteration 4208, loss = 424.07123055\n",
      "Iteration 4209, loss = 424.03094904\n",
      "Iteration 4210, loss = 423.99525542\n",
      "Iteration 4211, loss = 423.96204052\n",
      "Iteration 4212, loss = 423.92762013\n",
      "Iteration 4213, loss = 423.89197103\n",
      "Iteration 4214, loss = 423.85570686\n",
      "Iteration 4215, loss = 423.81887668\n",
      "Iteration 4216, loss = 423.78116274\n",
      "Iteration 4217, loss = 423.74265600\n",
      "Iteration 4218, loss = 423.70499020\n",
      "Iteration 4219, loss = 423.66651429\n",
      "Iteration 4220, loss = 423.62756668\n",
      "Iteration 4221, loss = 423.60644304\n",
      "Iteration 4222, loss = 423.56725882\n",
      "Iteration 4223, loss = 423.52040864\n",
      "Iteration 4224, loss = 423.48693428\n",
      "Iteration 4225, loss = 423.45332437\n",
      "Iteration 4226, loss = 423.41916602\n",
      "Iteration 4227, loss = 423.38366157\n",
      "Iteration 4228, loss = 423.34880213\n",
      "Iteration 4229, loss = 423.31343756\n",
      "Iteration 4230, loss = 423.27817718\n",
      "Iteration 4231, loss = 423.24237317\n",
      "Iteration 4232, loss = 423.20651042\n",
      "Iteration 4233, loss = 423.17164238\n",
      "Iteration 4234, loss = 423.13659797\n",
      "Iteration 4235, loss = 423.10146703\n",
      "Iteration 4236, loss = 423.06845881\n",
      "Iteration 4237, loss = 423.03516456\n",
      "Iteration 4238, loss = 423.00607827\n",
      "Iteration 4239, loss = 422.97952286\n",
      "Iteration 4240, loss = 422.95637190\n",
      "Iteration 4241, loss = 422.93090940\n",
      "Iteration 4242, loss = 422.89783626\n",
      "Iteration 4243, loss = 422.85238340\n",
      "Iteration 4244, loss = 422.79735398\n",
      "Iteration 4245, loss = 422.74540321\n",
      "Iteration 4246, loss = 422.70374477\n",
      "Iteration 4247, loss = 422.68499415\n",
      "Iteration 4248, loss = 422.65090479\n",
      "Iteration 4249, loss = 422.62273615\n",
      "Iteration 4250, loss = 422.58753286\n",
      "Iteration 4251, loss = 422.54710340\n",
      "Iteration 4252, loss = 422.50875929\n",
      "Iteration 4253, loss = 422.47544654\n",
      "Iteration 4254, loss = 422.44481747\n",
      "Iteration 4255, loss = 422.41285759\n",
      "Iteration 4256, loss = 422.37691337\n",
      "Iteration 4257, loss = 422.33795903\n",
      "Iteration 4258, loss = 422.30007579\n",
      "Iteration 4259, loss = 422.26605535\n",
      "Iteration 4260, loss = 422.23275613\n",
      "Iteration 4261, loss = 422.19753966\n",
      "Iteration 4262, loss = 422.15886444\n",
      "Iteration 4263, loss = 422.12001312\n",
      "Iteration 4264, loss = 422.09014895\n",
      "Iteration 4265, loss = 422.05160243\n",
      "Iteration 4266, loss = 422.02064448\n",
      "Iteration 4267, loss = 421.98811947\n",
      "Iteration 4268, loss = 421.95317617\n",
      "Iteration 4269, loss = 421.91772288\n",
      "Iteration 4270, loss = 421.88296665\n",
      "Iteration 4271, loss = 421.85005801\n",
      "Iteration 4272, loss = 421.81694457\n",
      "Iteration 4273, loss = 421.78221057\n",
      "Iteration 4274, loss = 421.74563812\n",
      "Iteration 4275, loss = 421.70876628\n",
      "Iteration 4276, loss = 421.67252141\n",
      "Iteration 4277, loss = 421.63551986\n",
      "Iteration 4278, loss = 421.60024622\n",
      "Iteration 4279, loss = 421.56485584\n",
      "Iteration 4280, loss = 421.52856030\n",
      "Iteration 4281, loss = 421.49160634\n",
      "Iteration 4282, loss = 421.46736087\n",
      "Iteration 4283, loss = 421.42513380\n",
      "Iteration 4284, loss = 421.38867927\n",
      "Iteration 4285, loss = 421.35644109\n",
      "Iteration 4286, loss = 421.32334475\n",
      "Iteration 4287, loss = 421.29011593\n",
      "Iteration 4288, loss = 421.25610141\n",
      "Iteration 4289, loss = 421.22314490\n",
      "Iteration 4290, loss = 421.18905923\n",
      "Iteration 4291, loss = 421.15459875\n",
      "Iteration 4292, loss = 421.11961610\n",
      "Iteration 4293, loss = 421.08354621\n",
      "Iteration 4294, loss = 421.04962507\n",
      "Iteration 4295, loss = 421.01552670\n",
      "Iteration 4296, loss = 420.98074636\n",
      "Iteration 4297, loss = 420.94450079\n",
      "Iteration 4298, loss = 420.90907945\n",
      "Iteration 4299, loss = 420.87370430\n",
      "Iteration 4300, loss = 420.83895149\n",
      "Iteration 4301, loss = 420.80341646\n",
      "Iteration 4302, loss = 420.77239575\n",
      "Iteration 4303, loss = 420.73463108\n",
      "Iteration 4304, loss = 420.70057962\n",
      "Iteration 4305, loss = 420.66738649\n",
      "Iteration 4306, loss = 420.63380988\n",
      "Iteration 4307, loss = 420.59977726\n",
      "Iteration 4308, loss = 420.56511116\n",
      "Iteration 4309, loss = 420.53140988\n",
      "Iteration 4310, loss = 420.49757294\n",
      "Iteration 4311, loss = 420.46358032\n",
      "Iteration 4312, loss = 420.43571963\n",
      "Iteration 4313, loss = 420.39664541\n",
      "Iteration 4314, loss = 420.36367802\n",
      "Iteration 4315, loss = 420.33156111\n",
      "Iteration 4316, loss = 420.29858032\n",
      "Iteration 4317, loss = 420.26500588\n",
      "Iteration 4318, loss = 420.23137147\n",
      "Iteration 4319, loss = 420.19816274\n",
      "Iteration 4320, loss = 420.16494085\n",
      "Iteration 4321, loss = 420.13139999\n",
      "Iteration 4322, loss = 420.09778225\n",
      "Iteration 4323, loss = 420.06322424\n",
      "Iteration 4324, loss = 420.02978974\n",
      "Iteration 4325, loss = 419.99706351\n",
      "Iteration 4326, loss = 419.96283134\n",
      "Iteration 4327, loss = 419.93688079\n",
      "Iteration 4328, loss = 419.89704304\n",
      "Iteration 4329, loss = 419.86517788\n",
      "Iteration 4330, loss = 419.83250500\n",
      "Iteration 4331, loss = 419.79936177\n",
      "Iteration 4332, loss = 419.76606477\n",
      "Iteration 4333, loss = 419.73292838\n",
      "Iteration 4334, loss = 419.70077569\n",
      "Iteration 4335, loss = 419.66777254\n",
      "Iteration 4336, loss = 419.63496271\n",
      "Iteration 4337, loss = 419.60197277\n",
      "Iteration 4338, loss = 419.56952064\n",
      "Iteration 4339, loss = 419.53634292\n",
      "Iteration 4340, loss = 419.50265631\n",
      "Iteration 4341, loss = 419.47023066\n",
      "Iteration 4342, loss = 419.44026126\n",
      "Iteration 4343, loss = 419.40567331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4344, loss = 419.37109098\n",
      "Iteration 4345, loss = 419.34330337\n",
      "Iteration 4346, loss = 419.30720318\n",
      "Iteration 4347, loss = 419.27745950\n",
      "Iteration 4348, loss = 419.24485139\n",
      "Iteration 4349, loss = 419.21329123\n",
      "Iteration 4350, loss = 419.18151354\n",
      "Iteration 4351, loss = 419.14899075\n",
      "Iteration 4352, loss = 419.11627108\n",
      "Iteration 4353, loss = 419.08432511\n",
      "Iteration 4354, loss = 419.05159204\n",
      "Iteration 4355, loss = 419.01900756\n",
      "Iteration 4356, loss = 418.98618410\n",
      "Iteration 4357, loss = 418.95367505\n",
      "Iteration 4358, loss = 418.92104927\n",
      "Iteration 4359, loss = 418.88851745\n",
      "Iteration 4360, loss = 418.85610076\n",
      "Iteration 4361, loss = 418.82375240\n",
      "Iteration 4362, loss = 418.79207161\n",
      "Iteration 4363, loss = 418.76629531\n",
      "Iteration 4364, loss = 418.72808469\n",
      "Iteration 4365, loss = 418.69695333\n",
      "Iteration 4366, loss = 418.66527805\n",
      "Iteration 4367, loss = 418.63385304\n",
      "Iteration 4368, loss = 418.60224635\n",
      "Iteration 4369, loss = 418.57113347\n",
      "Iteration 4370, loss = 418.53923525\n",
      "Iteration 4371, loss = 418.50715714\n",
      "Iteration 4372, loss = 418.47511594\n",
      "Iteration 4373, loss = 418.44364011\n",
      "Iteration 4374, loss = 418.41225283\n",
      "Iteration 4375, loss = 418.38081559\n",
      "Iteration 4376, loss = 418.34961444\n",
      "Iteration 4377, loss = 418.31786839\n",
      "Iteration 4378, loss = 418.28595671\n",
      "Iteration 4379, loss = 418.25333073\n",
      "Iteration 4380, loss = 418.22229717\n",
      "Iteration 4381, loss = 418.19081385\n",
      "Iteration 4382, loss = 418.15897848\n",
      "Iteration 4383, loss = 418.12762564\n",
      "Iteration 4384, loss = 418.09654241\n",
      "Iteration 4385, loss = 418.06534085\n",
      "Iteration 4386, loss = 418.03475506\n",
      "Iteration 4387, loss = 418.00341391\n",
      "Iteration 4388, loss = 417.97238866\n",
      "Iteration 4389, loss = 417.94180182\n",
      "Iteration 4390, loss = 417.91509985\n",
      "Iteration 4391, loss = 417.88043648\n",
      "Iteration 4392, loss = 417.85040492\n",
      "Iteration 4393, loss = 417.82004499\n",
      "Iteration 4394, loss = 417.78915707\n",
      "Iteration 4395, loss = 417.75814120\n",
      "Iteration 4396, loss = 417.72769612\n",
      "Iteration 4397, loss = 417.69639095\n",
      "Iteration 4398, loss = 417.66565470\n",
      "Iteration 4399, loss = 417.63317695\n",
      "Iteration 4400, loss = 417.60152390\n",
      "Iteration 4401, loss = 417.57006638\n",
      "Iteration 4402, loss = 417.53847327\n",
      "Iteration 4403, loss = 417.50726577\n",
      "Iteration 4404, loss = 417.47566348\n",
      "Iteration 4405, loss = 417.44610753\n",
      "Iteration 4406, loss = 417.41600537\n",
      "Iteration 4407, loss = 417.38425599\n",
      "Iteration 4408, loss = 417.35362489\n",
      "Iteration 4409, loss = 417.32282689\n",
      "Iteration 4410, loss = 417.29188330\n",
      "Iteration 4411, loss = 417.26064955\n",
      "Iteration 4412, loss = 417.23062547\n",
      "Iteration 4413, loss = 417.19955889\n",
      "Iteration 4414, loss = 417.16777581\n",
      "Iteration 4415, loss = 417.13686084\n",
      "Iteration 4416, loss = 417.10831026\n",
      "Iteration 4417, loss = 417.07803384\n",
      "Iteration 4418, loss = 417.04703709\n",
      "Iteration 4419, loss = 417.01651512\n",
      "Iteration 4420, loss = 416.98638490\n",
      "Iteration 4421, loss = 416.95594338\n",
      "Iteration 4422, loss = 416.92511293\n",
      "Iteration 4423, loss = 416.89355891\n",
      "Iteration 4424, loss = 416.86374757\n",
      "Iteration 4425, loss = 416.83277248\n",
      "Iteration 4426, loss = 416.80182357\n",
      "Iteration 4427, loss = 416.77087412\n",
      "Iteration 4428, loss = 416.73988889\n",
      "Iteration 4429, loss = 416.70961831\n",
      "Iteration 4430, loss = 416.67898496\n",
      "Iteration 4431, loss = 416.64881567\n",
      "Iteration 4432, loss = 416.61996140\n",
      "Iteration 4433, loss = 416.58909791\n",
      "Iteration 4434, loss = 416.55922717\n",
      "Iteration 4435, loss = 416.53016628\n",
      "Iteration 4436, loss = 416.50091701\n",
      "Iteration 4437, loss = 416.47060667\n",
      "Iteration 4438, loss = 416.44171208\n",
      "Iteration 4439, loss = 416.41265515\n",
      "Iteration 4440, loss = 416.38475075\n",
      "Iteration 4441, loss = 416.35601898\n",
      "Iteration 4442, loss = 416.32684593\n",
      "Iteration 4443, loss = 416.29863070\n",
      "Iteration 4444, loss = 416.27045628\n",
      "Iteration 4445, loss = 416.24276584\n",
      "Iteration 4446, loss = 416.21611698\n",
      "Iteration 4447, loss = 416.19035313\n",
      "Iteration 4448, loss = 416.16343666\n",
      "Iteration 4449, loss = 416.13541500\n",
      "Iteration 4450, loss = 416.10582367\n",
      "Iteration 4451, loss = 416.07534413\n",
      "Iteration 4452, loss = 416.04260088\n",
      "Iteration 4453, loss = 416.00816585\n",
      "Iteration 4454, loss = 415.97445268\n",
      "Iteration 4455, loss = 415.94196841\n",
      "Iteration 4456, loss = 415.91204488\n",
      "Iteration 4457, loss = 415.88315042\n",
      "Iteration 4458, loss = 415.85596549\n",
      "Iteration 4459, loss = 415.82882273\n",
      "Iteration 4460, loss = 415.79955755\n",
      "Iteration 4461, loss = 415.77108497\n",
      "Iteration 4462, loss = 415.74156326\n",
      "Iteration 4463, loss = 415.71143949\n",
      "Iteration 4464, loss = 415.68150278\n",
      "Iteration 4465, loss = 415.65202417\n",
      "Iteration 4466, loss = 415.62205909\n",
      "Iteration 4467, loss = 415.59278142\n",
      "Iteration 4468, loss = 415.56410775\n",
      "Iteration 4469, loss = 415.53473991\n",
      "Iteration 4470, loss = 415.50582275\n",
      "Iteration 4471, loss = 415.47694054\n",
      "Iteration 4472, loss = 415.44754416\n",
      "Iteration 4473, loss = 415.41791718\n",
      "Iteration 4474, loss = 415.38886106\n",
      "Iteration 4475, loss = 415.36022740\n",
      "Iteration 4476, loss = 415.33129588\n",
      "Iteration 4477, loss = 415.30235305\n",
      "Iteration 4478, loss = 415.27304126\n",
      "Iteration 4479, loss = 415.24402712\n",
      "Iteration 4480, loss = 415.21436815\n",
      "Iteration 4481, loss = 415.18580141\n",
      "Iteration 4482, loss = 415.15846902\n",
      "Iteration 4483, loss = 415.12797358\n",
      "Iteration 4484, loss = 415.09939181\n",
      "Iteration 4485, loss = 415.07136856\n",
      "Iteration 4486, loss = 415.04327616\n",
      "Iteration 4487, loss = 415.01498695\n",
      "Iteration 4488, loss = 414.98592630\n",
      "Iteration 4489, loss = 414.95632320\n",
      "Iteration 4490, loss = 414.92868371\n",
      "Iteration 4491, loss = 414.89969700\n",
      "Iteration 4492, loss = 414.86985864\n",
      "Iteration 4493, loss = 414.84271493\n",
      "Iteration 4494, loss = 414.81482887\n",
      "Iteration 4495, loss = 414.78551484\n",
      "Iteration 4496, loss = 414.75580607\n",
      "Iteration 4497, loss = 414.72752935\n",
      "Iteration 4498, loss = 414.69930802\n",
      "Iteration 4499, loss = 414.67108667\n",
      "Iteration 4500, loss = 414.64369073\n",
      "Iteration 4501, loss = 414.61594643\n",
      "Iteration 4502, loss = 414.58770083\n",
      "Iteration 4503, loss = 414.55998888\n",
      "Iteration 4504, loss = 414.53360861\n",
      "Iteration 4505, loss = 414.50707438\n",
      "Iteration 4506, loss = 414.48057759\n",
      "Iteration 4507, loss = 414.45402222\n",
      "Iteration 4508, loss = 414.42707270\n",
      "Iteration 4509, loss = 414.39965898\n",
      "Iteration 4510, loss = 414.37211770\n",
      "Iteration 4511, loss = 414.34301621\n",
      "Iteration 4512, loss = 414.31374388\n",
      "Iteration 4513, loss = 414.28480413\n",
      "Iteration 4514, loss = 414.25738799\n",
      "Iteration 4515, loss = 414.23041584\n",
      "Iteration 4516, loss = 414.20232082\n",
      "Iteration 4517, loss = 414.17760093\n",
      "Iteration 4518, loss = 414.15102573\n",
      "Iteration 4519, loss = 414.12396343\n",
      "Iteration 4520, loss = 414.09728830\n",
      "Iteration 4521, loss = 414.06980308\n",
      "Iteration 4522, loss = 414.04193055\n",
      "Iteration 4523, loss = 414.01378198\n",
      "Iteration 4524, loss = 413.98702277\n",
      "Iteration 4525, loss = 413.95992912\n",
      "Iteration 4526, loss = 413.93248813\n",
      "Iteration 4527, loss = 413.90630425\n",
      "Iteration 4528, loss = 413.87930248\n",
      "Iteration 4529, loss = 413.85229421\n",
      "Iteration 4530, loss = 413.82497174\n",
      "Iteration 4531, loss = 413.79901416\n",
      "Iteration 4532, loss = 413.77127290\n",
      "Iteration 4533, loss = 413.74417930\n",
      "Iteration 4534, loss = 413.71784802\n",
      "Iteration 4535, loss = 413.69133204\n",
      "Iteration 4536, loss = 413.66401434\n",
      "Iteration 4537, loss = 413.63722883\n",
      "Iteration 4538, loss = 413.61140751\n",
      "Iteration 4539, loss = 413.58447730\n",
      "Iteration 4540, loss = 413.55739072\n",
      "Iteration 4541, loss = 413.53085182\n",
      "Iteration 4542, loss = 413.50453198\n",
      "Iteration 4543, loss = 413.47717541\n",
      "Iteration 4544, loss = 413.45095399\n",
      "Iteration 4545, loss = 413.42444402\n",
      "Iteration 4546, loss = 413.39731130\n",
      "Iteration 4547, loss = 413.37038986\n",
      "Iteration 4548, loss = 413.34322974\n",
      "Iteration 4549, loss = 413.31527315\n",
      "Iteration 4550, loss = 413.28772824\n",
      "Iteration 4551, loss = 413.26124704\n",
      "Iteration 4552, loss = 413.23345204\n",
      "Iteration 4553, loss = 413.20617931\n",
      "Iteration 4554, loss = 413.17925061\n",
      "Iteration 4555, loss = 413.15214651\n",
      "Iteration 4556, loss = 413.12477621\n",
      "Iteration 4557, loss = 413.09795219\n",
      "Iteration 4558, loss = 413.07170881\n",
      "Iteration 4559, loss = 413.04468811\n",
      "Iteration 4560, loss = 413.01770761\n",
      "Iteration 4561, loss = 412.99160762\n",
      "Iteration 4562, loss = 412.96476214\n",
      "Iteration 4563, loss = 412.93842820\n",
      "Iteration 4564, loss = 412.91149766\n",
      "Iteration 4565, loss = 412.88554031\n",
      "Iteration 4566, loss = 412.85894157\n",
      "Iteration 4567, loss = 412.83232291\n",
      "Iteration 4568, loss = 412.80590125\n",
      "Iteration 4569, loss = 412.77956902\n",
      "Iteration 4570, loss = 412.75318142\n",
      "Iteration 4571, loss = 412.72672806\n",
      "Iteration 4572, loss = 412.70017732\n",
      "Iteration 4573, loss = 412.67382368\n",
      "Iteration 4574, loss = 412.64730196\n",
      "Iteration 4575, loss = 412.62160309\n",
      "Iteration 4576, loss = 412.59540162\n",
      "Iteration 4577, loss = 412.56744414\n",
      "Iteration 4578, loss = 412.54098833\n",
      "Iteration 4579, loss = 412.51577783\n",
      "Iteration 4580, loss = 412.48928231\n",
      "Iteration 4581, loss = 412.46296556\n",
      "Iteration 4582, loss = 412.43602910\n",
      "Iteration 4583, loss = 412.40923634\n",
      "Iteration 4584, loss = 412.38194020\n",
      "Iteration 4585, loss = 412.35560521\n",
      "Iteration 4586, loss = 412.32969511\n",
      "Iteration 4587, loss = 412.30195989\n",
      "Iteration 4588, loss = 412.27511505\n",
      "Iteration 4589, loss = 412.24940380\n",
      "Iteration 4590, loss = 412.22349785\n",
      "Iteration 4591, loss = 412.19725137\n",
      "Iteration 4592, loss = 412.17047835\n",
      "Iteration 4593, loss = 412.14325353\n",
      "Iteration 4594, loss = 412.11574224\n",
      "Iteration 4595, loss = 412.08765133\n",
      "Iteration 4596, loss = 412.06253744\n",
      "Iteration 4597, loss = 412.03651249\n",
      "Iteration 4598, loss = 412.00877680\n",
      "Iteration 4599, loss = 411.98135039\n",
      "Iteration 4600, loss = 411.95475700\n",
      "Iteration 4601, loss = 411.92835695\n",
      "Iteration 4602, loss = 411.90234572\n",
      "Iteration 4603, loss = 411.87651556\n",
      "Iteration 4604, loss = 411.84932531\n",
      "Iteration 4605, loss = 411.82269792\n",
      "Iteration 4606, loss = 411.79649633\n",
      "Iteration 4607, loss = 411.76962810\n",
      "Iteration 4608, loss = 411.74338100\n",
      "Iteration 4609, loss = 411.71704606\n",
      "Iteration 4610, loss = 411.69029483\n",
      "Iteration 4611, loss = 411.66459457\n",
      "Iteration 4612, loss = 411.63801678\n",
      "Iteration 4613, loss = 411.61132763\n",
      "Iteration 4614, loss = 411.58577548\n",
      "Iteration 4615, loss = 411.55860671\n",
      "Iteration 4616, loss = 411.53276807\n",
      "Iteration 4617, loss = 411.50653621\n",
      "Iteration 4618, loss = 411.48050500\n",
      "Iteration 4619, loss = 411.45416703\n",
      "Iteration 4620, loss = 411.42756782\n",
      "Iteration 4621, loss = 411.40145498\n",
      "Iteration 4622, loss = 411.37548343\n",
      "Iteration 4623, loss = 411.34871591\n",
      "Iteration 4624, loss = 411.32173425\n",
      "Iteration 4625, loss = 411.29616849\n",
      "Iteration 4626, loss = 411.27013261\n",
      "Iteration 4627, loss = 411.24193178\n",
      "Iteration 4628, loss = 411.21625015\n",
      "Iteration 4629, loss = 411.19092519\n",
      "Iteration 4630, loss = 411.16449552\n",
      "Iteration 4631, loss = 411.13706395\n",
      "Iteration 4632, loss = 411.11022504\n",
      "Iteration 4633, loss = 411.08313328\n",
      "Iteration 4634, loss = 411.05738621\n",
      "Iteration 4635, loss = 411.03046140\n",
      "Iteration 4636, loss = 411.00352085\n",
      "Iteration 4637, loss = 410.97856309\n",
      "Iteration 4638, loss = 410.95401063\n",
      "Iteration 4639, loss = 410.93026577\n",
      "Iteration 4640, loss = 410.90669866\n",
      "Iteration 4641, loss = 410.88485180\n",
      "Iteration 4642, loss = 410.86274440\n",
      "Iteration 4643, loss = 410.84054490\n",
      "Iteration 4644, loss = 410.81731274\n",
      "Iteration 4645, loss = 410.79147438\n",
      "Iteration 4646, loss = 410.76259336\n",
      "Iteration 4647, loss = 410.72887766\n",
      "Iteration 4648, loss = 410.69273488\n",
      "Iteration 4649, loss = 410.65809130\n",
      "Iteration 4650, loss = 410.62640329\n",
      "Iteration 4651, loss = 410.60024836\n",
      "Iteration 4652, loss = 410.57792341\n",
      "Iteration 4653, loss = 410.55520646\n",
      "Iteration 4654, loss = 410.52887047\n",
      "Iteration 4655, loss = 410.49918100\n",
      "Iteration 4656, loss = 410.46709294\n",
      "Iteration 4657, loss = 410.43653206\n",
      "Iteration 4658, loss = 410.40982638\n",
      "Iteration 4659, loss = 410.38652186\n",
      "Iteration 4660, loss = 410.36225013\n",
      "Iteration 4661, loss = 410.33575612\n",
      "Iteration 4662, loss = 410.30732384\n",
      "Iteration 4663, loss = 410.27848782\n",
      "Iteration 4664, loss = 410.25011819\n",
      "Iteration 4665, loss = 410.22366438\n",
      "Iteration 4666, loss = 410.19780843\n",
      "Iteration 4667, loss = 410.16937489\n",
      "Iteration 4668, loss = 410.14140283\n",
      "Iteration 4669, loss = 410.11509663\n",
      "Iteration 4670, loss = 410.08961351\n",
      "Iteration 4671, loss = 410.06218550\n",
      "Iteration 4672, loss = 410.03475637\n",
      "Iteration 4673, loss = 410.00769377\n",
      "Iteration 4674, loss = 409.98133822\n",
      "Iteration 4675, loss = 409.95506091\n",
      "Iteration 4676, loss = 409.92798103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4677, loss = 409.90106937\n",
      "Iteration 4678, loss = 409.87393732\n",
      "Iteration 4679, loss = 409.84721590\n",
      "Iteration 4680, loss = 409.81992106\n",
      "Iteration 4681, loss = 409.79283264\n",
      "Iteration 4682, loss = 409.76693235\n",
      "Iteration 4683, loss = 409.74057537\n",
      "Iteration 4684, loss = 409.71426700\n",
      "Iteration 4685, loss = 409.68766591\n",
      "Iteration 4686, loss = 409.66076383\n",
      "Iteration 4687, loss = 409.63381891\n",
      "Iteration 4688, loss = 409.60733097\n",
      "Iteration 4689, loss = 409.57982408\n",
      "Iteration 4690, loss = 409.55337945\n",
      "Iteration 4691, loss = 409.52835174\n",
      "Iteration 4692, loss = 409.50169405\n",
      "Iteration 4693, loss = 409.47418420\n",
      "Iteration 4694, loss = 409.44777495\n",
      "Iteration 4695, loss = 409.42194119\n",
      "Iteration 4696, loss = 409.39501907\n",
      "Iteration 4697, loss = 409.36968727\n",
      "Iteration 4698, loss = 409.34283356\n",
      "Iteration 4699, loss = 409.31623960\n",
      "Iteration 4700, loss = 409.28926107\n",
      "Iteration 4701, loss = 409.26177208\n",
      "Iteration 4702, loss = 409.23590600\n",
      "Iteration 4703, loss = 409.20951647\n",
      "Iteration 4704, loss = 409.18283420\n",
      "Iteration 4705, loss = 409.15645654\n",
      "Iteration 4706, loss = 409.12961779\n",
      "Iteration 4707, loss = 409.10347949\n",
      "Iteration 4708, loss = 409.07800592\n",
      "Iteration 4709, loss = 409.05095764\n",
      "Iteration 4710, loss = 409.02556703\n",
      "Iteration 4711, loss = 408.99923835\n",
      "Iteration 4712, loss = 408.97243167\n",
      "Iteration 4713, loss = 408.94558763\n",
      "Iteration 4714, loss = 408.91910791\n",
      "Iteration 4715, loss = 408.89357737\n",
      "Iteration 4716, loss = 408.86762724\n",
      "Iteration 4717, loss = 408.84007280\n",
      "Iteration 4718, loss = 408.81352164\n",
      "Iteration 4719, loss = 408.78837570\n",
      "Iteration 4720, loss = 408.76262956\n",
      "Iteration 4721, loss = 408.73492523\n",
      "Iteration 4722, loss = 408.70873806\n",
      "Iteration 4723, loss = 408.68144689\n",
      "Iteration 4724, loss = 408.65620061\n",
      "Iteration 4725, loss = 408.63037291\n",
      "Iteration 4726, loss = 408.60417118\n",
      "Iteration 4727, loss = 408.57611985\n",
      "Iteration 4728, loss = 408.55015463\n",
      "Iteration 4729, loss = 408.52506658\n",
      "Iteration 4730, loss = 408.49948409\n",
      "Iteration 4731, loss = 408.47367654\n",
      "Iteration 4732, loss = 408.44655999\n",
      "Iteration 4733, loss = 408.41985270\n",
      "Iteration 4734, loss = 408.39289982\n",
      "Iteration 4735, loss = 408.36586060\n",
      "Iteration 4736, loss = 408.34153662\n",
      "Iteration 4737, loss = 408.31632348\n",
      "Iteration 4738, loss = 408.28978525\n",
      "Iteration 4739, loss = 408.26265039\n",
      "Iteration 4740, loss = 408.23626986\n",
      "Iteration 4741, loss = 408.21149195\n",
      "Iteration 4742, loss = 408.18594992\n",
      "Iteration 4743, loss = 408.16053192\n",
      "Iteration 4744, loss = 408.13397313\n",
      "Iteration 4745, loss = 408.10695409\n",
      "Iteration 4746, loss = 408.07997709\n",
      "Iteration 4747, loss = 408.05345168\n",
      "Iteration 4748, loss = 408.02570964\n",
      "Iteration 4749, loss = 407.99956436\n",
      "Iteration 4750, loss = 407.97411796\n",
      "Iteration 4751, loss = 407.94724495\n",
      "Iteration 4752, loss = 407.92109734\n",
      "Iteration 4753, loss = 407.89495880\n",
      "Iteration 4754, loss = 407.86984293\n",
      "Iteration 4755, loss = 407.84405443\n",
      "Iteration 4756, loss = 407.81732416\n",
      "Iteration 4757, loss = 407.79087425\n",
      "Iteration 4758, loss = 407.76517757\n",
      "Iteration 4759, loss = 407.73854188\n",
      "Iteration 4760, loss = 407.71137830\n",
      "Iteration 4761, loss = 407.68545669\n",
      "Iteration 4762, loss = 407.65902403\n",
      "Iteration 4763, loss = 407.63238254\n",
      "Iteration 4764, loss = 407.60604795\n",
      "Iteration 4765, loss = 407.58200505\n",
      "Iteration 4766, loss = 407.55582263\n",
      "Iteration 4767, loss = 407.52940454\n",
      "Iteration 4768, loss = 407.50358827\n",
      "Iteration 4769, loss = 407.47764958\n",
      "Iteration 4770, loss = 407.45085981\n",
      "Iteration 4771, loss = 407.42499570\n",
      "Iteration 4772, loss = 407.39936023\n",
      "Iteration 4773, loss = 407.37255112\n",
      "Iteration 4774, loss = 407.34531689\n",
      "Iteration 4775, loss = 407.31978319\n",
      "Iteration 4776, loss = 407.29375311\n",
      "Iteration 4777, loss = 407.26741362\n",
      "Iteration 4778, loss = 407.24187835\n",
      "Iteration 4779, loss = 407.21598313\n",
      "Iteration 4780, loss = 407.18973636\n",
      "Iteration 4781, loss = 407.16423940\n",
      "Iteration 4782, loss = 407.13851650\n",
      "Iteration 4783, loss = 407.11204995\n",
      "Iteration 4784, loss = 407.08476281\n",
      "Iteration 4785, loss = 407.05822976\n",
      "Iteration 4786, loss = 407.03219325\n",
      "Iteration 4787, loss = 407.00495102\n",
      "Iteration 4788, loss = 406.97791294\n",
      "Iteration 4789, loss = 406.95321090\n",
      "Iteration 4790, loss = 406.92745791\n",
      "Iteration 4791, loss = 406.90086969\n",
      "Iteration 4792, loss = 406.87605968\n",
      "Iteration 4793, loss = 406.85232156\n",
      "Iteration 4794, loss = 406.82933893\n",
      "Iteration 4795, loss = 406.80721606\n",
      "Iteration 4796, loss = 406.78654501\n",
      "Iteration 4797, loss = 406.76374008\n",
      "Iteration 4798, loss = 406.73984375\n",
      "Iteration 4799, loss = 406.71292702\n",
      "Iteration 4800, loss = 406.67934739\n",
      "Iteration 4801, loss = 406.64278892\n",
      "Iteration 4802, loss = 406.60914563\n",
      "Iteration 4803, loss = 406.57774864\n",
      "Iteration 4804, loss = 406.54990905\n",
      "Iteration 4805, loss = 406.52668873\n",
      "Iteration 4806, loss = 406.50199542\n",
      "Iteration 4807, loss = 406.47428233\n",
      "Iteration 4808, loss = 406.44407206\n",
      "Iteration 4809, loss = 406.41598341\n",
      "Iteration 4810, loss = 406.38851614\n",
      "Iteration 4811, loss = 406.36123688\n",
      "Iteration 4812, loss = 406.33349841\n",
      "Iteration 4813, loss = 406.30488493\n",
      "Iteration 4814, loss = 406.27769096\n",
      "Iteration 4815, loss = 406.25023871\n",
      "Iteration 4816, loss = 406.22317453\n",
      "Iteration 4817, loss = 406.19655334\n",
      "Iteration 4818, loss = 406.16890932\n",
      "Iteration 4819, loss = 406.14226054\n",
      "Iteration 4820, loss = 406.11555475\n",
      "Iteration 4821, loss = 406.08658623\n",
      "Iteration 4822, loss = 406.05781578\n",
      "Iteration 4823, loss = 406.03157406\n",
      "Iteration 4824, loss = 406.00628303\n",
      "Iteration 4825, loss = 405.97987573\n",
      "Iteration 4826, loss = 405.95176204\n",
      "Iteration 4827, loss = 405.92400668\n",
      "Iteration 4828, loss = 405.89684315\n",
      "Iteration 4829, loss = 405.86957648\n",
      "Iteration 4830, loss = 405.84179346\n",
      "Iteration 4831, loss = 405.81735960\n",
      "Iteration 4832, loss = 405.79015539\n",
      "Iteration 4833, loss = 405.76230850\n",
      "Iteration 4834, loss = 405.73549815\n",
      "Iteration 4835, loss = 405.70928669\n",
      "Iteration 4836, loss = 405.68136251\n",
      "Iteration 4837, loss = 405.65549019\n",
      "Iteration 4838, loss = 405.62840317\n",
      "Iteration 4839, loss = 405.60191058\n",
      "Iteration 4840, loss = 405.57525516\n",
      "Iteration 4841, loss = 405.54806916\n",
      "Iteration 4842, loss = 405.52144746\n",
      "Iteration 4843, loss = 405.49395179\n",
      "Iteration 4844, loss = 405.46624777\n",
      "Iteration 4845, loss = 405.44045355\n",
      "Iteration 4846, loss = 405.41412590\n",
      "Iteration 4847, loss = 405.38693467\n",
      "Iteration 4848, loss = 405.35883056\n",
      "Iteration 4849, loss = 405.33456247\n",
      "Iteration 4850, loss = 405.30802394\n",
      "Iteration 4851, loss = 405.28295709\n",
      "Iteration 4852, loss = 405.25733925\n",
      "Iteration 4853, loss = 405.23329556\n",
      "Iteration 4854, loss = 405.20865248\n",
      "Iteration 4855, loss = 405.18138082\n",
      "Iteration 4856, loss = 405.15472768\n",
      "Iteration 4857, loss = 405.13201269\n",
      "Iteration 4858, loss = 405.10899118\n",
      "Iteration 4859, loss = 405.08487324\n",
      "Iteration 4860, loss = 405.06053296\n",
      "Iteration 4861, loss = 405.03414211\n",
      "Iteration 4862, loss = 405.00545960\n",
      "Iteration 4863, loss = 404.97672698\n",
      "Iteration 4864, loss = 404.94914744\n",
      "Iteration 4865, loss = 404.92138723\n",
      "Iteration 4866, loss = 404.89666827\n",
      "Iteration 4867, loss = 404.87089959\n",
      "Iteration 4868, loss = 404.84420853\n",
      "Iteration 4869, loss = 404.81905183\n",
      "Iteration 4870, loss = 404.79413754\n",
      "Iteration 4871, loss = 404.76996393\n",
      "Iteration 4872, loss = 404.74192965\n",
      "Iteration 4873, loss = 404.71652633\n",
      "Iteration 4874, loss = 404.68995501\n",
      "Iteration 4875, loss = 404.66561298\n",
      "Iteration 4876, loss = 404.64035623\n",
      "Iteration 4877, loss = 404.61398868\n",
      "Iteration 4878, loss = 404.58772370\n",
      "Iteration 4879, loss = 404.56542771\n",
      "Iteration 4880, loss = 404.53743553\n",
      "Iteration 4881, loss = 404.51109325\n",
      "Iteration 4882, loss = 404.48507250\n",
      "Iteration 4883, loss = 404.46050547\n",
      "Iteration 4884, loss = 404.43477223\n",
      "Iteration 4885, loss = 404.41012093\n",
      "Iteration 4886, loss = 404.38569195\n",
      "Iteration 4887, loss = 404.36058202\n",
      "Iteration 4888, loss = 404.33437359\n",
      "Iteration 4889, loss = 404.30822864\n",
      "Iteration 4890, loss = 404.28225567\n",
      "Iteration 4891, loss = 404.25630612\n",
      "Iteration 4892, loss = 404.23226126\n",
      "Iteration 4893, loss = 404.20660423\n",
      "Iteration 4894, loss = 404.18161998\n",
      "Iteration 4895, loss = 404.15515215\n",
      "Iteration 4896, loss = 404.13004389\n",
      "Iteration 4897, loss = 404.10442213\n",
      "Iteration 4898, loss = 404.07791932\n",
      "Iteration 4899, loss = 404.05566096\n",
      "Iteration 4900, loss = 404.02916471\n",
      "Iteration 4901, loss = 404.00488319\n",
      "Iteration 4902, loss = 403.97909717\n",
      "Iteration 4903, loss = 403.95273532\n",
      "Iteration 4904, loss = 403.92847126\n",
      "Iteration 4905, loss = 403.90635222\n",
      "Iteration 4906, loss = 403.87929226\n",
      "Iteration 4907, loss = 403.85405340\n",
      "Iteration 4908, loss = 403.82884408\n",
      "Iteration 4909, loss = 403.80446062\n",
      "Iteration 4910, loss = 403.77972835\n",
      "Iteration 4911, loss = 403.75474900\n",
      "Iteration 4912, loss = 403.72990806\n",
      "Iteration 4913, loss = 403.70480535\n",
      "Iteration 4914, loss = 403.68005773\n",
      "Iteration 4915, loss = 403.65550328\n",
      "Iteration 4916, loss = 403.63032415\n",
      "Iteration 4917, loss = 403.60516612\n",
      "Iteration 4918, loss = 403.58076030\n",
      "Iteration 4919, loss = 403.55543912\n",
      "Iteration 4920, loss = 403.53002038\n",
      "Iteration 4921, loss = 403.50590767\n",
      "Iteration 4922, loss = 403.48284460\n",
      "Iteration 4923, loss = 403.45816603\n",
      "Iteration 4924, loss = 403.43488942\n",
      "Iteration 4925, loss = 403.40724190\n",
      "Iteration 4926, loss = 403.38276765\n",
      "Iteration 4927, loss = 403.35989699\n",
      "Iteration 4928, loss = 403.33570265\n",
      "Iteration 4929, loss = 403.30983503\n",
      "Iteration 4930, loss = 403.28723938\n",
      "Iteration 4931, loss = 403.26183727\n",
      "Iteration 4932, loss = 403.23952773\n",
      "Iteration 4933, loss = 403.21765300\n",
      "Iteration 4934, loss = 403.19545575\n",
      "Iteration 4935, loss = 403.17180024\n",
      "Iteration 4936, loss = 403.15258251\n",
      "Iteration 4937, loss = 403.13116432\n",
      "Iteration 4938, loss = 403.10833357\n",
      "Iteration 4939, loss = 403.08378555\n",
      "Iteration 4940, loss = 403.05897098\n",
      "Iteration 4941, loss = 403.03260636\n",
      "Iteration 4942, loss = 403.00415324\n",
      "Iteration 4943, loss = 402.97504702\n",
      "Iteration 4944, loss = 402.94436422\n",
      "Iteration 4945, loss = 402.91629864\n",
      "Iteration 4946, loss = 402.89023740\n",
      "Iteration 4947, loss = 402.86770796\n",
      "Iteration 4948, loss = 402.84648331\n",
      "Iteration 4949, loss = 402.82426303\n",
      "Iteration 4950, loss = 402.80016152\n",
      "Iteration 4951, loss = 402.77566165\n",
      "Iteration 4952, loss = 402.75093811\n",
      "Iteration 4953, loss = 402.72315576\n",
      "Iteration 4954, loss = 402.69715320\n",
      "Iteration 4955, loss = 402.67422622\n",
      "Iteration 4956, loss = 402.65090986\n",
      "Iteration 4957, loss = 402.62778096\n",
      "Iteration 4958, loss = 402.60339181\n",
      "Iteration 4959, loss = 402.57749362\n",
      "Iteration 4960, loss = 402.55386640\n",
      "Iteration 4961, loss = 402.53091533\n",
      "Iteration 4962, loss = 402.50668842\n",
      "Iteration 4963, loss = 402.48042641\n",
      "Iteration 4964, loss = 402.45381536\n",
      "Iteration 4965, loss = 402.43146406\n",
      "Iteration 4966, loss = 402.40735237\n",
      "Iteration 4967, loss = 402.38378495\n",
      "Iteration 4968, loss = 402.35919540\n",
      "Iteration 4969, loss = 402.33465092\n",
      "Iteration 4970, loss = 402.30958020\n",
      "Iteration 4971, loss = 402.28814804\n",
      "Iteration 4972, loss = 402.26252375\n",
      "Iteration 4973, loss = 402.23753092\n",
      "Iteration 4974, loss = 402.21136238\n",
      "Iteration 4975, loss = 402.18773867\n",
      "Iteration 4976, loss = 402.16356881\n",
      "Iteration 4977, loss = 402.13870175\n",
      "Iteration 4978, loss = 402.11541557\n",
      "Iteration 4979, loss = 402.09162015\n",
      "Iteration 4980, loss = 402.06653683\n",
      "Iteration 4981, loss = 402.04182125\n",
      "Iteration 4982, loss = 402.01876911\n",
      "Iteration 4983, loss = 401.99348519\n",
      "Iteration 4984, loss = 401.96980491\n",
      "Iteration 4985, loss = 401.94570857\n",
      "Iteration 4986, loss = 401.92036604\n",
      "Iteration 4987, loss = 401.89672934\n",
      "Iteration 4988, loss = 401.87431376\n",
      "Iteration 4989, loss = 401.84648932\n",
      "Iteration 4990, loss = 401.82251931\n",
      "Iteration 4991, loss = 401.79995144\n",
      "Iteration 4992, loss = 401.77687905\n",
      "Iteration 4993, loss = 401.75141207\n",
      "Iteration 4994, loss = 401.72679236\n",
      "Iteration 4995, loss = 401.70535493\n",
      "Iteration 4996, loss = 401.68240392\n",
      "Iteration 4997, loss = 401.65862650\n",
      "Iteration 4998, loss = 401.63397372\n",
      "Iteration 4999, loss = 401.60950887\n",
      "Iteration 5000, loss = 401.58638972\n",
      "Iteration 5001, loss = 401.56474660\n",
      "Iteration 5002, loss = 401.53898338\n",
      "Iteration 5003, loss = 401.51383447\n",
      "Iteration 5004, loss = 401.48809109\n",
      "Iteration 5005, loss = 401.46258423\n",
      "Iteration 5006, loss = 401.43870107\n",
      "Iteration 5007, loss = 401.41427120\n",
      "Iteration 5008, loss = 401.38973556\n",
      "Iteration 5009, loss = 401.36358551\n",
      "Iteration 5010, loss = 401.34129805\n",
      "Iteration 5011, loss = 401.31970776\n",
      "Iteration 5012, loss = 401.29622608\n",
      "Iteration 5013, loss = 401.26907798\n",
      "Iteration 5014, loss = 401.24428800\n",
      "Iteration 5015, loss = 401.22152678\n",
      "Iteration 5016, loss = 401.19943652\n",
      "Iteration 5017, loss = 401.17415476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5018, loss = 401.14759383\n",
      "Iteration 5019, loss = 401.12362557\n",
      "Iteration 5020, loss = 401.10104205\n",
      "Iteration 5021, loss = 401.07863169\n",
      "Iteration 5022, loss = 401.05439080\n",
      "Iteration 5023, loss = 401.02845402\n",
      "Iteration 5024, loss = 401.00334816\n",
      "Iteration 5025, loss = 400.98048453\n",
      "Iteration 5026, loss = 400.95601843\n",
      "Iteration 5027, loss = 400.93200314\n",
      "Iteration 5028, loss = 400.90710619\n",
      "Iteration 5029, loss = 400.88376551\n",
      "Iteration 5030, loss = 400.86141462\n",
      "Iteration 5031, loss = 400.83856850\n",
      "Iteration 5032, loss = 400.81255786\n",
      "Iteration 5033, loss = 400.79024123\n",
      "Iteration 5034, loss = 400.76759660\n",
      "Iteration 5035, loss = 400.74361280\n",
      "Iteration 5036, loss = 400.71930857\n",
      "Iteration 5037, loss = 400.69448311\n",
      "Iteration 5038, loss = 400.67056130\n",
      "Iteration 5039, loss = 400.64850892\n",
      "Iteration 5040, loss = 400.62677515\n",
      "Iteration 5041, loss = 400.60237048\n",
      "Iteration 5042, loss = 400.57862598\n",
      "Iteration 5043, loss = 400.55535987\n",
      "Iteration 5044, loss = 400.53201291\n",
      "Iteration 5045, loss = 400.51055404\n",
      "Iteration 5046, loss = 400.49035989\n",
      "Iteration 5047, loss = 400.46888099\n",
      "Iteration 5048, loss = 400.44628330\n",
      "Iteration 5049, loss = 400.42594820\n",
      "Iteration 5050, loss = 400.40431317\n",
      "Iteration 5051, loss = 400.38142395\n",
      "Iteration 5052, loss = 400.35611642\n",
      "Iteration 5053, loss = 400.32968419\n",
      "Iteration 5054, loss = 400.30338089\n",
      "Iteration 5055, loss = 400.27849583\n",
      "Iteration 5056, loss = 400.24937064\n",
      "Iteration 5057, loss = 400.22491814\n",
      "Iteration 5058, loss = 400.20042761\n",
      "Iteration 5059, loss = 400.17704715\n",
      "Iteration 5060, loss = 400.15320475\n",
      "Iteration 5061, loss = 400.13050505\n",
      "Iteration 5062, loss = 400.10801776\n",
      "Iteration 5063, loss = 400.08629112\n",
      "Iteration 5064, loss = 400.06278741\n",
      "Iteration 5065, loss = 400.04060579\n",
      "Iteration 5066, loss = 400.01347850\n",
      "Iteration 5067, loss = 399.98754150\n",
      "Iteration 5068, loss = 399.96236260\n",
      "Iteration 5069, loss = 399.94293445\n",
      "Iteration 5070, loss = 399.91855240\n",
      "Iteration 5071, loss = 399.89731976\n",
      "Iteration 5072, loss = 399.87396785\n",
      "Iteration 5073, loss = 399.85235375\n",
      "Iteration 5074, loss = 399.82907274\n",
      "Iteration 5075, loss = 399.80474693\n",
      "Iteration 5076, loss = 399.77974273\n",
      "Iteration 5077, loss = 399.75755893\n",
      "Iteration 5078, loss = 399.73340558\n",
      "Iteration 5079, loss = 399.71129496\n",
      "Iteration 5080, loss = 399.68613327\n",
      "Iteration 5081, loss = 399.66414470\n",
      "Iteration 5082, loss = 399.64189571\n",
      "Iteration 5083, loss = 399.62006057\n",
      "Iteration 5084, loss = 399.59541507\n",
      "Iteration 5085, loss = 399.57341754\n",
      "Iteration 5086, loss = 399.54949514\n",
      "Iteration 5087, loss = 399.52648164\n",
      "Iteration 5088, loss = 399.50302818\n",
      "Iteration 5089, loss = 399.47980951\n",
      "Iteration 5090, loss = 399.45585257\n",
      "Iteration 5091, loss = 399.43261262\n",
      "Iteration 5092, loss = 399.40899272\n",
      "Iteration 5093, loss = 399.38570822\n",
      "Iteration 5094, loss = 399.36374364\n",
      "Iteration 5095, loss = 399.34121520\n",
      "Iteration 5096, loss = 399.31658565\n",
      "Iteration 5097, loss = 399.29254757\n",
      "Iteration 5098, loss = 399.27073103\n",
      "Iteration 5099, loss = 399.24838616\n",
      "Iteration 5100, loss = 399.22639873\n",
      "Iteration 5101, loss = 399.20222646\n",
      "Iteration 5102, loss = 399.17881649\n",
      "Iteration 5103, loss = 399.15638295\n",
      "Iteration 5104, loss = 399.13491552\n",
      "Iteration 5105, loss = 399.11150506\n",
      "Iteration 5106, loss = 399.08615093\n",
      "Iteration 5107, loss = 399.06580963\n",
      "Iteration 5108, loss = 399.04283667\n",
      "Iteration 5109, loss = 399.02012384\n",
      "Iteration 5110, loss = 398.99744390\n",
      "Iteration 5111, loss = 398.97268112\n",
      "Iteration 5112, loss = 398.95069951\n",
      "Iteration 5113, loss = 398.93074756\n",
      "Iteration 5114, loss = 398.90804931\n",
      "Iteration 5115, loss = 398.88308090\n",
      "Iteration 5116, loss = 398.86191313\n",
      "Iteration 5117, loss = 398.83512910\n",
      "Iteration 5118, loss = 398.81483029\n",
      "Iteration 5119, loss = 398.79135535\n",
      "Iteration 5120, loss = 398.76627165\n",
      "Iteration 5121, loss = 398.74403674\n",
      "Iteration 5122, loss = 398.72258763\n",
      "Iteration 5123, loss = 398.69924367\n",
      "Iteration 5124, loss = 398.67619501\n",
      "Iteration 5125, loss = 398.65400509\n",
      "Iteration 5126, loss = 398.63111129\n",
      "Iteration 5127, loss = 398.60892375\n",
      "Iteration 5128, loss = 398.58565504\n",
      "Iteration 5129, loss = 398.56330465\n",
      "Iteration 5130, loss = 398.53996971\n",
      "Iteration 5131, loss = 398.51730210\n",
      "Iteration 5132, loss = 398.49447334\n",
      "Iteration 5133, loss = 398.47292599\n",
      "Iteration 5134, loss = 398.45129005\n",
      "Iteration 5135, loss = 398.42967888\n",
      "Iteration 5136, loss = 398.40409558\n",
      "Iteration 5137, loss = 398.38177767\n",
      "Iteration 5138, loss = 398.35947544\n",
      "Iteration 5139, loss = 398.34071327\n",
      "Iteration 5140, loss = 398.31586534\n",
      "Iteration 5141, loss = 398.29325663\n",
      "Iteration 5142, loss = 398.27262536\n",
      "Iteration 5143, loss = 398.25036627\n",
      "Iteration 5144, loss = 398.22700068\n",
      "Iteration 5145, loss = 398.20401126\n",
      "Iteration 5146, loss = 398.18127596\n",
      "Iteration 5147, loss = 398.15811294\n",
      "Iteration 5148, loss = 398.13548548\n",
      "Iteration 5149, loss = 398.11128716\n",
      "Iteration 5150, loss = 398.09235190\n",
      "Iteration 5151, loss = 398.07112494\n",
      "Iteration 5152, loss = 398.04933797\n",
      "Iteration 5153, loss = 398.02744162\n",
      "Iteration 5154, loss = 398.00827273\n",
      "Iteration 5155, loss = 397.98599851\n",
      "Iteration 5156, loss = 397.96420841\n",
      "Iteration 5157, loss = 397.95148269\n",
      "Iteration 5158, loss = 397.93400362\n",
      "Iteration 5159, loss = 397.91509104\n",
      "Iteration 5160, loss = 397.89812294\n",
      "Iteration 5161, loss = 397.88239203\n",
      "Iteration 5162, loss = 397.86370134\n",
      "Iteration 5163, loss = 397.83879225\n",
      "Iteration 5164, loss = 397.80966602\n",
      "Iteration 5165, loss = 397.78104164\n",
      "Iteration 5166, loss = 397.74742463\n",
      "Iteration 5167, loss = 397.72428752\n",
      "Iteration 5168, loss = 397.69991677\n",
      "Iteration 5169, loss = 397.67844006\n",
      "Iteration 5170, loss = 397.65900619\n",
      "Iteration 5171, loss = 397.63859108\n",
      "Iteration 5172, loss = 397.61568179\n",
      "Iteration 5173, loss = 397.58970292\n",
      "Iteration 5174, loss = 397.56667700\n",
      "Iteration 5175, loss = 397.54230984\n",
      "Iteration 5176, loss = 397.51931741\n",
      "Iteration 5177, loss = 397.49771261\n",
      "Iteration 5178, loss = 397.47756518\n",
      "Iteration 5179, loss = 397.45662884\n",
      "Iteration 5180, loss = 397.43344675\n",
      "Iteration 5181, loss = 397.41080465\n",
      "Iteration 5182, loss = 397.38583118\n",
      "Iteration 5183, loss = 397.36376524\n",
      "Iteration 5184, loss = 397.34250883\n",
      "Iteration 5185, loss = 397.32075313\n",
      "Iteration 5186, loss = 397.29783293\n",
      "Iteration 5187, loss = 397.27651257\n",
      "Iteration 5188, loss = 397.25398980\n",
      "Iteration 5189, loss = 397.23384817\n",
      "Iteration 5190, loss = 397.21205696\n",
      "Iteration 5191, loss = 397.19012663\n",
      "Iteration 5192, loss = 397.16421104\n",
      "Iteration 5193, loss = 397.14321097\n",
      "Iteration 5194, loss = 397.12568648\n",
      "Iteration 5195, loss = 397.10278753\n",
      "Iteration 5196, loss = 397.07964570\n",
      "Iteration 5197, loss = 397.05871714\n",
      "Iteration 5198, loss = 397.03499851\n",
      "Iteration 5199, loss = 397.01574751\n",
      "Iteration 5200, loss = 396.99470963\n",
      "Iteration 5201, loss = 396.97008093\n",
      "Iteration 5202, loss = 396.94665923\n",
      "Iteration 5203, loss = 396.92677797\n",
      "Iteration 5204, loss = 396.90664601\n",
      "Iteration 5205, loss = 396.88417573\n",
      "Iteration 5206, loss = 396.86159935\n",
      "Iteration 5207, loss = 396.84003452\n",
      "Iteration 5208, loss = 396.82042993\n",
      "Iteration 5209, loss = 396.80049838\n",
      "Iteration 5210, loss = 396.77832631\n",
      "Iteration 5211, loss = 396.75369202\n",
      "Iteration 5212, loss = 396.73549338\n",
      "Iteration 5213, loss = 396.71330292\n",
      "Iteration 5214, loss = 396.69380868\n",
      "Iteration 5215, loss = 396.67257672\n",
      "Iteration 5216, loss = 396.65021692\n",
      "Iteration 5217, loss = 396.62875313\n",
      "Iteration 5218, loss = 396.60859542\n",
      "Iteration 5219, loss = 396.58681065\n",
      "Iteration 5220, loss = 396.56374991\n",
      "Iteration 5221, loss = 396.54354592\n",
      "Iteration 5222, loss = 396.52429162\n",
      "Iteration 5223, loss = 396.50152908\n",
      "Iteration 5224, loss = 396.48049277\n",
      "Iteration 5225, loss = 396.46023127\n",
      "Iteration 5226, loss = 396.44091530\n",
      "Iteration 5227, loss = 396.41954747\n",
      "Iteration 5228, loss = 396.39576366\n",
      "Iteration 5229, loss = 396.37486457\n",
      "Iteration 5230, loss = 396.35732181\n",
      "Iteration 5231, loss = 396.33677889\n",
      "Iteration 5232, loss = 396.31580776\n",
      "Iteration 5233, loss = 396.29093033\n",
      "Iteration 5234, loss = 396.27172064\n",
      "Iteration 5235, loss = 396.25309617\n",
      "Iteration 5236, loss = 396.23565181\n",
      "Iteration 5237, loss = 396.21531391\n",
      "Iteration 5238, loss = 396.19231224\n",
      "Iteration 5239, loss = 396.16821972\n",
      "Iteration 5240, loss = 396.14774253\n",
      "Iteration 5241, loss = 396.12639075\n",
      "Iteration 5242, loss = 396.10528392\n",
      "Iteration 5243, loss = 396.08730364\n",
      "Iteration 5244, loss = 396.06475414\n",
      "Iteration 5245, loss = 396.04064769\n",
      "Iteration 5246, loss = 396.02308121\n",
      "Iteration 5247, loss = 396.00174191\n",
      "Iteration 5248, loss = 395.97894679\n",
      "Iteration 5249, loss = 395.95705939\n",
      "Iteration 5250, loss = 395.93337999\n",
      "Iteration 5251, loss = 395.91398113\n",
      "Iteration 5252, loss = 395.89220978\n",
      "Iteration 5253, loss = 395.87072610\n",
      "Iteration 5254, loss = 395.85051538\n",
      "Iteration 5255, loss = 395.82666401\n",
      "Iteration 5256, loss = 395.80712339\n",
      "Iteration 5257, loss = 395.78751535\n",
      "Iteration 5258, loss = 395.76574755\n",
      "Iteration 5259, loss = 395.74239773\n",
      "Iteration 5260, loss = 395.71730624\n",
      "Iteration 5261, loss = 395.70047593\n",
      "Iteration 5262, loss = 395.68083871\n",
      "Iteration 5263, loss = 395.65919925\n",
      "Iteration 5264, loss = 395.63726719\n",
      "Iteration 5265, loss = 395.61850211\n",
      "Iteration 5266, loss = 395.59271778\n",
      "Iteration 5267, loss = 395.57014849\n",
      "Iteration 5268, loss = 395.55289680\n",
      "Iteration 5269, loss = 395.53353620\n",
      "Iteration 5270, loss = 395.51235912\n",
      "Iteration 5271, loss = 395.48888704\n",
      "Iteration 5272, loss = 395.46580230\n",
      "Iteration 5273, loss = 395.44565954\n",
      "Iteration 5274, loss = 395.42255541\n",
      "Iteration 5275, loss = 395.40422586\n",
      "Iteration 5276, loss = 395.38572208\n",
      "Iteration 5277, loss = 395.36418490\n",
      "Iteration 5278, loss = 395.34030896\n",
      "Iteration 5279, loss = 395.31891990\n",
      "Iteration 5280, loss = 395.29857708\n",
      "Iteration 5281, loss = 395.28137657\n",
      "Iteration 5282, loss = 395.25726387\n",
      "Iteration 5283, loss = 395.23588930\n",
      "Iteration 5284, loss = 395.21756676\n",
      "Iteration 5285, loss = 395.19473709\n",
      "Iteration 5286, loss = 395.17193241\n",
      "Iteration 5287, loss = 395.15064272\n",
      "Iteration 5288, loss = 395.13329898\n",
      "Iteration 5289, loss = 395.11500090\n",
      "Iteration 5290, loss = 395.09389358\n",
      "Iteration 5291, loss = 395.07603055\n",
      "Iteration 5292, loss = 395.05697689\n",
      "Iteration 5293, loss = 395.03812591\n",
      "Iteration 5294, loss = 395.02016024\n",
      "Iteration 5295, loss = 394.99735115\n",
      "Iteration 5296, loss = 394.97445622\n",
      "Iteration 5297, loss = 394.94830587\n",
      "Iteration 5298, loss = 394.92662655\n",
      "Iteration 5299, loss = 394.90476377\n",
      "Iteration 5300, loss = 394.87990635\n",
      "Iteration 5301, loss = 394.85724896\n",
      "Iteration 5302, loss = 394.83844028\n",
      "Iteration 5303, loss = 394.81824456\n",
      "Iteration 5304, loss = 394.79748063\n",
      "Iteration 5305, loss = 394.77883668\n",
      "Iteration 5306, loss = 394.75742704\n",
      "Iteration 5307, loss = 394.73790832\n",
      "Iteration 5308, loss = 394.71370871\n",
      "Iteration 5309, loss = 394.68930608\n",
      "Iteration 5310, loss = 394.66921326\n",
      "Iteration 5311, loss = 394.64896664\n",
      "Iteration 5312, loss = 394.62587968\n",
      "Iteration 5313, loss = 394.60512985\n",
      "Iteration 5314, loss = 394.58320950\n",
      "Iteration 5315, loss = 394.56610235\n",
      "Iteration 5316, loss = 394.54692371\n",
      "Iteration 5317, loss = 394.52641905\n",
      "Iteration 5318, loss = 394.50894906\n",
      "Iteration 5319, loss = 394.48364992\n",
      "Iteration 5320, loss = 394.46157561\n",
      "Iteration 5321, loss = 394.44314494\n",
      "Iteration 5322, loss = 394.42071191\n",
      "Iteration 5323, loss = 394.39955246\n",
      "Iteration 5324, loss = 394.37965503\n",
      "Iteration 5325, loss = 394.35494385\n",
      "Iteration 5326, loss = 394.33008174\n",
      "Iteration 5327, loss = 394.31324603\n",
      "Iteration 5328, loss = 394.29621609\n",
      "Iteration 5329, loss = 394.27439659\n",
      "Iteration 5330, loss = 394.25051824\n",
      "Iteration 5331, loss = 394.23000858\n",
      "Iteration 5332, loss = 394.20744581\n",
      "Iteration 5333, loss = 394.18734787\n",
      "Iteration 5334, loss = 394.16484761\n",
      "Iteration 5335, loss = 394.14384261\n",
      "Iteration 5336, loss = 394.12351508\n",
      "Iteration 5337, loss = 394.10081870\n",
      "Iteration 5338, loss = 394.08045559\n",
      "Iteration 5339, loss = 394.06407226\n",
      "Iteration 5340, loss = 394.03951418\n",
      "Iteration 5341, loss = 394.02061998\n",
      "Iteration 5342, loss = 394.00091716\n",
      "Iteration 5343, loss = 393.98023017\n",
      "Iteration 5344, loss = 393.95652914\n",
      "Iteration 5345, loss = 393.93354029\n",
      "Iteration 5346, loss = 393.91141752\n",
      "Iteration 5347, loss = 393.89110426\n",
      "Iteration 5348, loss = 393.87067942\n",
      "Iteration 5349, loss = 393.84964421\n",
      "Iteration 5350, loss = 393.82578572\n",
      "Iteration 5351, loss = 393.80508099\n",
      "Iteration 5352, loss = 393.78554800\n",
      "Iteration 5353, loss = 393.76514988\n",
      "Iteration 5354, loss = 393.74352702\n",
      "Iteration 5355, loss = 393.72096492\n",
      "Iteration 5356, loss = 393.70082584\n",
      "Iteration 5357, loss = 393.67803313\n",
      "Iteration 5358, loss = 393.66200961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5359, loss = 393.63957141\n",
      "Iteration 5360, loss = 393.61930822\n",
      "Iteration 5361, loss = 393.59747532\n",
      "Iteration 5362, loss = 393.57705689\n",
      "Iteration 5363, loss = 393.55739134\n",
      "Iteration 5364, loss = 393.53712257\n",
      "Iteration 5365, loss = 393.51282596\n",
      "Iteration 5366, loss = 393.49262774\n",
      "Iteration 5367, loss = 393.47234337\n",
      "Iteration 5368, loss = 393.45495553\n",
      "Iteration 5369, loss = 393.43373026\n",
      "Iteration 5370, loss = 393.41079758\n",
      "Iteration 5371, loss = 393.38731745\n",
      "Iteration 5372, loss = 393.36678813\n",
      "Iteration 5373, loss = 393.34559389\n",
      "Iteration 5374, loss = 393.32875180\n",
      "Iteration 5375, loss = 393.30414065\n",
      "Iteration 5376, loss = 393.28486075\n",
      "Iteration 5377, loss = 393.26641689\n",
      "Iteration 5378, loss = 393.24637114\n",
      "Iteration 5379, loss = 393.22703820\n",
      "Iteration 5380, loss = 393.20416919\n",
      "Iteration 5381, loss = 393.18071609\n",
      "Iteration 5382, loss = 393.16643733\n",
      "Iteration 5383, loss = 393.14749328\n",
      "Iteration 5384, loss = 393.12786176\n",
      "Iteration 5385, loss = 393.10834757\n",
      "Iteration 5386, loss = 393.09081379\n",
      "Iteration 5387, loss = 393.07583448\n",
      "Iteration 5388, loss = 393.06336618\n",
      "Iteration 5389, loss = 393.04279475\n",
      "Iteration 5390, loss = 393.02677929\n",
      "Iteration 5391, loss = 393.00736523\n",
      "Iteration 5392, loss = 392.98340804\n",
      "Iteration 5393, loss = 392.95374697\n",
      "Iteration 5394, loss = 392.92631270\n",
      "Iteration 5395, loss = 392.90196216\n",
      "Iteration 5396, loss = 392.87620756\n",
      "Iteration 5397, loss = 392.85592961\n",
      "Iteration 5398, loss = 392.83589750\n",
      "Iteration 5399, loss = 392.81673352\n",
      "Iteration 5400, loss = 392.79434453\n",
      "Iteration 5401, loss = 392.77040590\n",
      "Iteration 5402, loss = 392.75148554\n",
      "Iteration 5403, loss = 392.72636934\n",
      "Iteration 5404, loss = 392.70758053\n",
      "Iteration 5405, loss = 392.69083009\n",
      "Iteration 5406, loss = 392.67070815\n",
      "Iteration 5407, loss = 392.64646129\n",
      "Iteration 5408, loss = 392.62318107\n",
      "Iteration 5409, loss = 392.60652472\n",
      "Iteration 5410, loss = 392.58532443\n",
      "Iteration 5411, loss = 392.56210495\n",
      "Iteration 5412, loss = 392.54036037\n",
      "Iteration 5413, loss = 392.51734851\n",
      "Iteration 5414, loss = 392.49954386\n",
      "Iteration 5415, loss = 392.47989426\n",
      "Iteration 5416, loss = 392.46409605\n",
      "Iteration 5417, loss = 392.44126889\n",
      "Iteration 5418, loss = 392.41869965\n",
      "Iteration 5419, loss = 392.39998492\n",
      "Iteration 5420, loss = 392.37741257\n",
      "Iteration 5421, loss = 392.35616819\n",
      "Iteration 5422, loss = 392.33971925\n",
      "Iteration 5423, loss = 392.31699868\n",
      "Iteration 5424, loss = 392.29632427\n",
      "Iteration 5425, loss = 392.27746560\n",
      "Iteration 5426, loss = 392.25782741\n",
      "Iteration 5427, loss = 392.23817354\n",
      "Iteration 5428, loss = 392.21710861\n",
      "Iteration 5429, loss = 392.19605540\n",
      "Iteration 5430, loss = 392.17511133\n",
      "Iteration 5431, loss = 392.15378174\n",
      "Iteration 5432, loss = 392.13150217\n",
      "Iteration 5433, loss = 392.10966156\n",
      "Iteration 5434, loss = 392.09105604\n",
      "Iteration 5435, loss = 392.07026880\n",
      "Iteration 5436, loss = 392.04843081\n",
      "Iteration 5437, loss = 392.02766965\n",
      "Iteration 5438, loss = 392.01006971\n",
      "Iteration 5439, loss = 391.99057938\n",
      "Iteration 5440, loss = 391.96833027\n",
      "Iteration 5441, loss = 391.94833765\n",
      "Iteration 5442, loss = 391.93054563\n",
      "Iteration 5443, loss = 391.90914870\n",
      "Iteration 5444, loss = 391.89082487\n",
      "Iteration 5445, loss = 391.87275677\n",
      "Iteration 5446, loss = 391.84892333\n",
      "Iteration 5447, loss = 391.82877122\n",
      "Iteration 5448, loss = 391.80726214\n",
      "Iteration 5449, loss = 391.78708921\n",
      "Iteration 5450, loss = 391.76658308\n",
      "Iteration 5451, loss = 391.74620247\n",
      "Iteration 5452, loss = 391.72206099\n",
      "Iteration 5453, loss = 391.70232483\n",
      "Iteration 5454, loss = 391.68141314\n",
      "Iteration 5455, loss = 391.66430690\n",
      "Iteration 5456, loss = 391.64251381\n",
      "Iteration 5457, loss = 391.62553813\n",
      "Iteration 5458, loss = 391.60664643\n",
      "Iteration 5459, loss = 391.58808071\n",
      "Iteration 5460, loss = 391.56668660\n",
      "Iteration 5461, loss = 391.54334244\n",
      "Iteration 5462, loss = 391.52305333\n",
      "Iteration 5463, loss = 391.50672221\n",
      "Iteration 5464, loss = 391.48568225\n",
      "Iteration 5465, loss = 391.46483549\n",
      "Iteration 5466, loss = 391.44861184\n",
      "Iteration 5467, loss = 391.42963383\n",
      "Iteration 5468, loss = 391.40846483\n",
      "Iteration 5469, loss = 391.38926443\n",
      "Iteration 5470, loss = 391.36886044\n",
      "Iteration 5471, loss = 391.34771848\n",
      "Iteration 5472, loss = 391.32448002\n",
      "Iteration 5473, loss = 391.30556981\n",
      "Iteration 5474, loss = 391.28508232\n",
      "Iteration 5475, loss = 391.26491475\n",
      "Iteration 5476, loss = 391.24691706\n",
      "Iteration 5477, loss = 391.22490912\n",
      "Iteration 5478, loss = 391.20193262\n",
      "Iteration 5479, loss = 391.18402463\n",
      "Iteration 5480, loss = 391.16343233\n",
      "Iteration 5481, loss = 391.14381084\n",
      "Iteration 5482, loss = 391.12435212\n",
      "Iteration 5483, loss = 391.10252572\n",
      "Iteration 5484, loss = 391.08426714\n",
      "Iteration 5485, loss = 391.06332426\n",
      "Iteration 5486, loss = 391.04610568\n",
      "Iteration 5487, loss = 391.02594328\n",
      "Iteration 5488, loss = 391.00567101\n",
      "Iteration 5489, loss = 390.98601412\n",
      "Iteration 5490, loss = 390.96453184\n",
      "Iteration 5491, loss = 390.94118408\n",
      "Iteration 5492, loss = 390.92429854\n",
      "Iteration 5493, loss = 390.90787029\n",
      "Iteration 5494, loss = 390.88380667\n",
      "Iteration 5495, loss = 390.86531968\n",
      "Iteration 5496, loss = 390.84884253\n",
      "Iteration 5497, loss = 390.82936587\n",
      "Iteration 5498, loss = 390.80866528\n",
      "Iteration 5499, loss = 390.78860467\n",
      "Iteration 5500, loss = 390.76740906\n",
      "Iteration 5501, loss = 390.74633610\n",
      "Iteration 5502, loss = 390.73096510\n",
      "Iteration 5503, loss = 390.71771043\n",
      "Iteration 5504, loss = 390.70209384\n",
      "Iteration 5505, loss = 390.69506833\n",
      "Iteration 5506, loss = 390.69352734\n",
      "Iteration 5507, loss = 390.69194834\n",
      "Iteration 5508, loss = 390.68548708\n",
      "Iteration 5509, loss = 390.66100914\n",
      "Iteration 5510, loss = 390.61775730\n",
      "Iteration 5511, loss = 390.56669700\n",
      "Iteration 5512, loss = 390.52855026\n",
      "Iteration 5513, loss = 390.51077727\n",
      "Iteration 5514, loss = 390.49920268\n",
      "Iteration 5515, loss = 390.48528820\n",
      "Iteration 5516, loss = 390.46562720\n",
      "Iteration 5517, loss = 390.43985080\n",
      "Iteration 5518, loss = 390.41334953\n",
      "Iteration 5519, loss = 390.38771454\n",
      "Iteration 5520, loss = 390.36156186\n",
      "Iteration 5521, loss = 390.33838253\n",
      "Iteration 5522, loss = 390.31792625\n",
      "Iteration 5523, loss = 390.30144634\n",
      "Iteration 5524, loss = 390.27934052\n",
      "Iteration 5525, loss = 390.25786175\n",
      "Iteration 5526, loss = 390.23464179\n",
      "Iteration 5527, loss = 390.20966715\n",
      "Iteration 5528, loss = 390.18706790\n",
      "Iteration 5529, loss = 390.16900917\n",
      "Iteration 5530, loss = 390.14865025\n",
      "Iteration 5531, loss = 390.12844286\n",
      "Iteration 5532, loss = 390.10716771\n",
      "Iteration 5533, loss = 390.07945673\n",
      "Iteration 5534, loss = 390.06006997\n",
      "Iteration 5535, loss = 390.04097660\n",
      "Iteration 5536, loss = 390.02062720\n",
      "Iteration 5537, loss = 390.00480790\n",
      "Iteration 5538, loss = 389.98185929\n",
      "Iteration 5539, loss = 389.95423293\n",
      "Iteration 5540, loss = 389.93165441\n",
      "Iteration 5541, loss = 389.91071091\n",
      "Iteration 5542, loss = 389.88868286\n",
      "Iteration 5543, loss = 389.86595209\n",
      "Iteration 5544, loss = 389.84890763\n",
      "Iteration 5545, loss = 389.82669285\n",
      "Iteration 5546, loss = 389.80000482\n",
      "Iteration 5547, loss = 389.77814954\n",
      "Iteration 5548, loss = 389.75748881\n",
      "Iteration 5549, loss = 389.73863787\n",
      "Iteration 5550, loss = 389.71473332\n",
      "Iteration 5551, loss = 389.69593318\n",
      "Iteration 5552, loss = 389.67315795\n",
      "Iteration 5553, loss = 389.65232254\n",
      "Iteration 5554, loss = 389.63180188\n",
      "Iteration 5555, loss = 389.61044156\n",
      "Iteration 5556, loss = 389.58699267\n",
      "Iteration 5557, loss = 389.56736508\n",
      "Iteration 5558, loss = 389.54715087\n",
      "Iteration 5559, loss = 389.52566395\n",
      "Iteration 5560, loss = 389.50300961\n",
      "Iteration 5561, loss = 389.48205941\n",
      "Iteration 5562, loss = 389.46036431\n",
      "Iteration 5563, loss = 389.43998449\n",
      "Iteration 5564, loss = 389.41729861\n",
      "Iteration 5565, loss = 389.39146905\n",
      "Iteration 5566, loss = 389.37554967\n",
      "Iteration 5567, loss = 389.35447035\n",
      "Iteration 5568, loss = 389.32821944\n",
      "Iteration 5569, loss = 389.30829748\n",
      "Iteration 5570, loss = 389.28814656\n",
      "Iteration 5571, loss = 389.26583017\n",
      "Iteration 5572, loss = 389.24497442\n",
      "Iteration 5573, loss = 389.22163697\n",
      "Iteration 5574, loss = 389.20171339\n",
      "Iteration 5575, loss = 389.17894228\n",
      "Iteration 5576, loss = 389.15911734\n",
      "Iteration 5577, loss = 389.13610424\n",
      "Iteration 5578, loss = 389.11150028\n",
      "Iteration 5579, loss = 389.09235197\n",
      "Iteration 5580, loss = 389.06913106\n",
      "Iteration 5581, loss = 389.04596219\n",
      "Iteration 5582, loss = 389.02271626\n",
      "Iteration 5583, loss = 389.00087784\n",
      "Iteration 5584, loss = 388.98042503\n",
      "Iteration 5585, loss = 388.95984061\n",
      "Iteration 5586, loss = 388.93594470\n",
      "Iteration 5587, loss = 388.91364384\n",
      "Iteration 5588, loss = 388.89486245\n",
      "Iteration 5589, loss = 388.87263203\n",
      "Iteration 5590, loss = 388.84840700\n",
      "Iteration 5591, loss = 388.82809809\n",
      "Iteration 5592, loss = 388.80568469\n",
      "Iteration 5593, loss = 388.78275720\n",
      "Iteration 5594, loss = 388.76534355\n",
      "Iteration 5595, loss = 388.74206163\n",
      "Iteration 5596, loss = 388.71852324\n",
      "Iteration 5597, loss = 388.69647854\n",
      "Iteration 5598, loss = 388.67589961\n",
      "Iteration 5599, loss = 388.65452579\n",
      "Iteration 5600, loss = 388.63063568\n",
      "Iteration 5601, loss = 388.61028861\n",
      "Iteration 5602, loss = 388.59044442\n",
      "Iteration 5603, loss = 388.56687304\n",
      "Iteration 5604, loss = 388.54060464\n",
      "Iteration 5605, loss = 388.51721209\n",
      "Iteration 5606, loss = 388.49764876\n",
      "Iteration 5607, loss = 388.48014771\n",
      "Iteration 5608, loss = 388.46069753\n",
      "Iteration 5609, loss = 388.43523715\n",
      "Iteration 5610, loss = 388.41409279\n",
      "Iteration 5611, loss = 388.38583305\n",
      "Iteration 5612, loss = 388.36450217\n",
      "Iteration 5613, loss = 388.34557280\n",
      "Iteration 5614, loss = 388.32206389\n",
      "Iteration 5615, loss = 388.29606482\n",
      "Iteration 5616, loss = 388.27775654\n",
      "Iteration 5617, loss = 388.25324934\n",
      "Iteration 5618, loss = 388.22909705\n",
      "Iteration 5619, loss = 388.20801493\n",
      "Iteration 5620, loss = 388.18387806\n",
      "Iteration 5621, loss = 388.16194672\n",
      "Iteration 5622, loss = 388.14293851\n",
      "Iteration 5623, loss = 388.11546241\n",
      "Iteration 5624, loss = 388.09574123\n",
      "Iteration 5625, loss = 388.07526604\n",
      "Iteration 5626, loss = 388.05413041\n",
      "Iteration 5627, loss = 388.03054400\n",
      "Iteration 5628, loss = 388.00961024\n",
      "Iteration 5629, loss = 387.98437273\n",
      "Iteration 5630, loss = 387.96644156\n",
      "Iteration 5631, loss = 387.94351153\n",
      "Iteration 5632, loss = 387.92048370\n",
      "Iteration 5633, loss = 387.90035802\n",
      "Iteration 5634, loss = 387.87478519\n",
      "Iteration 5635, loss = 387.85193731\n",
      "Iteration 5636, loss = 387.83461561\n",
      "Iteration 5637, loss = 387.81463586\n",
      "Iteration 5638, loss = 387.78900033\n",
      "Iteration 5639, loss = 387.76779387\n",
      "Iteration 5640, loss = 387.74775470\n",
      "Iteration 5641, loss = 387.72718716\n",
      "Iteration 5642, loss = 387.70439679\n",
      "Iteration 5643, loss = 387.67743825\n",
      "Iteration 5644, loss = 387.66067469\n",
      "Iteration 5645, loss = 387.64321010\n",
      "Iteration 5646, loss = 387.61936971\n",
      "Iteration 5647, loss = 387.59679396\n",
      "Iteration 5648, loss = 387.57481924\n",
      "Iteration 5649, loss = 387.55479815\n",
      "Iteration 5650, loss = 387.53311854\n",
      "Iteration 5651, loss = 387.51257379\n",
      "Iteration 5652, loss = 387.49017929\n",
      "Iteration 5653, loss = 387.46248407\n",
      "Iteration 5654, loss = 387.44509332\n",
      "Iteration 5655, loss = 387.42553553\n",
      "Iteration 5656, loss = 387.40543091\n",
      "Iteration 5657, loss = 387.38426345\n",
      "Iteration 5658, loss = 387.36618794\n",
      "Iteration 5659, loss = 387.34337225\n",
      "Iteration 5660, loss = 387.32338617\n",
      "Iteration 5661, loss = 387.30542157\n",
      "Iteration 5662, loss = 387.28617485\n",
      "Iteration 5663, loss = 387.26478104\n",
      "Iteration 5664, loss = 387.24191523\n",
      "Iteration 5665, loss = 387.22588875\n",
      "Iteration 5666, loss = 387.20788052\n",
      "Iteration 5667, loss = 387.18672556\n",
      "Iteration 5668, loss = 387.16725471\n",
      "Iteration 5669, loss = 387.15053570\n",
      "Iteration 5670, loss = 387.13493243\n",
      "Iteration 5671, loss = 387.11672416\n",
      "Iteration 5672, loss = 387.10143300\n",
      "Iteration 5673, loss = 387.08070936\n",
      "Iteration 5674, loss = 387.06605554\n",
      "Iteration 5675, loss = 387.05223020\n",
      "Iteration 5676, loss = 387.03107401\n",
      "Iteration 5677, loss = 387.01694699\n",
      "Iteration 5678, loss = 386.99474778\n",
      "Iteration 5679, loss = 386.96587111\n",
      "Iteration 5680, loss = 386.93591947\n",
      "Iteration 5681, loss = 386.91005670\n",
      "Iteration 5682, loss = 386.88478168\n",
      "Iteration 5683, loss = 386.86972635\n",
      "Iteration 5684, loss = 386.85464300\n",
      "Iteration 5685, loss = 386.83520198\n",
      "Iteration 5686, loss = 386.81195965\n",
      "Iteration 5687, loss = 386.79455725\n",
      "Iteration 5688, loss = 386.77486169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5689, loss = 386.75359624\n",
      "Iteration 5690, loss = 386.73005429\n",
      "Iteration 5691, loss = 386.70946734\n",
      "Iteration 5692, loss = 386.69123251\n",
      "Iteration 5693, loss = 386.67160321\n",
      "Iteration 5694, loss = 386.64908085\n",
      "Iteration 5695, loss = 386.63025526\n",
      "Iteration 5696, loss = 386.60793259\n",
      "Iteration 5697, loss = 386.59374874\n",
      "Iteration 5698, loss = 386.57544259\n",
      "Iteration 5699, loss = 386.55041054\n",
      "Iteration 5700, loss = 386.52958609\n",
      "Iteration 5701, loss = 386.51003043\n",
      "Iteration 5702, loss = 386.49093137\n",
      "Iteration 5703, loss = 386.47203934\n",
      "Iteration 5704, loss = 386.45062668\n",
      "Iteration 5705, loss = 386.42812990\n",
      "Iteration 5706, loss = 386.40903848\n",
      "Iteration 5707, loss = 386.39196258\n",
      "Iteration 5708, loss = 386.37170285\n",
      "Iteration 5709, loss = 386.35060311\n",
      "Iteration 5710, loss = 386.32880274\n",
      "Iteration 5711, loss = 386.31266535\n",
      "Iteration 5712, loss = 386.29274696\n",
      "Iteration 5713, loss = 386.27092188\n",
      "Iteration 5714, loss = 386.25674641\n",
      "Iteration 5715, loss = 386.23510342\n",
      "Iteration 5716, loss = 386.21464678\n",
      "Iteration 5717, loss = 386.19690716\n",
      "Iteration 5718, loss = 386.17575679\n",
      "Iteration 5719, loss = 386.15468905\n",
      "Iteration 5720, loss = 386.14160805\n",
      "Iteration 5721, loss = 386.12059213\n",
      "Iteration 5722, loss = 386.09745869\n",
      "Iteration 5723, loss = 386.07729243\n",
      "Iteration 5724, loss = 386.05772878\n",
      "Iteration 5725, loss = 386.03859981\n",
      "Iteration 5726, loss = 386.01713294\n",
      "Iteration 5727, loss = 385.99814620\n",
      "Iteration 5728, loss = 385.98134522\n",
      "Iteration 5729, loss = 385.96016560\n",
      "Iteration 5730, loss = 385.94166271\n",
      "Iteration 5731, loss = 385.92518636\n",
      "Iteration 5732, loss = 385.90296824\n",
      "Iteration 5733, loss = 385.88464552\n",
      "Iteration 5734, loss = 385.86638675\n",
      "Iteration 5735, loss = 385.84461469\n",
      "Iteration 5736, loss = 385.82602035\n",
      "Iteration 5737, loss = 385.80480823\n",
      "Iteration 5738, loss = 385.78753299\n",
      "Iteration 5739, loss = 385.77265418\n",
      "Iteration 5740, loss = 385.74896547\n",
      "Iteration 5741, loss = 385.73019787\n",
      "Iteration 5742, loss = 385.71301502\n",
      "Iteration 5743, loss = 385.69043512\n",
      "Iteration 5744, loss = 385.66962718\n",
      "Iteration 5745, loss = 385.65194616\n",
      "Iteration 5746, loss = 385.63375602\n",
      "Iteration 5747, loss = 385.61728464\n",
      "Iteration 5748, loss = 385.59708740\n",
      "Iteration 5749, loss = 385.57879512\n",
      "Iteration 5750, loss = 385.55862892\n",
      "Iteration 5751, loss = 385.53868188\n",
      "Iteration 5752, loss = 385.52163149\n",
      "Iteration 5753, loss = 385.50488962\n",
      "Iteration 5754, loss = 385.48604594\n",
      "Iteration 5755, loss = 385.46793082\n",
      "Iteration 5756, loss = 385.45113748\n",
      "Iteration 5757, loss = 385.43611055\n",
      "Iteration 5758, loss = 385.41615524\n",
      "Iteration 5759, loss = 385.39507807\n",
      "Iteration 5760, loss = 385.37769970\n",
      "Iteration 5761, loss = 385.35454126\n",
      "Iteration 5762, loss = 385.32963804\n",
      "Iteration 5763, loss = 385.31117659\n",
      "Iteration 5764, loss = 385.28870520\n",
      "Iteration 5765, loss = 385.27163211\n",
      "Iteration 5766, loss = 385.25581287\n",
      "Iteration 5767, loss = 385.23392400\n",
      "Iteration 5768, loss = 385.21966183\n",
      "Iteration 5769, loss = 385.19878114\n",
      "Iteration 5770, loss = 385.17436161\n",
      "Iteration 5771, loss = 385.15428286\n",
      "Iteration 5772, loss = 385.13328586\n",
      "Iteration 5773, loss = 385.11323886\n",
      "Iteration 5774, loss = 385.09437191\n",
      "Iteration 5775, loss = 385.07580279\n",
      "Iteration 5776, loss = 385.06136420\n",
      "Iteration 5777, loss = 385.03908015\n",
      "Iteration 5778, loss = 385.01834095\n",
      "Iteration 5779, loss = 385.00094283\n",
      "Iteration 5780, loss = 384.97903053\n",
      "Iteration 5781, loss = 384.95751310\n",
      "Iteration 5782, loss = 384.93610285\n",
      "Iteration 5783, loss = 384.91651083\n",
      "Iteration 5784, loss = 384.89720945\n",
      "Iteration 5785, loss = 384.87758631\n",
      "Iteration 5786, loss = 384.86034725\n",
      "Iteration 5787, loss = 384.83726758\n",
      "Iteration 5788, loss = 384.82394902\n",
      "Iteration 5789, loss = 384.80458898\n",
      "Iteration 5790, loss = 384.78015529\n",
      "Iteration 5791, loss = 384.76134052\n",
      "Iteration 5792, loss = 384.74651101\n",
      "Iteration 5793, loss = 384.72979367\n",
      "Iteration 5794, loss = 384.70755424\n",
      "Iteration 5795, loss = 384.68636946\n",
      "Iteration 5796, loss = 384.66254699\n",
      "Iteration 5797, loss = 384.64611548\n",
      "Iteration 5798, loss = 384.62954056\n",
      "Iteration 5799, loss = 384.60753075\n",
      "Iteration 5800, loss = 384.58381443\n",
      "Iteration 5801, loss = 384.56942507\n",
      "Iteration 5802, loss = 384.55195043\n",
      "Iteration 5803, loss = 384.53223034\n",
      "Iteration 5804, loss = 384.51261544\n",
      "Iteration 5805, loss = 384.49142945\n",
      "Iteration 5806, loss = 384.46937193\n",
      "Iteration 5807, loss = 384.45013246\n",
      "Iteration 5808, loss = 384.43266167\n",
      "Iteration 5809, loss = 384.41399398\n",
      "Iteration 5810, loss = 384.39390533\n",
      "Iteration 5811, loss = 384.37401625\n",
      "Iteration 5812, loss = 384.35897007\n",
      "Iteration 5813, loss = 384.33816546\n",
      "Iteration 5814, loss = 384.32449545\n",
      "Iteration 5815, loss = 384.31077974\n",
      "Iteration 5816, loss = 384.29042743\n",
      "Iteration 5817, loss = 384.27231998\n",
      "Iteration 5818, loss = 384.25683781\n",
      "Iteration 5819, loss = 384.23854356\n",
      "Iteration 5820, loss = 384.21898093\n",
      "Iteration 5821, loss = 384.20006554\n",
      "Iteration 5822, loss = 384.17592623\n",
      "Iteration 5823, loss = 384.15731302\n",
      "Iteration 5824, loss = 384.13232543\n",
      "Iteration 5825, loss = 384.11144252\n",
      "Iteration 5826, loss = 384.09144361\n",
      "Iteration 5827, loss = 384.06933071\n",
      "Iteration 5828, loss = 384.05426681\n",
      "Iteration 5829, loss = 384.03413959\n",
      "Iteration 5830, loss = 384.01365634\n",
      "Iteration 5831, loss = 383.99590601\n",
      "Iteration 5832, loss = 383.97949705\n",
      "Iteration 5833, loss = 383.96063607\n",
      "Iteration 5834, loss = 383.94413064\n",
      "Iteration 5835, loss = 383.92192057\n",
      "Iteration 5836, loss = 383.90406003\n",
      "Iteration 5837, loss = 383.88863407\n",
      "Iteration 5838, loss = 383.86829439\n",
      "Iteration 5839, loss = 383.85036756\n",
      "Iteration 5840, loss = 383.83538465\n",
      "Iteration 5841, loss = 383.81378284\n",
      "Iteration 5842, loss = 383.79232580\n",
      "Iteration 5843, loss = 383.77098883\n",
      "Iteration 5844, loss = 383.75136139\n",
      "Iteration 5845, loss = 383.74045836\n",
      "Iteration 5846, loss = 383.71896217\n",
      "Iteration 5847, loss = 383.70286341\n",
      "Iteration 5848, loss = 383.68319501\n",
      "Iteration 5849, loss = 383.66151791\n",
      "Iteration 5850, loss = 383.64621732\n",
      "Iteration 5851, loss = 383.62315589\n",
      "Iteration 5852, loss = 383.60563188\n",
      "Iteration 5853, loss = 383.59153594\n",
      "Iteration 5854, loss = 383.57093974\n",
      "Iteration 5855, loss = 383.55134755\n",
      "Iteration 5856, loss = 383.53423748\n",
      "Iteration 5857, loss = 383.51795139\n",
      "Iteration 5858, loss = 383.49814937\n",
      "Iteration 5859, loss = 383.47856689\n",
      "Iteration 5860, loss = 383.46249794\n",
      "Iteration 5861, loss = 383.44085763\n",
      "Iteration 5862, loss = 383.42459020\n",
      "Iteration 5863, loss = 383.40395031\n",
      "Iteration 5864, loss = 383.38820699\n",
      "Iteration 5865, loss = 383.36888000\n",
      "Iteration 5866, loss = 383.34927669\n",
      "Iteration 5867, loss = 383.33582781\n",
      "Iteration 5868, loss = 383.31763186\n",
      "Iteration 5869, loss = 383.29726016\n",
      "Iteration 5870, loss = 383.27930365\n",
      "Iteration 5871, loss = 383.25870951\n",
      "Iteration 5872, loss = 383.24128116\n",
      "Iteration 5873, loss = 383.22247850\n",
      "Iteration 5874, loss = 383.20419394\n",
      "Iteration 5875, loss = 383.18885575\n",
      "Iteration 5876, loss = 383.16934484\n",
      "Iteration 5877, loss = 383.15320310\n",
      "Iteration 5878, loss = 383.13502405\n",
      "Iteration 5879, loss = 383.12049347\n",
      "Iteration 5880, loss = 383.10481940\n",
      "Iteration 5881, loss = 383.08497279\n",
      "Iteration 5882, loss = 383.06536918\n",
      "Iteration 5883, loss = 383.04537397\n",
      "Iteration 5884, loss = 383.02435261\n",
      "Iteration 5885, loss = 383.01426187\n",
      "Iteration 5886, loss = 382.99828229\n",
      "Iteration 5887, loss = 382.97372781\n",
      "Iteration 5888, loss = 382.96298311\n",
      "Iteration 5889, loss = 382.94349278\n",
      "Iteration 5890, loss = 382.92824991\n",
      "Iteration 5891, loss = 382.91275126\n",
      "Iteration 5892, loss = 382.89044260\n",
      "Iteration 5893, loss = 382.87542117\n",
      "Iteration 5894, loss = 382.85440056\n",
      "Iteration 5895, loss = 382.83431609\n",
      "Iteration 5896, loss = 382.82044991\n",
      "Iteration 5897, loss = 382.79846080\n",
      "Iteration 5898, loss = 382.78169747\n",
      "Iteration 5899, loss = 382.76536086\n",
      "Iteration 5900, loss = 382.74704253\n",
      "Iteration 5901, loss = 382.73415015\n",
      "Iteration 5902, loss = 382.71499256\n",
      "Iteration 5903, loss = 382.69898917\n",
      "Iteration 5904, loss = 382.68613877\n",
      "Iteration 5905, loss = 382.66635301\n",
      "Iteration 5906, loss = 382.64678115\n",
      "Iteration 5907, loss = 382.62768408\n",
      "Iteration 5908, loss = 382.60890170\n",
      "Iteration 5909, loss = 382.58740057\n",
      "Iteration 5910, loss = 382.56846629\n",
      "Iteration 5911, loss = 382.55217087\n",
      "Iteration 5912, loss = 382.53181143\n",
      "Iteration 5913, loss = 382.51205696\n",
      "Iteration 5914, loss = 382.49817472\n",
      "Iteration 5915, loss = 382.47709974\n",
      "Iteration 5916, loss = 382.45798545\n",
      "Iteration 5917, loss = 382.44703382\n",
      "Iteration 5918, loss = 382.42601397\n",
      "Iteration 5919, loss = 382.40826193\n",
      "Iteration 5920, loss = 382.39631133\n",
      "Iteration 5921, loss = 382.37764555\n",
      "Iteration 5922, loss = 382.36021465\n",
      "Iteration 5923, loss = 382.34180660\n",
      "Iteration 5924, loss = 382.32279688\n",
      "Iteration 5925, loss = 382.30533983\n",
      "Iteration 5926, loss = 382.28809374\n",
      "Iteration 5927, loss = 382.27195038\n",
      "Iteration 5928, loss = 382.25484557\n",
      "Iteration 5929, loss = 382.23622585\n",
      "Iteration 5930, loss = 382.21918727\n",
      "Iteration 5931, loss = 382.20302061\n",
      "Iteration 5932, loss = 382.18317546\n",
      "Iteration 5933, loss = 382.16375076\n",
      "Iteration 5934, loss = 382.14652311\n",
      "Iteration 5935, loss = 382.13164165\n",
      "Iteration 5936, loss = 382.11310943\n",
      "Iteration 5937, loss = 382.09881419\n",
      "Iteration 5938, loss = 382.08660575\n",
      "Iteration 5939, loss = 382.06806449\n",
      "Iteration 5940, loss = 382.05133811\n",
      "Iteration 5941, loss = 382.03305981\n",
      "Iteration 5942, loss = 382.01598508\n",
      "Iteration 5943, loss = 381.99584438\n",
      "Iteration 5944, loss = 381.98094675\n",
      "Iteration 5945, loss = 381.96594937\n",
      "Iteration 5946, loss = 381.94643409\n",
      "Iteration 5947, loss = 381.92673856\n",
      "Iteration 5948, loss = 381.91077598\n",
      "Iteration 5949, loss = 381.89823100\n",
      "Iteration 5950, loss = 381.87849451\n",
      "Iteration 5951, loss = 381.85492211\n",
      "Iteration 5952, loss = 381.84476922\n",
      "Iteration 5953, loss = 381.83051435\n",
      "Iteration 5954, loss = 381.80759986\n",
      "Iteration 5955, loss = 381.78488722\n",
      "Iteration 5956, loss = 381.77176659\n",
      "Iteration 5957, loss = 381.75403622\n",
      "Iteration 5958, loss = 381.73344161\n",
      "Iteration 5959, loss = 381.71627700\n",
      "Iteration 5960, loss = 381.69856443\n",
      "Iteration 5961, loss = 381.68018590\n",
      "Iteration 5962, loss = 381.66556350\n",
      "Iteration 5963, loss = 381.64593461\n",
      "Iteration 5964, loss = 381.63412558\n",
      "Iteration 5965, loss = 381.61369372\n",
      "Iteration 5966, loss = 381.59635999\n",
      "Iteration 5967, loss = 381.58238476\n",
      "Iteration 5968, loss = 381.56030542\n",
      "Iteration 5969, loss = 381.54829605\n",
      "Iteration 5970, loss = 381.53066482\n",
      "Iteration 5971, loss = 381.51815518\n",
      "Iteration 5972, loss = 381.49821408\n",
      "Iteration 5973, loss = 381.47805844\n",
      "Iteration 5974, loss = 381.46273447\n",
      "Iteration 5975, loss = 381.44191763\n",
      "Iteration 5976, loss = 381.42506717\n",
      "Iteration 5977, loss = 381.41057431\n",
      "Iteration 5978, loss = 381.39069104\n",
      "Iteration 5979, loss = 381.37850855\n",
      "Iteration 5980, loss = 381.35834426\n",
      "Iteration 5981, loss = 381.34797238\n",
      "Iteration 5982, loss = 381.33172874\n",
      "Iteration 5983, loss = 381.31206085\n",
      "Iteration 5984, loss = 381.29728102\n",
      "Iteration 5985, loss = 381.28348863\n",
      "Iteration 5986, loss = 381.26717957\n",
      "Iteration 5987, loss = 381.24895008\n",
      "Iteration 5988, loss = 381.23420795\n",
      "Iteration 5989, loss = 381.22336371\n",
      "Iteration 5990, loss = 381.21202316\n",
      "Iteration 5991, loss = 381.19512015\n",
      "Iteration 5992, loss = 381.17719265\n",
      "Iteration 5993, loss = 381.16079171\n",
      "Iteration 5994, loss = 381.14975672\n",
      "Iteration 5995, loss = 381.12458134\n",
      "Iteration 5996, loss = 381.09921604\n",
      "Iteration 5997, loss = 381.07790808\n",
      "Iteration 5998, loss = 381.05649519\n",
      "Iteration 5999, loss = 381.03662237\n",
      "Iteration 6000, loss = 381.02075626\n",
      "Iteration 6001, loss = 381.00676740\n",
      "Iteration 6002, loss = 380.98735228\n",
      "Iteration 6003, loss = 380.97415723\n",
      "Iteration 6004, loss = 380.95556724\n",
      "Iteration 6005, loss = 380.93714619\n",
      "Iteration 6006, loss = 380.91829534\n",
      "Iteration 6007, loss = 380.90044489\n",
      "Iteration 6008, loss = 380.88154164\n",
      "Iteration 6009, loss = 380.86424839\n",
      "Iteration 6010, loss = 380.84720450\n",
      "Iteration 6011, loss = 380.82747254\n",
      "Iteration 6012, loss = 380.81562408\n",
      "Iteration 6013, loss = 380.79530790\n",
      "Iteration 6014, loss = 380.77860333\n",
      "Iteration 6015, loss = 380.76016837\n",
      "Iteration 6016, loss = 380.74303631\n",
      "Iteration 6017, loss = 380.73052301\n",
      "Iteration 6018, loss = 380.71052208\n",
      "Iteration 6019, loss = 380.69560822\n",
      "Iteration 6020, loss = 380.68065672\n",
      "Iteration 6021, loss = 380.66407503\n",
      "Iteration 6022, loss = 380.64473297\n",
      "Iteration 6023, loss = 380.63154507\n",
      "Iteration 6024, loss = 380.61504275\n",
      "Iteration 6025, loss = 380.59675121\n",
      "Iteration 6026, loss = 380.58195549\n",
      "Iteration 6027, loss = 380.56809013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6028, loss = 380.55227298\n",
      "Iteration 6029, loss = 380.53427745\n",
      "Iteration 6030, loss = 380.51399188\n",
      "Iteration 6031, loss = 380.50295155\n",
      "Iteration 6032, loss = 380.48691643\n",
      "Iteration 6033, loss = 380.46342811\n",
      "Iteration 6034, loss = 380.44399198\n",
      "Iteration 6035, loss = 380.43332374\n",
      "Iteration 6036, loss = 380.41577997\n",
      "Iteration 6037, loss = 380.39280067\n",
      "Iteration 6038, loss = 380.38137209\n",
      "Iteration 6039, loss = 380.36630924\n",
      "Iteration 6040, loss = 380.34516471\n",
      "Iteration 6041, loss = 380.32933361\n",
      "Iteration 6042, loss = 380.31814963\n",
      "Iteration 6043, loss = 380.29945620\n",
      "Iteration 6044, loss = 380.28105934\n",
      "Iteration 6045, loss = 380.26098476\n",
      "Iteration 6046, loss = 380.25053892\n",
      "Iteration 6047, loss = 380.23768492\n",
      "Iteration 6048, loss = 380.21880603\n",
      "Iteration 6049, loss = 380.19389758\n",
      "Iteration 6050, loss = 380.17931938\n",
      "Iteration 6051, loss = 380.16299176\n",
      "Iteration 6052, loss = 380.14320055\n",
      "Iteration 6053, loss = 380.13085587\n",
      "Iteration 6054, loss = 380.11123963\n",
      "Iteration 6055, loss = 380.10356640\n",
      "Iteration 6056, loss = 380.08708678\n",
      "Iteration 6057, loss = 380.06254864\n",
      "Iteration 6058, loss = 380.05020261\n",
      "Iteration 6059, loss = 380.02979112\n",
      "Iteration 6060, loss = 380.01765609\n",
      "Iteration 6061, loss = 379.99966330\n",
      "Iteration 6062, loss = 379.98464470\n",
      "Iteration 6063, loss = 379.96796645\n",
      "Iteration 6064, loss = 379.94594004\n",
      "Iteration 6065, loss = 379.93182227\n",
      "Iteration 6066, loss = 379.91633721\n",
      "Iteration 6067, loss = 379.90418429\n",
      "Iteration 6068, loss = 379.88698282\n",
      "Iteration 6069, loss = 379.87361866\n",
      "Iteration 6070, loss = 379.85949522\n",
      "Iteration 6071, loss = 379.84203993\n",
      "Iteration 6072, loss = 379.82266152\n",
      "Iteration 6073, loss = 379.81180625\n",
      "Iteration 6074, loss = 379.80648647\n",
      "Iteration 6075, loss = 379.79201744\n",
      "Iteration 6076, loss = 379.77725387\n",
      "Iteration 6077, loss = 379.76272210\n",
      "Iteration 6078, loss = 379.74924872\n",
      "Iteration 6079, loss = 379.72635016\n",
      "Iteration 6080, loss = 379.70714312\n",
      "Iteration 6081, loss = 379.68583692\n",
      "Iteration 6082, loss = 379.66370666\n",
      "Iteration 6083, loss = 379.64840595\n",
      "Iteration 6084, loss = 379.63669982\n",
      "Iteration 6085, loss = 379.62228067\n",
      "Iteration 6086, loss = 379.60352072\n",
      "Iteration 6087, loss = 379.57991497\n",
      "Iteration 6088, loss = 379.56015556\n",
      "Iteration 6089, loss = 379.55199796\n",
      "Iteration 6090, loss = 379.53191635\n",
      "Iteration 6091, loss = 379.52345408\n",
      "Iteration 6092, loss = 379.50723514\n",
      "Iteration 6093, loss = 379.48568534\n",
      "Iteration 6094, loss = 379.46764473\n",
      "Iteration 6095, loss = 379.44746317\n",
      "Iteration 6096, loss = 379.43195822\n",
      "Iteration 6097, loss = 379.41748917\n",
      "Iteration 6098, loss = 379.39618571\n",
      "Iteration 6099, loss = 379.38159949\n",
      "Iteration 6100, loss = 379.36380545\n",
      "Iteration 6101, loss = 379.34505196\n",
      "Iteration 6102, loss = 379.33713720\n",
      "Iteration 6103, loss = 379.31541298\n",
      "Iteration 6104, loss = 379.30856751\n",
      "Iteration 6105, loss = 379.29295186\n",
      "Iteration 6106, loss = 379.27128613\n",
      "Iteration 6107, loss = 379.25952769\n",
      "Iteration 6108, loss = 379.23714804\n",
      "Iteration 6109, loss = 379.22695096\n",
      "Iteration 6110, loss = 379.20995799\n",
      "Iteration 6111, loss = 379.19119910\n",
      "Iteration 6112, loss = 379.17902140\n",
      "Iteration 6113, loss = 379.15866794\n",
      "Iteration 6114, loss = 379.14978254\n",
      "Iteration 6115, loss = 379.13051729\n",
      "Iteration 6116, loss = 379.11414690\n",
      "Iteration 6117, loss = 379.09626654\n",
      "Iteration 6118, loss = 379.07322612\n",
      "Iteration 6119, loss = 379.06703641\n",
      "Iteration 6120, loss = 379.05082775\n",
      "Iteration 6121, loss = 379.03131730\n",
      "Iteration 6122, loss = 379.01966526\n",
      "Iteration 6123, loss = 379.00717321\n",
      "Iteration 6124, loss = 378.99544358\n",
      "Iteration 6125, loss = 378.97348451\n",
      "Iteration 6126, loss = 378.95528960\n",
      "Iteration 6127, loss = 378.93848045\n",
      "Iteration 6128, loss = 378.92761808\n",
      "Iteration 6129, loss = 378.91189524\n",
      "Iteration 6130, loss = 378.89167651\n",
      "Iteration 6131, loss = 378.87675343\n",
      "Iteration 6132, loss = 378.85615544\n",
      "Iteration 6133, loss = 378.83520312\n",
      "Iteration 6134, loss = 378.81955449\n",
      "Iteration 6135, loss = 378.80356701\n",
      "Iteration 6136, loss = 378.78654253\n",
      "Iteration 6137, loss = 378.77306069\n",
      "Iteration 6138, loss = 378.75886430\n",
      "Iteration 6139, loss = 378.74205374\n",
      "Iteration 6140, loss = 378.72248524\n",
      "Iteration 6141, loss = 378.70857500\n",
      "Iteration 6142, loss = 378.69179346\n",
      "Iteration 6143, loss = 378.67773526\n",
      "Iteration 6144, loss = 378.66172257\n",
      "Iteration 6145, loss = 378.64671433\n",
      "Iteration 6146, loss = 378.63050883\n",
      "Iteration 6147, loss = 378.61753690\n",
      "Iteration 6148, loss = 378.60148953\n",
      "Iteration 6149, loss = 378.58532534\n",
      "Iteration 6150, loss = 378.56807961\n",
      "Iteration 6151, loss = 378.55356115\n",
      "Iteration 6152, loss = 378.53911625\n",
      "Iteration 6153, loss = 378.52251587\n",
      "Iteration 6154, loss = 378.51035655\n",
      "Iteration 6155, loss = 378.49524207\n",
      "Iteration 6156, loss = 378.48257204\n",
      "Iteration 6157, loss = 378.46439686\n",
      "Iteration 6158, loss = 378.45008541\n",
      "Iteration 6159, loss = 378.43563090\n",
      "Iteration 6160, loss = 378.41681421\n",
      "Iteration 6161, loss = 378.40691922\n",
      "Iteration 6162, loss = 378.39333264\n",
      "Iteration 6163, loss = 378.37782421\n",
      "Iteration 6164, loss = 378.35931140\n",
      "Iteration 6165, loss = 378.34529676\n",
      "Iteration 6166, loss = 378.33065988\n",
      "Iteration 6167, loss = 378.30938301\n",
      "Iteration 6168, loss = 378.30046284\n",
      "Iteration 6169, loss = 378.28817233\n",
      "Iteration 6170, loss = 378.27020317\n",
      "Iteration 6171, loss = 378.25747396\n",
      "Iteration 6172, loss = 378.24813682\n",
      "Iteration 6173, loss = 378.23723901\n",
      "Iteration 6174, loss = 378.21710726\n",
      "Iteration 6175, loss = 378.20747491\n",
      "Iteration 6176, loss = 378.19740487\n",
      "Iteration 6177, loss = 378.18662840\n",
      "Iteration 6178, loss = 378.18200154\n",
      "Iteration 6179, loss = 378.17675848\n",
      "Iteration 6180, loss = 378.16796231\n",
      "Iteration 6181, loss = 378.16330228\n",
      "Iteration 6182, loss = 378.13878232\n",
      "Iteration 6183, loss = 378.11484237\n",
      "Iteration 6184, loss = 378.08237602\n",
      "Iteration 6185, loss = 378.05517820\n",
      "Iteration 6186, loss = 378.03783533\n",
      "Iteration 6187, loss = 378.02434560\n",
      "Iteration 6188, loss = 378.02475178\n",
      "Iteration 6189, loss = 378.01545196\n",
      "Iteration 6190, loss = 377.99540713\n",
      "Iteration 6191, loss = 377.97882786\n",
      "Iteration 6192, loss = 377.95632565\n",
      "Iteration 6193, loss = 377.94021458\n",
      "Iteration 6194, loss = 377.92224532\n",
      "Iteration 6195, loss = 377.91223044\n",
      "Iteration 6196, loss = 377.90102812\n",
      "Iteration 6197, loss = 377.88990182\n",
      "Iteration 6198, loss = 377.87832557\n",
      "Iteration 6199, loss = 377.85897291\n",
      "Iteration 6200, loss = 377.83775003\n",
      "Iteration 6201, loss = 377.82632492\n",
      "Iteration 6202, loss = 377.81009593\n",
      "Iteration 6203, loss = 377.79236825\n",
      "Iteration 6204, loss = 377.78440452\n",
      "Iteration 6205, loss = 377.77269540\n",
      "Iteration 6206, loss = 377.75660991\n",
      "Iteration 6207, loss = 377.73405936\n",
      "Iteration 6208, loss = 377.72811225\n",
      "Iteration 6209, loss = 377.71490910\n",
      "Iteration 6210, loss = 377.69582254\n",
      "Iteration 6211, loss = 377.68039973\n",
      "Iteration 6212, loss = 377.66875541\n",
      "Iteration 6213, loss = 377.65172419\n",
      "Iteration 6214, loss = 377.63380961\n",
      "Iteration 6215, loss = 377.62161894\n",
      "Iteration 6216, loss = 377.61027026\n",
      "Iteration 6217, loss = 377.59309575\n",
      "Iteration 6218, loss = 377.57620603\n",
      "Iteration 6219, loss = 377.56663280\n",
      "Iteration 6220, loss = 377.55118425\n",
      "Iteration 6221, loss = 377.53119788\n",
      "Iteration 6222, loss = 377.51943241\n",
      "Iteration 6223, loss = 377.50600621\n",
      "Iteration 6224, loss = 377.48818557\n",
      "Iteration 6225, loss = 377.47681980\n",
      "Iteration 6226, loss = 377.46532293\n",
      "Iteration 6227, loss = 377.45157443\n",
      "Iteration 6228, loss = 377.43260252\n",
      "Iteration 6229, loss = 377.41922280\n",
      "Iteration 6230, loss = 377.40736004\n",
      "Iteration 6231, loss = 377.38930664\n",
      "Iteration 6232, loss = 377.37973123\n",
      "Iteration 6233, loss = 377.37079247\n",
      "Iteration 6234, loss = 377.35434483\n",
      "Iteration 6235, loss = 377.33547157\n",
      "Iteration 6236, loss = 377.31706957\n",
      "Iteration 6237, loss = 377.30330281\n",
      "Iteration 6238, loss = 377.29037922\n",
      "Iteration 6239, loss = 377.27776923\n",
      "Iteration 6240, loss = 377.26240791\n",
      "Iteration 6241, loss = 377.24961371\n",
      "Iteration 6242, loss = 377.23259223\n",
      "Iteration 6243, loss = 377.22312453\n",
      "Iteration 6244, loss = 377.21242665\n",
      "Iteration 6245, loss = 377.19221997\n",
      "Iteration 6246, loss = 377.17781255\n",
      "Iteration 6247, loss = 377.16979216\n",
      "Iteration 6248, loss = 377.15908463\n",
      "Iteration 6249, loss = 377.14024812\n",
      "Iteration 6250, loss = 377.12496878\n",
      "Iteration 6251, loss = 377.11232010\n",
      "Iteration 6252, loss = 377.09341966\n",
      "Iteration 6253, loss = 377.08361906\n",
      "Iteration 6254, loss = 377.07581398\n",
      "Iteration 6255, loss = 377.06084727\n",
      "Iteration 6256, loss = 377.04027443\n",
      "Iteration 6257, loss = 377.02619988\n",
      "Iteration 6258, loss = 377.01131141\n",
      "Iteration 6259, loss = 376.99256480\n",
      "Iteration 6260, loss = 376.97775952\n",
      "Iteration 6261, loss = 376.97028756\n",
      "Iteration 6262, loss = 376.95562210\n",
      "Iteration 6263, loss = 376.93897644\n",
      "Iteration 6264, loss = 376.93350844\n",
      "Iteration 6265, loss = 376.92323091\n",
      "Iteration 6266, loss = 376.90430195\n",
      "Iteration 6267, loss = 376.88701139\n",
      "Iteration 6268, loss = 376.87750321\n",
      "Iteration 6269, loss = 376.86265211\n",
      "Iteration 6270, loss = 376.84352431\n",
      "Iteration 6271, loss = 376.83546299\n",
      "Iteration 6272, loss = 376.82280688\n",
      "Iteration 6273, loss = 376.80149482\n",
      "Iteration 6274, loss = 376.79128407\n",
      "Iteration 6275, loss = 376.78190466\n",
      "Iteration 6276, loss = 376.76686583\n",
      "Iteration 6277, loss = 376.75040125\n",
      "Iteration 6278, loss = 376.73477203\n",
      "Iteration 6279, loss = 376.72512592\n",
      "Iteration 6280, loss = 376.70677957\n",
      "Iteration 6281, loss = 376.69404548\n",
      "Iteration 6282, loss = 376.67938194\n",
      "Iteration 6283, loss = 376.66484471\n",
      "Iteration 6284, loss = 376.64456241\n",
      "Iteration 6285, loss = 376.63751191\n",
      "Iteration 6286, loss = 376.62543800\n",
      "Iteration 6287, loss = 376.60809512\n",
      "Iteration 6288, loss = 376.58913212\n",
      "Iteration 6289, loss = 376.57886735\n",
      "Iteration 6290, loss = 376.56666831\n",
      "Iteration 6291, loss = 376.54840445\n",
      "Iteration 6292, loss = 376.54343744\n",
      "Iteration 6293, loss = 376.52973476\n",
      "Iteration 6294, loss = 376.50790183\n",
      "Iteration 6295, loss = 376.49066223\n",
      "Iteration 6296, loss = 376.48311147\n",
      "Iteration 6297, loss = 376.46200843\n",
      "Iteration 6298, loss = 376.45006635\n",
      "Iteration 6299, loss = 376.43760248\n",
      "Iteration 6300, loss = 376.42787283\n",
      "Iteration 6301, loss = 376.41288593\n",
      "Iteration 6302, loss = 376.39983569\n",
      "Iteration 6303, loss = 376.38117929\n",
      "Iteration 6304, loss = 376.36889996\n",
      "Iteration 6305, loss = 376.35853834\n",
      "Iteration 6306, loss = 376.33872433\n",
      "Iteration 6307, loss = 376.33756261\n",
      "Iteration 6308, loss = 376.31577895\n",
      "Iteration 6309, loss = 376.30742888\n",
      "Iteration 6310, loss = 376.29827051\n",
      "Iteration 6311, loss = 376.27849663\n",
      "Iteration 6312, loss = 376.26900948\n",
      "Iteration 6313, loss = 376.24598937\n",
      "Iteration 6314, loss = 376.24256222\n",
      "Iteration 6315, loss = 376.22810424\n",
      "Iteration 6316, loss = 376.20536966\n",
      "Iteration 6317, loss = 376.20027649\n",
      "Iteration 6318, loss = 376.18198920\n",
      "Iteration 6319, loss = 376.17589673\n",
      "Iteration 6320, loss = 376.16045495\n",
      "Iteration 6321, loss = 376.14586400\n",
      "Iteration 6322, loss = 376.13004320\n",
      "Iteration 6323, loss = 376.12026936\n",
      "Iteration 6324, loss = 376.10528187\n",
      "Iteration 6325, loss = 376.08648700\n",
      "Iteration 6326, loss = 376.07622331\n",
      "Iteration 6327, loss = 376.06073130\n",
      "Iteration 6328, loss = 376.04521681\n",
      "Iteration 6329, loss = 376.02938203\n",
      "Iteration 6330, loss = 376.02149800\n",
      "Iteration 6331, loss = 376.00347851\n",
      "Iteration 6332, loss = 375.99534890\n",
      "Iteration 6333, loss = 375.98378562\n",
      "Iteration 6334, loss = 375.96397448\n",
      "Iteration 6335, loss = 375.95196057\n",
      "Iteration 6336, loss = 375.93366232\n",
      "Iteration 6337, loss = 375.92749493\n",
      "Iteration 6338, loss = 375.90789818\n",
      "Iteration 6339, loss = 375.89362051\n",
      "Iteration 6340, loss = 375.88978636\n",
      "Iteration 6341, loss = 375.87143784\n",
      "Iteration 6342, loss = 375.86269223\n",
      "Iteration 6343, loss = 375.84059574\n",
      "Iteration 6344, loss = 375.83383391\n",
      "Iteration 6345, loss = 375.82571041\n",
      "Iteration 6346, loss = 375.80219362\n",
      "Iteration 6347, loss = 375.79442228\n",
      "Iteration 6348, loss = 375.77952041\n",
      "Iteration 6349, loss = 375.75758674\n",
      "Iteration 6350, loss = 375.74588039\n",
      "Iteration 6351, loss = 375.73888913\n",
      "Iteration 6352, loss = 375.72420700\n",
      "Iteration 6353, loss = 375.69995077\n",
      "Iteration 6354, loss = 375.69559804\n",
      "Iteration 6355, loss = 375.69058399\n",
      "Iteration 6356, loss = 375.67377157\n",
      "Iteration 6357, loss = 375.65212203\n",
      "Iteration 6358, loss = 375.64253705\n",
      "Iteration 6359, loss = 375.62975725\n",
      "Iteration 6360, loss = 375.61467789\n",
      "Iteration 6361, loss = 375.60317279\n",
      "Iteration 6362, loss = 375.59064452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6363, loss = 375.57338409\n",
      "Iteration 6364, loss = 375.56266745\n",
      "Iteration 6365, loss = 375.55162400\n",
      "Iteration 6366, loss = 375.53276357\n",
      "Iteration 6367, loss = 375.51947338\n",
      "Iteration 6368, loss = 375.50515899\n",
      "Iteration 6369, loss = 375.49262042\n",
      "Iteration 6370, loss = 375.47665224\n",
      "Iteration 6371, loss = 375.45921476\n",
      "Iteration 6372, loss = 375.44687492\n",
      "Iteration 6373, loss = 375.43048957\n",
      "Iteration 6374, loss = 375.42133303\n",
      "Iteration 6375, loss = 375.41177382\n",
      "Iteration 6376, loss = 375.39121323\n",
      "Iteration 6377, loss = 375.38950350\n",
      "Iteration 6378, loss = 375.37562037\n",
      "Iteration 6379, loss = 375.36380394\n",
      "Iteration 6380, loss = 375.34676709\n",
      "Iteration 6381, loss = 375.32922997\n",
      "Iteration 6382, loss = 375.32699212\n",
      "Iteration 6383, loss = 375.32046630\n",
      "Iteration 6384, loss = 375.30433860\n",
      "Iteration 6385, loss = 375.28271500\n",
      "Iteration 6386, loss = 375.26120492\n",
      "Iteration 6387, loss = 375.25192858\n",
      "Iteration 6388, loss = 375.23925124\n",
      "Iteration 6389, loss = 375.22214396\n",
      "Iteration 6390, loss = 375.20518659\n",
      "Iteration 6391, loss = 375.19548196\n",
      "Iteration 6392, loss = 375.17684012\n",
      "Iteration 6393, loss = 375.16308818\n",
      "Iteration 6394, loss = 375.15667668\n",
      "Iteration 6395, loss = 375.13860736\n",
      "Iteration 6396, loss = 375.13355966\n",
      "Iteration 6397, loss = 375.11689652\n",
      "Iteration 6398, loss = 375.10300134\n",
      "Iteration 6399, loss = 375.09467793\n",
      "Iteration 6400, loss = 375.07802658\n",
      "Iteration 6401, loss = 375.06787788\n",
      "Iteration 6402, loss = 375.04807674\n",
      "Iteration 6403, loss = 375.04021715\n",
      "Iteration 6404, loss = 375.02403268\n",
      "Iteration 6405, loss = 375.01248759\n",
      "Iteration 6406, loss = 375.00094140\n",
      "Iteration 6407, loss = 374.98354982\n",
      "Iteration 6408, loss = 374.97130978\n",
      "Iteration 6409, loss = 374.95759411\n",
      "Iteration 6410, loss = 374.94732619\n",
      "Iteration 6411, loss = 374.93123603\n",
      "Iteration 6412, loss = 374.92421639\n",
      "Iteration 6413, loss = 374.91019282\n",
      "Iteration 6414, loss = 374.89903152\n",
      "Iteration 6415, loss = 374.88494116\n",
      "Iteration 6416, loss = 374.86518688\n",
      "Iteration 6417, loss = 374.85298359\n",
      "Iteration 6418, loss = 374.84215614\n",
      "Iteration 6419, loss = 374.83106286\n",
      "Iteration 6420, loss = 374.81245101\n",
      "Iteration 6421, loss = 374.80841972\n",
      "Iteration 6422, loss = 374.79697836\n",
      "Iteration 6423, loss = 374.78909956\n",
      "Iteration 6424, loss = 374.77522077\n",
      "Iteration 6425, loss = 374.75662122\n",
      "Iteration 6426, loss = 374.74240823\n",
      "Iteration 6427, loss = 374.73516647\n",
      "Iteration 6428, loss = 374.72248001\n",
      "Iteration 6429, loss = 374.70702958\n",
      "Iteration 6430, loss = 374.68506750\n",
      "Iteration 6431, loss = 374.67593641\n",
      "Iteration 6432, loss = 374.66720698\n",
      "Iteration 6433, loss = 374.65144187\n",
      "Iteration 6434, loss = 374.63764619\n",
      "Iteration 6435, loss = 374.61579042\n",
      "Iteration 6436, loss = 374.60826866\n",
      "Iteration 6437, loss = 374.59757882\n",
      "Iteration 6438, loss = 374.58426866\n",
      "Iteration 6439, loss = 374.56128956\n",
      "Iteration 6440, loss = 374.55905999\n",
      "Iteration 6441, loss = 374.55068472\n",
      "Iteration 6442, loss = 374.53963123\n",
      "Iteration 6443, loss = 374.52600182\n",
      "Iteration 6444, loss = 374.50487739\n",
      "Iteration 6445, loss = 374.49228132\n",
      "Iteration 6446, loss = 374.48187209\n",
      "Iteration 6447, loss = 374.46813832\n",
      "Iteration 6448, loss = 374.44563341\n",
      "Iteration 6449, loss = 374.43395358\n",
      "Iteration 6450, loss = 374.42630880\n",
      "Iteration 6451, loss = 374.41218471\n",
      "Iteration 6452, loss = 374.40423547\n",
      "Iteration 6453, loss = 374.39440600\n",
      "Iteration 6454, loss = 374.38235066\n",
      "Iteration 6455, loss = 374.37966315\n",
      "Iteration 6456, loss = 374.36350586\n",
      "Iteration 6457, loss = 374.35685415\n",
      "Iteration 6458, loss = 374.35593223\n",
      "Iteration 6459, loss = 374.34404872\n",
      "Iteration 6460, loss = 374.33031190\n",
      "Iteration 6461, loss = 374.31092585\n",
      "Iteration 6462, loss = 374.29198691\n",
      "Iteration 6463, loss = 374.27349211\n",
      "Iteration 6464, loss = 374.25832806\n",
      "Iteration 6465, loss = 374.24539707\n",
      "Iteration 6466, loss = 374.22197891\n",
      "Iteration 6467, loss = 374.21776723\n",
      "Iteration 6468, loss = 374.21354010\n",
      "Iteration 6469, loss = 374.19372369\n",
      "Iteration 6470, loss = 374.18037947\n",
      "Iteration 6471, loss = 374.17071512\n",
      "Iteration 6472, loss = 374.14626373\n",
      "Iteration 6473, loss = 374.12813852\n",
      "Iteration 6474, loss = 374.11244621\n",
      "Iteration 6475, loss = 374.09840764\n",
      "Iteration 6476, loss = 374.09350746\n",
      "Iteration 6477, loss = 374.07879346\n",
      "Iteration 6478, loss = 374.06901831\n",
      "Iteration 6479, loss = 374.05806671\n",
      "Iteration 6480, loss = 374.03930977\n",
      "Iteration 6481, loss = 374.02023336\n",
      "Iteration 6482, loss = 374.01475487\n",
      "Iteration 6483, loss = 373.99893853\n",
      "Iteration 6484, loss = 373.98052656\n",
      "Iteration 6485, loss = 373.97886157\n",
      "Iteration 6486, loss = 373.96896177\n",
      "Iteration 6487, loss = 373.94808368\n",
      "Iteration 6488, loss = 373.93128921\n",
      "Iteration 6489, loss = 373.91918756\n",
      "Iteration 6490, loss = 373.89958131\n",
      "Iteration 6491, loss = 373.89424952\n",
      "Iteration 6492, loss = 373.88341278\n",
      "Iteration 6493, loss = 373.86005869\n",
      "Iteration 6494, loss = 373.85950896\n",
      "Iteration 6495, loss = 373.85646970\n",
      "Iteration 6496, loss = 373.83623815\n",
      "Iteration 6497, loss = 373.81900615\n",
      "Iteration 6498, loss = 373.80112125\n",
      "Iteration 6499, loss = 373.78964855\n",
      "Iteration 6500, loss = 373.77589300\n",
      "Iteration 6501, loss = 373.76249393\n",
      "Iteration 6502, loss = 373.75240820\n",
      "Iteration 6503, loss = 373.73987798\n",
      "Iteration 6504, loss = 373.73127540\n",
      "Iteration 6505, loss = 373.71100140\n",
      "Iteration 6506, loss = 373.70513719\n",
      "Iteration 6507, loss = 373.68760047\n",
      "Iteration 6508, loss = 373.67407301\n",
      "Iteration 6509, loss = 373.66668049\n",
      "Iteration 6510, loss = 373.64531685\n",
      "Iteration 6511, loss = 373.63771380\n",
      "Iteration 6512, loss = 373.62151069\n",
      "Iteration 6513, loss = 373.61229950\n",
      "Iteration 6514, loss = 373.59743534\n",
      "Iteration 6515, loss = 373.58641502\n",
      "Iteration 6516, loss = 373.57510089\n",
      "Iteration 6517, loss = 373.56002081\n",
      "Iteration 6518, loss = 373.55800118\n",
      "Iteration 6519, loss = 373.53965120\n",
      "Iteration 6520, loss = 373.52421417\n",
      "Iteration 6521, loss = 373.51502344\n",
      "Iteration 6522, loss = 373.51041474\n",
      "Iteration 6523, loss = 373.49644707\n",
      "Iteration 6524, loss = 373.47397866\n",
      "Iteration 6525, loss = 373.46567614\n",
      "Iteration 6526, loss = 373.45561118\n",
      "Iteration 6527, loss = 373.44277215\n",
      "Iteration 6528, loss = 373.42258877\n",
      "Iteration 6529, loss = 373.40864308\n",
      "Iteration 6530, loss = 373.39623377\n",
      "Iteration 6531, loss = 373.38840182\n",
      "Iteration 6532, loss = 373.38137591\n",
      "Iteration 6533, loss = 373.36446646\n",
      "Iteration 6534, loss = 373.35044137\n",
      "Iteration 6535, loss = 373.34102610\n",
      "Iteration 6536, loss = 373.32133363\n",
      "Iteration 6537, loss = 373.31430831\n",
      "Iteration 6538, loss = 373.30058006\n",
      "Iteration 6539, loss = 373.28588424\n",
      "Iteration 6540, loss = 373.27500302\n",
      "Iteration 6541, loss = 373.26274708\n",
      "Iteration 6542, loss = 373.24703325\n",
      "Iteration 6543, loss = 373.22869916\n",
      "Iteration 6544, loss = 373.22507186\n",
      "Iteration 6545, loss = 373.20786015\n",
      "Iteration 6546, loss = 373.19065925\n",
      "Iteration 6547, loss = 373.18603441\n",
      "Iteration 6548, loss = 373.17691135\n",
      "Iteration 6549, loss = 373.15705455\n",
      "Iteration 6550, loss = 373.13907767\n",
      "Iteration 6551, loss = 373.13015987\n",
      "Iteration 6552, loss = 373.11827289\n",
      "Iteration 6553, loss = 373.10841822\n",
      "Iteration 6554, loss = 373.09560759\n",
      "Iteration 6555, loss = 373.08097953\n",
      "Iteration 6556, loss = 373.06669831\n",
      "Iteration 6557, loss = 373.06119799\n",
      "Iteration 6558, loss = 373.04699500\n",
      "Iteration 6559, loss = 373.03304240\n",
      "Iteration 6560, loss = 373.01988088\n",
      "Iteration 6561, loss = 373.00972108\n",
      "Iteration 6562, loss = 372.99795719\n",
      "Iteration 6563, loss = 372.98545763\n",
      "Iteration 6564, loss = 372.97955581\n",
      "Iteration 6565, loss = 372.96842555\n",
      "Iteration 6566, loss = 372.95861493\n",
      "Iteration 6567, loss = 372.94572780\n",
      "Iteration 6568, loss = 372.93854826\n",
      "Iteration 6569, loss = 372.92399890\n",
      "Iteration 6570, loss = 372.91440585\n",
      "Iteration 6571, loss = 372.90168593\n",
      "Iteration 6572, loss = 372.89023277\n",
      "Iteration 6573, loss = 372.87665186\n",
      "Iteration 6574, loss = 372.85906112\n",
      "Iteration 6575, loss = 372.84909671\n",
      "Iteration 6576, loss = 372.83821802\n",
      "Iteration 6577, loss = 372.81934085\n",
      "Iteration 6578, loss = 372.81363884\n",
      "Iteration 6579, loss = 372.80352035\n",
      "Iteration 6580, loss = 372.78716178\n",
      "Iteration 6581, loss = 372.77830709\n",
      "Iteration 6582, loss = 372.76339130\n",
      "Iteration 6583, loss = 372.75216460\n",
      "Iteration 6584, loss = 372.74615231\n",
      "Iteration 6585, loss = 372.73081671\n",
      "Iteration 6586, loss = 372.70804557\n",
      "Iteration 6587, loss = 372.70992789\n",
      "Iteration 6588, loss = 372.70004103\n",
      "Iteration 6589, loss = 372.68394068\n",
      "Iteration 6590, loss = 372.66048443\n",
      "Iteration 6591, loss = 372.65948640\n",
      "Iteration 6592, loss = 372.65424648\n",
      "Iteration 6593, loss = 372.63763195\n",
      "Iteration 6594, loss = 372.62157348\n",
      "Iteration 6595, loss = 372.60501099\n",
      "Iteration 6596, loss = 372.60625156\n",
      "Iteration 6597, loss = 372.59655968\n",
      "Iteration 6598, loss = 372.58399094\n",
      "Iteration 6599, loss = 372.56406237\n",
      "Iteration 6600, loss = 372.54855252\n",
      "Iteration 6601, loss = 372.54017768\n",
      "Iteration 6602, loss = 372.52571210\n",
      "Iteration 6603, loss = 372.51308461\n",
      "Iteration 6604, loss = 372.50330041\n",
      "Iteration 6605, loss = 372.49014771\n",
      "Iteration 6606, loss = 372.47777751\n",
      "Iteration 6607, loss = 372.46704471\n",
      "Iteration 6608, loss = 372.46178256\n",
      "Iteration 6609, loss = 372.44611262\n",
      "Iteration 6610, loss = 372.42530352\n",
      "Iteration 6611, loss = 372.42764167\n",
      "Iteration 6612, loss = 372.41790254\n",
      "Iteration 6613, loss = 372.40203705\n",
      "Iteration 6614, loss = 372.38063583\n",
      "Iteration 6615, loss = 372.37946612\n",
      "Iteration 6616, loss = 372.37349057\n",
      "Iteration 6617, loss = 372.35942072\n",
      "Iteration 6618, loss = 372.34046416\n",
      "Iteration 6619, loss = 372.32461894\n",
      "Iteration 6620, loss = 372.31511310\n",
      "Iteration 6621, loss = 372.30534088\n",
      "Iteration 6622, loss = 372.29352186\n",
      "Iteration 6623, loss = 372.27848175\n",
      "Iteration 6624, loss = 372.26333115\n",
      "Iteration 6625, loss = 372.25909256\n",
      "Iteration 6626, loss = 372.25036615\n",
      "Iteration 6627, loss = 372.23291613\n",
      "Iteration 6628, loss = 372.22396759\n",
      "Iteration 6629, loss = 372.21584843\n",
      "Iteration 6630, loss = 372.19154656\n",
      "Iteration 6631, loss = 372.18161469\n",
      "Iteration 6632, loss = 372.18055476\n",
      "Iteration 6633, loss = 372.16807562\n",
      "Iteration 6634, loss = 372.14206133\n",
      "Iteration 6635, loss = 372.13378144\n",
      "Iteration 6636, loss = 372.13000863\n",
      "Iteration 6637, loss = 372.11382775\n",
      "Iteration 6638, loss = 372.10220017\n",
      "Iteration 6639, loss = 372.09178450\n",
      "Iteration 6640, loss = 372.07235023\n",
      "Iteration 6641, loss = 372.06563962\n",
      "Iteration 6642, loss = 372.05078357\n",
      "Iteration 6643, loss = 372.03618917\n",
      "Iteration 6644, loss = 372.02034779\n",
      "Iteration 6645, loss = 372.01236718\n",
      "Iteration 6646, loss = 372.00107038\n",
      "Iteration 6647, loss = 371.99320498\n",
      "Iteration 6648, loss = 371.98414181\n",
      "Iteration 6649, loss = 371.97085113\n",
      "Iteration 6650, loss = 371.95687152\n",
      "Iteration 6651, loss = 371.95601412\n",
      "Iteration 6652, loss = 371.94113099\n",
      "Iteration 6653, loss = 371.93301723\n",
      "Iteration 6654, loss = 371.92517283\n",
      "Iteration 6655, loss = 371.90859537\n",
      "Iteration 6656, loss = 371.89876328\n",
      "Iteration 6657, loss = 371.88676110\n",
      "Iteration 6658, loss = 371.87505451\n",
      "Iteration 6659, loss = 371.85221903\n",
      "Iteration 6660, loss = 371.84967988\n",
      "Iteration 6661, loss = 371.83294833\n",
      "Iteration 6662, loss = 371.82480624\n",
      "Iteration 6663, loss = 371.81518155\n",
      "Iteration 6664, loss = 371.80676714\n",
      "Iteration 6665, loss = 371.79585098\n",
      "Iteration 6666, loss = 371.77525530\n",
      "Iteration 6667, loss = 371.76533136\n",
      "Iteration 6668, loss = 371.76370522\n",
      "Iteration 6669, loss = 371.74837805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6670, loss = 371.72758373\n",
      "Iteration 6671, loss = 371.72591367\n",
      "Iteration 6672, loss = 371.70786403\n",
      "Iteration 6673, loss = 371.69129738\n",
      "Iteration 6674, loss = 371.68574299\n",
      "Iteration 6675, loss = 371.67197101\n",
      "Iteration 6676, loss = 371.65845947\n",
      "Iteration 6677, loss = 371.64721321\n",
      "Iteration 6678, loss = 371.63951797\n",
      "Iteration 6679, loss = 371.63843207\n",
      "Iteration 6680, loss = 371.62224760\n",
      "Iteration 6681, loss = 371.61987783\n",
      "Iteration 6682, loss = 371.60397504\n",
      "Iteration 6683, loss = 371.59165054\n",
      "Iteration 6684, loss = 371.58279153\n",
      "Iteration 6685, loss = 371.57428157\n",
      "Iteration 6686, loss = 371.55882268\n",
      "Iteration 6687, loss = 371.54909261\n",
      "Iteration 6688, loss = 371.53756302\n",
      "Iteration 6689, loss = 371.52065438\n",
      "Iteration 6690, loss = 371.50409455\n",
      "Iteration 6691, loss = 371.49900861\n",
      "Iteration 6692, loss = 371.48571065\n",
      "Iteration 6693, loss = 371.47361669\n",
      "Iteration 6694, loss = 371.44676103\n",
      "Iteration 6695, loss = 371.44941670\n",
      "Iteration 6696, loss = 371.44123353\n",
      "Iteration 6697, loss = 371.43234881\n",
      "Iteration 6698, loss = 371.41926644\n",
      "Iteration 6699, loss = 371.39605703\n",
      "Iteration 6700, loss = 371.38621292\n",
      "Iteration 6701, loss = 371.38252180\n",
      "Iteration 6702, loss = 371.37156438\n",
      "Iteration 6703, loss = 371.35021246\n",
      "Iteration 6704, loss = 371.33597760\n",
      "Iteration 6705, loss = 371.32808407\n",
      "Iteration 6706, loss = 371.31950120\n",
      "Iteration 6707, loss = 371.30230590\n",
      "Iteration 6708, loss = 371.29687641\n",
      "Iteration 6709, loss = 371.28933362\n",
      "Iteration 6710, loss = 371.27044357\n",
      "Iteration 6711, loss = 371.25456966\n",
      "Iteration 6712, loss = 371.24371132\n",
      "Iteration 6713, loss = 371.23392508\n",
      "Iteration 6714, loss = 371.22963026\n",
      "Iteration 6715, loss = 371.21672648\n",
      "Iteration 6716, loss = 371.19929598\n",
      "Iteration 6717, loss = 371.18890947\n",
      "Iteration 6718, loss = 371.18342401\n",
      "Iteration 6719, loss = 371.17734413\n",
      "Iteration 6720, loss = 371.15138926\n",
      "Iteration 6721, loss = 371.14523885\n",
      "Iteration 6722, loss = 371.14173530\n",
      "Iteration 6723, loss = 371.12625325\n",
      "Iteration 6724, loss = 371.10778119\n",
      "Iteration 6725, loss = 371.10947756\n",
      "Iteration 6726, loss = 371.10092904\n",
      "Iteration 6727, loss = 371.08948947\n",
      "Iteration 6728, loss = 371.07836805\n",
      "Iteration 6729, loss = 371.05794156\n",
      "Iteration 6730, loss = 371.05227632\n",
      "Iteration 6731, loss = 371.04671050\n",
      "Iteration 6732, loss = 371.03426799\n",
      "Iteration 6733, loss = 371.01704063\n",
      "Iteration 6734, loss = 370.99581481\n",
      "Iteration 6735, loss = 370.99444694\n",
      "Iteration 6736, loss = 370.98384662\n",
      "Iteration 6737, loss = 370.96701636\n",
      "Iteration 6738, loss = 370.96132247\n",
      "Iteration 6739, loss = 370.95883336\n",
      "Iteration 6740, loss = 370.94202255\n",
      "Iteration 6741, loss = 370.91563063\n",
      "Iteration 6742, loss = 370.91180707\n",
      "Iteration 6743, loss = 370.89817593\n",
      "Iteration 6744, loss = 370.88995552\n",
      "Iteration 6745, loss = 370.88088595\n",
      "Iteration 6746, loss = 370.86302183\n",
      "Iteration 6747, loss = 370.85531828\n",
      "Iteration 6748, loss = 370.85265869\n",
      "Iteration 6749, loss = 370.83615158\n",
      "Iteration 6750, loss = 370.82335111\n",
      "Iteration 6751, loss = 370.81894702\n",
      "Iteration 6752, loss = 370.81455284\n",
      "Iteration 6753, loss = 370.79811643\n",
      "Iteration 6754, loss = 370.77638260\n",
      "Iteration 6755, loss = 370.77461335\n",
      "Iteration 6756, loss = 370.77275703\n",
      "Iteration 6757, loss = 370.76267875\n",
      "Iteration 6758, loss = 370.74802588\n",
      "Iteration 6759, loss = 370.72962110\n",
      "Iteration 6760, loss = 370.73294033\n",
      "Iteration 6761, loss = 370.73016951\n",
      "Iteration 6762, loss = 370.72078015\n",
      "Iteration 6763, loss = 370.70676721\n",
      "Iteration 6764, loss = 370.68325672\n",
      "Iteration 6765, loss = 370.69286967\n",
      "Iteration 6766, loss = 370.69112732\n",
      "Iteration 6767, loss = 370.67791451\n",
      "Iteration 6768, loss = 370.65908954\n",
      "Iteration 6769, loss = 370.63937709\n",
      "Iteration 6770, loss = 370.61480626\n",
      "Iteration 6771, loss = 370.61304946\n",
      "Iteration 6772, loss = 370.60731083\n",
      "Iteration 6773, loss = 370.59908332\n",
      "Iteration 6774, loss = 370.58186518\n",
      "Iteration 6775, loss = 370.56491884\n",
      "Iteration 6776, loss = 370.55867278\n",
      "Iteration 6777, loss = 370.56029378\n",
      "Iteration 6778, loss = 370.54927596\n",
      "Iteration 6779, loss = 370.52850677\n",
      "Iteration 6780, loss = 370.51157944\n",
      "Iteration 6781, loss = 370.50438538\n",
      "Iteration 6782, loss = 370.49557276\n",
      "Iteration 6783, loss = 370.47974343\n",
      "Iteration 6784, loss = 370.46230160\n",
      "Iteration 6785, loss = 370.45795135\n",
      "Iteration 6786, loss = 370.45250566\n",
      "Iteration 6787, loss = 370.44169430\n",
      "Iteration 6788, loss = 370.42489381\n",
      "Iteration 6789, loss = 370.41973351\n",
      "Iteration 6790, loss = 370.40969295\n",
      "Iteration 6791, loss = 370.39681431\n",
      "Iteration 6792, loss = 370.38134128\n",
      "Iteration 6793, loss = 370.37127894\n",
      "Iteration 6794, loss = 370.35175983\n",
      "Iteration 6795, loss = 370.34881232\n",
      "Iteration 6796, loss = 370.34509954\n",
      "Iteration 6797, loss = 370.33255917\n",
      "Iteration 6798, loss = 370.32370856\n",
      "Iteration 6799, loss = 370.31435063\n",
      "Iteration 6800, loss = 370.30036600\n",
      "Iteration 6801, loss = 370.28616886\n",
      "Iteration 6802, loss = 370.28585133\n",
      "Iteration 6803, loss = 370.28066593\n",
      "Iteration 6804, loss = 370.26326825\n",
      "Iteration 6805, loss = 370.25033595\n",
      "Iteration 6806, loss = 370.23631799\n",
      "Iteration 6807, loss = 370.23542161\n",
      "Iteration 6808, loss = 370.22914627\n",
      "Iteration 6809, loss = 370.21408533\n",
      "Iteration 6810, loss = 370.19557015\n",
      "Iteration 6811, loss = 370.18784758\n",
      "Iteration 6812, loss = 370.17529900\n",
      "Iteration 6813, loss = 370.16646680\n",
      "Iteration 6814, loss = 370.16292821\n",
      "Iteration 6815, loss = 370.14757673\n",
      "Iteration 6816, loss = 370.13690122\n",
      "Iteration 6817, loss = 370.12965170\n",
      "Iteration 6818, loss = 370.11499066\n",
      "Iteration 6819, loss = 370.10805874\n",
      "Iteration 6820, loss = 370.09916026\n",
      "Iteration 6821, loss = 370.08414303\n",
      "Iteration 6822, loss = 370.07075870\n",
      "Iteration 6823, loss = 370.06725785\n",
      "Iteration 6824, loss = 370.05570358\n",
      "Iteration 6825, loss = 370.03835784\n",
      "Iteration 6826, loss = 370.03401977\n",
      "Iteration 6827, loss = 370.02881262\n",
      "Iteration 6828, loss = 370.02167435\n",
      "Iteration 6829, loss = 370.00975703\n",
      "Iteration 6830, loss = 369.99669323\n",
      "Iteration 6831, loss = 369.99002761\n",
      "Iteration 6832, loss = 369.97522509\n",
      "Iteration 6833, loss = 369.96301012\n",
      "Iteration 6834, loss = 369.95352003\n",
      "Iteration 6835, loss = 369.94219051\n",
      "Iteration 6836, loss = 369.93389320\n",
      "Iteration 6837, loss = 369.92201420\n",
      "Iteration 6838, loss = 369.91098622\n",
      "Iteration 6839, loss = 369.91060222\n",
      "Iteration 6840, loss = 369.89894661\n",
      "Iteration 6841, loss = 369.87858518\n",
      "Iteration 6842, loss = 369.88194416\n",
      "Iteration 6843, loss = 369.87646757\n",
      "Iteration 6844, loss = 369.86074933\n",
      "Iteration 6845, loss = 369.84219588\n",
      "Iteration 6846, loss = 369.84448077\n",
      "Iteration 6847, loss = 369.83704507\n",
      "Iteration 6848, loss = 369.82027537\n",
      "Iteration 6849, loss = 369.79730835\n",
      "Iteration 6850, loss = 369.80116386\n",
      "Iteration 6851, loss = 369.80016282\n",
      "Iteration 6852, loss = 369.78470710\n",
      "Iteration 6853, loss = 369.77370120\n",
      "Iteration 6854, loss = 369.75631958\n",
      "Iteration 6855, loss = 369.74907272\n",
      "Iteration 6856, loss = 369.73079028\n",
      "Iteration 6857, loss = 369.72932409\n",
      "Iteration 6858, loss = 369.71865206\n",
      "Iteration 6859, loss = 369.70716568\n",
      "Iteration 6860, loss = 369.70014815\n",
      "Iteration 6861, loss = 369.68685222\n",
      "Iteration 6862, loss = 369.67877507\n",
      "Iteration 6863, loss = 369.66641664\n",
      "Iteration 6864, loss = 369.66859672\n",
      "Iteration 6865, loss = 369.65716799\n",
      "Iteration 6866, loss = 369.64124442\n",
      "Iteration 6867, loss = 369.63443894\n",
      "Iteration 6868, loss = 369.62570197\n",
      "Iteration 6869, loss = 369.61206825\n",
      "Iteration 6870, loss = 369.59284319\n",
      "Iteration 6871, loss = 369.58158699\n",
      "Iteration 6872, loss = 369.57408220\n",
      "Iteration 6873, loss = 369.56368457\n",
      "Iteration 6874, loss = 369.55469845\n",
      "Iteration 6875, loss = 369.54193443\n",
      "Iteration 6876, loss = 369.53651192\n",
      "Iteration 6877, loss = 369.52264844\n",
      "Iteration 6878, loss = 369.51446171\n",
      "Iteration 6879, loss = 369.50241304\n",
      "Iteration 6880, loss = 369.50551036\n",
      "Iteration 6881, loss = 369.48673921\n",
      "Iteration 6882, loss = 369.47706085\n",
      "Iteration 6883, loss = 369.46990943\n",
      "Iteration 6884, loss = 369.46066548\n",
      "Iteration 6885, loss = 369.44379824\n",
      "Iteration 6886, loss = 369.43673109\n",
      "Iteration 6887, loss = 369.43792544\n",
      "Iteration 6888, loss = 369.41882184\n",
      "Iteration 6889, loss = 369.40019641\n",
      "Iteration 6890, loss = 369.40581406\n",
      "Iteration 6891, loss = 369.40811120\n",
      "Iteration 6892, loss = 369.39488638\n",
      "Iteration 6893, loss = 369.36647129\n",
      "Iteration 6894, loss = 369.35821590\n",
      "Iteration 6895, loss = 369.35897126\n",
      "Iteration 6896, loss = 369.34496721\n",
      "Iteration 6897, loss = 369.32470991\n",
      "Iteration 6898, loss = 369.33088913\n",
      "Iteration 6899, loss = 369.33127351\n",
      "Iteration 6900, loss = 369.31011226\n",
      "Iteration 6901, loss = 369.28715473\n",
      "Iteration 6902, loss = 369.28854961\n",
      "Iteration 6903, loss = 369.29391239\n",
      "Iteration 6904, loss = 369.27500234\n",
      "Iteration 6905, loss = 369.25783199\n",
      "Iteration 6906, loss = 369.24001729\n",
      "Iteration 6907, loss = 369.24335429\n",
      "Iteration 6908, loss = 369.24005571\n",
      "Iteration 6909, loss = 369.23478398\n",
      "Iteration 6910, loss = 369.21243392\n",
      "Iteration 6911, loss = 369.18524935\n",
      "Iteration 6912, loss = 369.18624778\n",
      "Iteration 6913, loss = 369.18664273\n",
      "Iteration 6914, loss = 369.17837441\n",
      "Iteration 6915, loss = 369.16960338\n",
      "Iteration 6916, loss = 369.15125371\n",
      "Iteration 6917, loss = 369.13681494\n",
      "Iteration 6918, loss = 369.12826979\n",
      "Iteration 6919, loss = 369.11609850\n",
      "Iteration 6920, loss = 369.09907885\n",
      "Iteration 6921, loss = 369.09338867\n",
      "Iteration 6922, loss = 369.08725069\n",
      "Iteration 6923, loss = 369.07398279\n",
      "Iteration 6924, loss = 369.06545713\n",
      "Iteration 6925, loss = 369.06125529\n",
      "Iteration 6926, loss = 369.05930920\n",
      "Iteration 6927, loss = 369.04449177\n",
      "Iteration 6928, loss = 369.02132876\n",
      "Iteration 6929, loss = 369.02110411\n",
      "Iteration 6930, loss = 369.01505564\n",
      "Iteration 6931, loss = 369.01171893\n",
      "Iteration 6932, loss = 368.99603162\n",
      "Iteration 6933, loss = 368.96829084\n",
      "Iteration 6934, loss = 368.97609935\n",
      "Iteration 6935, loss = 368.97721867\n",
      "Iteration 6936, loss = 368.97460681\n",
      "Iteration 6937, loss = 368.95618116\n",
      "Iteration 6938, loss = 368.92468221\n",
      "Iteration 6939, loss = 368.92033520\n",
      "Iteration 6940, loss = 368.91806640\n",
      "Iteration 6941, loss = 368.91196861\n",
      "Iteration 6942, loss = 368.89946663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6943, loss = 368.88161059\n",
      "Iteration 6944, loss = 368.88258466\n",
      "Iteration 6945, loss = 368.88058049\n",
      "Iteration 6946, loss = 368.86682403\n",
      "Iteration 6947, loss = 368.85038164\n",
      "Iteration 6948, loss = 368.83303954\n",
      "Iteration 6949, loss = 368.82214129\n",
      "Iteration 6950, loss = 368.80851523\n",
      "Iteration 6951, loss = 368.79885741\n",
      "Iteration 6952, loss = 368.79211567\n",
      "Iteration 6953, loss = 368.78671864\n",
      "Iteration 6954, loss = 368.77501763\n",
      "Iteration 6955, loss = 368.76551607\n",
      "Iteration 6956, loss = 368.75685135\n",
      "Iteration 6957, loss = 368.75608927\n",
      "Iteration 6958, loss = 368.73187399\n",
      "Iteration 6959, loss = 368.72990324\n",
      "Iteration 6960, loss = 368.70495955\n",
      "Iteration 6961, loss = 368.70754755\n",
      "Iteration 6962, loss = 368.68837877\n",
      "Iteration 6963, loss = 368.68159723\n",
      "Iteration 6964, loss = 368.68107625\n",
      "Iteration 6965, loss = 368.65903669\n",
      "Iteration 6966, loss = 368.65424168\n",
      "Iteration 6967, loss = 368.63773372\n",
      "Iteration 6968, loss = 368.62721431\n",
      "Iteration 6969, loss = 368.62855622\n",
      "Iteration 6970, loss = 368.60635870\n",
      "Iteration 6971, loss = 368.61377141\n",
      "Iteration 6972, loss = 368.59336437\n",
      "Iteration 6973, loss = 368.58493451\n",
      "Iteration 6974, loss = 368.57575171\n",
      "Iteration 6975, loss = 368.56869668\n",
      "Iteration 6976, loss = 368.56094350\n",
      "Iteration 6977, loss = 368.54207873\n",
      "Iteration 6978, loss = 368.54420350\n",
      "Iteration 6979, loss = 368.52411574\n",
      "Iteration 6980, loss = 368.50888944\n",
      "Iteration 6981, loss = 368.51612822\n",
      "Iteration 6982, loss = 368.49214402\n",
      "Iteration 6983, loss = 368.49236308\n",
      "Iteration 6984, loss = 368.47143432\n",
      "Iteration 6985, loss = 368.46637835\n",
      "Iteration 6986, loss = 368.44684872\n",
      "Iteration 6987, loss = 368.44280490\n",
      "Iteration 6988, loss = 368.43031155\n",
      "Iteration 6989, loss = 368.43259982\n",
      "Iteration 6990, loss = 368.42348589\n",
      "Iteration 6991, loss = 368.41542047\n",
      "Iteration 6992, loss = 368.39672200\n",
      "Iteration 6993, loss = 368.39572555\n",
      "Iteration 6994, loss = 368.39109046\n",
      "Iteration 6995, loss = 368.37802441\n",
      "Iteration 6996, loss = 368.35335399\n",
      "Iteration 6997, loss = 368.34932191\n",
      "Iteration 6998, loss = 368.35283893\n",
      "Iteration 6999, loss = 368.33795394\n",
      "Iteration 7000, loss = 368.31369661\n",
      "Iteration 7001, loss = 368.31004844\n",
      "Iteration 7002, loss = 368.31310519\n",
      "Iteration 7003, loss = 368.30414778\n",
      "Iteration 7004, loss = 368.27692772\n",
      "Iteration 7005, loss = 368.27256256\n",
      "Iteration 7006, loss = 368.27852003\n",
      "Iteration 7007, loss = 368.27085880\n",
      "Iteration 7008, loss = 368.25386141\n",
      "Iteration 7009, loss = 368.23474497\n",
      "Iteration 7010, loss = 368.24537735\n",
      "Iteration 7011, loss = 368.25034044\n",
      "Iteration 7012, loss = 368.24009795\n",
      "Iteration 7013, loss = 368.22433547\n",
      "Iteration 7014, loss = 368.20345934\n",
      "Iteration 7015, loss = 368.19570841\n",
      "Iteration 7016, loss = 368.19809503\n",
      "Iteration 7017, loss = 368.18388423\n",
      "Iteration 7018, loss = 368.16378647\n",
      "Iteration 7019, loss = 368.13745386\n",
      "Iteration 7020, loss = 368.14057286\n",
      "Iteration 7021, loss = 368.12984727\n",
      "Iteration 7022, loss = 368.12101048\n",
      "Iteration 7023, loss = 368.10567116\n",
      "Iteration 7024, loss = 368.07960900\n",
      "Iteration 7025, loss = 368.08562970\n",
      "Iteration 7026, loss = 368.08592844\n",
      "Iteration 7027, loss = 368.08547423\n",
      "Iteration 7028, loss = 368.06771096\n",
      "Iteration 7029, loss = 368.04304894\n",
      "Iteration 7030, loss = 368.03335400\n",
      "Iteration 7031, loss = 368.02666119\n",
      "Iteration 7032, loss = 368.01430902\n",
      "Iteration 7033, loss = 367.99344754\n",
      "Iteration 7034, loss = 367.98586100\n",
      "Iteration 7035, loss = 367.99208005\n",
      "Iteration 7036, loss = 367.98242297\n",
      "Iteration 7037, loss = 367.96159822\n",
      "Iteration 7038, loss = 367.95252863\n",
      "Iteration 7039, loss = 367.95060297\n",
      "Iteration 7040, loss = 367.93290495\n",
      "Iteration 7041, loss = 367.92683770\n",
      "Iteration 7042, loss = 367.90720339\n",
      "Iteration 7043, loss = 367.91131652\n",
      "Iteration 7044, loss = 367.89147667\n",
      "Iteration 7045, loss = 367.88833362\n",
      "Iteration 7046, loss = 367.86344737\n",
      "Iteration 7047, loss = 367.87228697\n",
      "Iteration 7048, loss = 367.84811883\n",
      "Iteration 7049, loss = 367.85059943\n",
      "Iteration 7050, loss = 367.83345896\n",
      "Iteration 7051, loss = 367.81716487\n",
      "Iteration 7052, loss = 367.81492689\n",
      "Iteration 7053, loss = 367.79671473\n",
      "Iteration 7054, loss = 367.78916476\n",
      "Iteration 7055, loss = 367.77827387\n",
      "Iteration 7056, loss = 367.77259194\n",
      "Iteration 7057, loss = 367.75263822\n",
      "Iteration 7058, loss = 367.76257238\n",
      "Iteration 7059, loss = 367.75151977\n",
      "Iteration 7060, loss = 367.74478812\n",
      "Iteration 7061, loss = 367.71998773\n",
      "Iteration 7062, loss = 367.71784290\n",
      "Iteration 7063, loss = 367.71685654\n",
      "Iteration 7064, loss = 367.70562898\n",
      "Iteration 7065, loss = 367.69817730\n",
      "Iteration 7066, loss = 367.67940174\n",
      "Iteration 7067, loss = 367.66999532\n",
      "Iteration 7068, loss = 367.65888679\n",
      "Iteration 7069, loss = 367.64826984\n",
      "Iteration 7070, loss = 367.63755453\n",
      "Iteration 7071, loss = 367.62465066\n",
      "Iteration 7072, loss = 367.61964994\n",
      "Iteration 7073, loss = 367.60794533\n",
      "Iteration 7074, loss = 367.59878605\n",
      "Iteration 7075, loss = 367.58347597\n",
      "Iteration 7076, loss = 367.58946369\n",
      "Iteration 7077, loss = 367.59198123\n",
      "Iteration 7078, loss = 367.58104245\n",
      "Iteration 7079, loss = 367.55979444\n",
      "Iteration 7080, loss = 367.53610537\n",
      "Iteration 7081, loss = 367.53267922\n",
      "Iteration 7082, loss = 367.53668243\n",
      "Iteration 7083, loss = 367.52578365\n",
      "Iteration 7084, loss = 367.51169233\n",
      "Iteration 7085, loss = 367.49224640\n",
      "Iteration 7086, loss = 367.48249770\n",
      "Iteration 7087, loss = 367.47920624\n",
      "Iteration 7088, loss = 367.47251173\n",
      "Iteration 7089, loss = 367.46083844\n",
      "Iteration 7090, loss = 367.43893371\n",
      "Iteration 7091, loss = 367.44928194\n",
      "Iteration 7092, loss = 367.44392469\n",
      "Iteration 7093, loss = 367.42780509\n",
      "Iteration 7094, loss = 367.41637987\n",
      "Iteration 7095, loss = 367.39469654\n",
      "Iteration 7096, loss = 367.40647315\n",
      "Iteration 7097, loss = 367.40644296\n",
      "Iteration 7098, loss = 367.40470270\n",
      "Iteration 7099, loss = 367.39344866\n",
      "Iteration 7100, loss = 367.37220071\n",
      "Iteration 7101, loss = 367.36574823\n",
      "Iteration 7102, loss = 367.35635438\n",
      "Iteration 7103, loss = 367.34238163\n",
      "Iteration 7104, loss = 367.32345037\n",
      "Iteration 7105, loss = 367.31333243\n",
      "Iteration 7106, loss = 367.30092961\n",
      "Iteration 7107, loss = 367.28661994\n",
      "Iteration 7108, loss = 367.28829989\n",
      "Iteration 7109, loss = 367.28527015\n",
      "Iteration 7110, loss = 367.26151639\n",
      "Iteration 7111, loss = 367.24574987\n",
      "Iteration 7112, loss = 367.24069385\n",
      "Iteration 7113, loss = 367.22192391\n",
      "Iteration 7114, loss = 367.21593293\n",
      "Iteration 7115, loss = 367.21950440\n",
      "Iteration 7116, loss = 367.21677617\n",
      "Iteration 7117, loss = 367.20280622\n",
      "Iteration 7118, loss = 367.18789845\n",
      "Iteration 7119, loss = 367.15925053\n",
      "Iteration 7120, loss = 367.16531583\n",
      "Iteration 7121, loss = 367.16071729\n",
      "Iteration 7122, loss = 367.15876816\n",
      "Iteration 7123, loss = 367.14756850\n",
      "Iteration 7124, loss = 367.12233267\n",
      "Iteration 7125, loss = 367.11114085\n",
      "Iteration 7126, loss = 367.11890514\n",
      "Iteration 7127, loss = 367.10676378\n",
      "Iteration 7128, loss = 367.07989913\n",
      "Iteration 7129, loss = 367.06358120\n",
      "Iteration 7130, loss = 367.06167483\n",
      "Iteration 7131, loss = 367.05075761\n",
      "Iteration 7132, loss = 367.02452502\n",
      "Iteration 7133, loss = 367.02167277\n",
      "Iteration 7134, loss = 367.01204825\n",
      "Iteration 7135, loss = 367.00525545\n",
      "Iteration 7136, loss = 366.99508442\n",
      "Iteration 7137, loss = 366.98352938\n",
      "Iteration 7138, loss = 366.98092203\n",
      "Iteration 7139, loss = 366.97695658\n",
      "Iteration 7140, loss = 366.95728207\n",
      "Iteration 7141, loss = 366.95110358\n",
      "Iteration 7142, loss = 366.95055531\n",
      "Iteration 7143, loss = 366.93734359\n",
      "Iteration 7144, loss = 366.91770195\n",
      "Iteration 7145, loss = 366.92444033\n",
      "Iteration 7146, loss = 366.91681556\n",
      "Iteration 7147, loss = 366.90593459\n",
      "Iteration 7148, loss = 366.88265617\n",
      "Iteration 7149, loss = 366.87066516\n",
      "Iteration 7150, loss = 366.86481951\n",
      "Iteration 7151, loss = 366.84246995\n",
      "Iteration 7152, loss = 366.84814852\n",
      "Iteration 7153, loss = 366.84148202\n",
      "Iteration 7154, loss = 366.82490952\n",
      "Iteration 7155, loss = 366.82470402\n",
      "Iteration 7156, loss = 366.82325805\n",
      "Iteration 7157, loss = 366.80101218\n",
      "Iteration 7158, loss = 366.77919254\n",
      "Iteration 7159, loss = 366.78199989\n",
      "Iteration 7160, loss = 366.77862320\n",
      "Iteration 7161, loss = 366.76743606\n",
      "Iteration 7162, loss = 366.74645122\n",
      "Iteration 7163, loss = 366.73169983\n",
      "Iteration 7164, loss = 366.72432554\n",
      "Iteration 7165, loss = 366.70711123\n",
      "Iteration 7166, loss = 366.70186690\n",
      "Iteration 7167, loss = 366.69247993\n",
      "Iteration 7168, loss = 366.68194079\n",
      "Iteration 7169, loss = 366.68143596\n",
      "Iteration 7170, loss = 366.67274587\n",
      "Iteration 7171, loss = 366.66141767\n",
      "Iteration 7172, loss = 366.64253653\n",
      "Iteration 7173, loss = 366.64693848\n",
      "Iteration 7174, loss = 366.64864540\n",
      "Iteration 7175, loss = 366.64032690\n",
      "Iteration 7176, loss = 366.61285341\n",
      "Iteration 7177, loss = 366.59124886\n",
      "Iteration 7178, loss = 366.58970584\n",
      "Iteration 7179, loss = 366.57690451\n",
      "Iteration 7180, loss = 366.56637966\n",
      "Iteration 7181, loss = 366.57069670\n",
      "Iteration 7182, loss = 366.55604193\n",
      "Iteration 7183, loss = 366.55083802\n",
      "Iteration 7184, loss = 366.52877179\n",
      "Iteration 7185, loss = 366.51601009\n",
      "Iteration 7186, loss = 366.52300103\n",
      "Iteration 7187, loss = 366.51598703\n",
      "Iteration 7188, loss = 366.49521454\n",
      "Iteration 7189, loss = 366.49114782\n",
      "Iteration 7190, loss = 366.48758047\n",
      "Iteration 7191, loss = 366.47087027\n",
      "Iteration 7192, loss = 366.44320943\n",
      "Iteration 7193, loss = 366.45051326\n",
      "Iteration 7194, loss = 366.45356717\n",
      "Iteration 7195, loss = 366.43848895\n",
      "Iteration 7196, loss = 366.42468639\n",
      "Iteration 7197, loss = 366.40834384\n",
      "Iteration 7198, loss = 366.41410234\n",
      "Iteration 7199, loss = 366.40357909\n",
      "Iteration 7200, loss = 366.40278194\n",
      "Iteration 7201, loss = 366.38641730\n",
      "Iteration 7202, loss = 366.36463197\n",
      "Iteration 7203, loss = 366.34906822\n",
      "Iteration 7204, loss = 366.34285438\n",
      "Iteration 7205, loss = 366.33406409\n",
      "Iteration 7206, loss = 366.31634951\n",
      "Iteration 7207, loss = 366.28980912\n",
      "Iteration 7208, loss = 366.28833126\n",
      "Iteration 7209, loss = 366.28391699\n",
      "Iteration 7210, loss = 366.28061552\n",
      "Iteration 7211, loss = 366.27018858\n",
      "Iteration 7212, loss = 366.26055795\n",
      "Iteration 7213, loss = 366.24201863\n",
      "Iteration 7214, loss = 366.23867930\n",
      "Iteration 7215, loss = 366.23499830\n",
      "Iteration 7216, loss = 366.21337874\n",
      "Iteration 7217, loss = 366.20615807\n",
      "Iteration 7218, loss = 366.20530202\n",
      "Iteration 7219, loss = 366.18796386\n",
      "Iteration 7220, loss = 366.18670049\n",
      "Iteration 7221, loss = 366.17751242\n",
      "Iteration 7222, loss = 366.15824024\n",
      "Iteration 7223, loss = 366.15268940\n",
      "Iteration 7224, loss = 366.15059491\n",
      "Iteration 7225, loss = 366.12564342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7226, loss = 366.11531975\n",
      "Iteration 7227, loss = 366.11439513\n",
      "Iteration 7228, loss = 366.09846130\n",
      "Iteration 7229, loss = 366.08127661\n",
      "Iteration 7230, loss = 366.07456221\n",
      "Iteration 7231, loss = 366.06038291\n",
      "Iteration 7232, loss = 366.06385992\n",
      "Iteration 7233, loss = 366.05005548\n",
      "Iteration 7234, loss = 366.03824558\n",
      "Iteration 7235, loss = 366.02622038\n",
      "Iteration 7236, loss = 366.01114540\n",
      "Iteration 7237, loss = 365.99912794\n",
      "Iteration 7238, loss = 365.99614524\n",
      "Iteration 7239, loss = 365.98622515\n",
      "Iteration 7240, loss = 365.96892967\n",
      "Iteration 7241, loss = 365.96329659\n",
      "Iteration 7242, loss = 365.96266158\n",
      "Iteration 7243, loss = 365.94306379\n",
      "Iteration 7244, loss = 365.94091677\n",
      "Iteration 7245, loss = 365.93650481\n",
      "Iteration 7246, loss = 365.92548826\n",
      "Iteration 7247, loss = 365.90362813\n",
      "Iteration 7248, loss = 365.90931758\n",
      "Iteration 7249, loss = 365.90546383\n",
      "Iteration 7250, loss = 365.89377934\n",
      "Iteration 7251, loss = 365.87129545\n",
      "Iteration 7252, loss = 365.84368369\n",
      "Iteration 7253, loss = 365.84472369\n",
      "Iteration 7254, loss = 365.83664072\n",
      "Iteration 7255, loss = 365.82222091\n",
      "Iteration 7256, loss = 365.80673108\n",
      "Iteration 7257, loss = 365.81196474\n",
      "Iteration 7258, loss = 365.79657879\n",
      "Iteration 7259, loss = 365.79831305\n",
      "Iteration 7260, loss = 365.77556700\n",
      "Iteration 7261, loss = 365.77980985\n",
      "Iteration 7262, loss = 365.75275724\n",
      "Iteration 7263, loss = 365.77035222\n",
      "Iteration 7264, loss = 365.73915876\n",
      "Iteration 7265, loss = 365.75568436\n",
      "Iteration 7266, loss = 365.71841763\n",
      "Iteration 7267, loss = 365.73187862\n",
      "Iteration 7268, loss = 365.70798769\n",
      "Iteration 7269, loss = 365.71322815\n",
      "Iteration 7270, loss = 365.69190291\n",
      "Iteration 7271, loss = 365.66963840\n",
      "Iteration 7272, loss = 365.66819366\n",
      "Iteration 7273, loss = 365.65006393\n",
      "Iteration 7274, loss = 365.65434255\n",
      "Iteration 7275, loss = 365.62848239\n",
      "Iteration 7276, loss = 365.62389670\n",
      "Iteration 7277, loss = 365.61664604\n",
      "Iteration 7278, loss = 365.60383361\n",
      "Iteration 7279, loss = 365.59427606\n",
      "Iteration 7280, loss = 365.58968399\n",
      "Iteration 7281, loss = 365.57852911\n",
      "Iteration 7282, loss = 365.55328529\n",
      "Iteration 7283, loss = 365.54827881\n",
      "Iteration 7284, loss = 365.54133698\n",
      "Iteration 7285, loss = 365.52110113\n",
      "Iteration 7286, loss = 365.51574352\n",
      "Iteration 7287, loss = 365.50263532\n",
      "Iteration 7288, loss = 365.49222332\n",
      "Iteration 7289, loss = 365.47915828\n",
      "Iteration 7290, loss = 365.47148133\n",
      "Iteration 7291, loss = 365.46667039\n",
      "Iteration 7292, loss = 365.46614841\n",
      "Iteration 7293, loss = 365.45250060\n",
      "Iteration 7294, loss = 365.43603855\n",
      "Iteration 7295, loss = 365.42964051\n",
      "Iteration 7296, loss = 365.42473204\n",
      "Iteration 7297, loss = 365.41482279\n",
      "Iteration 7298, loss = 365.39097357\n",
      "Iteration 7299, loss = 365.39164936\n",
      "Iteration 7300, loss = 365.36924684\n",
      "Iteration 7301, loss = 365.36836063\n",
      "Iteration 7302, loss = 365.35446705\n",
      "Iteration 7303, loss = 365.34543045\n",
      "Iteration 7304, loss = 365.33798286\n",
      "Iteration 7305, loss = 365.32972725\n",
      "Iteration 7306, loss = 365.30953673\n",
      "Iteration 7307, loss = 365.30047728\n",
      "Iteration 7308, loss = 365.30158059\n",
      "Iteration 7309, loss = 365.30119788\n",
      "Iteration 7310, loss = 365.29656121\n",
      "Iteration 7311, loss = 365.28256616\n",
      "Iteration 7312, loss = 365.28595634\n",
      "Iteration 7313, loss = 365.27001382\n",
      "Iteration 7314, loss = 365.25789310\n",
      "Iteration 7315, loss = 365.23465951\n",
      "Iteration 7316, loss = 365.24087413\n",
      "Iteration 7317, loss = 365.21455948\n",
      "Iteration 7318, loss = 365.18735029\n",
      "Iteration 7319, loss = 365.17522016\n",
      "Iteration 7320, loss = 365.17391670\n",
      "Iteration 7321, loss = 365.15959831\n",
      "Iteration 7322, loss = 365.14837430\n",
      "Iteration 7323, loss = 365.12991877\n",
      "Iteration 7324, loss = 365.13122949\n",
      "Iteration 7325, loss = 365.12170677\n",
      "Iteration 7326, loss = 365.09949782\n",
      "Iteration 7327, loss = 365.09745515\n",
      "Iteration 7328, loss = 365.09847910\n",
      "Iteration 7329, loss = 365.08088572\n",
      "Iteration 7330, loss = 365.06057382\n",
      "Iteration 7331, loss = 365.06061962\n",
      "Iteration 7332, loss = 365.05929520\n",
      "Iteration 7333, loss = 365.03587877\n",
      "Iteration 7334, loss = 365.02740750\n",
      "Iteration 7335, loss = 365.02189458\n",
      "Iteration 7336, loss = 364.98483665\n",
      "Iteration 7337, loss = 364.97895572\n",
      "Iteration 7338, loss = 364.97879339\n",
      "Iteration 7339, loss = 364.95828271\n",
      "Iteration 7340, loss = 364.94919671\n",
      "Iteration 7341, loss = 364.93930499\n",
      "Iteration 7342, loss = 364.92386484\n",
      "Iteration 7343, loss = 364.89993526\n",
      "Iteration 7344, loss = 364.89795833\n",
      "Iteration 7345, loss = 364.88538650\n",
      "Iteration 7346, loss = 364.87229739\n",
      "Iteration 7347, loss = 364.86637429\n",
      "Iteration 7348, loss = 364.85415768\n",
      "Iteration 7349, loss = 364.84456206\n",
      "Iteration 7350, loss = 364.82799276\n",
      "Iteration 7351, loss = 364.81499820\n",
      "Iteration 7352, loss = 364.81400660\n",
      "Iteration 7353, loss = 364.80399801\n",
      "Iteration 7354, loss = 364.80103111\n",
      "Iteration 7355, loss = 364.78701860\n",
      "Iteration 7356, loss = 364.76720528\n",
      "Iteration 7357, loss = 364.75715736\n",
      "Iteration 7358, loss = 364.73753254\n",
      "Iteration 7359, loss = 364.74200648\n",
      "Iteration 7360, loss = 364.72348306\n",
      "Iteration 7361, loss = 364.71297412\n",
      "Iteration 7362, loss = 364.70746576\n",
      "Iteration 7363, loss = 364.69608923\n",
      "Iteration 7364, loss = 364.68664352\n",
      "Iteration 7365, loss = 364.67676137\n",
      "Iteration 7366, loss = 364.64951857\n",
      "Iteration 7367, loss = 364.65415825\n",
      "Iteration 7368, loss = 364.62855839\n",
      "Iteration 7369, loss = 364.63028855\n",
      "Iteration 7370, loss = 364.61836310\n",
      "Iteration 7371, loss = 364.61239798\n",
      "Iteration 7372, loss = 364.59639738\n",
      "Iteration 7373, loss = 364.58620601\n",
      "Iteration 7374, loss = 364.57578543\n",
      "Iteration 7375, loss = 364.56679518\n",
      "Iteration 7376, loss = 364.57173229\n",
      "Iteration 7377, loss = 364.53700758\n",
      "Iteration 7378, loss = 364.52042145\n",
      "Iteration 7379, loss = 364.51404908\n",
      "Iteration 7380, loss = 364.50399935\n",
      "Iteration 7381, loss = 364.49667355\n",
      "Iteration 7382, loss = 364.47969770\n",
      "Iteration 7383, loss = 364.46729865\n",
      "Iteration 7384, loss = 364.45003844\n",
      "Iteration 7385, loss = 364.45672802\n",
      "Iteration 7386, loss = 364.45081536\n",
      "Iteration 7387, loss = 364.43608150\n",
      "Iteration 7388, loss = 364.41711848\n",
      "Iteration 7389, loss = 364.39415127\n",
      "Iteration 7390, loss = 364.38839898\n",
      "Iteration 7391, loss = 364.37065571\n",
      "Iteration 7392, loss = 364.35776191\n",
      "Iteration 7393, loss = 364.36653333\n",
      "Iteration 7394, loss = 364.35978917\n",
      "Iteration 7395, loss = 364.34899240\n",
      "Iteration 7396, loss = 364.32531761\n",
      "Iteration 7397, loss = 364.32470781\n",
      "Iteration 7398, loss = 364.33268872\n",
      "Iteration 7399, loss = 364.32031419\n",
      "Iteration 7400, loss = 364.29470492\n",
      "Iteration 7401, loss = 364.28046255\n",
      "Iteration 7402, loss = 364.27149916\n",
      "Iteration 7403, loss = 364.25543072\n",
      "Iteration 7404, loss = 364.25374795\n",
      "Iteration 7405, loss = 364.24725241\n",
      "Iteration 7406, loss = 364.22081295\n",
      "Iteration 7407, loss = 364.21935755\n",
      "Iteration 7408, loss = 364.22109797\n",
      "Iteration 7409, loss = 364.20966419\n",
      "Iteration 7410, loss = 364.19849123\n",
      "Iteration 7411, loss = 364.19744369\n",
      "Iteration 7412, loss = 364.18339114\n",
      "Iteration 7413, loss = 364.16969625\n",
      "Iteration 7414, loss = 364.15843298\n",
      "Iteration 7415, loss = 364.13965589\n",
      "Iteration 7416, loss = 364.14421822\n",
      "Iteration 7417, loss = 364.14468509\n",
      "Iteration 7418, loss = 364.13537497\n",
      "Iteration 7419, loss = 364.10691289\n",
      "Iteration 7420, loss = 364.10024116\n",
      "Iteration 7421, loss = 364.10391612\n",
      "Iteration 7422, loss = 364.09359071\n",
      "Iteration 7423, loss = 364.07517953\n",
      "Iteration 7424, loss = 364.07237713\n",
      "Iteration 7425, loss = 364.06806798\n",
      "Iteration 7426, loss = 364.04707742\n",
      "Iteration 7427, loss = 364.02545866\n",
      "Iteration 7428, loss = 364.02260408\n",
      "Iteration 7429, loss = 364.02242940\n",
      "Iteration 7430, loss = 364.01180329\n",
      "Iteration 7431, loss = 363.99304621\n",
      "Iteration 7432, loss = 363.98833773\n",
      "Iteration 7433, loss = 363.97239761\n",
      "Iteration 7434, loss = 363.95852587\n",
      "Iteration 7435, loss = 363.95539629\n",
      "Iteration 7436, loss = 363.94591358\n",
      "Iteration 7437, loss = 363.94478834\n",
      "Iteration 7438, loss = 363.92778498\n",
      "Iteration 7439, loss = 363.92170594\n",
      "Iteration 7440, loss = 363.92263090\n",
      "Iteration 7441, loss = 363.91237126\n",
      "Iteration 7442, loss = 363.91321186\n",
      "Iteration 7443, loss = 363.89737087\n",
      "Iteration 7444, loss = 363.88201615\n",
      "Iteration 7445, loss = 363.86444643\n",
      "Iteration 7446, loss = 363.85518512\n",
      "Iteration 7447, loss = 363.84673361\n",
      "Iteration 7448, loss = 363.84488047\n",
      "Iteration 7449, loss = 363.83170675\n",
      "Iteration 7450, loss = 363.83329535\n",
      "Iteration 7451, loss = 363.81417355\n",
      "Iteration 7452, loss = 363.79563807\n",
      "Iteration 7453, loss = 363.78737808\n",
      "Iteration 7454, loss = 363.78339097\n",
      "Iteration 7455, loss = 363.77003905\n",
      "Iteration 7456, loss = 363.75470191\n",
      "Iteration 7457, loss = 363.75463918\n",
      "Iteration 7458, loss = 363.75569439\n",
      "Iteration 7459, loss = 363.73541125\n",
      "Iteration 7460, loss = 363.71751039\n",
      "Iteration 7461, loss = 363.71037617\n",
      "Iteration 7462, loss = 363.70075294\n",
      "Iteration 7463, loss = 363.69756718\n",
      "Iteration 7464, loss = 363.69553067\n",
      "Iteration 7465, loss = 363.68393621\n",
      "Iteration 7466, loss = 363.66597888\n",
      "Iteration 7467, loss = 363.65618466\n",
      "Iteration 7468, loss = 363.64386652\n",
      "Iteration 7469, loss = 363.64656532\n",
      "Iteration 7470, loss = 363.62948426\n",
      "Iteration 7471, loss = 363.62090477\n",
      "Iteration 7472, loss = 363.60533534\n",
      "Iteration 7473, loss = 363.61249798\n",
      "Iteration 7474, loss = 363.58623945\n",
      "Iteration 7475, loss = 363.59045993\n",
      "Iteration 7476, loss = 363.57293937\n",
      "Iteration 7477, loss = 363.57384421\n",
      "Iteration 7478, loss = 363.56666214\n",
      "Iteration 7479, loss = 363.54886998\n",
      "Iteration 7480, loss = 363.53933104\n",
      "Iteration 7481, loss = 363.53185827\n",
      "Iteration 7482, loss = 363.51467362\n",
      "Iteration 7483, loss = 363.51180759\n",
      "Iteration 7484, loss = 363.51438756\n",
      "Iteration 7485, loss = 363.49972854\n",
      "Iteration 7486, loss = 363.47714030\n",
      "Iteration 7487, loss = 363.48133252\n",
      "Iteration 7488, loss = 363.48740073\n",
      "Iteration 7489, loss = 363.46721900\n",
      "Iteration 7490, loss = 363.44273884\n",
      "Iteration 7491, loss = 363.43894909\n",
      "Iteration 7492, loss = 363.44146162\n",
      "Iteration 7493, loss = 363.42711620\n",
      "Iteration 7494, loss = 363.41117193\n",
      "Iteration 7495, loss = 363.39311932\n",
      "Iteration 7496, loss = 363.39825252\n",
      "Iteration 7497, loss = 363.38834875\n",
      "Iteration 7498, loss = 363.38121286\n",
      "Iteration 7499, loss = 363.37771703\n",
      "Iteration 7500, loss = 363.36572921\n",
      "Iteration 7501, loss = 363.35379961\n",
      "Iteration 7502, loss = 363.33896544\n",
      "Iteration 7503, loss = 363.31970178\n",
      "Iteration 7504, loss = 363.31063508\n",
      "Iteration 7505, loss = 363.30410350\n",
      "Iteration 7506, loss = 363.29971400\n",
      "Iteration 7507, loss = 363.28541055\n",
      "Iteration 7508, loss = 363.27994377\n",
      "Iteration 7509, loss = 363.27678607\n",
      "Iteration 7510, loss = 363.27439810\n",
      "Iteration 7511, loss = 363.25532119\n",
      "Iteration 7512, loss = 363.23924974\n",
      "Iteration 7513, loss = 363.23460898\n",
      "Iteration 7514, loss = 363.22003548\n",
      "Iteration 7515, loss = 363.22717132\n",
      "Iteration 7516, loss = 363.21770915\n",
      "Iteration 7517, loss = 363.21816985\n",
      "Iteration 7518, loss = 363.20015956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7519, loss = 363.19122670\n",
      "Iteration 7520, loss = 363.17705271\n",
      "Iteration 7521, loss = 363.17810215\n",
      "Iteration 7522, loss = 363.16798110\n",
      "Iteration 7523, loss = 363.14479738\n",
      "Iteration 7524, loss = 363.14308702\n",
      "Iteration 7525, loss = 363.13437320\n",
      "Iteration 7526, loss = 363.10677813\n",
      "Iteration 7527, loss = 363.10514149\n",
      "Iteration 7528, loss = 363.09565760\n",
      "Iteration 7529, loss = 363.08987504\n",
      "Iteration 7530, loss = 363.09653783\n",
      "Iteration 7531, loss = 363.08740203\n",
      "Iteration 7532, loss = 363.06795859\n",
      "Iteration 7533, loss = 363.06501512\n",
      "Iteration 7534, loss = 363.06804661\n",
      "Iteration 7535, loss = 363.04583955\n",
      "Iteration 7536, loss = 363.04461263\n",
      "Iteration 7537, loss = 363.03366260\n",
      "Iteration 7538, loss = 363.01856207\n",
      "Iteration 7539, loss = 363.00878339\n",
      "Iteration 7540, loss = 363.00320543\n",
      "Iteration 7541, loss = 363.00712211\n",
      "Iteration 7542, loss = 362.98968074\n",
      "Iteration 7543, loss = 362.98258013\n",
      "Iteration 7544, loss = 362.96545051\n",
      "Iteration 7545, loss = 362.95769452\n",
      "Iteration 7546, loss = 362.94003400\n",
      "Iteration 7547, loss = 362.92739476\n",
      "Iteration 7548, loss = 362.90961583\n",
      "Iteration 7549, loss = 362.90525156\n",
      "Iteration 7550, loss = 362.89730150\n",
      "Iteration 7551, loss = 362.89138807\n",
      "Iteration 7552, loss = 362.88976215\n",
      "Iteration 7553, loss = 362.86959257\n",
      "Iteration 7554, loss = 362.87587234\n",
      "Iteration 7555, loss = 362.86005333\n",
      "Iteration 7556, loss = 362.83954490\n",
      "Iteration 7557, loss = 362.84152461\n",
      "Iteration 7558, loss = 362.84103461\n",
      "Iteration 7559, loss = 362.82131530\n",
      "Iteration 7560, loss = 362.81002121\n",
      "Iteration 7561, loss = 362.80055680\n",
      "Iteration 7562, loss = 362.80523930\n",
      "Iteration 7563, loss = 362.78749852\n",
      "Iteration 7564, loss = 362.77451818\n",
      "Iteration 7565, loss = 362.76944100\n",
      "Iteration 7566, loss = 362.75275924\n",
      "Iteration 7567, loss = 362.75574393\n",
      "Iteration 7568, loss = 362.73498705\n",
      "Iteration 7569, loss = 362.73530606\n",
      "Iteration 7570, loss = 362.72631604\n",
      "Iteration 7571, loss = 362.73120726\n",
      "Iteration 7572, loss = 362.72113509\n",
      "Iteration 7573, loss = 362.69545903\n",
      "Iteration 7574, loss = 362.69603703\n",
      "Iteration 7575, loss = 362.69067811\n",
      "Iteration 7576, loss = 362.70277801\n",
      "Iteration 7577, loss = 362.66604123\n",
      "Iteration 7578, loss = 362.65470931\n",
      "Iteration 7579, loss = 362.66570378\n",
      "Iteration 7580, loss = 362.64643301\n",
      "Iteration 7581, loss = 362.63726595\n",
      "Iteration 7582, loss = 362.62530044\n",
      "Iteration 7583, loss = 362.62699906\n",
      "Iteration 7584, loss = 362.62183725\n",
      "Iteration 7585, loss = 362.60076730\n",
      "Iteration 7586, loss = 362.58827412\n",
      "Iteration 7587, loss = 362.60466223\n",
      "Iteration 7588, loss = 362.60569122\n",
      "Iteration 7589, loss = 362.57945902\n",
      "Iteration 7590, loss = 362.56041257\n",
      "Iteration 7591, loss = 362.55161987\n",
      "Iteration 7592, loss = 362.54816535\n",
      "Iteration 7593, loss = 362.53600301\n",
      "Iteration 7594, loss = 362.52851508\n",
      "Iteration 7595, loss = 362.50762398\n",
      "Iteration 7596, loss = 362.50844935\n",
      "Iteration 7597, loss = 362.48644237\n",
      "Iteration 7598, loss = 362.48767142\n",
      "Iteration 7599, loss = 362.48848813\n",
      "Iteration 7600, loss = 362.47365962\n",
      "Iteration 7601, loss = 362.45647015\n",
      "Iteration 7602, loss = 362.45245337\n",
      "Iteration 7603, loss = 362.44014897\n",
      "Iteration 7604, loss = 362.42169827\n",
      "Iteration 7605, loss = 362.43091774\n",
      "Iteration 7606, loss = 362.40460015\n",
      "Iteration 7607, loss = 362.40088254\n",
      "Iteration 7608, loss = 362.39846532\n",
      "Iteration 7609, loss = 362.39006577\n",
      "Iteration 7610, loss = 362.37795913\n",
      "Iteration 7611, loss = 362.37862253\n",
      "Iteration 7612, loss = 362.35855931\n",
      "Iteration 7613, loss = 362.35572085\n",
      "Iteration 7614, loss = 362.33524478\n",
      "Iteration 7615, loss = 362.32390636\n",
      "Iteration 7616, loss = 362.32368161\n",
      "Iteration 7617, loss = 362.31324774\n",
      "Iteration 7618, loss = 362.30333030\n",
      "Iteration 7619, loss = 362.29510634\n",
      "Iteration 7620, loss = 362.29512875\n",
      "Iteration 7621, loss = 362.27399315\n",
      "Iteration 7622, loss = 362.26503774\n",
      "Iteration 7623, loss = 362.26507563\n",
      "Iteration 7624, loss = 362.24604874\n",
      "Iteration 7625, loss = 362.24013197\n",
      "Iteration 7626, loss = 362.24768660\n",
      "Iteration 7627, loss = 362.22673314\n",
      "Iteration 7628, loss = 362.21648421\n",
      "Iteration 7629, loss = 362.21491825\n",
      "Iteration 7630, loss = 362.19773689\n",
      "Iteration 7631, loss = 362.18617639\n",
      "Iteration 7632, loss = 362.17951431\n",
      "Iteration 7633, loss = 362.17357837\n",
      "Iteration 7634, loss = 362.16558072\n",
      "Iteration 7635, loss = 362.16221386\n",
      "Iteration 7636, loss = 362.15450535\n",
      "Iteration 7637, loss = 362.15797668\n",
      "Iteration 7638, loss = 362.14491646\n",
      "Iteration 7639, loss = 362.13416102\n",
      "Iteration 7640, loss = 362.12858186\n",
      "Iteration 7641, loss = 362.11743685\n",
      "Iteration 7642, loss = 362.11212418\n",
      "Iteration 7643, loss = 362.10522836\n",
      "Iteration 7644, loss = 362.08577999\n",
      "Iteration 7645, loss = 362.09749747\n",
      "Iteration 7646, loss = 362.08078635\n",
      "Iteration 7647, loss = 362.06178382\n",
      "Iteration 7648, loss = 362.04628536\n",
      "Iteration 7649, loss = 362.04120774\n",
      "Iteration 7650, loss = 362.03821805\n",
      "Iteration 7651, loss = 362.02749563\n",
      "Iteration 7652, loss = 362.00450695\n",
      "Iteration 7653, loss = 362.01034069\n",
      "Iteration 7654, loss = 362.00453370\n",
      "Iteration 7655, loss = 361.98548894\n",
      "Iteration 7656, loss = 361.99715918\n",
      "Iteration 7657, loss = 361.98518963\n",
      "Iteration 7658, loss = 361.97359140\n",
      "Iteration 7659, loss = 361.95858275\n",
      "Iteration 7660, loss = 361.94785168\n",
      "Iteration 7661, loss = 361.94440045\n",
      "Iteration 7662, loss = 361.93118668\n",
      "Iteration 7663, loss = 361.91986522\n",
      "Iteration 7664, loss = 361.92194050\n",
      "Iteration 7665, loss = 361.92032912\n",
      "Iteration 7666, loss = 361.90269668\n",
      "Iteration 7667, loss = 361.88926059\n",
      "Iteration 7668, loss = 361.88548962\n",
      "Iteration 7669, loss = 361.86905772\n",
      "Iteration 7670, loss = 361.87537286\n",
      "Iteration 7671, loss = 361.86471927\n",
      "Iteration 7672, loss = 361.84289335\n",
      "Iteration 7673, loss = 361.84044181\n",
      "Iteration 7674, loss = 361.85323102\n",
      "Iteration 7675, loss = 361.85144880\n",
      "Iteration 7676, loss = 361.83596279\n",
      "Iteration 7677, loss = 361.80750894\n",
      "Iteration 7678, loss = 361.80527309\n",
      "Iteration 7679, loss = 361.79773850\n",
      "Iteration 7680, loss = 361.79125153\n",
      "Iteration 7681, loss = 361.78308120\n",
      "Iteration 7682, loss = 361.76925496\n",
      "Iteration 7683, loss = 361.76185479\n",
      "Iteration 7684, loss = 361.75777434\n",
      "Iteration 7685, loss = 361.73428435\n",
      "Iteration 7686, loss = 361.74409736\n",
      "Iteration 7687, loss = 361.74041097\n",
      "Iteration 7688, loss = 361.73111794\n",
      "Iteration 7689, loss = 361.70445176\n",
      "Iteration 7690, loss = 361.72264114\n",
      "Iteration 7691, loss = 361.70222627\n",
      "Iteration 7692, loss = 361.69515024\n",
      "Iteration 7693, loss = 361.67153169\n",
      "Iteration 7694, loss = 361.68261216\n",
      "Iteration 7695, loss = 361.65533968\n",
      "Iteration 7696, loss = 361.65325196\n",
      "Iteration 7697, loss = 361.64627251\n",
      "Iteration 7698, loss = 361.62457593\n",
      "Iteration 7699, loss = 361.62395555\n",
      "Iteration 7700, loss = 361.61583155\n",
      "Iteration 7701, loss = 361.61203377\n",
      "Iteration 7702, loss = 361.60596455\n",
      "Iteration 7703, loss = 361.59190714\n",
      "Iteration 7704, loss = 361.58523266\n",
      "Iteration 7705, loss = 361.59209738\n",
      "Iteration 7706, loss = 361.57250857\n",
      "Iteration 7707, loss = 361.55641787\n",
      "Iteration 7708, loss = 361.54934177\n",
      "Iteration 7709, loss = 361.53740043\n",
      "Iteration 7710, loss = 361.53376847\n",
      "Iteration 7711, loss = 361.53420894\n",
      "Iteration 7712, loss = 361.52352433\n",
      "Iteration 7713, loss = 361.50317558\n",
      "Iteration 7714, loss = 361.49002267\n",
      "Iteration 7715, loss = 361.47967588\n",
      "Iteration 7716, loss = 361.46729558\n",
      "Iteration 7717, loss = 361.47248460\n",
      "Iteration 7718, loss = 361.48403325\n",
      "Iteration 7719, loss = 361.46376595\n",
      "Iteration 7720, loss = 361.43579196\n",
      "Iteration 7721, loss = 361.45278266\n",
      "Iteration 7722, loss = 361.46228086\n",
      "Iteration 7723, loss = 361.44132715\n",
      "Iteration 7724, loss = 361.42429851\n",
      "Iteration 7725, loss = 361.41783531\n",
      "Iteration 7726, loss = 361.41990235\n",
      "Iteration 7727, loss = 361.40738942\n",
      "Iteration 7728, loss = 361.38598972\n",
      "Iteration 7729, loss = 361.36781045\n",
      "Iteration 7730, loss = 361.36945107\n",
      "Iteration 7731, loss = 361.35065763\n",
      "Iteration 7732, loss = 361.36175746\n",
      "Iteration 7733, loss = 361.36287823\n",
      "Iteration 7734, loss = 361.33704232\n",
      "Iteration 7735, loss = 361.32336783\n",
      "Iteration 7736, loss = 361.33464802\n",
      "Iteration 7737, loss = 361.32420443\n",
      "Iteration 7738, loss = 361.30766291\n",
      "Iteration 7739, loss = 361.29144238\n",
      "Iteration 7740, loss = 361.30254795\n",
      "Iteration 7741, loss = 361.27142376\n",
      "Iteration 7742, loss = 361.26229863\n",
      "Iteration 7743, loss = 361.27670783\n",
      "Iteration 7744, loss = 361.28451640\n",
      "Iteration 7745, loss = 361.26714480\n",
      "Iteration 7746, loss = 361.26686930\n",
      "Iteration 7747, loss = 361.26199102\n",
      "Iteration 7748, loss = 361.25604796\n",
      "Iteration 7749, loss = 361.22779775\n",
      "Iteration 7750, loss = 361.22089106\n",
      "Iteration 7751, loss = 361.19390202\n",
      "Iteration 7752, loss = 361.18664372\n",
      "Iteration 7753, loss = 361.18694276\n",
      "Iteration 7754, loss = 361.20850626\n",
      "Iteration 7755, loss = 361.18424400\n",
      "Iteration 7756, loss = 361.17129221\n",
      "Iteration 7757, loss = 361.18766150\n",
      "Iteration 7758, loss = 361.16449296\n",
      "Iteration 7759, loss = 361.14691607\n",
      "Iteration 7760, loss = 361.13445240\n",
      "Iteration 7761, loss = 361.13717486\n",
      "Iteration 7762, loss = 361.10779940\n",
      "Iteration 7763, loss = 361.12619957\n",
      "Iteration 7764, loss = 361.12083408\n",
      "Iteration 7765, loss = 361.10331178\n",
      "Iteration 7766, loss = 361.07990938\n",
      "Iteration 7767, loss = 361.06719420\n",
      "Iteration 7768, loss = 361.09496791\n",
      "Iteration 7769, loss = 361.05756477\n",
      "Iteration 7770, loss = 361.04984723\n",
      "Iteration 7771, loss = 361.04378830\n",
      "Iteration 7772, loss = 361.06326110\n",
      "Iteration 7773, loss = 361.03736139\n",
      "Iteration 7774, loss = 361.05059888\n",
      "Iteration 7775, loss = 361.02158063\n",
      "Iteration 7776, loss = 361.00904719\n",
      "Iteration 7777, loss = 360.98218663\n",
      "Iteration 7778, loss = 360.98177181\n",
      "Iteration 7779, loss = 360.98293124\n",
      "Iteration 7780, loss = 360.97321836\n",
      "Iteration 7781, loss = 360.96016908\n",
      "Iteration 7782, loss = 360.95501204\n",
      "Iteration 7783, loss = 360.94235074\n",
      "Iteration 7784, loss = 360.93280036\n",
      "Iteration 7785, loss = 360.94831554\n",
      "Iteration 7786, loss = 360.93319316\n",
      "Iteration 7787, loss = 360.91522428\n",
      "Iteration 7788, loss = 360.88885492\n",
      "Iteration 7789, loss = 360.89605621\n",
      "Iteration 7790, loss = 360.87952021\n",
      "Iteration 7791, loss = 360.87643027\n",
      "Iteration 7792, loss = 360.86774894\n",
      "Iteration 7793, loss = 360.86337717\n",
      "Iteration 7794, loss = 360.84566034\n",
      "Iteration 7795, loss = 360.86277891\n",
      "Iteration 7796, loss = 360.85212107\n",
      "Iteration 7797, loss = 360.85167096\n",
      "Iteration 7798, loss = 360.82516877\n",
      "Iteration 7799, loss = 360.83441272\n",
      "Iteration 7800, loss = 360.79759899\n",
      "Iteration 7801, loss = 360.80204958\n",
      "Iteration 7802, loss = 360.78895381\n",
      "Iteration 7803, loss = 360.78126857\n",
      "Iteration 7804, loss = 360.78300446\n",
      "Iteration 7805, loss = 360.75856678\n",
      "Iteration 7806, loss = 360.75952688\n",
      "Iteration 7807, loss = 360.74724913\n",
      "Iteration 7808, loss = 360.74589259\n",
      "Iteration 7809, loss = 360.75401740\n",
      "Iteration 7810, loss = 360.74710424\n",
      "Iteration 7811, loss = 360.73032697\n",
      "Iteration 7812, loss = 360.70120770\n",
      "Iteration 7813, loss = 360.72454859\n",
      "Iteration 7814, loss = 360.72434479\n",
      "Iteration 7815, loss = 360.69739963\n",
      "Iteration 7816, loss = 360.67346531\n",
      "Iteration 7817, loss = 360.67815008\n",
      "Iteration 7818, loss = 360.67792013\n",
      "Iteration 7819, loss = 360.68607082\n",
      "Iteration 7820, loss = 360.66403508\n",
      "Iteration 7821, loss = 360.63114243\n",
      "Iteration 7822, loss = 360.63544470\n",
      "Iteration 7823, loss = 360.64261351\n",
      "Iteration 7824, loss = 360.63812844\n",
      "Iteration 7825, loss = 360.60617770\n",
      "Iteration 7826, loss = 360.60800762\n",
      "Iteration 7827, loss = 360.61661845\n",
      "Iteration 7828, loss = 360.60136298\n",
      "Iteration 7829, loss = 360.57716260\n",
      "Iteration 7830, loss = 360.55671924\n",
      "Iteration 7831, loss = 360.55114998\n",
      "Iteration 7832, loss = 360.54781391\n",
      "Iteration 7833, loss = 360.54414527\n",
      "Iteration 7834, loss = 360.54631811\n",
      "Iteration 7835, loss = 360.53626323\n",
      "Iteration 7836, loss = 360.51354463\n",
      "Iteration 7837, loss = 360.52459343\n",
      "Iteration 7838, loss = 360.52028248\n",
      "Iteration 7839, loss = 360.47984202\n",
      "Iteration 7840, loss = 360.48533180\n",
      "Iteration 7841, loss = 360.50555321\n",
      "Iteration 7842, loss = 360.47029945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7843, loss = 360.44155946\n",
      "Iteration 7844, loss = 360.48136806\n",
      "Iteration 7845, loss = 360.48762155\n",
      "Iteration 7846, loss = 360.46387141\n",
      "Iteration 7847, loss = 360.44499976\n",
      "Iteration 7848, loss = 360.45090639\n",
      "Iteration 7849, loss = 360.43986269\n",
      "Iteration 7850, loss = 360.41961075\n",
      "Iteration 7851, loss = 360.43006767\n",
      "Iteration 7852, loss = 360.41075684\n",
      "Iteration 7853, loss = 360.40941731\n",
      "Iteration 7854, loss = 360.41547017\n",
      "Iteration 7855, loss = 360.41068728\n",
      "Iteration 7856, loss = 360.37182940\n",
      "Iteration 7857, loss = 360.35543706\n",
      "Iteration 7858, loss = 360.35564170\n",
      "Iteration 7859, loss = 360.32872485\n",
      "Iteration 7860, loss = 360.32440754\n",
      "Iteration 7861, loss = 360.32823302\n",
      "Iteration 7862, loss = 360.31670309\n",
      "Iteration 7863, loss = 360.28876894\n",
      "Iteration 7864, loss = 360.30498859\n",
      "Iteration 7865, loss = 360.29585035\n",
      "Iteration 7866, loss = 360.27945914\n",
      "Iteration 7867, loss = 360.25407606\n",
      "Iteration 7868, loss = 360.25515348\n",
      "Iteration 7869, loss = 360.25148703\n",
      "Iteration 7870, loss = 360.24470005\n",
      "Iteration 7871, loss = 360.23738310\n",
      "Iteration 7872, loss = 360.22097671\n",
      "Iteration 7873, loss = 360.20358962\n",
      "Iteration 7874, loss = 360.20567558\n",
      "Iteration 7875, loss = 360.19396216\n",
      "Iteration 7876, loss = 360.17641268\n",
      "Iteration 7877, loss = 360.17670789\n",
      "Iteration 7878, loss = 360.16656443\n",
      "Iteration 7879, loss = 360.16561512\n",
      "Iteration 7880, loss = 360.15576699\n",
      "Iteration 7881, loss = 360.13995457\n",
      "Iteration 7882, loss = 360.13834834\n",
      "Iteration 7883, loss = 360.13992845\n",
      "Iteration 7884, loss = 360.13304517\n",
      "Iteration 7885, loss = 360.10106286\n",
      "Iteration 7886, loss = 360.13017683\n",
      "Iteration 7887, loss = 360.13805394\n",
      "Iteration 7888, loss = 360.10737671\n",
      "Iteration 7889, loss = 360.07967354\n",
      "Iteration 7890, loss = 360.08709095\n",
      "Iteration 7891, loss = 360.08015887\n",
      "Iteration 7892, loss = 360.07420787\n",
      "Iteration 7893, loss = 360.05795996\n",
      "Iteration 7894, loss = 360.03801081\n",
      "Iteration 7895, loss = 360.03943178\n",
      "Iteration 7896, loss = 360.05088345\n",
      "Iteration 7897, loss = 360.04470831\n",
      "Iteration 7898, loss = 360.01137539\n",
      "Iteration 7899, loss = 360.00531016\n",
      "Iteration 7900, loss = 360.00674457\n",
      "Iteration 7901, loss = 359.99782836\n",
      "Iteration 7902, loss = 359.97224857\n",
      "Iteration 7903, loss = 359.95316014\n",
      "Iteration 7904, loss = 359.97002127\n",
      "Iteration 7905, loss = 359.97027082\n",
      "Iteration 7906, loss = 359.96387834\n",
      "Iteration 7907, loss = 359.93942413\n",
      "Iteration 7908, loss = 359.91345668\n",
      "Iteration 7909, loss = 359.92094278\n",
      "Iteration 7910, loss = 359.93498196\n",
      "Iteration 7911, loss = 359.91027970\n",
      "Iteration 7912, loss = 359.87176553\n",
      "Iteration 7913, loss = 359.88253158\n",
      "Iteration 7914, loss = 359.88114120\n",
      "Iteration 7915, loss = 359.86344158\n",
      "Iteration 7916, loss = 359.86199645\n",
      "Iteration 7917, loss = 359.85018019\n",
      "Iteration 7918, loss = 359.83000713\n",
      "Iteration 7919, loss = 359.83038515\n",
      "Iteration 7920, loss = 359.83691420\n",
      "Iteration 7921, loss = 359.82806520\n",
      "Iteration 7922, loss = 359.81241253\n",
      "Iteration 7923, loss = 359.80907962\n",
      "Iteration 7924, loss = 359.79465254\n",
      "Iteration 7925, loss = 359.78983419\n",
      "Iteration 7926, loss = 359.78463904\n",
      "Iteration 7927, loss = 359.75602909\n",
      "Iteration 7928, loss = 359.75889258\n",
      "Iteration 7929, loss = 359.77190925\n",
      "Iteration 7930, loss = 359.77369126\n",
      "Iteration 7931, loss = 359.74005415\n",
      "Iteration 7932, loss = 359.73269760\n",
      "Iteration 7933, loss = 359.73338541\n",
      "Iteration 7934, loss = 359.72087703\n",
      "Iteration 7935, loss = 359.71855623\n",
      "Iteration 7936, loss = 359.71650743\n",
      "Iteration 7937, loss = 359.69871323\n",
      "Iteration 7938, loss = 359.67388026\n",
      "Iteration 7939, loss = 359.66353992\n",
      "Iteration 7940, loss = 359.67319278\n",
      "Iteration 7941, loss = 359.67079858\n",
      "Iteration 7942, loss = 359.64274762\n",
      "Iteration 7943, loss = 359.64946214\n",
      "Iteration 7944, loss = 359.63633469\n",
      "Iteration 7945, loss = 359.62969794\n",
      "Iteration 7946, loss = 359.62490640\n",
      "Iteration 7947, loss = 359.59920459\n",
      "Iteration 7948, loss = 359.60463145\n",
      "Iteration 7949, loss = 359.57826196\n",
      "Iteration 7950, loss = 359.59703164\n",
      "Iteration 7951, loss = 359.56921544\n",
      "Iteration 7952, loss = 359.57284609\n",
      "Iteration 7953, loss = 359.56187552\n",
      "Iteration 7954, loss = 359.54860763\n",
      "Iteration 7955, loss = 359.54856333\n",
      "Iteration 7956, loss = 359.54102252\n",
      "Iteration 7957, loss = 359.52535332\n",
      "Iteration 7958, loss = 359.52298782\n",
      "Iteration 7959, loss = 359.54350947\n",
      "Iteration 7960, loss = 359.52356646\n",
      "Iteration 7961, loss = 359.50413212\n",
      "Iteration 7962, loss = 359.49391747\n",
      "Iteration 7963, loss = 359.48542452\n",
      "Iteration 7964, loss = 359.47305894\n",
      "Iteration 7965, loss = 359.46382777\n",
      "Iteration 7966, loss = 359.47454069\n",
      "Iteration 7967, loss = 359.46642237\n",
      "Iteration 7968, loss = 359.45723609\n",
      "Iteration 7969, loss = 359.43144189\n",
      "Iteration 7970, loss = 359.42232508\n",
      "Iteration 7971, loss = 359.40107873\n",
      "Iteration 7972, loss = 359.40388558\n",
      "Iteration 7973, loss = 359.39674099\n",
      "Iteration 7974, loss = 359.38700086\n",
      "Iteration 7975, loss = 359.37882169\n",
      "Iteration 7976, loss = 359.36503613\n",
      "Iteration 7977, loss = 359.35835370\n",
      "Iteration 7978, loss = 359.36481831\n",
      "Iteration 7979, loss = 359.33752560\n",
      "Iteration 7980, loss = 359.32958255\n",
      "Iteration 7981, loss = 359.33409058\n",
      "Iteration 7982, loss = 359.33325328\n",
      "Iteration 7983, loss = 359.33294367\n",
      "Iteration 7984, loss = 359.31571268\n",
      "Iteration 7985, loss = 359.30859343\n",
      "Iteration 7986, loss = 359.29780525\n",
      "Iteration 7987, loss = 359.28942497\n",
      "Iteration 7988, loss = 359.28078901\n",
      "Iteration 7989, loss = 359.27822165\n",
      "Iteration 7990, loss = 359.25104365\n",
      "Iteration 7991, loss = 359.26151691\n",
      "Iteration 7992, loss = 359.26400940\n",
      "Iteration 7993, loss = 359.24379034\n",
      "Iteration 7994, loss = 359.23569144\n",
      "Iteration 7995, loss = 359.23351390\n",
      "Iteration 7996, loss = 359.22675730\n",
      "Iteration 7997, loss = 359.20861091\n",
      "Iteration 7998, loss = 359.21017607\n",
      "Iteration 7999, loss = 359.19796517\n",
      "Iteration 8000, loss = 359.17646444\n",
      "Iteration 8001, loss = 359.16770164\n",
      "Iteration 8002, loss = 359.16646002\n",
      "Iteration 8003, loss = 359.15553946\n",
      "Iteration 8004, loss = 359.16042609\n",
      "Iteration 8005, loss = 359.14839734\n",
      "Iteration 8006, loss = 359.15897140\n",
      "Iteration 8007, loss = 359.15431647\n",
      "Iteration 8008, loss = 359.13239471\n",
      "Iteration 8009, loss = 359.10981443\n",
      "Iteration 8010, loss = 359.11219163\n",
      "Iteration 8011, loss = 359.10575747\n",
      "Iteration 8012, loss = 359.09516714\n",
      "Iteration 8013, loss = 359.09687472\n",
      "Iteration 8014, loss = 359.09568441\n",
      "Iteration 8015, loss = 359.08754365\n",
      "Iteration 8016, loss = 359.07050117\n",
      "Iteration 8017, loss = 359.06116547\n",
      "Iteration 8018, loss = 359.05712165\n",
      "Iteration 8019, loss = 359.04757789\n",
      "Iteration 8020, loss = 359.04344275\n",
      "Iteration 8021, loss = 359.01882998\n",
      "Iteration 8022, loss = 359.01817053\n",
      "Iteration 8023, loss = 358.99664298\n",
      "Iteration 8024, loss = 359.01657646\n",
      "Iteration 8025, loss = 358.98813263\n",
      "Iteration 8026, loss = 358.98537593\n",
      "Iteration 8027, loss = 358.95842694\n",
      "Iteration 8028, loss = 358.96654663\n",
      "Iteration 8029, loss = 358.96384703\n",
      "Iteration 8030, loss = 358.93620022\n",
      "Iteration 8031, loss = 358.93377109\n",
      "Iteration 8032, loss = 358.93356230\n",
      "Iteration 8033, loss = 358.92604985\n",
      "Iteration 8034, loss = 358.91843799\n",
      "Iteration 8035, loss = 358.90529283\n",
      "Iteration 8036, loss = 358.91046890\n",
      "Iteration 8037, loss = 358.91175898\n",
      "Iteration 8038, loss = 358.90289085\n",
      "Iteration 8039, loss = 358.91459731\n",
      "Iteration 8040, loss = 358.89853937\n",
      "Iteration 8041, loss = 358.88996821\n",
      "Iteration 8042, loss = 358.86949718\n",
      "Iteration 8043, loss = 358.86397704\n",
      "Iteration 8044, loss = 358.86407103\n",
      "Iteration 8045, loss = 358.83642779\n",
      "Iteration 8046, loss = 358.81725743\n",
      "Iteration 8047, loss = 358.84379810\n",
      "Iteration 8048, loss = 358.86108774\n",
      "Iteration 8049, loss = 358.82766749\n",
      "Iteration 8050, loss = 358.79818632\n",
      "Iteration 8051, loss = 358.81888839\n",
      "Iteration 8052, loss = 358.81952465\n",
      "Iteration 8053, loss = 358.80215423\n",
      "Iteration 8054, loss = 358.78284528\n",
      "Iteration 8055, loss = 358.76429467\n",
      "Iteration 8056, loss = 358.75008832\n",
      "Iteration 8057, loss = 358.76337051\n",
      "Iteration 8058, loss = 358.75273828\n",
      "Iteration 8059, loss = 358.72435381\n",
      "Iteration 8060, loss = 358.73647714\n",
      "Iteration 8061, loss = 358.71204676\n",
      "Iteration 8062, loss = 358.70385217\n",
      "Iteration 8063, loss = 358.69899287\n",
      "Iteration 8064, loss = 358.68788460\n",
      "Iteration 8065, loss = 358.69986853\n",
      "Iteration 8066, loss = 358.69707532\n",
      "Iteration 8067, loss = 358.68364349\n",
      "Iteration 8068, loss = 358.65658438\n",
      "Iteration 8069, loss = 358.64950620\n",
      "Iteration 8070, loss = 358.65226062\n",
      "Iteration 8071, loss = 358.63426004\n",
      "Iteration 8072, loss = 358.65036879\n",
      "Iteration 8073, loss = 358.63933234\n",
      "Iteration 8074, loss = 358.62391967\n",
      "Iteration 8075, loss = 358.60273810\n",
      "Iteration 8076, loss = 358.59535253\n",
      "Iteration 8077, loss = 358.59678410\n",
      "Iteration 8078, loss = 358.57691197\n",
      "Iteration 8079, loss = 358.56878357\n",
      "Iteration 8080, loss = 358.56660827\n",
      "Iteration 8081, loss = 358.54957617\n",
      "Iteration 8082, loss = 358.55368378\n",
      "Iteration 8083, loss = 358.53683511\n",
      "Iteration 8084, loss = 358.53178259\n",
      "Iteration 8085, loss = 358.52394563\n",
      "Iteration 8086, loss = 358.51490469\n",
      "Iteration 8087, loss = 358.51880012\n",
      "Iteration 8088, loss = 358.49796364\n",
      "Iteration 8089, loss = 358.50911052\n",
      "Iteration 8090, loss = 358.49288011\n",
      "Iteration 8091, loss = 358.49777407\n",
      "Iteration 8092, loss = 358.47026622\n",
      "Iteration 8093, loss = 358.49253500\n",
      "Iteration 8094, loss = 358.48065894\n",
      "Iteration 8095, loss = 358.45336666\n",
      "Iteration 8096, loss = 358.45013803\n",
      "Iteration 8097, loss = 358.44028500\n",
      "Iteration 8098, loss = 358.42610837\n",
      "Iteration 8099, loss = 358.41763176\n",
      "Iteration 8100, loss = 358.41853093\n",
      "Iteration 8101, loss = 358.39893624\n",
      "Iteration 8102, loss = 358.38589083\n",
      "Iteration 8103, loss = 358.38428889\n",
      "Iteration 8104, loss = 358.36650274\n",
      "Iteration 8105, loss = 358.37236264\n",
      "Iteration 8106, loss = 358.36099207\n",
      "Iteration 8107, loss = 358.36031649\n",
      "Iteration 8108, loss = 358.35954926\n",
      "Iteration 8109, loss = 358.35411363\n",
      "Iteration 8110, loss = 358.33256134\n",
      "Iteration 8111, loss = 358.32317917\n",
      "Iteration 8112, loss = 358.32015473\n",
      "Iteration 8113, loss = 358.32100702\n",
      "Iteration 8114, loss = 358.31028650\n",
      "Iteration 8115, loss = 358.31200985\n",
      "Iteration 8116, loss = 358.31690458\n",
      "Iteration 8117, loss = 358.31246809\n",
      "Iteration 8118, loss = 358.29508672\n",
      "Iteration 8119, loss = 358.29206489\n",
      "Iteration 8120, loss = 358.27264907\n",
      "Iteration 8121, loss = 358.26243062\n",
      "Iteration 8122, loss = 358.25414106\n",
      "Iteration 8123, loss = 358.25959646\n",
      "Iteration 8124, loss = 358.25940059\n",
      "Iteration 8125, loss = 358.26703340\n",
      "Iteration 8126, loss = 358.23555898\n",
      "Iteration 8127, loss = 358.21078769\n",
      "Iteration 8128, loss = 358.22348014\n",
      "Iteration 8129, loss = 358.20900430\n",
      "Iteration 8130, loss = 358.21213504\n",
      "Iteration 8131, loss = 358.20243052\n",
      "Iteration 8132, loss = 358.18004034\n",
      "Iteration 8133, loss = 358.19532154\n",
      "Iteration 8134, loss = 358.20298203\n",
      "Iteration 8135, loss = 358.18830680\n",
      "Iteration 8136, loss = 358.15956531\n",
      "Iteration 8137, loss = 358.15090427\n",
      "Iteration 8138, loss = 358.14711723\n",
      "Iteration 8139, loss = 358.14872725\n",
      "Iteration 8140, loss = 358.13570741\n",
      "Iteration 8141, loss = 358.12457291\n",
      "Iteration 8142, loss = 358.11816314\n",
      "Iteration 8143, loss = 358.08909630\n",
      "Iteration 8144, loss = 358.09025703\n",
      "Iteration 8145, loss = 358.08553178\n",
      "Iteration 8146, loss = 358.07992452\n",
      "Iteration 8147, loss = 358.07698191\n",
      "Iteration 8148, loss = 358.08552832\n",
      "Iteration 8149, loss = 358.06379385\n",
      "Iteration 8150, loss = 358.04596149\n",
      "Iteration 8151, loss = 358.03400354\n",
      "Iteration 8152, loss = 358.02607863\n",
      "Iteration 8153, loss = 358.03203985\n",
      "Iteration 8154, loss = 358.01267237\n",
      "Iteration 8155, loss = 358.00707309\n",
      "Iteration 8156, loss = 358.01800927\n",
      "Iteration 8157, loss = 358.00372552\n",
      "Iteration 8158, loss = 357.98334848\n",
      "Iteration 8159, loss = 357.97010807\n",
      "Iteration 8160, loss = 357.97923074\n",
      "Iteration 8161, loss = 357.99835108\n",
      "Iteration 8162, loss = 357.97091718\n",
      "Iteration 8163, loss = 357.98289671\n",
      "Iteration 8164, loss = 357.96839074\n",
      "Iteration 8165, loss = 357.96664703\n",
      "Iteration 8166, loss = 357.92004214\n",
      "Iteration 8167, loss = 357.94797013\n",
      "Iteration 8168, loss = 357.93640173\n",
      "Iteration 8169, loss = 357.91189481\n",
      "Iteration 8170, loss = 357.89485646\n",
      "Iteration 8171, loss = 357.90274232\n",
      "Iteration 8172, loss = 357.88461714\n",
      "Iteration 8173, loss = 357.87535829\n",
      "Iteration 8174, loss = 357.87611380\n",
      "Iteration 8175, loss = 357.86521567\n",
      "Iteration 8176, loss = 357.86283543\n",
      "Iteration 8177, loss = 357.84686674\n",
      "Iteration 8178, loss = 357.85087535\n",
      "Iteration 8179, loss = 357.84404977\n",
      "Iteration 8180, loss = 357.82342462\n",
      "Iteration 8181, loss = 357.82497260\n",
      "Iteration 8182, loss = 357.82606014\n",
      "Iteration 8183, loss = 357.81586856\n",
      "Iteration 8184, loss = 357.78413286\n",
      "Iteration 8185, loss = 357.78062927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8186, loss = 357.78792835\n",
      "Iteration 8187, loss = 357.77011120\n",
      "Iteration 8188, loss = 357.76582248\n",
      "Iteration 8189, loss = 357.77531015\n",
      "Iteration 8190, loss = 357.76277586\n",
      "Iteration 8191, loss = 357.73970420\n",
      "Iteration 8192, loss = 357.75026970\n",
      "Iteration 8193, loss = 357.75132285\n",
      "Iteration 8194, loss = 357.72159702\n",
      "Iteration 8195, loss = 357.71298169\n",
      "Iteration 8196, loss = 357.71920124\n",
      "Iteration 8197, loss = 357.71234776\n",
      "Iteration 8198, loss = 357.70529700\n",
      "Iteration 8199, loss = 357.67903060\n",
      "Iteration 8200, loss = 357.67899187\n",
      "Iteration 8201, loss = 357.66272560\n",
      "Iteration 8202, loss = 357.66650886\n",
      "Iteration 8203, loss = 357.67704071\n",
      "Iteration 8204, loss = 357.66379221\n",
      "Iteration 8205, loss = 357.63758353\n",
      "Iteration 8206, loss = 357.63795677\n",
      "Iteration 8207, loss = 357.64713052\n",
      "Iteration 8208, loss = 357.63560952\n",
      "Iteration 8209, loss = 357.60711108\n",
      "Iteration 8210, loss = 357.60700598\n",
      "Iteration 8211, loss = 357.59465565\n",
      "Iteration 8212, loss = 357.59554969\n",
      "Iteration 8213, loss = 357.59124339\n",
      "Iteration 8214, loss = 357.58154397\n",
      "Iteration 8215, loss = 357.57528335\n",
      "Iteration 8216, loss = 357.55852993\n",
      "Iteration 8217, loss = 357.57012533\n",
      "Iteration 8218, loss = 357.56727658\n",
      "Iteration 8219, loss = 357.53692160\n",
      "Iteration 8220, loss = 357.54164061\n",
      "Iteration 8221, loss = 357.54020376\n",
      "Iteration 8222, loss = 357.54749011\n",
      "Iteration 8223, loss = 357.53009805\n",
      "Iteration 8224, loss = 357.50270223\n",
      "Iteration 8225, loss = 357.49187000\n",
      "Iteration 8226, loss = 357.48011052\n",
      "Iteration 8227, loss = 357.50918427\n",
      "Iteration 8228, loss = 357.51116745\n",
      "Iteration 8229, loss = 357.50573242\n",
      "Iteration 8230, loss = 357.48907980\n",
      "Iteration 8231, loss = 357.47072489\n",
      "Iteration 8232, loss = 357.46266847\n",
      "Iteration 8233, loss = 357.43506107\n",
      "Iteration 8234, loss = 357.44657357\n",
      "Iteration 8235, loss = 357.45358312\n",
      "Iteration 8236, loss = 357.43819974\n",
      "Iteration 8237, loss = 357.41127000\n",
      "Iteration 8238, loss = 357.41633670\n",
      "Iteration 8239, loss = 357.41762162\n",
      "Iteration 8240, loss = 357.40705397\n",
      "Iteration 8241, loss = 357.39676583\n",
      "Iteration 8242, loss = 357.40749841\n",
      "Iteration 8243, loss = 357.39296611\n",
      "Iteration 8244, loss = 357.36788027\n",
      "Iteration 8245, loss = 357.35251707\n",
      "Iteration 8246, loss = 357.36026588\n",
      "Iteration 8247, loss = 357.33916043\n",
      "Iteration 8248, loss = 357.34729592\n",
      "Iteration 8249, loss = 357.33966173\n",
      "Iteration 8250, loss = 357.33974938\n",
      "Iteration 8251, loss = 357.30763538\n",
      "Iteration 8252, loss = 357.32421022\n",
      "Iteration 8253, loss = 357.32892370\n",
      "Iteration 8254, loss = 357.30546211\n",
      "Iteration 8255, loss = 357.28246304\n",
      "Iteration 8256, loss = 357.28877611\n",
      "Iteration 8257, loss = 357.27127597\n",
      "Iteration 8258, loss = 357.26592162\n",
      "Iteration 8259, loss = 357.26054542\n",
      "Iteration 8260, loss = 357.24696007\n",
      "Iteration 8261, loss = 357.25234231\n",
      "Iteration 8262, loss = 357.23092593\n",
      "Iteration 8263, loss = 357.23966216\n",
      "Iteration 8264, loss = 357.24161930\n",
      "Iteration 8265, loss = 357.21841230\n",
      "Iteration 8266, loss = 357.22621111\n",
      "Iteration 8267, loss = 357.22315887\n",
      "Iteration 8268, loss = 357.21507132\n",
      "Iteration 8269, loss = 357.19687596\n",
      "Iteration 8270, loss = 357.16322186\n",
      "Iteration 8271, loss = 357.20021211\n",
      "Iteration 8272, loss = 357.20314758\n",
      "Iteration 8273, loss = 357.18417645\n",
      "Iteration 8274, loss = 357.16326689\n",
      "Iteration 8275, loss = 357.13521517\n",
      "Iteration 8276, loss = 357.14229719\n",
      "Iteration 8277, loss = 357.14497988\n",
      "Iteration 8278, loss = 357.12389457\n",
      "Iteration 8279, loss = 357.09993189\n",
      "Iteration 8280, loss = 357.11610044\n",
      "Iteration 8281, loss = 357.12288713\n",
      "Iteration 8282, loss = 357.11023323\n",
      "Iteration 8283, loss = 357.08625456\n",
      "Iteration 8284, loss = 357.09085081\n",
      "Iteration 8285, loss = 357.10281600\n",
      "Iteration 8286, loss = 357.08747558\n",
      "Iteration 8287, loss = 357.07180149\n",
      "Iteration 8288, loss = 357.05516014\n",
      "Iteration 8289, loss = 357.04236104\n",
      "Iteration 8290, loss = 357.04086902\n",
      "Iteration 8291, loss = 357.02476208\n",
      "Iteration 8292, loss = 357.01644788\n",
      "Iteration 8293, loss = 357.02361817\n",
      "Iteration 8294, loss = 356.99963485\n",
      "Iteration 8295, loss = 356.98730686\n",
      "Iteration 8296, loss = 357.02309639\n",
      "Iteration 8297, loss = 357.01821900\n",
      "Iteration 8298, loss = 356.99903680\n",
      "Iteration 8299, loss = 356.97297467\n",
      "Iteration 8300, loss = 356.99451699\n",
      "Iteration 8301, loss = 357.00104538\n",
      "Iteration 8302, loss = 356.99517614\n",
      "Iteration 8303, loss = 356.97705371\n",
      "Iteration 8304, loss = 356.94639748\n",
      "Iteration 8305, loss = 356.92032394\n",
      "Iteration 8306, loss = 356.95027314\n",
      "Iteration 8307, loss = 356.95420263\n",
      "Iteration 8308, loss = 356.95893959\n",
      "Iteration 8309, loss = 356.93667532\n",
      "Iteration 8310, loss = 356.89734334\n",
      "Iteration 8311, loss = 356.89677499\n",
      "Iteration 8312, loss = 356.89338068\n",
      "Iteration 8313, loss = 356.87993203\n",
      "Iteration 8314, loss = 356.87788328\n",
      "Iteration 8315, loss = 356.87802955\n",
      "Iteration 8316, loss = 356.86061702\n",
      "Iteration 8317, loss = 356.85726556\n",
      "Iteration 8318, loss = 356.87941638\n",
      "Iteration 8319, loss = 356.86492623\n",
      "Iteration 8320, loss = 356.82685432\n",
      "Iteration 8321, loss = 356.83068440\n",
      "Iteration 8322, loss = 356.81898099\n",
      "Iteration 8323, loss = 356.79105364\n",
      "Iteration 8324, loss = 356.78881293\n",
      "Iteration 8325, loss = 356.79406248\n",
      "Iteration 8326, loss = 356.77248123\n",
      "Iteration 8327, loss = 356.74921226\n",
      "Iteration 8328, loss = 356.74392088\n",
      "Iteration 8329, loss = 356.75091226\n",
      "Iteration 8330, loss = 356.73867070\n",
      "Iteration 8331, loss = 356.75157370\n",
      "Iteration 8332, loss = 356.77047436\n",
      "Iteration 8333, loss = 356.73846306\n",
      "Iteration 8334, loss = 356.72953613\n",
      "Iteration 8335, loss = 356.72116850\n",
      "Iteration 8336, loss = 356.71226769\n",
      "Iteration 8337, loss = 356.69715270\n",
      "Iteration 8338, loss = 356.68468300\n",
      "Iteration 8339, loss = 356.69400555\n",
      "Iteration 8340, loss = 356.65849999\n",
      "Iteration 8341, loss = 356.63206340\n",
      "Iteration 8342, loss = 356.63841014\n",
      "Iteration 8343, loss = 356.64173964\n",
      "Iteration 8344, loss = 356.63958053\n",
      "Iteration 8345, loss = 356.60529088\n",
      "Iteration 8346, loss = 356.59759188\n",
      "Iteration 8347, loss = 356.59791574\n",
      "Iteration 8348, loss = 356.60323598\n",
      "Iteration 8349, loss = 356.58145955\n",
      "Iteration 8350, loss = 356.56549241\n",
      "Iteration 8351, loss = 356.57342000\n",
      "Iteration 8352, loss = 356.57668003\n",
      "Iteration 8353, loss = 356.57434891\n",
      "Iteration 8354, loss = 356.54895798\n",
      "Iteration 8355, loss = 356.56425943\n",
      "Iteration 8356, loss = 356.51437205\n",
      "Iteration 8357, loss = 356.53792504\n",
      "Iteration 8358, loss = 356.51378069\n",
      "Iteration 8359, loss = 356.54511927\n",
      "Iteration 8360, loss = 356.52449151\n",
      "Iteration 8361, loss = 356.50952289\n",
      "Iteration 8362, loss = 356.50803917\n",
      "Iteration 8363, loss = 356.50534494\n",
      "Iteration 8364, loss = 356.51316334\n",
      "Iteration 8365, loss = 356.47510936\n",
      "Iteration 8366, loss = 356.44890803\n",
      "Iteration 8367, loss = 356.43764649\n",
      "Iteration 8368, loss = 356.44167958\n",
      "Iteration 8369, loss = 356.42969410\n",
      "Iteration 8370, loss = 356.43516155\n",
      "Iteration 8371, loss = 356.40581797\n",
      "Iteration 8372, loss = 356.43998450\n",
      "Iteration 8373, loss = 356.40174086\n",
      "Iteration 8374, loss = 356.42460064\n",
      "Iteration 8375, loss = 356.39488938\n",
      "Iteration 8376, loss = 356.37785805\n",
      "Iteration 8377, loss = 356.38479084\n",
      "Iteration 8378, loss = 356.38508985\n",
      "Iteration 8379, loss = 356.38368840\n",
      "Iteration 8380, loss = 356.37038275\n",
      "Iteration 8381, loss = 356.33450122\n",
      "Iteration 8382, loss = 356.35667855\n",
      "Iteration 8383, loss = 356.35811793\n",
      "Iteration 8384, loss = 356.35057866\n",
      "Iteration 8385, loss = 356.32871007\n",
      "Iteration 8386, loss = 356.32446733\n",
      "Iteration 8387, loss = 356.34015329\n",
      "Iteration 8388, loss = 356.33315987\n",
      "Iteration 8389, loss = 356.30412949\n",
      "Iteration 8390, loss = 356.28571750\n",
      "Iteration 8391, loss = 356.30091683\n",
      "Iteration 8392, loss = 356.30447655\n",
      "Iteration 8393, loss = 356.28268603\n",
      "Iteration 8394, loss = 356.27416925\n",
      "Iteration 8395, loss = 356.27545527\n",
      "Iteration 8396, loss = 356.24879281\n",
      "Iteration 8397, loss = 356.25437466\n",
      "Iteration 8398, loss = 356.23526229\n",
      "Iteration 8399, loss = 356.22502561\n",
      "Iteration 8400, loss = 356.22899608\n",
      "Iteration 8401, loss = 356.21305954\n",
      "Iteration 8402, loss = 356.21294162\n",
      "Iteration 8403, loss = 356.21318289\n",
      "Iteration 8404, loss = 356.19742615\n",
      "Iteration 8405, loss = 356.20105905\n",
      "Iteration 8406, loss = 356.20990883\n",
      "Iteration 8407, loss = 356.18759511\n",
      "Iteration 8408, loss = 356.19805761\n",
      "Iteration 8409, loss = 356.16727850\n",
      "Iteration 8410, loss = 356.15190205\n",
      "Iteration 8411, loss = 356.14450214\n",
      "Iteration 8412, loss = 356.13102624\n",
      "Iteration 8413, loss = 356.12809429\n",
      "Iteration 8414, loss = 356.13147830\n",
      "Iteration 8415, loss = 356.11695708\n",
      "Iteration 8416, loss = 356.11768341\n",
      "Iteration 8417, loss = 356.11140819\n",
      "Iteration 8418, loss = 356.10930141\n",
      "Iteration 8419, loss = 356.09740282\n",
      "Iteration 8420, loss = 356.08907193\n",
      "Iteration 8421, loss = 356.08883485\n",
      "Iteration 8422, loss = 356.08094990\n",
      "Iteration 8423, loss = 356.08590451\n",
      "Iteration 8424, loss = 356.07452884\n",
      "Iteration 8425, loss = 356.06630419\n",
      "Iteration 8426, loss = 356.05962722\n",
      "Iteration 8427, loss = 356.05269360\n",
      "Iteration 8428, loss = 356.06411999\n",
      "Iteration 8429, loss = 356.07210016\n",
      "Iteration 8430, loss = 356.05828188\n",
      "Iteration 8431, loss = 356.03414153\n",
      "Iteration 8432, loss = 356.05292213\n",
      "Iteration 8433, loss = 356.03366342\n",
      "Iteration 8434, loss = 356.01172241\n",
      "Iteration 8435, loss = 356.03199732\n",
      "Iteration 8436, loss = 356.01861401\n",
      "Iteration 8437, loss = 355.98478187\n",
      "Iteration 8438, loss = 355.98467323\n",
      "Iteration 8439, loss = 355.97799720\n",
      "Iteration 8440, loss = 355.99956217\n",
      "Iteration 8441, loss = 355.97067553\n",
      "Iteration 8442, loss = 355.99539449\n",
      "Iteration 8443, loss = 355.96931640\n",
      "Iteration 8444, loss = 355.95996563\n",
      "Iteration 8445, loss = 355.93995325\n",
      "Iteration 8446, loss = 355.94027801\n",
      "Iteration 8447, loss = 355.92024178\n",
      "Iteration 8448, loss = 355.91041483\n",
      "Iteration 8449, loss = 355.92386130\n",
      "Iteration 8450, loss = 355.90501386\n",
      "Iteration 8451, loss = 355.88352063\n",
      "Iteration 8452, loss = 355.87019977\n",
      "Iteration 8453, loss = 355.89478014\n",
      "Iteration 8454, loss = 355.89684331\n",
      "Iteration 8455, loss = 355.86671912\n",
      "Iteration 8456, loss = 355.86399787\n",
      "Iteration 8457, loss = 355.86713340\n",
      "Iteration 8458, loss = 355.84454067\n",
      "Iteration 8459, loss = 355.83601412\n",
      "Iteration 8460, loss = 355.83836484\n",
      "Iteration 8461, loss = 355.83835419\n",
      "Iteration 8462, loss = 355.82423881\n",
      "Iteration 8463, loss = 355.79319960\n",
      "Iteration 8464, loss = 355.81145186\n",
      "Iteration 8465, loss = 355.83265228\n",
      "Iteration 8466, loss = 355.82773746\n",
      "Iteration 8467, loss = 355.78436667\n",
      "Iteration 8468, loss = 355.78650613\n",
      "Iteration 8469, loss = 355.80315157\n",
      "Iteration 8470, loss = 355.80088725\n",
      "Iteration 8471, loss = 355.77995817\n",
      "Iteration 8472, loss = 355.75620123\n",
      "Iteration 8473, loss = 355.77340388\n",
      "Iteration 8474, loss = 355.75953906\n",
      "Iteration 8475, loss = 355.75177264\n",
      "Iteration 8476, loss = 355.72856247\n",
      "Iteration 8477, loss = 355.73119797\n",
      "Iteration 8478, loss = 355.72057464\n",
      "Iteration 8479, loss = 355.69450414\n",
      "Iteration 8480, loss = 355.69630049\n",
      "Iteration 8481, loss = 355.69872656\n",
      "Iteration 8482, loss = 355.69027535\n",
      "Iteration 8483, loss = 355.68100938\n",
      "Iteration 8484, loss = 355.68175516\n",
      "Iteration 8485, loss = 355.66679437\n",
      "Iteration 8486, loss = 355.65159500\n",
      "Iteration 8487, loss = 355.65400205\n",
      "Iteration 8488, loss = 355.63467313\n",
      "Iteration 8489, loss = 355.63716343\n",
      "Iteration 8490, loss = 355.64030072\n",
      "Iteration 8491, loss = 355.62886650\n",
      "Iteration 8492, loss = 355.61959055\n",
      "Iteration 8493, loss = 355.61462036\n",
      "Iteration 8494, loss = 355.62319413\n",
      "Iteration 8495, loss = 355.61629951\n",
      "Iteration 8496, loss = 355.60233164\n",
      "Iteration 8497, loss = 355.58926294\n",
      "Iteration 8498, loss = 355.58104580\n",
      "Iteration 8499, loss = 355.57997308\n",
      "Iteration 8500, loss = 355.57241159\n",
      "Iteration 8501, loss = 355.57262172\n",
      "Iteration 8502, loss = 355.54973377\n",
      "Iteration 8503, loss = 355.55783832\n",
      "Iteration 8504, loss = 355.57685772\n",
      "Iteration 8505, loss = 355.53945423\n",
      "Iteration 8506, loss = 355.54021406\n",
      "Iteration 8507, loss = 355.55485637\n",
      "Iteration 8508, loss = 355.54788221\n",
      "Iteration 8509, loss = 355.52998574\n",
      "Iteration 8510, loss = 355.50680708\n",
      "Iteration 8511, loss = 355.50810515\n",
      "Iteration 8512, loss = 355.52077189\n",
      "Iteration 8513, loss = 355.50684211\n",
      "Iteration 8514, loss = 355.49771876\n",
      "Iteration 8515, loss = 355.50017376\n",
      "Iteration 8516, loss = 355.46870224\n",
      "Iteration 8517, loss = 355.48966485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8518, loss = 355.47127072\n",
      "Iteration 8519, loss = 355.49388399\n",
      "Iteration 8520, loss = 355.45984369\n",
      "Iteration 8521, loss = 355.50937590\n",
      "Iteration 8522, loss = 355.46235283\n",
      "Iteration 8523, loss = 355.46263404\n",
      "Iteration 8524, loss = 355.44959527\n",
      "Iteration 8525, loss = 355.47759161\n",
      "Iteration 8526, loss = 355.41063855\n",
      "Iteration 8527, loss = 355.41945053\n",
      "Iteration 8528, loss = 355.43840647\n",
      "Iteration 8529, loss = 355.43818642\n",
      "Iteration 8530, loss = 355.41896556\n",
      "Iteration 8531, loss = 355.39478380\n",
      "Iteration 8532, loss = 355.39324080\n",
      "Iteration 8533, loss = 355.39974857\n",
      "Iteration 8534, loss = 355.38642867\n",
      "Iteration 8535, loss = 355.36942068\n",
      "Iteration 8536, loss = 355.39776669\n",
      "Iteration 8537, loss = 355.41036290\n",
      "Iteration 8538, loss = 355.40046115\n",
      "Iteration 8539, loss = 355.36980493\n",
      "Iteration 8540, loss = 355.34423789\n",
      "Iteration 8541, loss = 355.32324301\n",
      "Iteration 8542, loss = 355.34328863\n",
      "Iteration 8543, loss = 355.32680419\n",
      "Iteration 8544, loss = 355.32842974\n",
      "Iteration 8545, loss = 355.31736477\n",
      "Iteration 8546, loss = 355.31531931\n",
      "Iteration 8547, loss = 355.29867879\n",
      "Iteration 8548, loss = 355.29512256\n",
      "Iteration 8549, loss = 355.29471548\n",
      "Iteration 8550, loss = 355.27209090\n",
      "Iteration 8551, loss = 355.24917217\n",
      "Iteration 8552, loss = 355.26254740\n",
      "Iteration 8553, loss = 355.26993735\n",
      "Iteration 8554, loss = 355.25848600\n",
      "Iteration 8555, loss = 355.24546171\n",
      "Iteration 8556, loss = 355.23974859\n",
      "Iteration 8557, loss = 355.23168484\n",
      "Iteration 8558, loss = 355.23578629\n",
      "Iteration 8559, loss = 355.23144841\n",
      "Iteration 8560, loss = 355.22394071\n",
      "Iteration 8561, loss = 355.22286789\n",
      "Iteration 8562, loss = 355.19974195\n",
      "Iteration 8563, loss = 355.20716528\n",
      "Iteration 8564, loss = 355.18916942\n",
      "Iteration 8565, loss = 355.18995554\n",
      "Iteration 8566, loss = 355.19623958\n",
      "Iteration 8567, loss = 355.18387214\n",
      "Iteration 8568, loss = 355.16231764\n",
      "Iteration 8569, loss = 355.13237383\n",
      "Iteration 8570, loss = 355.13364768\n",
      "Iteration 8571, loss = 355.12786794\n",
      "Iteration 8572, loss = 355.11961825\n",
      "Iteration 8573, loss = 355.13535282\n",
      "Iteration 8574, loss = 355.13464982\n",
      "Iteration 8575, loss = 355.11292120\n",
      "Iteration 8576, loss = 355.11987894\n",
      "Iteration 8577, loss = 355.12521042\n",
      "Iteration 8578, loss = 355.08668244\n",
      "Iteration 8579, loss = 355.10540203\n",
      "Iteration 8580, loss = 355.12625721\n",
      "Iteration 8581, loss = 355.11457488\n",
      "Iteration 8582, loss = 355.08592165\n",
      "Iteration 8583, loss = 355.06601288\n",
      "Iteration 8584, loss = 355.08832369\n",
      "Iteration 8585, loss = 355.09845413\n",
      "Iteration 8586, loss = 355.08770966\n",
      "Iteration 8587, loss = 355.04660202\n",
      "Iteration 8588, loss = 355.05198174\n",
      "Iteration 8589, loss = 355.05962846\n",
      "Iteration 8590, loss = 355.05260717\n",
      "Iteration 8591, loss = 355.02406978\n",
      "Iteration 8592, loss = 355.01299278\n",
      "Iteration 8593, loss = 355.00220762\n",
      "Iteration 8594, loss = 354.99607885\n",
      "Iteration 8595, loss = 354.97581711\n",
      "Iteration 8596, loss = 354.98233287\n",
      "Iteration 8597, loss = 354.99405568\n",
      "Iteration 8598, loss = 354.97871255\n",
      "Iteration 8599, loss = 354.95098511\n",
      "Iteration 8600, loss = 354.96122531\n",
      "Iteration 8601, loss = 354.95992442\n",
      "Iteration 8602, loss = 354.94656178\n",
      "Iteration 8603, loss = 354.93466541\n",
      "Iteration 8604, loss = 354.96330094\n",
      "Iteration 8605, loss = 354.93999097\n",
      "Iteration 8606, loss = 354.91328037\n",
      "Iteration 8607, loss = 354.95553853\n",
      "Iteration 8608, loss = 354.93136752\n",
      "Iteration 8609, loss = 354.91892057\n",
      "Iteration 8610, loss = 354.91926222\n",
      "Iteration 8611, loss = 354.94177944\n",
      "Iteration 8612, loss = 354.91087793\n",
      "Iteration 8613, loss = 354.88935776\n",
      "Iteration 8614, loss = 354.89556779\n",
      "Iteration 8615, loss = 354.88904051\n",
      "Iteration 8616, loss = 354.88147736\n",
      "Iteration 8617, loss = 354.86759454\n",
      "Iteration 8618, loss = 354.90994564\n",
      "Iteration 8619, loss = 354.88219253\n",
      "Iteration 8620, loss = 354.87317516\n",
      "Iteration 8621, loss = 354.82743106\n",
      "Iteration 8622, loss = 354.82427176\n",
      "Iteration 8623, loss = 354.83760755\n",
      "Iteration 8624, loss = 354.82273016\n",
      "Iteration 8625, loss = 354.82648708\n",
      "Iteration 8626, loss = 354.81366149\n",
      "Iteration 8627, loss = 354.82800510\n",
      "Iteration 8628, loss = 354.81760033\n",
      "Iteration 8629, loss = 354.79363307\n",
      "Iteration 8630, loss = 354.81553498\n",
      "Iteration 8631, loss = 354.79181788\n",
      "Iteration 8632, loss = 354.79157347\n",
      "Iteration 8633, loss = 354.76572045\n",
      "Iteration 8634, loss = 354.78759027\n",
      "Iteration 8635, loss = 354.73674071\n",
      "Iteration 8636, loss = 354.75877198\n",
      "Iteration 8637, loss = 354.76199223\n",
      "Iteration 8638, loss = 354.75561632\n",
      "Iteration 8639, loss = 354.74369787\n",
      "Iteration 8640, loss = 354.72667894\n",
      "Iteration 8641, loss = 354.70623009\n",
      "Iteration 8642, loss = 354.70291053\n",
      "Iteration 8643, loss = 354.70964555\n",
      "Iteration 8644, loss = 354.68134153\n",
      "Iteration 8645, loss = 354.71259027\n",
      "Iteration 8646, loss = 354.68665743\n",
      "Iteration 8647, loss = 354.68737972\n",
      "Iteration 8648, loss = 354.66792181\n",
      "Iteration 8649, loss = 354.67610486\n",
      "Iteration 8650, loss = 354.66359838\n",
      "Iteration 8651, loss = 354.65420714\n",
      "Iteration 8652, loss = 354.65564373\n",
      "Iteration 8653, loss = 354.64567736\n",
      "Iteration 8654, loss = 354.63033016\n",
      "Iteration 8655, loss = 354.62386185\n",
      "Iteration 8656, loss = 354.61934413\n",
      "Iteration 8657, loss = 354.60914433\n",
      "Iteration 8658, loss = 354.61743255\n",
      "Iteration 8659, loss = 354.60709225\n",
      "Iteration 8660, loss = 354.61441971\n",
      "Iteration 8661, loss = 354.58929484\n",
      "Iteration 8662, loss = 354.61419724\n",
      "Iteration 8663, loss = 354.60818472\n",
      "Iteration 8664, loss = 354.58820765\n",
      "Iteration 8665, loss = 354.56016490\n",
      "Iteration 8666, loss = 354.56229129\n",
      "Iteration 8667, loss = 354.55165504\n",
      "Iteration 8668, loss = 354.52829214\n",
      "Iteration 8669, loss = 354.52765270\n",
      "Iteration 8670, loss = 354.53486421\n",
      "Iteration 8671, loss = 354.52046048\n",
      "Iteration 8672, loss = 354.51453728\n",
      "Iteration 8673, loss = 354.52762352\n",
      "Iteration 8674, loss = 354.51799376\n",
      "Iteration 8675, loss = 354.49498744\n",
      "Iteration 8676, loss = 354.51909422\n",
      "Iteration 8677, loss = 354.48972208\n",
      "Iteration 8678, loss = 354.52368475\n",
      "Iteration 8679, loss = 354.51019079\n",
      "Iteration 8680, loss = 354.50732334\n",
      "Iteration 8681, loss = 354.49305617\n",
      "Iteration 8682, loss = 354.51826635\n",
      "Iteration 8683, loss = 354.53196813\n",
      "Iteration 8684, loss = 354.47206864\n",
      "Iteration 8685, loss = 354.49799132\n",
      "Iteration 8686, loss = 354.47351657\n",
      "Iteration 8687, loss = 354.48743194\n",
      "Iteration 8688, loss = 354.45958533\n",
      "Iteration 8689, loss = 354.43422676\n",
      "Iteration 8690, loss = 354.46269643\n",
      "Iteration 8691, loss = 354.45982200\n",
      "Iteration 8692, loss = 354.46777681\n",
      "Iteration 8693, loss = 354.45237247\n",
      "Iteration 8694, loss = 354.43324777\n",
      "Iteration 8695, loss = 354.39650457\n",
      "Iteration 8696, loss = 354.39382626\n",
      "Iteration 8697, loss = 354.41410805\n",
      "Iteration 8698, loss = 354.39661705\n",
      "Iteration 8699, loss = 354.37567374\n",
      "Iteration 8700, loss = 354.37498366\n",
      "Iteration 8701, loss = 354.38770972\n",
      "Iteration 8702, loss = 354.36978799\n",
      "Iteration 8703, loss = 354.35196077\n",
      "Iteration 8704, loss = 354.33236810\n",
      "Iteration 8705, loss = 354.32460209\n",
      "Iteration 8706, loss = 354.33356334\n",
      "Iteration 8707, loss = 354.33256523\n",
      "Iteration 8708, loss = 354.31875049\n",
      "Iteration 8709, loss = 354.32062178\n",
      "Iteration 8710, loss = 354.30702810\n",
      "Iteration 8711, loss = 354.27996869\n",
      "Iteration 8712, loss = 354.30976971\n",
      "Iteration 8713, loss = 354.31091565\n",
      "Iteration 8714, loss = 354.28524844\n",
      "Iteration 8715, loss = 354.27240836\n",
      "Iteration 8716, loss = 354.28688045\n",
      "Iteration 8717, loss = 354.27085532\n",
      "Iteration 8718, loss = 354.26445981\n",
      "Iteration 8719, loss = 354.26946433\n",
      "Iteration 8720, loss = 354.27675616\n",
      "Iteration 8721, loss = 354.26045001\n",
      "Iteration 8722, loss = 354.26460050\n",
      "Iteration 8723, loss = 354.25864936\n",
      "Iteration 8724, loss = 354.23461373\n",
      "Iteration 8725, loss = 354.22756362\n",
      "Iteration 8726, loss = 354.21337038\n",
      "Iteration 8727, loss = 354.20539599\n",
      "Iteration 8728, loss = 354.20895344\n",
      "Iteration 8729, loss = 354.20493550\n",
      "Iteration 8730, loss = 354.18907958\n",
      "Iteration 8731, loss = 354.18299269\n",
      "Iteration 8732, loss = 354.19875449\n",
      "Iteration 8733, loss = 354.19039693\n",
      "Iteration 8734, loss = 354.15131470\n",
      "Iteration 8735, loss = 354.15083330\n",
      "Iteration 8736, loss = 354.16636371\n",
      "Iteration 8737, loss = 354.16483554\n",
      "Iteration 8738, loss = 354.16816717\n",
      "Iteration 8739, loss = 354.17719104\n",
      "Iteration 8740, loss = 354.12611675\n",
      "Iteration 8741, loss = 354.15445187\n",
      "Iteration 8742, loss = 354.17495718\n",
      "Iteration 8743, loss = 354.12970737\n",
      "Iteration 8744, loss = 354.08701121\n",
      "Iteration 8745, loss = 354.12713198\n",
      "Iteration 8746, loss = 354.13930096\n",
      "Iteration 8747, loss = 354.12283145\n",
      "Iteration 8748, loss = 354.13497296\n",
      "Iteration 8749, loss = 354.10653980\n",
      "Iteration 8750, loss = 354.06834059\n",
      "Iteration 8751, loss = 354.05411244\n",
      "Iteration 8752, loss = 354.07528139\n",
      "Iteration 8753, loss = 354.05299786\n",
      "Iteration 8754, loss = 354.03615012\n",
      "Iteration 8755, loss = 354.05502179\n",
      "Iteration 8756, loss = 354.05605825\n",
      "Iteration 8757, loss = 354.06312303\n",
      "Iteration 8758, loss = 354.03744980\n",
      "Iteration 8759, loss = 354.02138890\n",
      "Iteration 8760, loss = 353.99077197\n",
      "Iteration 8761, loss = 353.99516377\n",
      "Iteration 8762, loss = 353.98490524\n",
      "Iteration 8763, loss = 353.96943031\n",
      "Iteration 8764, loss = 353.98310052\n",
      "Iteration 8765, loss = 353.98386919\n",
      "Iteration 8766, loss = 353.96024237\n",
      "Iteration 8767, loss = 353.95189053\n",
      "Iteration 8768, loss = 353.98350355\n",
      "Iteration 8769, loss = 353.96482976\n",
      "Iteration 8770, loss = 353.93254623\n",
      "Iteration 8771, loss = 353.98333057\n",
      "Iteration 8772, loss = 353.97306461\n",
      "Iteration 8773, loss = 353.93817581\n",
      "Iteration 8774, loss = 353.96385534\n",
      "Iteration 8775, loss = 353.97223406\n",
      "Iteration 8776, loss = 353.89697312\n",
      "Iteration 8777, loss = 353.90411192\n",
      "Iteration 8778, loss = 353.91059511\n",
      "Iteration 8779, loss = 353.91480783\n",
      "Iteration 8780, loss = 353.88477481\n",
      "Iteration 8781, loss = 353.87228231\n",
      "Iteration 8782, loss = 353.87626902\n",
      "Iteration 8783, loss = 353.86300032\n",
      "Iteration 8784, loss = 353.86061006\n",
      "Iteration 8785, loss = 353.84818370\n",
      "Iteration 8786, loss = 353.86671423\n",
      "Iteration 8787, loss = 353.84402930\n",
      "Iteration 8788, loss = 353.84129999\n",
      "Iteration 8789, loss = 353.85258434\n",
      "Iteration 8790, loss = 353.87921196\n",
      "Iteration 8791, loss = 353.82586022\n",
      "Iteration 8792, loss = 353.84137826\n",
      "Iteration 8793, loss = 353.86510700\n",
      "Iteration 8794, loss = 353.82304202\n",
      "Iteration 8795, loss = 353.79752729\n",
      "Iteration 8796, loss = 353.83461080\n",
      "Iteration 8797, loss = 353.81496369\n",
      "Iteration 8798, loss = 353.77976111\n",
      "Iteration 8799, loss = 353.81390206\n",
      "Iteration 8800, loss = 353.79949434\n",
      "Iteration 8801, loss = 353.76774882\n",
      "Iteration 8802, loss = 353.76743988\n",
      "Iteration 8803, loss = 353.76780549\n",
      "Iteration 8804, loss = 353.74165980\n",
      "Iteration 8805, loss = 353.75008411\n",
      "Iteration 8806, loss = 353.75111217\n",
      "Iteration 8807, loss = 353.73687247\n",
      "Iteration 8808, loss = 353.73888237\n",
      "Iteration 8809, loss = 353.72102904\n",
      "Iteration 8810, loss = 353.72331436\n",
      "Iteration 8811, loss = 353.71248568\n",
      "Iteration 8812, loss = 353.71813538\n",
      "Iteration 8813, loss = 353.70677640\n",
      "Iteration 8814, loss = 353.70458678\n",
      "Iteration 8815, loss = 353.68378937\n",
      "Iteration 8816, loss = 353.70675991\n",
      "Iteration 8817, loss = 353.66959671\n",
      "Iteration 8818, loss = 353.66630067\n",
      "Iteration 8819, loss = 353.68953781\n",
      "Iteration 8820, loss = 353.68124984\n",
      "Iteration 8821, loss = 353.67268324\n",
      "Iteration 8822, loss = 353.65151355\n",
      "Iteration 8823, loss = 353.67623409\n",
      "Iteration 8824, loss = 353.66628670\n",
      "Iteration 8825, loss = 353.66790356\n",
      "Iteration 8826, loss = 353.63628032\n",
      "Iteration 8827, loss = 353.67332882\n",
      "Iteration 8828, loss = 353.67369667\n",
      "Iteration 8829, loss = 353.67250675\n",
      "Iteration 8830, loss = 353.64960397\n",
      "Iteration 8831, loss = 353.62765543\n",
      "Iteration 8832, loss = 353.60068091\n",
      "Iteration 8833, loss = 353.57637868\n",
      "Iteration 8834, loss = 353.59145272\n",
      "Iteration 8835, loss = 353.59870457\n",
      "Iteration 8836, loss = 353.57783226\n",
      "Iteration 8837, loss = 353.57990325\n",
      "Iteration 8838, loss = 353.54699072\n",
      "Iteration 8839, loss = 353.55397103\n",
      "Iteration 8840, loss = 353.55612110\n",
      "Iteration 8841, loss = 353.53810720\n",
      "Iteration 8842, loss = 353.55341751\n",
      "Iteration 8843, loss = 353.56321162\n",
      "Iteration 8844, loss = 353.56134030\n",
      "Iteration 8845, loss = 353.54754662\n",
      "Iteration 8846, loss = 353.51462112\n",
      "Iteration 8847, loss = 353.49239308\n",
      "Iteration 8848, loss = 353.50137979\n",
      "Iteration 8849, loss = 353.49025926\n",
      "Iteration 8850, loss = 353.49347270\n",
      "Iteration 8851, loss = 353.48430558\n",
      "Iteration 8852, loss = 353.49387271\n",
      "Iteration 8853, loss = 353.46755567\n",
      "Iteration 8854, loss = 353.46606815\n",
      "Iteration 8855, loss = 353.47606944\n",
      "Iteration 8856, loss = 353.45918450\n",
      "Iteration 8857, loss = 353.47141194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8858, loss = 353.47366070\n",
      "Iteration 8859, loss = 353.45609505\n",
      "Iteration 8860, loss = 353.43648102\n",
      "Iteration 8861, loss = 353.41356981\n",
      "Iteration 8862, loss = 353.42478531\n",
      "Iteration 8863, loss = 353.45763013\n",
      "Iteration 8864, loss = 353.43958018\n",
      "Iteration 8865, loss = 353.42598630\n",
      "Iteration 8866, loss = 353.41923369\n",
      "Iteration 8867, loss = 353.40008791\n",
      "Iteration 8868, loss = 353.41233063\n",
      "Iteration 8869, loss = 353.41388807\n",
      "Iteration 8870, loss = 353.39070853\n",
      "Iteration 8871, loss = 353.38469893\n",
      "Iteration 8872, loss = 353.36793666\n",
      "Iteration 8873, loss = 353.36980573\n",
      "Iteration 8874, loss = 353.35505353\n",
      "Iteration 8875, loss = 353.33752198\n",
      "Iteration 8876, loss = 353.33995986\n",
      "Iteration 8877, loss = 353.32025574\n",
      "Iteration 8878, loss = 353.35743257\n",
      "Iteration 8879, loss = 353.35063952\n",
      "Iteration 8880, loss = 353.32516825\n",
      "Iteration 8881, loss = 353.32963634\n",
      "Iteration 8882, loss = 353.33378702\n",
      "Iteration 8883, loss = 353.31566691\n",
      "Iteration 8884, loss = 353.29427321\n",
      "Iteration 8885, loss = 353.29143896\n",
      "Iteration 8886, loss = 353.29741010\n",
      "Iteration 8887, loss = 353.29924416\n",
      "Iteration 8888, loss = 353.26809425\n",
      "Iteration 8889, loss = 353.26043731\n",
      "Iteration 8890, loss = 353.27209565\n",
      "Iteration 8891, loss = 353.27113658\n",
      "Iteration 8892, loss = 353.23715023\n",
      "Iteration 8893, loss = 353.24768467\n",
      "Iteration 8894, loss = 353.25797309\n",
      "Iteration 8895, loss = 353.24308227\n",
      "Iteration 8896, loss = 353.24952187\n",
      "Iteration 8897, loss = 353.25448939\n",
      "Iteration 8898, loss = 353.22737784\n",
      "Iteration 8899, loss = 353.21360839\n",
      "Iteration 8900, loss = 353.20887638\n",
      "Iteration 8901, loss = 353.19587102\n",
      "Iteration 8902, loss = 353.19224115\n",
      "Iteration 8903, loss = 353.18179875\n",
      "Iteration 8904, loss = 353.18200089\n",
      "Iteration 8905, loss = 353.19412935\n",
      "Iteration 8906, loss = 353.17540428\n",
      "Iteration 8907, loss = 353.16462820\n",
      "Iteration 8908, loss = 353.14250726\n",
      "Iteration 8909, loss = 353.15123252\n",
      "Iteration 8910, loss = 353.15096684\n",
      "Iteration 8911, loss = 353.17264662\n",
      "Iteration 8912, loss = 353.15058050\n",
      "Iteration 8913, loss = 353.14651493\n",
      "Iteration 8914, loss = 353.15744307\n",
      "Iteration 8915, loss = 353.11264973\n",
      "Iteration 8916, loss = 353.13887289\n",
      "Iteration 8917, loss = 353.13615360\n",
      "Iteration 8918, loss = 353.11407375\n",
      "Iteration 8919, loss = 353.07451397\n",
      "Iteration 8920, loss = 353.12467405\n",
      "Iteration 8921, loss = 353.12120202\n",
      "Iteration 8922, loss = 353.07769235\n",
      "Iteration 8923, loss = 353.07255133\n",
      "Iteration 8924, loss = 353.07531002\n",
      "Iteration 8925, loss = 353.06114131\n",
      "Iteration 8926, loss = 353.05187978\n",
      "Iteration 8927, loss = 353.04167304\n",
      "Iteration 8928, loss = 353.05425895\n",
      "Iteration 8929, loss = 353.02202698\n",
      "Iteration 8930, loss = 353.03558029\n",
      "Iteration 8931, loss = 353.05788814\n",
      "Iteration 8932, loss = 353.03912704\n",
      "Iteration 8933, loss = 353.02603911\n",
      "Iteration 8934, loss = 353.00112551\n",
      "Iteration 8935, loss = 353.01472188\n",
      "Iteration 8936, loss = 353.02281649\n",
      "Iteration 8937, loss = 353.00047478\n",
      "Iteration 8938, loss = 352.99201972\n",
      "Iteration 8939, loss = 353.01172878\n",
      "Iteration 8940, loss = 353.02591250\n",
      "Iteration 8941, loss = 353.00782056\n",
      "Iteration 8942, loss = 353.00789684\n",
      "Iteration 8943, loss = 352.98160809\n",
      "Iteration 8944, loss = 352.94839249\n",
      "Iteration 8945, loss = 352.96030090\n",
      "Iteration 8946, loss = 352.96596030\n",
      "Iteration 8947, loss = 352.95521707\n",
      "Iteration 8948, loss = 352.90970059\n",
      "Iteration 8949, loss = 352.91219834\n",
      "Iteration 8950, loss = 352.92611209\n",
      "Iteration 8951, loss = 352.92179582\n",
      "Iteration 8952, loss = 352.90545242\n",
      "Iteration 8953, loss = 352.88932514\n",
      "Iteration 8954, loss = 352.85962456\n",
      "Iteration 8955, loss = 352.90670354\n",
      "Iteration 8956, loss = 352.92174257\n",
      "Iteration 8957, loss = 352.91037786\n",
      "Iteration 8958, loss = 352.87521088\n",
      "Iteration 8959, loss = 352.83401618\n",
      "Iteration 8960, loss = 352.84084427\n",
      "Iteration 8961, loss = 352.84461222\n",
      "Iteration 8962, loss = 352.82534286\n",
      "Iteration 8963, loss = 352.81471080\n",
      "Iteration 8964, loss = 352.82457285\n",
      "Iteration 8965, loss = 352.81636570\n",
      "Iteration 8966, loss = 352.79756623\n",
      "Iteration 8967, loss = 352.78169747\n",
      "Iteration 8968, loss = 352.77503499\n",
      "Iteration 8969, loss = 352.77588531\n",
      "Iteration 8970, loss = 352.76660379\n",
      "Iteration 8971, loss = 352.77238043\n",
      "Iteration 8972, loss = 352.77850151\n",
      "Iteration 8973, loss = 352.77969766\n",
      "Iteration 8974, loss = 352.75635098\n",
      "Iteration 8975, loss = 352.74658098\n",
      "Iteration 8976, loss = 352.75491463\n",
      "Iteration 8977, loss = 352.73171032\n",
      "Iteration 8978, loss = 352.73327924\n",
      "Iteration 8979, loss = 352.73343792\n",
      "Iteration 8980, loss = 352.68929449\n",
      "Iteration 8981, loss = 352.72150666\n",
      "Iteration 8982, loss = 352.73515671\n",
      "Iteration 8983, loss = 352.70024547\n",
      "Iteration 8984, loss = 352.68465995\n",
      "Iteration 8985, loss = 352.68062038\n",
      "Iteration 8986, loss = 352.68159414\n",
      "Iteration 8987, loss = 352.66749112\n",
      "Iteration 8988, loss = 352.66548405\n",
      "Iteration 8989, loss = 352.66964078\n",
      "Iteration 8990, loss = 352.64858702\n",
      "Iteration 8991, loss = 352.67459261\n",
      "Iteration 8992, loss = 352.68227178\n",
      "Iteration 8993, loss = 352.66851248\n",
      "Iteration 8994, loss = 352.65149219\n",
      "Iteration 8995, loss = 352.61193144\n",
      "Iteration 8996, loss = 352.64619794\n",
      "Iteration 8997, loss = 352.66299456\n",
      "Iteration 8998, loss = 352.64706594\n",
      "Iteration 8999, loss = 352.59727804\n",
      "Iteration 9000, loss = 352.62534916\n",
      "Iteration 9001, loss = 352.64446591\n",
      "Iteration 9002, loss = 352.64992900\n",
      "Iteration 9003, loss = 352.62008883\n",
      "Iteration 9004, loss = 352.60480606\n",
      "Iteration 9005, loss = 352.56951736\n",
      "Iteration 9006, loss = 352.57505957\n",
      "Iteration 9007, loss = 352.59894201\n",
      "Iteration 9008, loss = 352.58934445\n",
      "Iteration 9009, loss = 352.55226880\n",
      "Iteration 9010, loss = 352.55631208\n",
      "Iteration 9011, loss = 352.57758366\n",
      "Iteration 9012, loss = 352.56003143\n",
      "Iteration 9013, loss = 352.53406485\n",
      "Iteration 9014, loss = 352.52182842\n",
      "Iteration 9015, loss = 352.50125564\n",
      "Iteration 9016, loss = 352.50725045\n",
      "Iteration 9017, loss = 352.48907427\n",
      "Iteration 9018, loss = 352.49409304\n",
      "Iteration 9019, loss = 352.50197545\n",
      "Iteration 9020, loss = 352.50425778\n",
      "Iteration 9021, loss = 352.46782177\n",
      "Iteration 9022, loss = 352.51025043\n",
      "Iteration 9023, loss = 352.49072824\n",
      "Iteration 9024, loss = 352.46828997\n",
      "Iteration 9025, loss = 352.49725540\n",
      "Iteration 9026, loss = 352.47097182\n",
      "Iteration 9027, loss = 352.45133161\n",
      "Iteration 9028, loss = 352.46437992\n",
      "Iteration 9029, loss = 352.44174173\n",
      "Iteration 9030, loss = 352.42701566\n",
      "Iteration 9031, loss = 352.42693472\n",
      "Iteration 9032, loss = 352.44918636\n",
      "Iteration 9033, loss = 352.39231164\n",
      "Iteration 9034, loss = 352.41219960\n",
      "Iteration 9035, loss = 352.40579358\n",
      "Iteration 9036, loss = 352.39602366\n",
      "Iteration 9037, loss = 352.37848923\n",
      "Iteration 9038, loss = 352.34839943\n",
      "Iteration 9039, loss = 352.38069183\n",
      "Iteration 9040, loss = 352.38631807\n",
      "Iteration 9041, loss = 352.35383637\n",
      "Iteration 9042, loss = 352.36597977\n",
      "Iteration 9043, loss = 352.37148421\n",
      "Iteration 9044, loss = 352.35778717\n",
      "Iteration 9045, loss = 352.34099491\n",
      "Iteration 9046, loss = 352.32365726\n",
      "Iteration 9047, loss = 352.31836247\n",
      "Iteration 9048, loss = 352.33014427\n",
      "Iteration 9049, loss = 352.29676722\n",
      "Iteration 9050, loss = 352.32098124\n",
      "Iteration 9051, loss = 352.30610014\n",
      "Iteration 9052, loss = 352.29294564\n",
      "Iteration 9053, loss = 352.26715674\n",
      "Iteration 9054, loss = 352.30102758\n",
      "Iteration 9055, loss = 352.29674790\n",
      "Iteration 9056, loss = 352.25925448\n",
      "Iteration 9057, loss = 352.24774930\n",
      "Iteration 9058, loss = 352.27751092\n",
      "Iteration 9059, loss = 352.27512070\n",
      "Iteration 9060, loss = 352.24612426\n",
      "Iteration 9061, loss = 352.22348151\n",
      "Iteration 9062, loss = 352.21721703\n",
      "Iteration 9063, loss = 352.24208776\n",
      "Iteration 9064, loss = 352.20334846\n",
      "Iteration 9065, loss = 352.20814192\n",
      "Iteration 9066, loss = 352.22543251\n",
      "Iteration 9067, loss = 352.19196103\n",
      "Iteration 9068, loss = 352.17846643\n",
      "Iteration 9069, loss = 352.17378861\n",
      "Iteration 9070, loss = 352.18784516\n",
      "Iteration 9071, loss = 352.17771627\n",
      "Iteration 9072, loss = 352.15265411\n",
      "Iteration 9073, loss = 352.13444473\n",
      "Iteration 9074, loss = 352.13056878\n",
      "Iteration 9075, loss = 352.13214103\n",
      "Iteration 9076, loss = 352.14022130\n",
      "Iteration 9077, loss = 352.13308548\n",
      "Iteration 9078, loss = 352.13432257\n",
      "Iteration 9079, loss = 352.12460761\n",
      "Iteration 9080, loss = 352.11042254\n",
      "Iteration 9081, loss = 352.11592838\n",
      "Iteration 9082, loss = 352.12585667\n",
      "Iteration 9083, loss = 352.16754084\n",
      "Iteration 9084, loss = 352.12290102\n",
      "Iteration 9085, loss = 352.08664998\n",
      "Iteration 9086, loss = 352.12642204\n",
      "Iteration 9087, loss = 352.13479605\n",
      "Iteration 9088, loss = 352.13792206\n",
      "Iteration 9089, loss = 352.07850417\n",
      "Iteration 9090, loss = 352.04746003\n",
      "Iteration 9091, loss = 352.05336134\n",
      "Iteration 9092, loss = 352.11972505\n",
      "Iteration 9093, loss = 352.07731058\n",
      "Iteration 9094, loss = 352.03846735\n",
      "Iteration 9095, loss = 352.03308472\n",
      "Iteration 9096, loss = 352.04930419\n",
      "Iteration 9097, loss = 352.11487203\n",
      "Iteration 9098, loss = 352.07720734\n",
      "Iteration 9099, loss = 352.01027671\n",
      "Iteration 9100, loss = 351.98040186\n",
      "Iteration 9101, loss = 351.99874529\n",
      "Iteration 9102, loss = 352.00215623\n",
      "Iteration 9103, loss = 352.00164435\n",
      "Iteration 9104, loss = 351.98261053\n",
      "Iteration 9105, loss = 351.98202179\n",
      "Iteration 9106, loss = 351.97917582\n",
      "Iteration 9107, loss = 351.97609090\n",
      "Iteration 9108, loss = 351.97054458\n",
      "Iteration 9109, loss = 351.97294185\n",
      "Iteration 9110, loss = 351.94701121\n",
      "Iteration 9111, loss = 351.93519058\n",
      "Iteration 9112, loss = 351.94814487\n",
      "Iteration 9113, loss = 351.94330933\n",
      "Iteration 9114, loss = 351.92098622\n",
      "Iteration 9115, loss = 351.93248834\n",
      "Iteration 9116, loss = 351.92080540\n",
      "Iteration 9117, loss = 351.89018909\n",
      "Iteration 9118, loss = 351.94107245\n",
      "Iteration 9119, loss = 351.92874368\n",
      "Iteration 9120, loss = 351.87120841\n",
      "Iteration 9121, loss = 351.91061056\n",
      "Iteration 9122, loss = 351.94163552\n",
      "Iteration 9123, loss = 351.90327181\n",
      "Iteration 9124, loss = 351.86650406\n",
      "Iteration 9125, loss = 351.86536651\n",
      "Iteration 9126, loss = 351.85034310\n",
      "Iteration 9127, loss = 351.89039343\n",
      "Iteration 9128, loss = 351.86114662\n",
      "Iteration 9129, loss = 351.83415786\n",
      "Iteration 9130, loss = 351.89786367\n",
      "Iteration 9131, loss = 351.83436315\n",
      "Iteration 9132, loss = 351.81032371\n",
      "Iteration 9133, loss = 351.85042096\n",
      "Iteration 9134, loss = 351.82365114\n",
      "Iteration 9135, loss = 351.79226828\n",
      "Iteration 9136, loss = 351.82205962\n",
      "Iteration 9137, loss = 351.79402538\n",
      "Iteration 9138, loss = 351.80525042\n",
      "Iteration 9139, loss = 351.78707245\n",
      "Iteration 9140, loss = 351.74911920\n",
      "Iteration 9141, loss = 351.78664631\n",
      "Iteration 9142, loss = 351.79099971\n",
      "Iteration 9143, loss = 351.76761608\n",
      "Iteration 9144, loss = 351.73432050\n",
      "Iteration 9145, loss = 351.73278513\n",
      "Iteration 9146, loss = 351.71544169\n",
      "Iteration 9147, loss = 351.72363423\n",
      "Iteration 9148, loss = 351.70347385\n",
      "Iteration 9149, loss = 351.69858996\n",
      "Iteration 9150, loss = 351.71464956\n",
      "Iteration 9151, loss = 351.70142355\n",
      "Iteration 9152, loss = 351.68431370\n",
      "Iteration 9153, loss = 351.68598953\n",
      "Iteration 9154, loss = 351.70035837\n",
      "Iteration 9155, loss = 351.65938735\n",
      "Iteration 9156, loss = 351.65082602\n",
      "Iteration 9157, loss = 351.64303324\n",
      "Iteration 9158, loss = 351.66469869\n",
      "Iteration 9159, loss = 351.63563320\n",
      "Iteration 9160, loss = 351.64864021\n",
      "Iteration 9161, loss = 351.64541395\n",
      "Iteration 9162, loss = 351.62872198\n",
      "Iteration 9163, loss = 351.63028500\n",
      "Iteration 9164, loss = 351.63849941\n",
      "Iteration 9165, loss = 351.62681714\n",
      "Iteration 9166, loss = 351.61126206\n",
      "Iteration 9167, loss = 351.58802410\n",
      "Iteration 9168, loss = 351.59206651\n",
      "Iteration 9169, loss = 351.60839627\n",
      "Iteration 9170, loss = 351.59850703\n",
      "Iteration 9171, loss = 351.58108858\n",
      "Iteration 9172, loss = 351.59006368\n",
      "Iteration 9173, loss = 351.56352714\n",
      "Iteration 9174, loss = 351.54323165\n",
      "Iteration 9175, loss = 351.58972097\n",
      "Iteration 9176, loss = 351.60729030\n",
      "Iteration 9177, loss = 351.55431573\n",
      "Iteration 9178, loss = 351.55715499\n",
      "Iteration 9179, loss = 351.57401744\n",
      "Iteration 9180, loss = 351.57785882\n",
      "Iteration 9181, loss = 351.55444087\n",
      "Iteration 9182, loss = 351.51694279\n",
      "Iteration 9183, loss = 351.56661156\n",
      "Iteration 9184, loss = 351.57925096\n",
      "Iteration 9185, loss = 351.55093025\n",
      "Iteration 9186, loss = 351.49149793\n",
      "Iteration 9187, loss = 351.51232940\n",
      "Iteration 9188, loss = 351.55065248\n",
      "Iteration 9189, loss = 351.53779837\n",
      "Iteration 9190, loss = 351.52363160\n",
      "Iteration 9191, loss = 351.50495920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9192, loss = 351.48444454\n",
      "Iteration 9193, loss = 351.47965501\n",
      "Iteration 9194, loss = 351.47593012\n",
      "Iteration 9195, loss = 351.44945887\n",
      "Iteration 9196, loss = 351.43107162\n",
      "Iteration 9197, loss = 351.43598317\n",
      "Iteration 9198, loss = 351.42503334\n",
      "Iteration 9199, loss = 351.41319097\n",
      "Iteration 9200, loss = 351.39902638\n",
      "Iteration 9201, loss = 351.38818855\n",
      "Iteration 9202, loss = 351.40906137\n",
      "Iteration 9203, loss = 351.39818186\n",
      "Iteration 9204, loss = 351.38801480\n",
      "Iteration 9205, loss = 351.37682658\n",
      "Iteration 9206, loss = 351.39107298\n",
      "Iteration 9207, loss = 351.37752375\n",
      "Iteration 9208, loss = 351.35856602\n",
      "Iteration 9209, loss = 351.34985855\n",
      "Iteration 9210, loss = 351.34016283\n",
      "Iteration 9211, loss = 351.32423271\n",
      "Iteration 9212, loss = 351.34886246\n",
      "Iteration 9213, loss = 351.34287002\n",
      "Iteration 9214, loss = 351.33948131\n",
      "Iteration 9215, loss = 351.31672796\n",
      "Iteration 9216, loss = 351.30805425\n",
      "Iteration 9217, loss = 351.33162680\n",
      "Iteration 9218, loss = 351.33112241\n",
      "Iteration 9219, loss = 351.30618950\n",
      "Iteration 9220, loss = 351.30297404\n",
      "Iteration 9221, loss = 351.32918181\n",
      "Iteration 9222, loss = 351.33804766\n",
      "Iteration 9223, loss = 351.30877342\n",
      "Iteration 9224, loss = 351.27215709\n",
      "Iteration 9225, loss = 351.27539302\n",
      "Iteration 9226, loss = 351.29839167\n",
      "Iteration 9227, loss = 351.27946447\n",
      "Iteration 9228, loss = 351.25454556\n",
      "Iteration 9229, loss = 351.25410489\n",
      "Iteration 9230, loss = 351.25083396\n",
      "Iteration 9231, loss = 351.24610564\n",
      "Iteration 9232, loss = 351.25052335\n",
      "Iteration 9233, loss = 351.21727781\n",
      "Iteration 9234, loss = 351.22397428\n",
      "Iteration 9235, loss = 351.21158451\n",
      "Iteration 9236, loss = 351.19728206\n",
      "Iteration 9237, loss = 351.21083924\n",
      "Iteration 9238, loss = 351.21042161\n",
      "Iteration 9239, loss = 351.19546063\n",
      "Iteration 9240, loss = 351.18260528\n",
      "Iteration 9241, loss = 351.16755812\n",
      "Iteration 9242, loss = 351.18294667\n",
      "Iteration 9243, loss = 351.18653393\n",
      "Iteration 9244, loss = 351.18050106\n",
      "Iteration 9245, loss = 351.15947601\n",
      "Iteration 9246, loss = 351.15098859\n",
      "Iteration 9247, loss = 351.20173302\n",
      "Iteration 9248, loss = 351.21320694\n",
      "Iteration 9249, loss = 351.17396056\n",
      "Iteration 9250, loss = 351.12971409\n",
      "Iteration 9251, loss = 351.15427099\n",
      "Iteration 9252, loss = 351.18042439\n",
      "Iteration 9253, loss = 351.16689324\n",
      "Iteration 9254, loss = 351.11634579\n",
      "Iteration 9255, loss = 351.08695837\n",
      "Iteration 9256, loss = 351.10814791\n",
      "Iteration 9257, loss = 351.12401142\n",
      "Iteration 9258, loss = 351.11038348\n",
      "Iteration 9259, loss = 351.06350981\n",
      "Iteration 9260, loss = 351.06770303\n",
      "Iteration 9261, loss = 351.07057650\n",
      "Iteration 9262, loss = 351.08885830\n",
      "Iteration 9263, loss = 351.06738645\n",
      "Iteration 9264, loss = 351.03878191\n",
      "Iteration 9265, loss = 351.02546695\n",
      "Iteration 9266, loss = 351.04159587\n",
      "Iteration 9267, loss = 351.05378025\n",
      "Iteration 9268, loss = 351.06648030\n",
      "Iteration 9269, loss = 351.01258843\n",
      "Iteration 9270, loss = 350.99336764\n",
      "Iteration 9271, loss = 351.02291127\n",
      "Iteration 9272, loss = 351.02915516\n",
      "Iteration 9273, loss = 351.00292694\n",
      "Iteration 9274, loss = 350.97678726\n",
      "Iteration 9275, loss = 350.97081330\n",
      "Iteration 9276, loss = 350.98143568\n",
      "Iteration 9277, loss = 351.01566864\n",
      "Iteration 9278, loss = 351.00216054\n",
      "Iteration 9279, loss = 350.96271261\n",
      "Iteration 9280, loss = 350.94557784\n",
      "Iteration 9281, loss = 350.95995145\n",
      "Iteration 9282, loss = 351.00284596\n",
      "Iteration 9283, loss = 350.96041728\n",
      "Iteration 9284, loss = 350.92264272\n",
      "Iteration 9285, loss = 350.91038782\n",
      "Iteration 9286, loss = 350.94162808\n",
      "Iteration 9287, loss = 350.95035100\n",
      "Iteration 9288, loss = 350.90311152\n",
      "Iteration 9289, loss = 350.87565866\n",
      "Iteration 9290, loss = 350.88194488\n",
      "Iteration 9291, loss = 350.87677479\n",
      "Iteration 9292, loss = 350.89613691\n",
      "Iteration 9293, loss = 350.90250356\n",
      "Iteration 9294, loss = 350.87953911\n",
      "Iteration 9295, loss = 350.89290450\n",
      "Iteration 9296, loss = 350.87067287\n",
      "Iteration 9297, loss = 350.87086315\n",
      "Iteration 9298, loss = 350.86207037\n",
      "Iteration 9299, loss = 350.84493839\n",
      "Iteration 9300, loss = 350.85511181\n",
      "Iteration 9301, loss = 350.86466133\n",
      "Iteration 9302, loss = 350.85434376\n",
      "Iteration 9303, loss = 350.83879834\n",
      "Iteration 9304, loss = 350.83421482\n",
      "Iteration 9305, loss = 350.81064460\n",
      "Iteration 9306, loss = 350.80439693\n",
      "Iteration 9307, loss = 350.80900600\n",
      "Iteration 9308, loss = 350.82006858\n",
      "Iteration 9309, loss = 350.80392124\n",
      "Iteration 9310, loss = 350.81142188\n",
      "Iteration 9311, loss = 350.78505106\n",
      "Iteration 9312, loss = 350.80592780\n",
      "Iteration 9313, loss = 350.80705635\n",
      "Iteration 9314, loss = 350.79777793\n",
      "Iteration 9315, loss = 350.75956407\n",
      "Iteration 9316, loss = 350.76248406\n",
      "Iteration 9317, loss = 350.77678306\n",
      "Iteration 9318, loss = 350.76775578\n",
      "Iteration 9319, loss = 350.75515997\n",
      "Iteration 9320, loss = 350.73091501\n",
      "Iteration 9321, loss = 350.73251602\n",
      "Iteration 9322, loss = 350.76044097\n",
      "Iteration 9323, loss = 350.75415355\n",
      "Iteration 9324, loss = 350.70588840\n",
      "Iteration 9325, loss = 350.69356833\n",
      "Iteration 9326, loss = 350.69076723\n",
      "Iteration 9327, loss = 350.70152989\n",
      "Iteration 9328, loss = 350.68006368\n",
      "Iteration 9329, loss = 350.69945458\n",
      "Iteration 9330, loss = 350.68483181\n",
      "Iteration 9331, loss = 350.68501599\n",
      "Iteration 9332, loss = 350.67172344\n",
      "Iteration 9333, loss = 350.66856076\n",
      "Iteration 9334, loss = 350.64748520\n",
      "Iteration 9335, loss = 350.63780407\n",
      "Iteration 9336, loss = 350.63363941\n",
      "Iteration 9337, loss = 350.65151114\n",
      "Iteration 9338, loss = 350.65115964\n",
      "Iteration 9339, loss = 350.63807107\n",
      "Iteration 9340, loss = 350.63295928\n",
      "Iteration 9341, loss = 350.60786427\n",
      "Iteration 9342, loss = 350.62585473\n",
      "Iteration 9343, loss = 350.61709718\n",
      "Iteration 9344, loss = 350.61485993\n",
      "Iteration 9345, loss = 350.59763344\n",
      "Iteration 9346, loss = 350.58416828\n",
      "Iteration 9347, loss = 350.62818929\n",
      "Iteration 9348, loss = 350.61381581\n",
      "Iteration 9349, loss = 350.59094736\n",
      "Iteration 9350, loss = 350.58165531\n",
      "Iteration 9351, loss = 350.57084900\n",
      "Iteration 9352, loss = 350.57377044\n",
      "Iteration 9353, loss = 350.55708889\n",
      "Iteration 9354, loss = 350.54417053\n",
      "Iteration 9355, loss = 350.54794183\n",
      "Iteration 9356, loss = 350.55022804\n",
      "Iteration 9357, loss = 350.54120926\n",
      "Iteration 9358, loss = 350.53115402\n",
      "Iteration 9359, loss = 350.53044503\n",
      "Iteration 9360, loss = 350.52344168\n",
      "Iteration 9361, loss = 350.50941062\n",
      "Iteration 9362, loss = 350.52068000\n",
      "Iteration 9363, loss = 350.52299644\n",
      "Iteration 9364, loss = 350.48829086\n",
      "Iteration 9365, loss = 350.48510724\n",
      "Iteration 9366, loss = 350.47444691\n",
      "Iteration 9367, loss = 350.45700942\n",
      "Iteration 9368, loss = 350.46777783\n",
      "Iteration 9369, loss = 350.46302289\n",
      "Iteration 9370, loss = 350.44417734\n",
      "Iteration 9371, loss = 350.43419293\n",
      "Iteration 9372, loss = 350.44184352\n",
      "Iteration 9373, loss = 350.44358970\n",
      "Iteration 9374, loss = 350.47504812\n",
      "Iteration 9375, loss = 350.45307030\n",
      "Iteration 9376, loss = 350.42014098\n",
      "Iteration 9377, loss = 350.42810991\n",
      "Iteration 9378, loss = 350.44422641\n",
      "Iteration 9379, loss = 350.41086697\n",
      "Iteration 9380, loss = 350.41458787\n",
      "Iteration 9381, loss = 350.42117234\n",
      "Iteration 9382, loss = 350.42669797\n",
      "Iteration 9383, loss = 350.40553099\n",
      "Iteration 9384, loss = 350.37598201\n",
      "Iteration 9385, loss = 350.38255955\n",
      "Iteration 9386, loss = 350.38009357\n",
      "Iteration 9387, loss = 350.34501579\n",
      "Iteration 9388, loss = 350.36189680\n",
      "Iteration 9389, loss = 350.36141894\n",
      "Iteration 9390, loss = 350.35709148\n",
      "Iteration 9391, loss = 350.34272788\n",
      "Iteration 9392, loss = 350.32452644\n",
      "Iteration 9393, loss = 350.33224156\n",
      "Iteration 9394, loss = 350.32118199\n",
      "Iteration 9395, loss = 350.32065446\n",
      "Iteration 9396, loss = 350.31199571\n",
      "Iteration 9397, loss = 350.31312758\n",
      "Iteration 9398, loss = 350.30804505\n",
      "Iteration 9399, loss = 350.32105218\n",
      "Iteration 9400, loss = 350.29334416\n",
      "Iteration 9401, loss = 350.28183697\n",
      "Iteration 9402, loss = 350.29567224\n",
      "Iteration 9403, loss = 350.27266310\n",
      "Iteration 9404, loss = 350.25007068\n",
      "Iteration 9405, loss = 350.25153370\n",
      "Iteration 9406, loss = 350.25656787\n",
      "Iteration 9407, loss = 350.24234342\n",
      "Iteration 9408, loss = 350.25827664\n",
      "Iteration 9409, loss = 350.26140106\n",
      "Iteration 9410, loss = 350.23845933\n",
      "Iteration 9411, loss = 350.21279360\n",
      "Iteration 9412, loss = 350.23082206\n",
      "Iteration 9413, loss = 350.22137714\n",
      "Iteration 9414, loss = 350.21215649\n",
      "Iteration 9415, loss = 350.21289470\n",
      "Iteration 9416, loss = 350.20060614\n",
      "Iteration 9417, loss = 350.20599419\n",
      "Iteration 9418, loss = 350.19938725\n",
      "Iteration 9419, loss = 350.20336320\n",
      "Iteration 9420, loss = 350.17125021\n",
      "Iteration 9421, loss = 350.17065599\n",
      "Iteration 9422, loss = 350.16268149\n",
      "Iteration 9423, loss = 350.14947509\n",
      "Iteration 9424, loss = 350.14962667\n",
      "Iteration 9425, loss = 350.13662926\n",
      "Iteration 9426, loss = 350.12976263\n",
      "Iteration 9427, loss = 350.14548013\n",
      "Iteration 9428, loss = 350.13817658\n",
      "Iteration 9429, loss = 350.11509315\n",
      "Iteration 9430, loss = 350.12170109\n",
      "Iteration 9431, loss = 350.15123471\n",
      "Iteration 9432, loss = 350.12854346\n",
      "Iteration 9433, loss = 350.13171526\n",
      "Iteration 9434, loss = 350.09482196\n",
      "Iteration 9435, loss = 350.09112320\n",
      "Iteration 9436, loss = 350.09366439\n",
      "Iteration 9437, loss = 350.06346650\n",
      "Iteration 9438, loss = 350.08885357\n",
      "Iteration 9439, loss = 350.11215725\n",
      "Iteration 9440, loss = 350.09619775\n",
      "Iteration 9441, loss = 350.08147856\n",
      "Iteration 9442, loss = 350.05379757\n",
      "Iteration 9443, loss = 350.07031844\n",
      "Iteration 9444, loss = 350.08633140\n",
      "Iteration 9445, loss = 350.06978762\n",
      "Iteration 9446, loss = 350.03027139\n",
      "Iteration 9447, loss = 350.03349168\n",
      "Iteration 9448, loss = 350.02688823\n",
      "Iteration 9449, loss = 350.01249889\n",
      "Iteration 9450, loss = 350.00939339\n",
      "Iteration 9451, loss = 350.02355674\n",
      "Iteration 9452, loss = 350.01601954\n",
      "Iteration 9453, loss = 349.99738514\n",
      "Iteration 9454, loss = 350.00158259\n",
      "Iteration 9455, loss = 350.00029372\n",
      "Iteration 9456, loss = 349.99795762\n",
      "Iteration 9457, loss = 350.00132049\n",
      "Iteration 9458, loss = 350.01566120\n",
      "Iteration 9459, loss = 349.97486718\n",
      "Iteration 9460, loss = 350.00139403\n",
      "Iteration 9461, loss = 350.01303328\n",
      "Iteration 9462, loss = 350.00956650\n",
      "Iteration 9463, loss = 349.96214133\n",
      "Iteration 9464, loss = 349.94592659\n",
      "Iteration 9465, loss = 350.00667572\n",
      "Iteration 9466, loss = 349.98843941\n",
      "Iteration 9467, loss = 349.94928492\n",
      "Iteration 9468, loss = 349.92082671\n",
      "Iteration 9469, loss = 349.94493955\n",
      "Iteration 9470, loss = 349.94330276\n",
      "Iteration 9471, loss = 349.92042039\n",
      "Iteration 9472, loss = 349.89468863\n",
      "Iteration 9473, loss = 349.94443281\n",
      "Iteration 9474, loss = 349.95067684\n",
      "Iteration 9475, loss = 349.91784722\n",
      "Iteration 9476, loss = 349.90344405\n",
      "Iteration 9477, loss = 349.90541829\n",
      "Iteration 9478, loss = 349.88767847\n",
      "Iteration 9479, loss = 349.86984487\n",
      "Iteration 9480, loss = 349.86399857\n",
      "Iteration 9481, loss = 349.88746104\n",
      "Iteration 9482, loss = 349.89152976\n",
      "Iteration 9483, loss = 349.85610663\n",
      "Iteration 9484, loss = 349.84744503\n",
      "Iteration 9485, loss = 349.83700507\n",
      "Iteration 9486, loss = 349.82070762\n",
      "Iteration 9487, loss = 349.80343146\n",
      "Iteration 9488, loss = 349.82406631\n",
      "Iteration 9489, loss = 349.81006533\n",
      "Iteration 9490, loss = 349.82172819\n",
      "Iteration 9491, loss = 349.80183950\n",
      "Iteration 9492, loss = 349.76862528\n",
      "Iteration 9493, loss = 349.79843420\n",
      "Iteration 9494, loss = 349.81937828\n",
      "Iteration 9495, loss = 349.81053430\n",
      "Iteration 9496, loss = 349.79300337\n",
      "Iteration 9497, loss = 349.77415969\n",
      "Iteration 9498, loss = 349.74581898\n",
      "Iteration 9499, loss = 349.75367197\n",
      "Iteration 9500, loss = 349.72503796\n",
      "Iteration 9501, loss = 349.75122338\n",
      "Iteration 9502, loss = 349.77961262\n",
      "Iteration 9503, loss = 349.74667101\n",
      "Iteration 9504, loss = 349.72414074\n",
      "Iteration 9505, loss = 349.74936287\n",
      "Iteration 9506, loss = 349.72984830\n",
      "Iteration 9507, loss = 349.70608231\n",
      "Iteration 9508, loss = 349.70659473\n",
      "Iteration 9509, loss = 349.68729914\n",
      "Iteration 9510, loss = 349.72535688\n",
      "Iteration 9511, loss = 349.70581291\n",
      "Iteration 9512, loss = 349.69237236\n",
      "Iteration 9513, loss = 349.68285461\n",
      "Iteration 9514, loss = 349.72436814\n",
      "Iteration 9515, loss = 349.70076620\n",
      "Iteration 9516, loss = 349.67527536\n",
      "Iteration 9517, loss = 349.68831647\n",
      "Iteration 9518, loss = 349.72899248\n",
      "Iteration 9519, loss = 349.68287314\n",
      "Iteration 9520, loss = 349.65562628\n",
      "Iteration 9521, loss = 349.64427889\n",
      "Iteration 9522, loss = 349.64961449\n",
      "Iteration 9523, loss = 349.66796513\n",
      "Iteration 9524, loss = 349.64641082\n",
      "Iteration 9525, loss = 349.64046665\n",
      "Iteration 9526, loss = 349.63088981\n",
      "Iteration 9527, loss = 349.62042678\n",
      "Iteration 9528, loss = 349.63471571\n",
      "Iteration 9529, loss = 349.61083581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9530, loss = 349.59745490\n",
      "Iteration 9531, loss = 349.58341552\n",
      "Iteration 9532, loss = 349.59997910\n",
      "Iteration 9533, loss = 349.62754164\n",
      "Iteration 9534, loss = 349.56711867\n",
      "Iteration 9535, loss = 349.59519353\n",
      "Iteration 9536, loss = 349.58647210\n",
      "Iteration 9537, loss = 349.60201478\n",
      "Iteration 9538, loss = 349.54894452\n",
      "Iteration 9539, loss = 349.57052519\n",
      "Iteration 9540, loss = 349.58570801\n",
      "Iteration 9541, loss = 349.56964283\n",
      "Iteration 9542, loss = 349.55491613\n",
      "Iteration 9543, loss = 349.52442867\n",
      "Iteration 9544, loss = 349.55206142\n",
      "Iteration 9545, loss = 349.58582186\n",
      "Iteration 9546, loss = 349.52256601\n",
      "Iteration 9547, loss = 349.51197587\n",
      "Iteration 9548, loss = 349.54662727\n",
      "Iteration 9549, loss = 349.56155802\n",
      "Iteration 9550, loss = 349.51742832\n",
      "Iteration 9551, loss = 349.50710893\n",
      "Iteration 9552, loss = 349.55234639\n",
      "Iteration 9553, loss = 349.53163424\n",
      "Iteration 9554, loss = 349.50208150\n",
      "Iteration 9555, loss = 349.50578805\n",
      "Iteration 9556, loss = 349.52390972\n",
      "Iteration 9557, loss = 349.50769033\n",
      "Iteration 9558, loss = 349.44725879\n",
      "Iteration 9559, loss = 349.48098118\n",
      "Iteration 9560, loss = 349.51751964\n",
      "Iteration 9561, loss = 349.48574555\n",
      "Iteration 9562, loss = 349.42919519\n",
      "Iteration 9563, loss = 349.41919512\n",
      "Iteration 9564, loss = 349.42754733\n",
      "Iteration 9565, loss = 349.40866189\n",
      "Iteration 9566, loss = 349.42350363\n",
      "Iteration 9567, loss = 349.40729879\n",
      "Iteration 9568, loss = 349.39508656\n",
      "Iteration 9569, loss = 349.43369621\n",
      "Iteration 9570, loss = 349.41664437\n",
      "Iteration 9571, loss = 349.39284437\n",
      "Iteration 9572, loss = 349.38906076\n",
      "Iteration 9573, loss = 349.36588327\n",
      "Iteration 9574, loss = 349.40413129\n",
      "Iteration 9575, loss = 349.41216074\n",
      "Iteration 9576, loss = 349.35773081\n",
      "Iteration 9577, loss = 349.34292290\n",
      "Iteration 9578, loss = 349.34864567\n",
      "Iteration 9579, loss = 349.33804311\n",
      "Iteration 9580, loss = 349.33259439\n",
      "Iteration 9581, loss = 349.32147444\n",
      "Iteration 9582, loss = 349.30470872\n",
      "Iteration 9583, loss = 349.31205725\n",
      "Iteration 9584, loss = 349.33327904\n",
      "Iteration 9585, loss = 349.31235785\n",
      "Iteration 9586, loss = 349.30949456\n",
      "Iteration 9587, loss = 349.29682507\n",
      "Iteration 9588, loss = 349.27770862\n",
      "Iteration 9589, loss = 349.29192952\n",
      "Iteration 9590, loss = 349.27915757\n",
      "Iteration 9591, loss = 349.28299054\n",
      "Iteration 9592, loss = 349.25625887\n",
      "Iteration 9593, loss = 349.24603595\n",
      "Iteration 9594, loss = 349.29058454\n",
      "Iteration 9595, loss = 349.27142018\n",
      "Iteration 9596, loss = 349.27131189\n",
      "Iteration 9597, loss = 349.23826738\n",
      "Iteration 9598, loss = 349.24263646\n",
      "Iteration 9599, loss = 349.26949933\n",
      "Iteration 9600, loss = 349.24382334\n",
      "Iteration 9601, loss = 349.21850450\n",
      "Iteration 9602, loss = 349.20826675\n",
      "Iteration 9603, loss = 349.23202903\n",
      "Iteration 9604, loss = 349.23282761\n",
      "Iteration 9605, loss = 349.20818017\n",
      "Iteration 9606, loss = 349.17816567\n",
      "Iteration 9607, loss = 349.23146295\n",
      "Iteration 9608, loss = 349.23406191\n",
      "Iteration 9609, loss = 349.20455845\n",
      "Iteration 9610, loss = 349.18281367\n",
      "Iteration 9611, loss = 349.21215006\n",
      "Iteration 9612, loss = 349.19414135\n",
      "Iteration 9613, loss = 349.19567814\n",
      "Iteration 9614, loss = 349.17828063\n",
      "Iteration 9615, loss = 349.17368540\n",
      "Iteration 9616, loss = 349.17655485\n",
      "Iteration 9617, loss = 349.15636180\n",
      "Iteration 9618, loss = 349.18702870\n",
      "Iteration 9619, loss = 349.19324860\n",
      "Iteration 9620, loss = 349.15939214\n",
      "Iteration 9621, loss = 349.15451666\n",
      "Iteration 9622, loss = 349.15120829\n",
      "Iteration 9623, loss = 349.14129245\n",
      "Iteration 9624, loss = 349.13308025\n",
      "Iteration 9625, loss = 349.12935212\n",
      "Iteration 9626, loss = 349.12214306\n",
      "Iteration 9627, loss = 349.13888969\n",
      "Iteration 9628, loss = 349.12909227\n",
      "Iteration 9629, loss = 349.07625156\n",
      "Iteration 9630, loss = 349.13259469\n",
      "Iteration 9631, loss = 349.14308792\n",
      "Iteration 9632, loss = 349.11444692\n",
      "Iteration 9633, loss = 349.09783698\n",
      "Iteration 9634, loss = 349.11860376\n",
      "Iteration 9635, loss = 349.08216795\n",
      "Iteration 9636, loss = 349.06168598\n",
      "Iteration 9637, loss = 349.06100624\n",
      "Iteration 9638, loss = 349.05066481\n",
      "Iteration 9639, loss = 349.04520444\n",
      "Iteration 9640, loss = 349.04092040\n",
      "Iteration 9641, loss = 349.00939743\n",
      "Iteration 9642, loss = 349.02780051\n",
      "Iteration 9643, loss = 349.04214453\n",
      "Iteration 9644, loss = 349.01841709\n",
      "Iteration 9645, loss = 349.02990192\n",
      "Iteration 9646, loss = 349.02510807\n",
      "Iteration 9647, loss = 349.04483472\n",
      "Iteration 9648, loss = 349.00189113\n",
      "Iteration 9649, loss = 348.98888124\n",
      "Iteration 9650, loss = 349.02282217\n",
      "Iteration 9651, loss = 349.02928507\n",
      "Iteration 9652, loss = 348.98418596\n",
      "Iteration 9653, loss = 348.95792893\n",
      "Iteration 9654, loss = 348.97869632\n",
      "Iteration 9655, loss = 349.00260909\n",
      "Iteration 9656, loss = 348.96969093\n",
      "Iteration 9657, loss = 348.92031615\n",
      "Iteration 9658, loss = 348.98572126\n",
      "Iteration 9659, loss = 349.00373385\n",
      "Iteration 9660, loss = 348.95684816\n",
      "Iteration 9661, loss = 348.92983124\n",
      "Iteration 9662, loss = 348.94367591\n",
      "Iteration 9663, loss = 348.95225217\n",
      "Iteration 9664, loss = 348.93133902\n",
      "Iteration 9665, loss = 348.89876784\n",
      "Iteration 9666, loss = 348.90511804\n",
      "Iteration 9667, loss = 348.91751802\n",
      "Iteration 9668, loss = 348.92006768\n",
      "Iteration 9669, loss = 348.88662477\n",
      "Iteration 9670, loss = 348.87499843\n",
      "Iteration 9671, loss = 348.86971440\n",
      "Iteration 9672, loss = 348.88639778\n",
      "Iteration 9673, loss = 348.88486336\n",
      "Iteration 9674, loss = 348.85634876\n",
      "Iteration 9675, loss = 348.83616321\n",
      "Iteration 9676, loss = 348.84656422\n",
      "Iteration 9677, loss = 348.84105155\n",
      "Iteration 9678, loss = 348.83887363\n",
      "Iteration 9679, loss = 348.83470536\n",
      "Iteration 9680, loss = 348.84984975\n",
      "Iteration 9681, loss = 348.83755787\n",
      "Iteration 9682, loss = 348.82204136\n",
      "Iteration 9683, loss = 348.81459277\n",
      "Iteration 9684, loss = 348.81749072\n",
      "Iteration 9685, loss = 348.79601357\n",
      "Iteration 9686, loss = 348.82525698\n",
      "Iteration 9687, loss = 348.79645372\n",
      "Iteration 9688, loss = 348.79046797\n",
      "Iteration 9689, loss = 348.78045431\n",
      "Iteration 9690, loss = 348.79828832\n",
      "Iteration 9691, loss = 348.79519967\n",
      "Iteration 9692, loss = 348.76859426\n",
      "Iteration 9693, loss = 348.77199441\n",
      "Iteration 9694, loss = 348.77270654\n",
      "Iteration 9695, loss = 348.76614065\n",
      "Iteration 9696, loss = 348.76157058\n",
      "Iteration 9697, loss = 348.75500102\n",
      "Iteration 9698, loss = 348.73682731\n",
      "Iteration 9699, loss = 348.75776832\n",
      "Iteration 9700, loss = 348.75358800\n",
      "Iteration 9701, loss = 348.73316081\n",
      "Iteration 9702, loss = 348.72350643\n",
      "Iteration 9703, loss = 348.72248035\n",
      "Iteration 9704, loss = 348.71105852\n",
      "Iteration 9705, loss = 348.72797265\n",
      "Iteration 9706, loss = 348.71496208\n",
      "Iteration 9707, loss = 348.70678385\n",
      "Iteration 9708, loss = 348.68853172\n",
      "Iteration 9709, loss = 348.69930881\n",
      "Iteration 9710, loss = 348.68295074\n",
      "Iteration 9711, loss = 348.65682868\n",
      "Iteration 9712, loss = 348.67104971\n",
      "Iteration 9713, loss = 348.67988212\n",
      "Iteration 9714, loss = 348.67643666\n",
      "Iteration 9715, loss = 348.65473340\n",
      "Iteration 9716, loss = 348.63669697\n",
      "Iteration 9717, loss = 348.64529848\n",
      "Iteration 9718, loss = 348.64509220\n",
      "Iteration 9719, loss = 348.63512254\n",
      "Iteration 9720, loss = 348.63545390\n",
      "Iteration 9721, loss = 348.63907529\n",
      "Iteration 9722, loss = 348.61797107\n",
      "Iteration 9723, loss = 348.62059027\n",
      "Iteration 9724, loss = 348.61647175\n",
      "Iteration 9725, loss = 348.59497784\n",
      "Iteration 9726, loss = 348.58315042\n",
      "Iteration 9727, loss = 348.59222978\n",
      "Iteration 9728, loss = 348.59348985\n",
      "Iteration 9729, loss = 348.58370787\n",
      "Iteration 9730, loss = 348.56544646\n",
      "Iteration 9731, loss = 348.54353546\n",
      "Iteration 9732, loss = 348.58759765\n",
      "Iteration 9733, loss = 348.57071297\n",
      "Iteration 9734, loss = 348.55040865\n",
      "Iteration 9735, loss = 348.51971260\n",
      "Iteration 9736, loss = 348.53260218\n",
      "Iteration 9737, loss = 348.56235192\n",
      "Iteration 9738, loss = 348.53697809\n",
      "Iteration 9739, loss = 348.49127085\n",
      "Iteration 9740, loss = 348.47994343\n",
      "Iteration 9741, loss = 348.50636633\n",
      "Iteration 9742, loss = 348.50381250\n",
      "Iteration 9743, loss = 348.48197322\n",
      "Iteration 9744, loss = 348.45679362\n",
      "Iteration 9745, loss = 348.49434319\n",
      "Iteration 9746, loss = 348.52518458\n",
      "Iteration 9747, loss = 348.46889952\n",
      "Iteration 9748, loss = 348.44670602\n",
      "Iteration 9749, loss = 348.46293845\n",
      "Iteration 9750, loss = 348.46598323\n",
      "Iteration 9751, loss = 348.44228369\n",
      "Iteration 9752, loss = 348.41943608\n",
      "Iteration 9753, loss = 348.42936860\n",
      "Iteration 9754, loss = 348.43503254\n",
      "Iteration 9755, loss = 348.40407637\n",
      "Iteration 9756, loss = 348.42249261\n",
      "Iteration 9757, loss = 348.42878172\n",
      "Iteration 9758, loss = 348.40762603\n",
      "Iteration 9759, loss = 348.40014042\n",
      "Iteration 9760, loss = 348.39966997\n",
      "Iteration 9761, loss = 348.38050792\n",
      "Iteration 9762, loss = 348.36129079\n",
      "Iteration 9763, loss = 348.37515259\n",
      "Iteration 9764, loss = 348.33844151\n",
      "Iteration 9765, loss = 348.37970021\n",
      "Iteration 9766, loss = 348.36901587\n",
      "Iteration 9767, loss = 348.32854519\n",
      "Iteration 9768, loss = 348.35151645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9769, loss = 348.36415925\n",
      "Iteration 9770, loss = 348.35138386\n",
      "Iteration 9771, loss = 348.34271091\n",
      "Iteration 9772, loss = 348.32345934\n",
      "Iteration 9773, loss = 348.29750083\n",
      "Iteration 9774, loss = 348.30190449\n",
      "Iteration 9775, loss = 348.28207163\n",
      "Iteration 9776, loss = 348.28197714\n",
      "Iteration 9777, loss = 348.28132191\n",
      "Iteration 9778, loss = 348.31409442\n",
      "Iteration 9779, loss = 348.31370902\n",
      "Iteration 9780, loss = 348.31228724\n",
      "Iteration 9781, loss = 348.27982055\n",
      "Iteration 9782, loss = 348.26954067\n",
      "Iteration 9783, loss = 348.32531990\n",
      "Iteration 9784, loss = 348.31828517\n",
      "Iteration 9785, loss = 348.27806795\n",
      "Iteration 9786, loss = 348.24372387\n",
      "Iteration 9787, loss = 348.22414635\n",
      "Iteration 9788, loss = 348.24566016\n",
      "Iteration 9789, loss = 348.25441943\n",
      "Iteration 9790, loss = 348.21708108\n",
      "Iteration 9791, loss = 348.22600918\n",
      "Iteration 9792, loss = 348.20212504\n",
      "Iteration 9793, loss = 348.19175466\n",
      "Iteration 9794, loss = 348.19069141\n",
      "Iteration 9795, loss = 348.17625864\n",
      "Iteration 9796, loss = 348.17331963\n",
      "Iteration 9797, loss = 348.14605375\n",
      "Iteration 9798, loss = 348.15984135\n",
      "Iteration 9799, loss = 348.13625432\n",
      "Iteration 9800, loss = 348.14196271\n",
      "Iteration 9801, loss = 348.14308652\n",
      "Iteration 9802, loss = 348.12643698\n",
      "Iteration 9803, loss = 348.10342604\n",
      "Iteration 9804, loss = 348.09576397\n",
      "Iteration 9805, loss = 348.10209849\n",
      "Iteration 9806, loss = 348.10779420\n",
      "Iteration 9807, loss = 348.10366353\n",
      "Iteration 9808, loss = 348.13526372\n",
      "Iteration 9809, loss = 348.10769445\n",
      "Iteration 9810, loss = 348.08134051\n",
      "Iteration 9811, loss = 348.08304035\n",
      "Iteration 9812, loss = 348.07882297\n",
      "Iteration 9813, loss = 348.06118586\n",
      "Iteration 9814, loss = 348.05676241\n",
      "Iteration 9815, loss = 348.04457569\n",
      "Iteration 9816, loss = 348.04323065\n",
      "Iteration 9817, loss = 348.03259785\n",
      "Iteration 9818, loss = 348.03838856\n",
      "Iteration 9819, loss = 348.05693455\n",
      "Iteration 9820, loss = 348.02673808\n",
      "Iteration 9821, loss = 348.00518821\n",
      "Iteration 9822, loss = 348.00395373\n",
      "Iteration 9823, loss = 348.04069886\n",
      "Iteration 9824, loss = 348.04680086\n",
      "Iteration 9825, loss = 347.99652145\n",
      "Iteration 9826, loss = 348.01363877\n",
      "Iteration 9827, loss = 348.02500340\n",
      "Iteration 9828, loss = 348.02261903\n",
      "Iteration 9829, loss = 347.98243814\n",
      "Iteration 9830, loss = 347.96363843\n",
      "Iteration 9831, loss = 347.95565952\n",
      "Iteration 9832, loss = 347.96051856\n",
      "Iteration 9833, loss = 347.96019061\n",
      "Iteration 9834, loss = 347.93259517\n",
      "Iteration 9835, loss = 347.96925536\n",
      "Iteration 9836, loss = 347.97605887\n",
      "Iteration 9837, loss = 347.96267935\n",
      "Iteration 9838, loss = 347.93526115\n",
      "Iteration 9839, loss = 347.93545711\n",
      "Iteration 9840, loss = 347.92795214\n",
      "Iteration 9841, loss = 347.90837338\n",
      "Iteration 9842, loss = 347.89682772\n",
      "Iteration 9843, loss = 347.89862558\n",
      "Iteration 9844, loss = 347.87965199\n",
      "Iteration 9845, loss = 347.90030890\n",
      "Iteration 9846, loss = 347.88403542\n",
      "Iteration 9847, loss = 347.86768970\n",
      "Iteration 9848, loss = 347.84898458\n",
      "Iteration 9849, loss = 347.85875410\n",
      "Iteration 9850, loss = 347.85639655\n",
      "Iteration 9851, loss = 347.84510243\n",
      "Iteration 9852, loss = 347.84616532\n",
      "Iteration 9853, loss = 347.84109732\n",
      "Iteration 9854, loss = 347.86198745\n",
      "Iteration 9855, loss = 347.82030667\n",
      "Iteration 9856, loss = 347.80043988\n",
      "Iteration 9857, loss = 347.81759219\n",
      "Iteration 9858, loss = 347.81061341\n",
      "Iteration 9859, loss = 347.79933199\n",
      "Iteration 9860, loss = 347.79091459\n",
      "Iteration 9861, loss = 347.78415255\n",
      "Iteration 9862, loss = 347.77883143\n",
      "Iteration 9863, loss = 347.78081098\n",
      "Iteration 9864, loss = 347.77506567\n",
      "Iteration 9865, loss = 347.76893166\n",
      "Iteration 9866, loss = 347.75347840\n",
      "Iteration 9867, loss = 347.74695722\n",
      "Iteration 9868, loss = 347.75382779\n",
      "Iteration 9869, loss = 347.73646031\n",
      "Iteration 9870, loss = 347.71747787\n",
      "Iteration 9871, loss = 347.72855181\n",
      "Iteration 9872, loss = 347.74987483\n",
      "Iteration 9873, loss = 347.73700060\n",
      "Iteration 9874, loss = 347.70459034\n",
      "Iteration 9875, loss = 347.71373588\n",
      "Iteration 9876, loss = 347.70464935\n",
      "Iteration 9877, loss = 347.69223249\n",
      "Iteration 9878, loss = 347.69100607\n",
      "Iteration 9879, loss = 347.68664020\n",
      "Iteration 9880, loss = 347.66839956\n",
      "Iteration 9881, loss = 347.69711885\n",
      "Iteration 9882, loss = 347.66634670\n",
      "Iteration 9883, loss = 347.66059154\n",
      "Iteration 9884, loss = 347.65778069\n",
      "Iteration 9885, loss = 347.67365564\n",
      "Iteration 9886, loss = 347.67641904\n",
      "Iteration 9887, loss = 347.65721705\n",
      "Iteration 9888, loss = 347.62190628\n",
      "Iteration 9889, loss = 347.61174577\n",
      "Iteration 9890, loss = 347.63432840\n",
      "Iteration 9891, loss = 347.62509734\n",
      "Iteration 9892, loss = 347.62125214\n",
      "Iteration 9893, loss = 347.59326933\n",
      "Iteration 9894, loss = 347.60718470\n",
      "Iteration 9895, loss = 347.60858012\n",
      "Iteration 9896, loss = 347.57609457\n",
      "Iteration 9897, loss = 347.58621754\n",
      "Iteration 9898, loss = 347.59591180\n",
      "Iteration 9899, loss = 347.58618614\n",
      "Iteration 9900, loss = 347.57330323\n",
      "Iteration 9901, loss = 347.53945013\n",
      "Iteration 9902, loss = 347.56237176\n",
      "Iteration 9903, loss = 347.58024257\n",
      "Iteration 9904, loss = 347.54180674\n",
      "Iteration 9905, loss = 347.51959893\n",
      "Iteration 9906, loss = 347.54169544\n",
      "Iteration 9907, loss = 347.52137893\n",
      "Iteration 9908, loss = 347.51066805\n",
      "Iteration 9909, loss = 347.50765545\n",
      "Iteration 9910, loss = 347.49925082\n",
      "Iteration 9911, loss = 347.48747258\n",
      "Iteration 9912, loss = 347.48664838\n",
      "Iteration 9913, loss = 347.47833614\n",
      "Iteration 9914, loss = 347.49443766\n",
      "Iteration 9915, loss = 347.49728543\n",
      "Iteration 9916, loss = 347.46922025\n",
      "Iteration 9917, loss = 347.47963155\n",
      "Iteration 9918, loss = 347.45422951\n",
      "Iteration 9919, loss = 347.46250359\n",
      "Iteration 9920, loss = 347.45802172\n",
      "Iteration 9921, loss = 347.43850330\n",
      "Iteration 9922, loss = 347.44508406\n",
      "Iteration 9923, loss = 347.44494440\n",
      "Iteration 9924, loss = 347.44446607\n",
      "Iteration 9925, loss = 347.42613139\n",
      "Iteration 9926, loss = 347.43372423\n",
      "Iteration 9927, loss = 347.41671582\n",
      "Iteration 9928, loss = 347.39724775\n",
      "Iteration 9929, loss = 347.42951171\n",
      "Iteration 9930, loss = 347.46934748\n",
      "Iteration 9931, loss = 347.46813335\n",
      "Iteration 9932, loss = 347.40567948\n",
      "Iteration 9933, loss = 347.37027761\n",
      "Iteration 9934, loss = 347.38213300\n",
      "Iteration 9935, loss = 347.43177650\n",
      "Iteration 9936, loss = 347.40324340\n",
      "Iteration 9937, loss = 347.37946814\n",
      "Iteration 9938, loss = 347.36390396\n",
      "Iteration 9939, loss = 347.34715781\n",
      "Iteration 9940, loss = 347.36363318\n",
      "Iteration 9941, loss = 347.37192339\n",
      "Iteration 9942, loss = 347.33292081\n",
      "Iteration 9943, loss = 347.33283311\n",
      "Iteration 9944, loss = 347.31633886\n",
      "Iteration 9945, loss = 347.34298560\n",
      "Iteration 9946, loss = 347.33040781\n",
      "Iteration 9947, loss = 347.30571355\n",
      "Iteration 9948, loss = 347.33062618\n",
      "Iteration 9949, loss = 347.32177347\n",
      "Iteration 9950, loss = 347.32253188\n",
      "Iteration 9951, loss = 347.28190243\n",
      "Iteration 9952, loss = 347.27251015\n",
      "Iteration 9953, loss = 347.29698171\n",
      "Iteration 9954, loss = 347.28315336\n",
      "Iteration 9955, loss = 347.27459991\n",
      "Iteration 9956, loss = 347.29644213\n",
      "Iteration 9957, loss = 347.30642251\n",
      "Iteration 9958, loss = 347.28283292\n",
      "Iteration 9959, loss = 347.26796319\n",
      "Iteration 9960, loss = 347.26556899\n",
      "Iteration 9961, loss = 347.24444263\n",
      "Iteration 9962, loss = 347.23694825\n",
      "Iteration 9963, loss = 347.22179289\n",
      "Iteration 9964, loss = 347.25081643\n",
      "Iteration 9965, loss = 347.24804048\n",
      "Iteration 9966, loss = 347.23356385\n",
      "Iteration 9967, loss = 347.20468232\n",
      "Iteration 9968, loss = 347.22242943\n",
      "Iteration 9969, loss = 347.18868251\n",
      "Iteration 9970, loss = 347.16912124\n",
      "Iteration 9971, loss = 347.21070936\n",
      "Iteration 9972, loss = 347.21559958\n",
      "Iteration 9973, loss = 347.19138712\n",
      "Iteration 9974, loss = 347.16379941\n",
      "Iteration 9975, loss = 347.17552405\n",
      "Iteration 9976, loss = 347.18173085\n",
      "Iteration 9977, loss = 347.19226469\n",
      "Iteration 9978, loss = 347.15783196\n",
      "Iteration 9979, loss = 347.17700645\n",
      "Iteration 9980, loss = 347.15362525\n",
      "Iteration 9981, loss = 347.15659174\n",
      "Iteration 9982, loss = 347.12079732\n",
      "Iteration 9983, loss = 347.12203242\n",
      "Iteration 9984, loss = 347.15316575\n",
      "Iteration 9985, loss = 347.13580655\n",
      "Iteration 9986, loss = 347.08443951\n",
      "Iteration 9987, loss = 347.09593844\n",
      "Iteration 9988, loss = 347.12041372\n",
      "Iteration 9989, loss = 347.09565504\n",
      "Iteration 9990, loss = 347.08407460\n",
      "Iteration 9991, loss = 347.09132863\n",
      "Iteration 9992, loss = 347.08401046\n",
      "Iteration 9993, loss = 347.09620388\n",
      "Iteration 9994, loss = 347.06829886\n",
      "Iteration 9995, loss = 347.07551053\n",
      "Iteration 9996, loss = 347.07524613\n",
      "Iteration 9997, loss = 347.07073089\n",
      "Iteration 9998, loss = 347.05118038\n",
      "Iteration 9999, loss = 347.05418026\n",
      "Iteration 10000, loss = 347.01323542\n",
      "Mean squared error: 37254.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristian/anaconda3/envs/cristi/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Antrenam modeul folosind setul de train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Facem predictii\n",
    "y_pred = regr.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0]),\n",
       " array([-1,  0,  0,  0]),\n",
       " array([1045,   21,  157,    4]),\n",
       " array([7265,  367,  309,   20]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([2772,  105,  308,   15]),\n",
       " array([6969,  349,  311,   21]),\n",
       " array([5491,  263,  316,   21]),\n",
       " array([9594,  515,  345,   22]),\n",
       " array([10,  0,  3,  0]),\n",
       " array([0, 0, 1, 0]),\n",
       " array([27,  0,  9,  0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([2275,   80,  266,   14]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([6082,  298,  314,   21]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertim din float in int\n",
    "result_int = []\n",
    "for x in y_pred:\n",
    "    result_int.append(x.astype(int))\n",
    "\n",
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -66.35071839,   -12.76870591,   -11.20112433, -2226.14712916])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#MLP Regressor pentru NN Multy Layer\n",
    "regr = MLPRegressor(solver='adam', hidden_layer_sizes=(200,100), max_iter=10000,activation='relu')\n",
    "#regr = MLPRegressor(solver=â€™lbfgsâ€™, hiddenlayersizes=(200,150), maxiter=20000,activation=â€™reluâ€™, alpha = 0.0003)\n",
    "#regr = MLPRegressor(solver=â€™adamâ€™, hiddenlayersizes=(200,100), maxiter=10000,activation=â€™reluâ€™)\n",
    "\n",
    "#Cross validation score\n",
    "cross_val_score(regr, y_test, X_test, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   16,    21,  -259,  8605,  9872, 11714,    61,  3852,  4803,\n",
       "         466,  6387,    26,     7,    -9,  9238,  -201,   145,   -10,\n",
       "          -8,   -20,  1634])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregatim coloana pentru cazuri de persoane infectate\n",
    "y = data.iloc[:, 2].values\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "X_final = data.iloc[:, 0:2].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.17)\n",
    "\n",
    "regr.fit(X_train, y_train.ravel())\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    4],\n",
       "       [    9],\n",
       "       [    0],\n",
       "       [ 8746],\n",
       "       [10096],\n",
       "       [11978],\n",
       "       [   49],\n",
       "       [ 3613],\n",
       "       [ 4417],\n",
       "       [  433],\n",
       "       [ 6300],\n",
       "       [   15],\n",
       "       [    3],\n",
       "       [    0],\n",
       "       [ 9242],\n",
       "       [    0],\n",
       "       [  131],\n",
       "       [    0],\n",
       "       [    0],\n",
       "       [    0],\n",
       "       [ 1452]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   16,    21,     0,  8605,  9872, 11714,    61,  3852,  4803,\n",
       "         466,  6387,    26,     7,     0,  9238,     0,   145,     0,\n",
       "           0,     0,  1634])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daca avem numere negative, le facem 0 pentru a putea aplica metricile de evaluare\n",
    "num = 0\n",
    "while(num < len(y_pred)): \n",
    "      \n",
    "    if y_pred[num] < 0: \n",
    "        y_pred[num] = 0\n",
    "    num = num + 1\n",
    "    \n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988410749190094"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Am folosit diferite metrici pentru a putea estima acuritatea rezultatelor obtinute\n",
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386.0519888629724"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import max_error\n",
    "max_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.5143368510001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18509.955708129797"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1502340769853373"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.309641524331969"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988218466146671"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnkAAAI3CAYAAADnW029AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5xkdX3n/9ebUZCIKyIjIIKDZlyvCKE1iVdUNLqbCCoGjImQ1YwacRMNGtR9qDG6kpDEXLzgxBBYr0TX6JgQEcELXmEGB3BABMH9AUEZRPCCgHR/fn/UaS2bPjU93T1Vc868nj7q0XUudc63TtfYH97f7/dUqgpJkiT1y06TboAkSZKWn0WeJElSD1nkSZIk9ZBFniRJUg9Z5EmSJPWQRZ4kSVIPWeRJkiQtUZJTklyf5Ost25Pk75NckeSiJL8ytO2YJJc3j2OWq00WeZIkSUt3KvD0EdufAaxuHmuAdwEk2QN4A/CrwKOBNyS513I0yCJPkiRpiarq88CNI3Y5HPg/NfAVYPck+wC/AZxVVTdW1feBsxhdLC7YXZbjIJIkSeP2G0+6e33vxumxnGvDRbdtAm4dWrW2qtZuxSH2Ba4eWr6mWde2fsks8iRJUid978Zpzjtz/7Gca8U+l99aVVNjOdkysbtWkiRp27sW2G9o+X7Nurb1S2aRJ0mSOqmAmTH9bxmsA17QzLL9NeDmqroOOBN4WpJ7NRMuntasWzK7ayVJkpYoyQeBQ4E9k1zDYMbsXQGq6mTgDOC/AVcAtwC/32y7McmfA+c3h3pTVY2awLFgFnmSJKmjiulalpRtyarqeVvYXsDLWradApyy3G2yu1aSJKmHTPIkSVInDcbk1aSbsd0yyZMkSeohkzxJktRZyzTztZdM8iRJknrIJE+SJHVSUUyXY/LamORJkiT1kEmeJEnqLGfXtjPJkyRJ6iGLPEmSpB6yu1aSJHVSAdN217YyyZMkSeohkzxJktRZTrxoZ5InSZLUQyZ5kiSpkwq8GfIIJnmSJEk9ZJInSZI6a2bSDdiOmeRJkiT1kEmeJEnqpKK8T94IJnmSJEk9ZJInSZK6qWDaIK+VSZ4kSVIPmeRJkqROKpxdO4pJniRJUg+Z5EmSpI4K02TSjdhumeRJkiT1kEWeJElSD1nkjVmSvZN8KMm3kmxIckaSBy3j8Q9N8pjlOt5WnHc6ycYkm5JcmORPkoz8fCVZleR3lrkdy3J9kzy+eS8bk+yb5CPL2c4R5/3RAvbZ6ms94li7J/nDoeVDk/zbYo61wPM9I8n6JJck+VqSv17CsU5qrsFJSV6S5AXL2daWcx6b5O0L2Gdz8/4uT3LmUv5Nzv03neTUJEcu9nhSnxQwU+N5dJFj8sYoSYB/BU6rqqObdY8E9gK+uUynORT4EfClec5/l6q6Y5nOM9dPquqg5jz3AT4A/BfgDSNeswr4nWbfJVvm6/t84K1V9b5m+U5/VLfx9RxlMde6ze7AHwLvXL7mzS/Jw4G3A/+9qr6RZAWwZgmHXAPsUVXTI845qd/R6VV1XNOGJwEfTfKkqrp0Ecc6lJZ/05I0ikneeD0J+GlVnTy7oqouBL7QpBFfT3JxkqPgzqlKkrcnObZ5/u0kf5bkguY1D06yCngJ8Iom6Xl881/9Jyf5KvCXTbKwsjnGTkmumF1eLlV1PYM/wMdlYFWSc5u2XjCUSpwIPL5p6yuSrGiuw/lJLkry4q089WKu72eTfCTJN5K8v2nvi4DfBv68Wbcqydeb1xybZF2Sc4Czm+WPJTmr+Z0cl+SVTYrzlSR7NK97YJJPNuniuUke3Kw/IMmXm3a9eRmu9bzXMMluSc4e+rwcPvQ7eGDzOzipWbdbc02+leTmJP+YQWL2qSS7zvdemvNe1bRh9wzSxic05/58ktXAq4G3VNU3mrZPV9W7mn1WJTmnafPZSfZv1p+a5O+TfCnJlWkSrCTrgN2ADUmOSvLGJMc32z6b5G+TrAf+qFl+WwYJ4qVJHpXko82/hTc35740yWeS3JLkB0nek2R18z6/3ay/CHgc8IItvM+5v6PPAGub39Ooz8JvJflq89n5dJK9Ms+/6eawT5h7TaQd1XQz+WJbP7rIIm+8Hg5smGf9s4GDgEcChwEnJdlnAce7oap+BXgXcHxVfRs4GXhbVR1UVec2+90PeExVvRJ4H4OUiuZcF1bV5sW+oTZVdSWwArgPcD3w1KatRwF/3+x2AnBu09a3AS8Ebq6qRwGPAv4gyQFbcdrFXN+DgT8GHgo8AHhsVb0HWAe8qqqeP8/xfgU4sqqeOHTeZzdtfgtwS1UdDHwZmO1CXAu8vKoOAY7n58nZ3wHvqqpHANdtxXv9mTnXuu0a3go8q/kdPAn46yRh8Dv4VvM7eNWca3IYg4Twi1X1MOAm4DnzvZcmTbusuY6PAy5gUMDvAuxXVZfT/vsB+AcGCeyBwPv5+WcEYJ/mmL/JoCilqp5Jk2hW1enzHG/nqpqqqtnu4NuraorBv4+PAy9r2nMsgzRzNYP/P7wn8EkGKfPHgDc1658FfA94CPD9LbzP+VwAPLh53vZZ+ALwa81n50PAq0f8m77TNZGkueyu3T48Dvhg84fyu0k+x+AP9A+28LqPNj83MCgy2nx4qEvrFAZ/5P4W+B/APy+61Qt3V+DtSQ4CpoG2MXJPAw4cSibuyeCP71VLPP+o63teVV0DkGQjgz/uX9jC8c6qqhuHlj9TVT8EfpjkZuATzfqLm/ezG/AY4MODugqAXZqfj2VQOAG8F/iLxb3Fn2m7htcA/7tJnWaAfRl0Y8/nvKq6pkmRbgZmuzs3MLg+be/lXOAJwAHAW4E/AD4HnL+Adv86P/8Mvxf4y6FtH6uqGeCSJG1tnmtu4beu+XkxsKmqrgNIciVwX+BGBtfpfAbF8l0ZFH/vZ5AY/gWD9/ku4HmLeJ9pzjfqs3A/4PTmP0B2ZvTnfjHXROqdgs6mbONgkTdem5hnbNcId/CLaevd5my/rfk5zejf5Y9nn1TV1Um+m+TJwKP5eaq3rJI8oGnX9QzGin2XQZK2E4NUad6XMUg4zlzkabf2+sLPryFs+TrO+vGc5eFjzAwtzzTH2wm4aXYc3TyWNKR3zrWe9xpm0M2/Ejikqn6a5Nvc+fM0q+2aTDMoDNvey+eBlzIoml4PvIrBeLLZ9GkTcAhw4cLf3Z3as9D/N2/7HQ3/fmaXVzD4t3ZaVb2m6fa9L4Ni7hXAs6vqBQBJ/ifwn8DjaX+f8zkYuJTRn4V/AP6mqtYlORR444jjLeaaSNrB2F07XucAuyT52WDzJAcy6AY7qhnXtJJBSnAe8P+AhybZJcnuwFMWcI4fAvfYwj7vYdBtO5zwLZvmPZwMvL2qikGadF2TPPwegz+q87X1TOClSe7aHOdBSe6+Fafe2us7FlX1A+CqJM9t2pQMJoQAfBE4unm+1QX3PNe67RreE7i+KfCeBNy/OcRCPi/DRr2X8xikVDNVdSuwEXgxg+IP4CTgtWlmO2cwJvQlzbYv8YvXYVTBtC38GDgyg4ksAD9lUMytBJ6Y5N5JDgGey+A/WEa9z1+Q5IkMxuP94xY+C/cErm2eHzN0iK39HUk7lJnKWB5dZJE3Rs0f4WcBh2UwqH0Tg+6eDwAXMUg4zmEwFuc7VXU18C/A15ufX1vAaT4BPGvOIO25ZgetL2dX7a7NOTcBnwY+BfxZs+2dwDFJLmQwLmk2ZbkImM7gNiCvYFB8XgJckMFEh3ezFWnz1l7fpb3drfZ84IXNNdgEzE58+CPgZUkuZtCFuhCjrnXbNXw/MNWc5wXA7OSH7wFfzGBSykkszLzvpapuA64GvtLsdy6D4uTiZvtFDMb6fTDJpQw+1w9o9n058PvN5Ibfa67LON0G/C8G1/KVTRvezKArPQwKvo8zSONmGPE+G0c1v6NvAq8FnjM0s7bts/BGBt24G4Abho61kH/TknQnGfxd1I4kyRSDgdz+wZAkddZDD9y53vdve4/lXIfc/+oNzQSuznBM3g4myQkMxk1tk7F4kiRp+2CRt4OpqhPxlguSpB4owrQjz1p5ZSRJknrIJE+SJHVWV2e+joNJXkcN3yaka2z7ZNj2ybDtk2HbJ6PLbe8ji7zu6vI/JNs+GbZ9Mmz7ZNj2yRhr22e/8cLvrp2fRZ4kSVIPeZ+8bWjPPfesVatWbZNjb968mZUrV26TY29rtn0ybPtk2PbJsO2TsWHDhh9V1di+oeXBB+5Sp3xiofeRX5rHrrrK++Tp51atWsX69esn3QxJksYiyWVjPiPTZadkG6+MJElSD5nkSZKkTipgxryqlVdGkiSph0zyJElSZ3X19ibjYJInSZLUQyZ5kiSpk6qcXTuKV0aSJKmHTPIkSVJnzTgmr5VJniRJUg+Z5EmSpE4qYNq8qpVXRpIkqYdM8iRJUkc5u3YUr4wkSVIPmeRJkqRO8rtrR/PKSJIkLYMkT09yWZIrkpwwz/a3JdnYPL6Z5KahbdND29YtR3tM8iRJkpYoyQrgHcBTgWuA85Osq6pLZvepqlcM7f9y4OChQ/ykqg5azjZZ5EmSpM6aru3mZsiPBq6oqisBknwIOBy4pGX/5wFv2JYNsrtWkiRpy/ZMsn7osWbO9n2Bq4eWr2nW3UmS+wMHAOcMrb5bc9yvJDliORrcmSQvyd7A3wKPAm4Cvgv8cVV9c5mOfyhwe1V9aTmOJ0mStq0i47wZ8g1VNbVMxzoa+EhVTQ+tu39VXZvkAcA5SS6uqm8t5SSdSPKSBPhX4LNV9cCqOgR4DbDXMp7mUOAxLefvTDEsSZIm4lpgv6Hl+zXr5nM08MHhFVV1bfPzSuCz/OJ4vUXpRJEHPAn4aVWdPLuiqi4EvpDkpCRfT3JxkqNgkMol+bfZfZO8PcmxzfNvJ/mzJBc0r3lwklXAS4BXNLNaHp/k1CQnJ/kq8JdJLk+ysjnGTs3MmZXjugCSJOnOZmqnsTwW4HxgdZIDkuzMoJC70yzZJA8G7gV8eWjdvZLs0jzfE3gs7WP5FqwrCdXDgQ3zrH82cBDwSGBPBjNZPr+A491QVb+S5A+B46vqRUlOBn5UVX8FkOSFDKrwx1TVdJKbgecz6DI+DLiwqjbPPXDTR78GYP/999/a9ylJkjqoqu5IchxwJrACOKWqNiV5E7C+qmYLvqOBD1VVDb38IcC7k8wwCOBOHJ6Vu1hdKfLaPA74YNOn/d0kn2MwZu8HW3jdR5ufGxgUim0+PNRffgrwcQZF3v8A/nm+F1TVWmAtwNTUVM23jyRJWrqCcY7J26KqOgM4Y866189ZfuM8r/sS8Ijlbs/2c2VG2wQcshX738Evvre7zdl+W/NzmtGF7o9nn1TV1QwKySczmCb9H1vRHkmSpLHqSpF3DrDL8HTlJAcymGV7VJIVzfi4JwDnAf8PeGiSXZLsDjxlAef4IXCPLezzHuB9/GLCJ0mSJqAI0zWeRxd1oshr+q2fBRyW5FtJNgFvBT4AXARcyKAQfHVVfadJ3f4F+Hrz82sLOM0ngGfNTrxo2WcdsBstXbWSJEnbi86Myauq/wR+e55Nr2oec/d/NfDqedavGnq+nsGtU2jut3fg0K7nznOuRzKYcPGNrWi6JEnaRma6kVdNRGeKvElrvmj4pQxm2EqSJG3XLPIWqKpOBE6cdDskSdJAFUwv7B52OySvjCRJUg+Z5EmSpI4KM3Rz5us4mORJkiT1kEWeJElSD9ldK0mSOqlw4sUoXhlJkqQeMsmTJEmdNW1e1corI0mS1EMmeZIkqZOKMFPeQqWNSZ4kSVIPmeRJkqTOckxeO6+MJElSD5nkSZKkTipgxvvktfLKSJIk9ZBJniRJ6qgwjbNr25jkSZIk9ZBJnuY1853Vk27Coq378S9NugmL9sOZXSfdhEXb+y43TboJi3Zr3XXSTVi033rAxZNugjQxjskbzSsjSZLUQyZ5kiSpsxyT184kT5IkqYdM8iRJUidVxTF5I3hlJEmSesgiT5IkqYfsrpUkSZ01bXdtK6+MJElSD5nkSZKkTipgxluotDLJkyRJ6iGTPEmS1FFxTN4IXhlJkqQeMsmTJEmdVMBMOSavjUmeJElSD5nkSZKkzpo2r2rllZEkSeohkzxJktRJRRyTN4JJniRJUg+Z5EmSpM6aMa9qtUNcmSTTSTYm2ZTkwiR/kmTke0+yKsnvjKuNkiRJy2lHSfJ+UlUHASS5D/AB4L8AbxjxmlXA7zT7SpKk7UwVTDsmr9UOkeQNq6rrgTXAcRlYleTcJBc0j8c0u54IPL5JAF+RZEWSk5Kcn+SiJC+e3LuQJEkabUdJ8n5BVV2ZZAVwH+B64KlVdWuS1cAHgSngBOD4qvpNgCRrgJur6lFJdgG+mORTVXXV8LGb/dYA7L///uN7U5IkSUN2yCJvjrsCb09yEDANPKhlv6cBByY5slm+J7Aa+IUir6rWAmsBpqamapu0WJIkAX6t2Sg7ZJGX5AEMCrrrGYzL+y7wSAbd17e2vQx4eVWdOZZGSpIkLcEOV+QlWQmcDLy9qirJPYFrqmomyTHAimbXHwL3GHrpmcBLk5xTVT9N8iDg2qr68VjfgCRJAmZvhrzDTS9YsB2lyNs1yUYGXbN3AO8F/qbZ9k7g/yZ5AfBJYLZouwiYTnIhcCrwdwxm3F6QJMBm4IhxvQFJkqStsUMUeVW1YsS2y4EDh1b9abP+p8CT5+z+2uYhSZK2A9M4Jq+NGackSVIP7RBJniRJ6p/C2bWjmORJkiT1kEmeJEnqKGfXjuKVkSRJ6iGTPEmS1Fkzzq5tZZInSZLUQyZ5kiSpk6pg2tm1rUzyJEmSlkGSpye5LMkVSU6YZ/uxSTYn2dg8XjS07ZgklzePY5ajPSZ5kiSps7aX2bVJVgDvAJ4KXAOcn2RdVV0yZ9fTq+q4Oa/dA3gDMMXg9n8bmtd+fylt2j6ujCRJUrc9Griiqq6sqtuBDwGHL/C1vwGcVVU3NoXdWcDTl9ogizxJkqQt2zPJ+qHHmjnb9wWuHlq+plk313OSXJTkI0n228rXbhW7ayVJUicVGefXmt1QVVNLPMYngA9W1W1JXgycBjx56U2bn0meJEnS0l0L7De0fL9m3c9U1feq6rZm8T3AIQt97WJY5EmSpM6aIWN5LMD5wOokByTZGTgaWDe8Q5J9hhafCVzaPD8TeFqSeyW5F/C0Zt2S2F0rSZK0RFV1R5LjGBRnK4BTqmpTkjcB66tqHfA/kzwTuAO4ETi2ee2NSf6cQaEI8KaqunGpbbLIkyRJnVQwzjF5W1RVZwBnzFn3+qHnrwFe0/LaU4BTlrM9dtdKkiT1kEme5rXux7806SYs2jPvfsukm7AE3W37httun3QTFm2PnW6edBMkLdL2cjPk7ZFXRpIkqYdM8iRJUjfVWO+T1zkmeZIkST1kkidJkjqpYKH3sNshmeRJkiT1kEmeJEnqLMfktTPJkyRJ6iGTPEmS1Enb2zdebG9M8iRJknrIIk+SJKmH7K6VJEmdZXdtO5M8SZKkHjLJkyRJnVT4tWajmORJkiT1kEmeJEnqLL/WrJ1JniRJUg+Z5EmSpG4qZ9eOYpInSZLUQyZ5kiSpk/xas9EmkuQl2TvJh5J8K8mGJGckedAijvP4JJuSbEyyb5KPbIv2znPeH43jPJIkSYs19iQvSYB/BU6rqqObdY8E9gK+uZWHez7w1qp6X7N85Dznu0tV3bGEJkuSpO2USV67SXTXPgn4aVWdPLuiqi7MwEnAMxgksG+uqtOTHAq8EbgBeDiwAfhd4IXAbwO/keQZwOuAf6uqhyc5Fng2sBuwIsk/A0cAdwdWA38F7Az8HnAb8N+q6sYkDwTeAawEbgH+oKq+keQA4APN8T6+za6MJEnSMplEd+1soTbXs4GDgEcChwEnJdmn2XYw8MfAQ4EHAI+tqvcA64BXVdXz5znerwBHVtUTh877bOBRwFuAW6rqYODLwAuafdYCL6+qQ4DjgXc26/8OeFdVPQK4btSbS7Imyfok6zdv3jxqV0mStASz33gxjkcXbU+zax8HfLCqpqvqu8DnGBRkAOdV1TVVNQNsBFYt4HhnVdWNQ8ufqaofVtVm4GbgE836i4FVSXYDHgN8OMlG4N3AbJH5WOCDzfP3jjppVa2tqqmqmlq5cuUCmilJkrT8JtFdu4l5xs5twW1Dz6dZWLt/POIYM0PLM83xdgJuqqqDWo5XCzinJEkao+poyjYOk0jyzgF2SbJmdkWSA4GbgKOSrEiyEngCcN64GlVVPwCuSvLcpk1pJoQAfBE4unk+X9ewJEnSdmXsRV5VFfAs4LDmFiqbgLcymNhwEXAhg0Lw1VX1nTE37/nAC5NcyCBxPLxZ/0fAy5JcDOw75jZJkiRttQxqLm0LU1NTtX79+kk3Y1E+9q1Hbnmn7dQz737LpJuwQ9pw2+2TbsKi7bFTd9v+wP1GzgWTxirJhqqaGtf57vFf966D3/l7YznXuYf91Vjf23LYniZeSJIkaZn4tWaSJKmTqrwZ8igmeZIkST1kkidJkjrLW6i0M8mTJEnqIZM8SZLUUd39yrFxMMmTJEnqIZM8SZLUWY7Ja2eSJ0mS1EMmeZIkqZMK75M3ikmeJElSD5nkSZKkbqrBt15ofiZ5kiRJPWSSJ0mSOmsGx+S1McmTJEnqIYs8SZKkHrK7VpIkdVLhzZBHMcmTJEnqIZM8zeuHM7tOuglLcMukG7BDuqnDn5lfyh2TboKkRYk3Qx7BJE+SJKmHTPIkSVJneTPkdiZ5kiRJPWSSJ0mSOsvZte1M8iRJknrIJE+SJHVSlUneKCZ5kiRJPWSSJ0mSOsv75LUzyZMkSeohkzxJktRZ3ievnUmeJEnSMkjy9CSXJbkiyQnzbH9lkkuSXJTk7CT3H9o2nWRj81i3HO0xyZMkSZ21vcyuTbICeAfwVOAa4Pwk66rqkqHdvgZMVdUtSV4K/CVwVLPtJ1V10HK2ySRPkiRp6R4NXFFVV1bV7cCHgMOHd6iqz1TVLc3iV4D7bcsGWeRJkiRt2Z5J1g891szZvi9w9dDyNc26Ni8E/mNo+W7Ncb+S5IjlaLDdtZIkqZOKjLO79oaqmlqOAyX5XWAKeOLQ6vtX1bVJHgCck+TiqvrWUs5jkidJkrR01wL7DS3fr1n3C5IcBrwOeGZV3Ta7vqqubX5eCXwWOHipDbLIkyRJnVVjeizA+cDqJAck2Rk4GviFWbJJDgbezaDAu35o/b2S7NI83xN4LDA8YWNR7K6VJElaoqq6I8lxwJnACuCUqtqU5E3A+qpaB5wE7AZ8OAnA/1dVzwQeArw7yQyDAO7EObNyF8UiT5IkdVNtP7dQAaiqM4Az5qx7/dDzw1pe9yXgEcvdnt501w7dRHBTkguT/EmSRb2/JLsn+cOh5UOT/NvytVaSJGnb6k2RR3MTwap6GIMbET4DeMMij7U78Idb3EuSJE3WdjQob3vTpyLvZ5rBjGuA4zKwIslJSc5vvkrkxQBJdmu+VuSCJBcnmb1p4YnAA5tk8KRm3W5JPpLkG0nen6YzXZIkaXvU2zF5VXVl8xUj92Fwx+mbq+pRzeyVLyb5FIObFj6rqn7QzGb5SvN9cScAD5/9epEkhzKYyvww4D+BLzKY+fKFuedtbo64BmD//fffxu9SkqQd2/Y0Jm9708skbx5PA16QZCPwVeDewGogwP9OchHwaQZ3pt6r5RjnVdU1VTUDbARWzbdTVa2tqqmqmlq5cuUyvw1JkqSF6W2S19wxehq4nkEx9/KqOnPOPscCK4FDquqnSb4N3K3lkLcNPZ+mx9dOkqSuqI6OlxuHXiZ5SVYCJwNvr6picM+alya5a7P9QUnuDtwTuL4p8J4E3L85xA+Be0yg6ZIkScuiT2nUrk137F2BO4D3An/TbHsPg+7VC5oJE5uBI4D3A59IcjGwHvgGQFV9L8kXk3ydwZcH//s434gkSdqywjF5o/SmyKuqFSO2zQCvbR5z/XrLa35nzqrPDm07bhFNlCRJGpveFHmSJGkHU4BJXqtejsmTJEna0VnkSZIk9ZDdtZIkqbO8hUo7kzxJkqQeMsmTJEndZZLXyiRPkiSph0zyJElSR8WbIY9gkidJktRDJnmSJKm7HJPXyiRPkiSph0zyJElSNxWOyRvBJE+SJKmHTPIkSVJ3OSavlUmeJElSD5nkSZKkDnNMXhuTPEmSpB4yyZMkSd3lmLxWFnma1953uWnSTVi0DbfdPukmLNpNM7tOugmL9pRdpyfdhEW7tLsfGUlqZXetJElSD5nkSZKk7rK7tpVJniRJUg+Z5EmSpG4qwK81a2WSJ0mS1EMmeZIkqbPKMXmtTPIkSZJ6yCRPkiR1l0leK5M8SZKkHjLJkyRJ3eXs2lYmeZIkST1kkidJkjorjslrZZInSZLUQyZ5kiSpmwpn145gkidJktRDJnmSJKmj4uzaEUzyJEmSesgiT5IkqYfsrpUkSd3lxItWE0nykjwjyfoklyT5WpK/XsKxTkqyqfn5kiQvWM62tpzz2CRv39bnkSRJWqyxJ3lJHg68HfjvVfWNJCuANUs45Bpgj6qaHnHOu1TVHUs4hyRJ2h6Z5LXaYpKXZFWSS5P8Y5OYfSrJrkkemOSTSTYkOTfJg5OsSHJVBnZPMp3kCc1xPp9kNfBq4C1V9Q2AqpquqncNneucJBclOTvJ/s36U5P8fZIvJbkyyZHN+nXAbsCGJEcleWOS45ttn03yt0nWA3/ULL+tSRAvTfKoJB9NcnmSNw+9399Ncl6SjUne3RShJPn9JN9Mch7w2OX7FUiSJC2/hXbXrgbeUVUPA24CngOsBV5eVYcAxwPvbNK0y4CHAo8DLgAen2QXYL+quhx4OLCh5Tz/AJxWVQcC7wf+fmjbPs0xfxM4EaCqngn8pKoOqqrT5znezlU1VVWz3cG3V9UUcDLwceBlTXuOTXLvJA8BjgIeW1UHAdPA85PsA/wZg+Lucc37m1eSNU0huX7z5s1tu0mSpOVQY3p00EK7a6+qqo3N8w3AKuAxwIeTn92fZpfm57nAE4ADgLcCfwB8Djh/Aef5deDZzfP3An85tO1jVTUDXJJkrwW2e27ht675eTGwqaquA8u71b8AABPpSURBVEhyJbAfgwLuEOD85n3tClwP/Crw2ara3Ox/OvCg+U5YVWsZFMBMTU119GMhSZK6bqFF3m1Dz6eBvYCbmrRrrs8DLwXuC7weeBVwKIPiD2ATg0Lqwq1s63AbFnrnwx+3HGNmzvFmGFyLMEgSXzP8oiRHbEU7JUnSOBTeDHmExc6u/QFwVZLnAjRj8B7ZbDuPQco3U1W3AhuBFzMo/gBOAl6b5EHNa3dK8pJm25eAo5vnz+fnheG4nA0cmeQ+Tdv2SHJ/4KvAE5su3bsCzx1zuyRJkrbKUm6h8nzghUkuZJDOHQ5QVbcBVwNfafY7F7gHgy5Squoi4I+BDya5FPg68IBm35cDv5/kIuD3gD9aQvu2WlVdAvwv4FNNG84C9mm6dd8IfBn4InDpONslSZLmlxrPo4tS1dGWd8DU1FStX79+0s1YlLOuevCkm7Bou+/0k0k3YdFumtl10k1YtKfs2noXo+3epbffMukmLNrD9r920k2QfibJhmaC41jssv9+dd9X//FYzvXtlx8/1ve2HPzGC0mS1F1mVa387lpJkqQessiTJEnqIYs8SZKkZZDk6UkuS3JFkhPm2b5LktOb7V9Nsmpo22ua9Zcl+Y3laI9j8iRJUmdtLzNfm69BfQfwVOAaBl+ssK65c8esFwLfr6pfTnI08BfAUUkeyuAWcg9jcJ/hTyd5UPNNYotmkidJkrR0jwauqKorq+p24EM0t5cbcjhwWvP8I8BTMviKrcOBD1XVbVV1FXBFc7wlsciTJEndVRnPA/ac/W765rFmTkv2ZXCf4FnXNOvm3aeq7gBuBu69wNduNbtrJUmStuyGrt0nzyRPkiRp6a4F9htavl+zbt59ktwFuCfwvQW+dqtZ5EmSpG6qMT627HxgdZIDkuzMYCLFujn7rAOOaZ4fCZxTg68eWwcc3cy+PQBYDZy38AsxP7trJUmSlqiq7khyHHAmsAI4pao2JXkTsL6q1gH/BLw3yRXAjQwKQZr9/gW4BLgDeNlSZ9aCRZ4kSeqy7eQWKgBVdQZwxpx1rx96fivw3JbXvgV4y3K2x+5aSZKkHjLJkyRJnbW93Ax5e2SSJ0mS1EMmeZIkqbtM8lqZ5EmSJPWQSZ4kSeouk7xWFnma161110k3YdH22OnmSTdh0X4pd0y6CYt26e2TbsHiPWTnX5p0EyRp2VnkSZKkTko5u3YUx+RJkiT1kEmeJEnqrsqkW7DdMsmTJEnqIZM8SZLUXY7Ja2WSJ0mS1EMWeZIkST1kd60kSeosb6HSziRPkiSph0zyJElSd5nktTLJkyRJ6iGTPEmS1E1+rdlIJnmSJEk9ZJInSZK6yySvlUmeJElSD5nkSZKk7jLJa2WSJ0mS1EMmeZIkqbOcXdvOJE+SJKmHelPkJTk2yeYkX0tyeZIzkzxmCcc7dPj1SU5NcuTytFaSJGnb6k2R1zi9qg6uqtXAicBHkzxkkcc6FFh0kShJkjRJEyvykqxKcmmSf0yyKcmnkuya5IFJPplkQ5Jzkzw4yYokV2Vg9yTTSZ7QHOfzSVbPPX5VfQZYC6xp9rvTcZv1v5Xkq00C+OkkeyVZBbwEeEWSjUke3xz2CUm+lORKUz1JkrYDNaZHB006yVsNvKOqHgbcBDyHQWH28qo6BDgeeGdVTQOXAQ8FHgdcADw+yS7AflV1ecvxLwAe3Dy/03Gb9V8Afq2qDgY+BLy6qr4NnAy8raoOqqpzm333ac7/mwySwjtJsibJ+iTrN2/evPVXRJIkaRlMenbtVVW1sXm+AVjFoIv0w0lm99ml+Xku8ATgAOCtwB8AnwPOH3H8ACTZbcRx7wecnmQfYGfgqhHH+1hVzQCXJNlrvh2qai2DgpKpqamO1v6SJKnrJl3k3Tb0fBrYC7ipqg6aZ9/PAy8F7gu8HngVg3Fz586z76yDgUsZJJZtx/0H4G+qal2SQ4E3LrC9ad1LkiRte+UtVEaZdHftXD8ArkryXIBmDN4jm23nMUjjZqrqVmAj8GIGxd+dJHkig/F4/1hVo457T+Da5vkxQ4f4IXCPZXtnkiRJY7S9FXkAzwdemORCYBNwOEBV3QZcDXyl2e9cBkXYxUOvPaqZKPFN4LXAc6rq0lHHZZDcfTjJBuCGoWN9AnjWnIkXkiRpe+LEi1YT665tJjc8fGj5r4Y2P73lNY8fev4B4ANDy6cCp44431XzHbeqPg58fJ713wQOHFp17pztu7WdS5IkadImPSZPkiRp8Tqaso3D9thdK0mSpCUyyZMkSZ0UnF07ikmeJElSD5nkSZKk7jLJa2WSJ0mS1EMmeZIkqZv8xouRTPIkSZJ6yCRPkiR1l0leK5M8SZKkHjLJkyRJ3WWS18okT5IkqYcs8iRJknrI7lpJktRZ3kKlnUmeJElSD5nkSZKk7jLJa2WSJ0mS1EMmeZIkqZsKk7wRLPI0r996wMWTboIkSVoCizxJktRZzq5t55g8SZKkHjLJkyRJ3WWS18okT5IkqYdM8iRJUmc5Jq+dSZ4kSdI2lGSPJGclubz5ea959jkoyZeTbEpyUZKjhradmuSqJBubx0ELOa9FniRJ6q4a02NpTgDOrqrVwNnN8ly3AC+oqocBTwf+NsnuQ9tfVVUHNY+NCzmpRZ4kSdK2dThwWvP8NOCIuTtU1Ter6vLm+X8C1wMrl3JSizxJktRN40rxBknenknWDz3WbEVL96qq65rn3wH2GrVzkkcDOwPfGlr9lqYb921JdlnISZ14IUmStGU3VNVU28Yknwb2nmfT64YXqqqS9ukiSfYB3gscU1UzzerXMCgOdwbWAn8KvGlLDbbIkyRJWqKqOqxtW5LvJtmnqq5rirjrW/b7L8C/A6+rqq8MHXs2BbwtyT8Dxy+kTXbXSpKkTsoYH0u0DjimeX4M8PE7vZdkZ+Bfgf9TVR+Zs22f5mcYjOf7+kJOapEnSZK0bZ0IPDXJ5cBhzTJJppK8p9nnt4EnAMfOc6uU9ye5GLgY2BN480JOanetJEnqrg7cDLmqvgc8ZZ7164EXNc/fB7yv5fVPXsx5TfIkSZJ6yCRPkiR1ll9r1s4kT5IkqYdM8iRJUneZ5LUyyZMkSeohkzxJktRdJnmtTPIkSZJ6yCRPkiR1Uzm7dhSTvGWWZE2S9UnWb968edLNkSRJOyiLvGVWVWuraqqqplauXDnp5kiS1G81pkcHWeRJkiT1kGPyJElSZzkmr51JniRJUg9Z5EmSJPWQ3bWSJKm77K5tZZInSZLUQyZ5kiSps5x40c4kT5IkqYdM8iRJUjd1+EbF42CSJ0mS1EMmeZIkqbtM8lqZ5EmSJPWQSZ4kSeqk4OzaUUzyJEmSesgkT5IkdZdJXiuTPEmSpB4yyZMkSZ2VMsprY5InSZLUQyZ5kiSpm/zGi5FM8iRJknrIIk+SJKmH7K6VJEmd5c2Q25nkSZIk9ZBJniRJ6i6TvFYmeZIkST1kkidJkjrLMXntTPIkSZJ6yCRPkiR1l0leK5M8SZKkHjLJkyRJ3VSOyRvFJE+SJKmHTPIkSVJ3meS1MsmTJEnqIZM8SZLUScExeaOY5EmSJPWQSZ4kSequMsprY5InSZLUQxZ5kiRJPWR3rSRJ6iwnXrQzyZMkSeohkzxJktRNhTdDHsEkT5IkqYdM8iRJUmdlZtIt2H6Z5EmSJPWQSZ4kSeoux+S1MslbZknWJFmfZP3mzZsn3RxJkrSDsshbZlW1tqqmqmpq5cqVk26OJEm9lhrPo4ss8iRJknrIMXmSJKmbCqiOxmxjYJInSZK0DSXZI8lZSS5vft6rZb/pJBubx7qh9Qck+WqSK5KcnmTnhZzXIk+SJHVWR8bknQCcXVWrgbOb5fn8pKoOah7PHFr/F8DbquqXge8DL1zISS3yJEmStq3DgdOa56cBRyz0hUkCPBn4yNa+3iJPkiR1V43pAXvO3iKteazZilbuVVXXNc+/A+zVst/dmmN/JclsIXdv4KaquqNZvgbYdyEndeKFJEnSlt1QVVNtG5N8Gth7nk2vG16oqkpaO4DvX1XXJnkAcE6Si4GbF9tgizxJkqQlqqrD2rYl+W6SfarquiT7ANe3HOPa5ueVST4LHAz8X2D3JHdp0rz7AdcupE1210qSpE4KnZl4sQ44pnl+DPDxO72X5F5Jdmme7wk8Frikqgr4DHDkqNfPxyJPkiRp2zoReGqSy4HDmmWSTCV5T7PPQ4D1SS5kUNSdWFWXNNv+FHhlkisYjNH7p4Wc1O5aSZLUTVWduBlyVX0PeMo869cDL2qefwl4RMvrrwQevbXnNcmTJEnqIZM8SZLUWcswXq63TPIkSZJ6yCRPkiR1l0leK5M8SZKkHjLJkyRJneWYvHYmeZIkST1kkidJkrqpgBmjvDYmeZIkST1kkidJkrrLIK+VSZ4kSVIPmeRJkqTOcnZtO5M8SZKkHrLIkyRJ6iG7ayVJUneV/bVtTPIkSZJ6yCRPkiR1lhMv2pnkSZIk9ZBJniRJ6qbCmyGPYJInSZLUQyZ5kiSpkwLE2bWtTPIkSZJ6yCRPkiR118ykG7D9MsmTJEnqIZM8SZLUWY7Ja2eSJ0mS1EMmeZIkqZu8T95IJnmSJEk9ZJInSZI6qsAxea1M8iRJknrIJE+SJHVWDPJameRJkiT1kEWeJElSD9ldK0mSusuJF61M8pZZkjVJ1idZv3nz5kk3R5Ik7aAs8pZZVa2tqqmqmlq5cuWkmyNJUn8VZGY8jy6yyJMkSeohx+RJkqTuckxeK5M8SZKkHjLJkyRJ3WWQ18okT5IkqYdM8iRJUmfFMXmtTPIkSZJ6yCRPkiR1l0leK5M8SZKkHjLJkyRJ3VRAR7+NYhxM8iRJknrIJE+SJHVSKGfXjmCSJ0mS1EMWeZIkST1kd60kSeouu2tbmeRJkiT1kEmeJEnqLpO8ViZ5kiRJPWSSJ0mSusmbIY9kkidJktRDJnmSJKmzvBlyO5M8SZKkHjLJkyRJ3WWS18okT5IkaRtKskeSs5Jc3vy81zz7PCnJxqHHrUmOaLadmuSqoW0HLeS8FnmSJKmjapDkjeOxNCcAZ1fVauDsZvkX30nVZ6rqoKo6CHgycAvwqaFdXjW7vao2LuSkFnmSJEnb1uHAac3z04AjtrD/kcB/VNUtSzmpRZ4kSeqmYpxJ3p5J1g891mxFS/eqquua598B9trC/kcDH5yz7i1JLkrytiS7LOSkTryQJEnashuqaqptY5JPA3vPs+l1wwtVVUla+3+T7AM8AjhzaPVrGBSHOwNrgT8F3rSlBlvkSZKk7tpOvvGiqg5r25bku0n2qarrmiLu+hGH+m3gX6vqp0PHnk0Bb0vyz8DxC2mT3bWSJEnb1jrgmOb5McDHR+z7POZ01TaFIUnCYDzf1xdyUos8SZKkbetE4KlJLgcOa5ZJMpXkPbM7JVkF7Ad8bs7r35/kYuBiYE/gzQs5qd21kiSps7rwtWZV9T3gKfOsXw+8aGj528C+8+z35MWc1yRPkiSph0zyJElSd3UgyZsUkzxJkqQeMsmTJEndVMCMSV4bkzxJkqQeMsmTJEkdVY7JG8EkT5IkqYdM8iRJUneZ5LUyyZMkSeohkzxJktRdJnmtTPIkSZJ6yCRPkiR1k/fJG8kkT5IkqYdM8pZZkjXAmmbxR0ku20an2hO4YRsde1uz7ZNh2yfDtk+GbZ+M/zre0xXUzHhP2SEWecusqtYCa7f1eZKsr6qpbX2ebcG2T4ZtnwzbPhm2fTKSrJ90G/RzdtdKkiT1kEmeJEnqLm+h0sokr7u2eZfwNmTbJ8O2T4ZtnwzbPhldbnvvpKyAJUlSB91z573qMXs/byzn+uTVf7eha2MlTfIkSZJ6yDF5kiSpu+yRbGWSJ0mS1EMmeZIkqbtM8lqZ5EmSJPWQSZ4kSeqoMskbwSRPkiSph0zyJElSNxUwMzPpVmy3TPIkSZJ6yCRPkiR1l2PyWpnkSZIk9ZBJniRJ6i6TvFYmeZIkST1kkSdJktRDdtdKkqSOKpixu7aNSZ4kSVIPmeRJkqRuKqjyZshtTPIkSZJ6yCRPkiR1l2PyWpnkSZIk9ZBJniRJ6i5vhtzKJE+SJKmHTPIkSVI3VcGMs2vbmORJkiT1kEmeJEnqLsfktTLJkyRJ6iGTPEmS1FnlmLxWJnmSJEk9ZJInSZI6qhyTN4JJniRJUg9Z5EmSJPWQ3bWSJKmbCpixu7aNSZ4kSVIPmeRJkqTuKm+h0sYkT5IkqYdM8iRJUicVUI7Ja2WSJ0mS1EMmeZIkqZuqHJM3gkmeJElSD5nkSZKkznJMXjuTPEmSpG0oyXOTbEoyk2RqxH5PT3JZkiuSnDC0/oAkX23Wn55k54Wc1yJPkiR1V82M57E0XweeDXy+bYckK4B3AM8AHgo8L8lDm81/Abytqn4Z+D7wwoWc1CJPkiRpG6qqS6vqsi3s9mjgiqq6sqpuBz4EHJ4kwJOBjzT7nQYcsZDzOiZPkiR10g/5/pmfro/sOabT3S3J+qHltVW1dhmPvy9w9dDyNcCvAvcGbqqqO4bW77uQA1rkSZKkTqqqp0+6DbOSfBrYe55Nr6uqj4+7PWCRJ0mStGRVddgSD3EtsN/Q8v2add8Ddk9ylybNm12/RY7JkyRJmrzzgdXNTNqdgaOBdVVVwGeAI5v9jgEWlAxa5EmSJG1DSZ6V5Brg14F/T3Jms/6+Sc4AaFK644AzgUuBf6mqTc0h/hR4ZZIrGIzR+6cFnXdQIEqSJKlPTPIkSZJ6yCJPkiSphyzyJEmSesgiT5IkqYcs8iRJknrIIk+SJKmHLPIkSZJ66P8HdppA84vxPZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = data.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,10,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(data.columns.values)\n",
    "ax.set_yticklabels(data.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYyUlEQVR4nO3df4xd5X3n8feH8QBj2mUMzFowNmuvYhGl9YLZUUpEVWWhWTBNY8tKKdlocVJL/qO0TbYRjdn80a20kh1lWwpSl5ULaUyVTUIpMVbKJmUNUbWVoBkzKb8cyoSGtW8NniSMk8XTZDx894/7HPv4+o7n3rk/z7mflzS65z7n3LnP8TEfjp/zPc9RRGBmZuVyQa87YGZm7edwNzMrIYe7mVkJOdzNzErI4W5mVkIret0BgCuuuCLWrVvX626YmRXKoUOHvh8RY/XW9UW4r1u3jsnJyV53w8ysUCS9vtg6D8uYmZWQw93MrIQc7mZmJbRkuEu6RtK3cz8/kvRJSZdJelLSq+l1Vdpeku6XNC3peUnXd343zMwsb8lwj4hXIuK6iLgO+LfASeCrwC7gYERsAA6m9wCbgQ3pZyfwQCc6bmZmi2u2WuZm4LsR8bqkLcD7U/s+4JvAp4EtwMNRnZHsGUmjkq6MiGNt6rOZWeHtn6rwuW+8wj/NznHV6Ah333INWzeNt+33NzvmfgfwpbS8OhfYbwCr0/I4cCT3maOp7SySdkqalDQ5MzPTZDfMzIpr/1SFex57gcrsHAFUZue457EX2D9Vadt3NBzuki4EPgT8Re26dJbe1NzBEbE3IiYiYmJsrG4NvplZKX3uG68wN79wVtvc/AKf+8YrbfuOZs7cNwPPRcSb6f2bkq4ESK/HU3sFWJv73JrUZmZmwD/NzjXVvhzNhPtHODMkA3AA2J6WtwOP59rvTFUzNwAnPN5uZnbGVaMjTbUvR0PhLukS4APAY7nmPcAHJL0K/HJ6D/AE8BowDfwp8Jtt662ZWQncfcs1jAwPndU2MjzE3bdc07bvaKhaJiLeBi6vafsB1eqZ2m0DuKstvTMzK6GsKqaT1TJ9MXGYmdmg2bppvK1hXsvTD5iZlZDP3M3MuqTTNy7lOdzNzLogu3Epq2/PblwCOhLwHpYxM+uCbty4lOdwNzPrgm7cuJTncDcz64Ju3LiU53A3M+uCbty4lOcLqmZmHZZVyczNLzAksRDBuKtlzMyKq7ZKZiHi9Bm7b2IyMyuoblfJZBzuZmYd1O0qmYzD3cysg7pdJZNxuJuZdVC3q2QyvqBqZtYB+XlkLh0Z5uLhC5g9Od/xOWUyDnczszarrZCZnZtnZHiIe3/9uo6HesbDMmZmbdarCpk8h7uZWZv1qkImz+FuZtZmvaqQyXO4m5m10f6pCm//5NQ57d2okMlrKNwljUp6VNJ3JB2W9D5Jl0l6UtKr6XVV2laS7pc0Lel5Sdd3dhfMzPpDdiF1dm7+rPZVK4fZvW1j1y6mQuNn7vcBX4+IdwPXAoeBXcDBiNgAHEzvATYDG9LPTuCBtvbYzKxP1buQCrDywhVdDXZoINwlXQr8EvAQQET8NCJmgS3AvrTZPmBrWt4CPBxVzwCjkq5se8/NzPpMP1xIzTRy5r4emAH+TNKUpAclXQKsjohjaZs3gNVpeRw4kvv80dR2Fkk7JU1KmpyZmVn+HpiZ9Yl+uJCaaSTcVwDXAw9ExCbgbc4MwQAQEQFEM18cEXsjYiIiJsbGxpr5qJlZX+rVVAP1NBLuR4GjEfFsev8o1bB/MxtuSa/H0/oKsDb3+TWpzcys1LZuGmf3to2Mj44gYHx0pOsXUjNLTj8QEW9IOiLpmoh4BbgZeDn9bAf2pNfH00cOAL8l6cvALwAncsM3ZmaltnXTeE/CvFajc8v8NvBFSRcCrwEfp3rW/4ikHcDrwO1p2yeA24Bp4GTa1szMuqihcI+IbwMTdVbdXGfbAO5qsV9mZtYCzwppZtai/PS+3ZrSdykOdzOzFtRO71uZneOex14A6GnAe24ZM7MW9MP0vvU43M3MWtBPd6XmOdzNzFrQT3el5jnczcxa0E93peb5gqqZ2TL0+gHYS3G4m5k1qR8egL0UD8uYmTWpXytk8hzuZmZN6tcKmTyHu5lZk/q1QibP4W5m1qR+rZDJ8wVVM7MmZFUyc/MLDEksRDDeJxUyeQ53M7MG1VbJLEScPmPvp2AHD8uYmTWsCFUyGYe7mVmDilAlk3G4m5k1qAhVMhmHu5lZg4pQJZPxBVUzswZlF0377alL9TQU7pK+B/wYWABORcSEpMuArwDrgO8Bt0fEW5IE3Ef1IdkngY9FxHPt77qZWfdt3TTel2Feq5lhmX8XEddFRPag7F3AwYjYABxM7wE2AxvSz07ggXZ11sysF/ZPVbhxz1Os3/VX3LjnKfZPVXrdpSW1Mua+BdiXlvcBW3PtD0fVM8CopCtb+B4zs57Jatsrs3MEZ56R2u8B32i4B/DXkg5J2pnaVkfEsbT8BrA6LY8DR3KfPZraziJpp6RJSZMzMzPL6LqZWecVqbY9r9ELqr8YERVJ/xJ4UtJ38isjIiRFM18cEXuBvQATExNNfdbMrFuKVNue19CZe0RU0utx4KvAe4E3s+GW9Ho8bV4B1uY+via1mZkVTpFq2/OWDHdJl0j62WwZ+PfAi8ABYHvabDvweFo+ANypqhuAE7nhGzOzQilSbXteI8Myq4GvViscWQH8z4j4uqRvAY9I2gG8Dtyetn+CahnkNNVSyI+3vddmZl1QlBkg61ky3CPiNeDaOu0/AG6u0x7AXW3pnZlZjxRpBsh6PP2AmVkdRa2SyTjczczqKGqVTMbhbmZWR1GrZDIOdzOzOopaJZPxrJBmZnUUaQbIehzuZmY5WfljEQM9z+FuZpbUlj9mk4QBhQt4j7mbmSVFL3/Mc7ibmSVFL3/Mc7ibmSVFL3/Mc7ibmSVFL3/M8wVVM7Ok6OWPeQ53M7OcojwAeykeljEzKyGfuZuZUZ6blzIOdzMbeGW6eSnjYRkzG3hlunkp4zN3MxtY2VBMpUQ3L2Uc7mY2kGqHYuop4s1LGQ/LmNlAqjcUk1fUm5cyDYe7pCFJU5K+lt6vl/SspGlJX5F0YWq/KL2fTuvXdabrZmbLd74hl/HREXZv21jYi6nQ3Jn7J4DDufefBe6NiHcBbwE7UvsO4K3Ufm/azsysryw25DI+OsLf7rqp0MEODYa7pDXArwAPpvcCbgIeTZvsA7am5S3pPWn9zWl7M7O+sH+qwts/OXVOe9GHYvIaPXP/Y+D3gHfS+8uB2YjI/nSOAtn/5saBIwBp/Ym0/Vkk7ZQ0KWlyZmZmmd03M2tOdiF1dm7+rPZVK4cLPxSTt2S4S/ogcDwiDrXziyNib0RMRMTE2NhYO3+1mdmiFruQuvLCFaUJdmisFPJG4EOSbgMuBv4FcB8wKmlFOjtfA1TS9hVgLXBU0grgUuAHbe+5mdkylOmBHOez5Jl7RNwTEWsiYh1wB/BURHwUeBr4cNpsO/B4Wj6Q3pPWPxUR0dZem5ktU5keyHE+rdS5fxr4XUnTVMfUH0rtDwGXp/bfBXa11kUzs/Yp0wM5zqepO1Qj4pvAN9Pya8B762zzz8CvtaFvZmZtk5/18dKRYS4evoDZk/OlmAGyHk8/YGalVzvVwOzcPCPDQ9z769eVLtQznn7AzEqvjLM+LsXhbmalNygVMnkOdzMrvUGpkMlzuJtZ6Q1KhUyeL6iaWallVTJz8wsMSSxEMF7SCpk8h7uZlVZtlcxCxOkz9jIHO3hYxsxKbBCrZDIOdzMrrUGsksk43M2stAaxSibjcDez0hrEKpmML6iaWekM2jwy9TjczaxUBnEemXo8LGNmpTLIFTJ5DnczK5VBrpDJc7ibWWnsn6pwgVR33SBUyOQ53M2sFLKx9oU6T/UclAqZPIe7mZVCvbF2gCGJ3ds2DtTFVHC4m1lJLDam/k7EwAU7NBDuki6W9HeS/l7SS5L+ILWvl/SspGlJX5F0YWq/KL2fTuvXdXYXzMwG+27Ueho5c/8JcFNEXAtcB9wq6Qbgs8C9EfEu4C1gR9p+B/BWar83bWdm1lGDfDdqPUuGe1T9v/R2OP0EcBPwaGrfB2xNy1vSe9L6m6VFLl+bmbXJ1k3j7N62kfHREQSMj44M5Fh7pqE7VCUNAYeAdwF/AnwXmI2IU2mTo0D2JzgOHAGIiFOSTgCXA9+v+Z07gZ0AV199dWt7YWYDKz/VwCBNL7CUhi6oRsRCRFwHrAHeC7y71S+OiL0RMRERE2NjY63+OjMbQFn5Y2V2jgAqs3Pc89gL7J+q9LprPddUtUxEzAJPA+8DRiVlZ/5rgOxPswKsBUjrLwV+0JbempnleKqBxTVSLTMmaTQtjwAfAA5TDfkPp822A4+n5QPpPWn9UxF17iowM2uRpxpYXCNj7lcC+9K4+wXAIxHxNUkvA1+W9F+BKeChtP1DwJ9LmgZ+CNzRgX6bmXHV6AiVOkE+qOWPeUuGe0Q8D2yq0/4a1fH32vZ/Bn6tLb0zMzuPu2+55qzpfWGwyx/zPJ+7mRWOH8axNIe7mRWKH8bRGM8tY2aF4gqZxjjczaxQXCHTGIe7mRWKJwhrjMPdzArFE4Q1xhdUzawwsiqZufkFhiQWIhh3hUxdDnczK4TaKpmFiNNn7A72c3lYxswKwVUyzXG4m1khuEqmOQ53MysEV8k0x+FuZoXgKpnm+IKqmRVCdtHUT11qjMPdzApj66Zxh3mDHO5m1tf8jNTlcbibWd+qrW3PnpEKOOCX4AuqZta3XNu+fA53M+tbrm1fPoe7mfUt17Yvn8PdzPqWa9uXb8lwl7RW0tOSXpb0kqRPpPbLJD0p6dX0uiq1S9L9kqYlPS/p+k7vhJmV09ZN4+zetpHx0REEjI+OsHvbRl9MbUAj1TKngE9FxHOSfhY4JOlJ4GPAwYjYI2kXsAv4NLAZ2JB+fgF4IL2amTWstgTSz0htzpJn7hFxLCKeS8s/Bg4D48AWYF/abB+wNS1vAR6OqmeAUUlXtr3nZlZaWQlkZXaO4EwJ5P6pSq+7VhhNjblLWgdsAp4FVkfEsbTqDWB1Wh4HjuQ+djS11f6unZImJU3OzMw02W0zKzOXQLau4XCX9DPAXwKfjIgf5ddFRADRzBdHxN6ImIiIibGxsWY+amYl5xLI1jUU7pKGqQb7FyPisdT8Zjbckl6Pp/YKsDb38TWpzcysIS6BbF0j1TICHgIOR8Qf5VYdALan5e3A47n2O1PVzA3AidzwjZnZklwC2bpGqmVuBP4j8IKkb6e2/wzsAR6RtAN4Hbg9rXsCuA2YBk4CH29rj82stPIVMpeODHPx8AXMnpz3hGHLsGS4R8T/AbTI6pvrbB/AXS32y8wGTO0kYbNz84wMD7kEcpl8h6qZ9QVXyLSXw93M+oIrZNrL4W5mfcEVMu3lcDezvuAKmfbyk5jMrC/4Adjt5XA3s57zJGHt53A3s57IAr0yO4c4M3+Jn5PaHh5zN7Ouy8/6COdOTOUSyNY53M2s6+rVtNdyCWRrHO5m1nWNBLdLIFvjcDezrto/VeECLTajSZVLIFvnC6pm1jXZWPtCnPv4h+yi6rhLINvC4W5mXbPYWPuQxB/efq0DvY08LGNmXbPYWPs7EQ72NnO4m1nXeP6Y7vGwjJl13GI3LIEvnnaKw93MOqr2IRyBL552g8PdzDqq3kXULNj/dtdNvenUAPCYu5l1lB/C0RtLhrukz0s6LunFXNtlkp6U9Gp6XZXaJel+SdOSnpd0fSc7b2b9zxdRe6ORM/cvALfWtO0CDkbEBuBgeg+wGdiQfnYCD7Snm2ZWVH4IR28sGe4R8TfAD2uatwD70vI+YGuu/eGoegYYlXRluzprZsWzddM4u7dtZHx0BFEda9+9baMvonbYci+oro6IY2n5DWB1Wh4HjuS2O5rajlFD0k6qZ/dcffXVy+yGmfUzP4Sjd1q+oBoRwbnTMTfyub0RMRERE2NjY612w8z6TH7O9uDMQzj2T1V63bWBsNxwfzMbbkmvx1N7BVib225NajOzAVOvBNIP4eie5Yb7AWB7Wt4OPJ5rvzNVzdwAnMgN35jZANg/VeHGPU+dfspSLZdAdseSY+6SvgS8H7hC0lHg94E9wCOSdgCvA7enzZ8AbgOmgZPAxzvQZzPrU7V3o9bjEsjuWDLcI+Iji6y6uc62AdzVaqfMrJiWenyeSyC7x9MPmFnbnG/IxfPIdJfD3czaInt8Xr2nLHkeme7z3DJm1rLzPT7PQzG94XA3s5ad7/F5vhu1NxzuZtYyPz6v/zjczaxlnvmx/zjczaxlnvmx/7haxsxalg295CcJc9ljbznczWzZamd9dKD3D4e7mTUlC/TK7NzpB13DmVkfAQd8H/CYu5k1LD+NL5w717dnfewfDncza9hSc8eAZ33sFw53M2tYI8Ht8sf+4DF3M1tU/oLppSPDSFBnhoHTXP7YPxzuZlZX7dzss3PzdbfLLqp61sf+4nA3s3Psn6rwqUf+vu5EYHlDEn94+7UO9D7kMXczO8v5Znis5blj+pfP3M0MOLt+vVG+eNq/HO5mA27/VIX/cuClRcfUF+OLp/3N4W42gBa7y/R8BIyuHGb25LynGiiAjoS7pFuB+4Ah4MGI2NPu76hXovXWyXmG0mO+Rs/TNntyvunPdKOtH/rlPvR3v9rRh5+eWuDk/Dun/1tqJNhHhof80I2CUTRw0aSpXygNAf8AfAA4CnwL+EhEvLzYZyYmJmJycrLh76gt0TKzznGJY/+SdCgiJuqt68SZ+3uB6Yh4LX35l4EtwKLh3qxGboE2s9b4bL3YOlEKOQ4cyb0/mtrOImmnpElJkzMzM019geeuMOusVSuHHewF17MLqhGxF9gL1WGZZj571ehIU+VaZnZ+vsu0fDoR7hVgbe79mtTWNnffco3H3M3aZNXKYX7/V3/OgV4ynQj3bwEbJK2nGup3AP+hnV9Q+0gvV8u4D4PSr3b1weWM5df2cI+IU5J+C/gG1VLIz0fES+3+nq2bxv2X0sxsER0Zc4+IJ4AnOvG7zcxsaZ44zMyshBzuZmYl5HA3Myshh7uZWQm1fW6ZZXVCmgFeX+bHrwC+38bu9JL3pf+UZT/A+9KvWtmXfxURY/VW9EW4t0LS5GIT5xSN96X/lGU/wPvSrzq1Lx6WMTMrIYe7mVkJlSHc9/a6A23kfek/ZdkP8L70q47sS+HH3M3M7FxlOHM3M7MaDnczsxIqdLhLulXSK5KmJe3qdX8aJWmtpKclvSzpJUmfSO2XSXpS0qvpdVWv+9ooSUOSpiR9Lb1fL+nZdGy+IunCXvexEZJGJT0q6TuSDkt6X1GPi6T/lP5+vSjpS5IuLspxkfR5ScclvZhrq3scVHV/2qfnJV3fu56fbZH9+Fz6+/W8pK9KGs2tuyftxyuSbmnluwsb7ulB3H8CbAbeA3xE0nt626uGnQI+FRHvAW4A7kp93wUcjIgNwMH0vig+ARzOvf8scG9EvAt4C9jRk1417z7g6xHxbuBaqvtUuOMiaRz4HWAiIn6e6vTbd1Cc4/IF4NaatsWOw2ZgQ/rZCTzQpT424gucux9PAj8fEf8G+AfgHoCUAXcAP5c+899Tzi1LYcOd3IO4I+KnQPYg7r4XEcci4rm0/GOqATJOtf/70mb7gK296WFzJK0BfgV4ML0XcBPwaNqkEPsi6VLgl4CHACLipxExS0GPC9UpvUckrQBWAscoyHGJiL8BfljTvNhx2AI8HFXPAKOSruxOT8+v3n5ExF9HxKn09hmqT6uD6n58OSJ+EhH/CExTzbllKXK4N/Qg7n4naR2wCXgWWB0Rx9KqN4DVPepWs/4Y+D3gnfT+cmA29xe4KMdmPTAD/FkaYnpQ0iUU8LhERAX4b8D/pRrqJ4BDFPO4ZBY7DkXOgt8A/ldabut+FDncC0/SzwB/CXwyIn6UXxfVGtW+r1OV9EHgeEQc6nVf2mAFcD3wQERsAt6mZgimQMdlFdUzwfXAVcAlnDs8UFhFOQ7nI+kzVIdov9iJ31/kcO/4g7g7SdIw1WD/YkQ8lprfzP45mV6P96p/TbgR+JCk71EdGruJ6rj1aBoOgOIcm6PA0Yh4Nr1/lGrYF/G4/DLwjxExExHzwGNUj1URj0tmseNQuCyQ9DHgg8BH48zNRm3djyKH++kHcacr/ncAB3rcp4akMemHgMMR8Ue5VQeA7Wl5O/B4t/vWrIi4JyLWRMQ6qsfgqYj4KPA08OG0WVH25Q3giKRrUtPNwMsU8LhQHY65QdLK9Pct25fCHZecxY7DAeDOVDVzA3AiN3zTdyTdSnUY80MRcTK36gBwh6SLJK2neoH475b9RRFR2B/gNqpXm78LfKbX/Wmi379I9Z+UzwPfTj+3UR2rPgi8Cvxv4LJe97XJ/Xo/8LW0/K/TX8xp4C+Ai3rdvwb34TpgMh2b/cCqoh4X4A+A7wAvAn8OXFSU4wJ8ieq1gnmq/6LasdhxAES1cu67wAtUK4R6vg/n2Y9pqmPr2X/7/yO3/WfSfrwCbG7luz39gJlZCRV5WMbMzBbhcDczKyGHu5lZCTnczcxKyOFuZlZCDnczsxJyuJuZldD/B0Ol+Vl81ZADAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['Date'], data['Death'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "X1 = np.arange(-5, 5, 0.25)\n",
    "Y1 = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X1, Y1)\n",
    "X,Y\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "Z1=1/(1+np.exp(0.2*X+2*Y)) # two inputs, one output neuron (soft threshold)\n",
    "Z2=1/(1+np.exp(-0.2*X-2*Y+1)) # oposing face soft threshold\n",
    "surf = ax.plot_surface(X, Y, Z1, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "ax.set_title('Perceptron - soft threshold separation')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z2, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "ax.set_title(' opossite facing soft threshold separation')\n",
    "#surf = ax.plot_surface(X, Y, 1/(1+np.exp(Z1+Z2)), cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "pandas 1.0.3\n",
      "numpy 1.18.2\n",
      "sklearn 0.0\n",
      "matplotlib 3.2.1\n",
      "watermark 2.0.2\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.3.0-59-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      " \n",
      "last updated: Thu Jun 18 2020 21:26:03 EEST\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# versiuni de pachete folosite\n",
    "%watermark -v -m -p pandas,numpy,sklearn,matplotlib,watermark\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
