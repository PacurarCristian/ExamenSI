{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.  Country        Date  Confirmed  Death  newConfirmed  newDeath\n",
       "0    1  Romania  2019-12-31          0      0             0         0\n",
       "1    2  Romania  2020-01-01          0      0             0         0\n",
       "2    3  Romania  2020-01-02          0      0             0         0\n",
       "3    4  Romania  2020-01-03          0      0             0         0\n",
       "4    5  Romania  2020-01-04          0      0             0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#importam datasetul nostru\n",
    "input_file = \"Dataset.csv\"\n",
    "\n",
    "#citim din csv si punem in data\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>10635</td>\n",
       "      <td>601</td>\n",
       "      <td>218</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>11036</td>\n",
       "      <td>619</td>\n",
       "      <td>401</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>11339</td>\n",
       "      <td>641</td>\n",
       "      <td>303</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11616</td>\n",
       "      <td>663</td>\n",
       "      <td>277</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Romania</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>11978</td>\n",
       "      <td>693</td>\n",
       "      <td>362</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country        Date  Confirmed  Death  newConfirmed  newDeath\n",
       "0    Romania  2019-12-31          0      0             0         0\n",
       "1    Romania  2020-01-01          0      0             0         0\n",
       "2    Romania  2020-01-02          0      0             0         0\n",
       "3    Romania  2020-01-03          0      0             0         0\n",
       "4    Romania  2020-01-04          0      0             0         0\n",
       "..       ...         ...        ...    ...           ...       ...\n",
       "116  Romania  2020-04-25      10635    601           218        34\n",
       "117  Romania  2020-04-26      11036    619           401        18\n",
       "118  Romania  2020-04-27      11339    641           303        22\n",
       "119  Romania  2020-04-28      11616    663           277        22\n",
       "120  Romania  2020-04-29      11978    693           362        30\n",
       "\n",
       "[121 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stergem coloana cu numarul deoarece nu avem nevoie de ele in prelucrarea datelor\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#folosim un label encoder pentru coloanele country si date pentru a le putea transforma in valori numerice\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(data['Date'])\n",
    "data.loc[:, 'Date'] = le.transform(data['Date'])\n",
    "\n",
    "le.fit(data['Country'])\n",
    "data.loc[:, 'Country'] = le.transform(data['Country'])\n",
    "\n",
    "#punem in y doar Country si Date\n",
    "y = data.drop(data.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "y = y.drop(y.columns[2], axis=1)\n",
    "\n",
    "#In X_final punem restul coloanelor\n",
    "X_final = data.drop(data.columns[1], axis=1)\n",
    "X_final = X_final.drop(X_final.columns[0], axis=1)\n",
    "\n",
    "y_train, y_test, X_train, X_test = train_test_split(X_final, y, test_size=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Date\n",
       "106        0   106\n",
       "40         0    40\n",
       "89         0    89\n",
       "91         0    91\n",
       "115        0   115\n",
       "..       ...   ...\n",
       "74         0    74\n",
       "54         0    54\n",
       "33         0    33\n",
       "66         0    66\n",
       "75         0    75\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train contine datele de train pentru input\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7216</td>\n",
       "      <td>372</td>\n",
       "      <td>337</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1815</td>\n",
       "      <td>43</td>\n",
       "      <td>363</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2245</td>\n",
       "      <td>82</td>\n",
       "      <td>136</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10417</td>\n",
       "      <td>567</td>\n",
       "      <td>321</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Confirmed  Death  newConfirmed  newDeath\n",
       "106       7216    372           337        21\n",
       "40           0      0             0         0\n",
       "89        1815     43           363         6\n",
       "91        2245     82           136        17\n",
       "115      10417    567           321        22\n",
       "..         ...    ...           ...       ...\n",
       "74         123      0            34         0\n",
       "54           0      0             0         0\n",
       "33           0      0             0         0\n",
       "66           9      0             3         0\n",
       "75         131      0             8         0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train contine datele de train pentru rezultatul inputului\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Date\n",
       "43         0    43\n",
       "114        0   114\n",
       "69         0    69\n",
       "1          0     1\n",
       "24         0    24\n",
       "5          0     5\n",
       "90         0    90\n",
       "73         0    73\n",
       "48         0    48\n",
       "99         0    99\n",
       "111        0   111\n",
       "34         0    34\n",
       "98         0    98\n",
       "80         0    80\n",
       "96         0    96\n",
       "56         0    56\n",
       "103        0   103\n",
       "105        0   105\n",
       "83         0    83\n",
       "21         0    21\n",
       "28         0    28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test contine datele de input pentru test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>newConfirmed</th>\n",
       "      <th>newDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10096</td>\n",
       "      <td>545</td>\n",
       "      <td>386</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2109</td>\n",
       "      <td>65</td>\n",
       "      <td>294</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4761</td>\n",
       "      <td>220</td>\n",
       "      <td>344</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8936</td>\n",
       "      <td>478</td>\n",
       "      <td>190</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4417</td>\n",
       "      <td>197</td>\n",
       "      <td>360</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3864</td>\n",
       "      <td>151</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6300</td>\n",
       "      <td>316</td>\n",
       "      <td>310</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6879</td>\n",
       "      <td>351</td>\n",
       "      <td>246</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>576</td>\n",
       "      <td>7</td>\n",
       "      <td>143</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Confirmed  Death  newConfirmed  newDeath\n",
       "43           0      0             0         0\n",
       "114      10096    545           386        21\n",
       "69          15      0             0         0\n",
       "1            0      0             0         0\n",
       "24           0      0             0         0\n",
       "5            0      0             0         0\n",
       "90        2109     65           294        22\n",
       "73          89      0            40         0\n",
       "48           0      0             0         0\n",
       "99        4761    220           344        23\n",
       "111       8936    478           190        27\n",
       "34           0      0             0         0\n",
       "98        4417    197           360        21\n",
       "80         308      0            31         0\n",
       "96        3864    151           251         5\n",
       "56           0      0             0         0\n",
       "103       6300    316           310        25\n",
       "105       6879    351           246        20\n",
       "83         576      7           143         4\n",
       "21           0      0             0         0\n",
       "28           0      0             0         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test contine datele rezultate in urma inputului de test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1830936.68331180\n",
      "Iteration 2, loss = 1828448.38639063\n",
      "Iteration 3, loss = 1826004.90702470\n",
      "Iteration 4, loss = 1823608.24872706\n",
      "Iteration 5, loss = 1821248.23365866\n",
      "Iteration 6, loss = 1818922.92608939\n",
      "Iteration 7, loss = 1816512.78863579\n",
      "Iteration 8, loss = 1814184.85218181\n",
      "Iteration 9, loss = 1811931.23585688\n",
      "Iteration 10, loss = 1809726.55909973\n",
      "Iteration 11, loss = 1807623.77860923\n",
      "Iteration 12, loss = 1805578.43456729\n",
      "Iteration 13, loss = 1803545.13207835\n",
      "Iteration 14, loss = 1801503.58069065\n",
      "Iteration 15, loss = 1799352.95408390\n",
      "Iteration 16, loss = 1797168.52916932\n",
      "Iteration 17, loss = 1794917.81617692\n",
      "Iteration 18, loss = 1792630.88408161\n",
      "Iteration 19, loss = 1790274.48721072\n",
      "Iteration 20, loss = 1787843.22107124\n",
      "Iteration 21, loss = 1785334.27299182\n",
      "Iteration 22, loss = 1782744.74632543\n",
      "Iteration 23, loss = 1780071.67574791\n",
      "Iteration 24, loss = 1777312.05516904\n",
      "Iteration 25, loss = 1774462.84328087\n",
      "Iteration 26, loss = 1771520.97618172\n",
      "Iteration 27, loss = 1768483.37141484\n",
      "Iteration 28, loss = 1765346.96576931\n",
      "Iteration 29, loss = 1762108.64557987\n",
      "Iteration 30, loss = 1758765.38985250\n",
      "Iteration 31, loss = 1755314.14037611\n",
      "Iteration 32, loss = 1751751.89360362\n",
      "Iteration 33, loss = 1748075.68439283\n",
      "Iteration 34, loss = 1744285.01618633\n",
      "Iteration 35, loss = 1740370.30550058\n",
      "Iteration 36, loss = 1736335.41717718\n",
      "Iteration 37, loss = 1732175.16307295\n",
      "Iteration 38, loss = 1727886.82424212\n",
      "Iteration 39, loss = 1723467.71756749\n",
      "Iteration 40, loss = 1718957.02361707\n",
      "Iteration 41, loss = 1714227.35019401\n",
      "Iteration 42, loss = 1709405.62948176\n",
      "Iteration 43, loss = 1704436.06162616\n",
      "Iteration 44, loss = 1699324.91777413\n",
      "Iteration 45, loss = 1694027.76100594\n",
      "Iteration 46, loss = 1688566.72814215\n",
      "Iteration 47, loss = 1682944.70239120\n",
      "Iteration 48, loss = 1677162.07568069\n",
      "Iteration 49, loss = 1671222.29653117\n",
      "Iteration 50, loss = 1665114.41137749\n",
      "Iteration 51, loss = 1658853.54887340\n",
      "Iteration 52, loss = 1652426.35895096\n",
      "Iteration 53, loss = 1645830.76357423\n",
      "Iteration 54, loss = 1639077.65745198\n",
      "Iteration 55, loss = 1632161.47934262\n",
      "Iteration 56, loss = 1625082.24506104\n",
      "Iteration 57, loss = 1617840.95444100\n",
      "Iteration 58, loss = 1610436.61902341\n",
      "Iteration 59, loss = 1602875.78566191\n",
      "Iteration 60, loss = 1595146.00112886\n",
      "Iteration 61, loss = 1587260.70960178\n",
      "Iteration 62, loss = 1579216.71610254\n",
      "Iteration 63, loss = 1571015.22061536\n",
      "Iteration 64, loss = 1562665.97447678\n",
      "Iteration 65, loss = 1554148.10372510\n",
      "Iteration 66, loss = 1545487.50448298\n",
      "Iteration 67, loss = 1536675.48360063\n",
      "Iteration 68, loss = 1527716.41963641\n",
      "Iteration 69, loss = 1518610.80834873\n",
      "Iteration 70, loss = 1509361.25965179\n",
      "Iteration 71, loss = 1499970.42091893\n",
      "Iteration 72, loss = 1490439.97275087\n",
      "Iteration 73, loss = 1480770.68539350\n",
      "Iteration 74, loss = 1470964.37459488\n",
      "Iteration 75, loss = 1461022.56892361\n",
      "Iteration 76, loss = 1450953.77649310\n",
      "Iteration 77, loss = 1440762.27554792\n",
      "Iteration 78, loss = 1430417.26426660\n",
      "Iteration 79, loss = 1419941.81099317\n",
      "Iteration 80, loss = 1409354.80552435\n",
      "Iteration 81, loss = 1398642.98314687\n",
      "Iteration 82, loss = 1387818.01951656\n",
      "Iteration 83, loss = 1376887.33001566\n",
      "Iteration 84, loss = 1365823.32115080\n",
      "Iteration 85, loss = 1354682.07654820\n",
      "Iteration 86, loss = 1343413.55773770\n",
      "Iteration 87, loss = 1332065.87615697\n",
      "Iteration 88, loss = 1320649.78409941\n",
      "Iteration 89, loss = 1309128.60613975\n",
      "Iteration 90, loss = 1297552.55824519\n",
      "Iteration 91, loss = 1285927.30446701\n",
      "Iteration 92, loss = 1274227.52022327\n",
      "Iteration 93, loss = 1262499.89918607\n",
      "Iteration 94, loss = 1250744.56592900\n",
      "Iteration 95, loss = 1238973.01826638\n",
      "Iteration 96, loss = 1227177.29610948\n",
      "Iteration 97, loss = 1215392.61808322\n",
      "Iteration 98, loss = 1203615.44343194\n",
      "Iteration 99, loss = 1191873.07617920\n",
      "Iteration 100, loss = 1180150.90376629\n",
      "Iteration 101, loss = 1168495.43349293\n",
      "Iteration 102, loss = 1156885.29493496\n",
      "Iteration 103, loss = 1145344.51280055\n",
      "Iteration 104, loss = 1133905.81208350\n",
      "Iteration 105, loss = 1122553.12498548\n",
      "Iteration 106, loss = 1111329.41287124\n",
      "Iteration 107, loss = 1100169.35496228\n",
      "Iteration 108, loss = 1089144.32637159\n",
      "Iteration 109, loss = 1078267.93444973\n",
      "Iteration 110, loss = 1067528.59279552\n",
      "Iteration 111, loss = 1056924.39374274\n",
      "Iteration 112, loss = 1046536.67063650\n",
      "Iteration 113, loss = 1036251.32762653\n",
      "Iteration 114, loss = 1026215.13642697\n",
      "Iteration 115, loss = 1016357.05829643\n",
      "Iteration 116, loss = 1006720.01487427\n",
      "Iteration 117, loss = 997310.90519709\n",
      "Iteration 118, loss = 988134.57194121\n",
      "Iteration 119, loss = 979207.31315037\n",
      "Iteration 120, loss = 970498.46279987\n",
      "Iteration 121, loss = 962075.46423233\n",
      "Iteration 122, loss = 953976.47535543\n",
      "Iteration 123, loss = 946086.39508940\n",
      "Iteration 124, loss = 938482.27275794\n",
      "Iteration 125, loss = 931183.01505719\n",
      "Iteration 126, loss = 924184.29213887\n",
      "Iteration 127, loss = 917485.51430368\n",
      "Iteration 128, loss = 911040.61472358\n",
      "Iteration 129, loss = 904836.61153819\n",
      "Iteration 130, loss = 899024.37901896\n",
      "Iteration 131, loss = 893444.48976356\n",
      "Iteration 132, loss = 888212.98246923\n",
      "Iteration 133, loss = 883193.98387945\n",
      "Iteration 134, loss = 878611.16992084\n",
      "Iteration 135, loss = 874273.41761250\n",
      "Iteration 136, loss = 870221.85935789\n",
      "Iteration 137, loss = 866391.20078040\n",
      "Iteration 138, loss = 862918.23474268\n",
      "Iteration 139, loss = 859667.89791175\n",
      "Iteration 140, loss = 856665.66206508\n",
      "Iteration 141, loss = 853916.61951524\n",
      "Iteration 142, loss = 851341.78734623\n",
      "Iteration 143, loss = 849005.47307578\n",
      "Iteration 144, loss = 846853.41474287\n",
      "Iteration 145, loss = 844954.07277966\n",
      "Iteration 146, loss = 843237.39303040\n",
      "Iteration 147, loss = 841699.25436896\n",
      "Iteration 148, loss = 840372.17809658\n",
      "Iteration 149, loss = 839158.38305203\n",
      "Iteration 150, loss = 838061.67532288\n",
      "Iteration 151, loss = 837138.74545092\n",
      "Iteration 152, loss = 836310.49569773\n",
      "Iteration 153, loss = 835579.78544075\n",
      "Iteration 154, loss = 834950.97173505\n",
      "Iteration 155, loss = 834349.77247599\n",
      "Iteration 156, loss = 833853.67040902\n",
      "Iteration 157, loss = 833448.63890600\n",
      "Iteration 158, loss = 833136.74397183\n",
      "Iteration 159, loss = 832801.50616486\n",
      "Iteration 160, loss = 832503.07832863\n",
      "Iteration 161, loss = 832172.47401052\n",
      "Iteration 162, loss = 831863.47638246\n",
      "Iteration 163, loss = 831625.19700952\n",
      "Iteration 164, loss = 831429.49688487\n",
      "Iteration 165, loss = 831260.79670428\n",
      "Iteration 166, loss = 831100.58300677\n",
      "Iteration 167, loss = 830943.80947486\n",
      "Iteration 168, loss = 830785.81340491\n",
      "Iteration 169, loss = 830626.62497720\n",
      "Iteration 170, loss = 830465.66883684\n",
      "Iteration 171, loss = 830300.98675747\n",
      "Iteration 172, loss = 830128.72878644\n",
      "Iteration 173, loss = 829928.17903310\n",
      "Iteration 174, loss = 829753.58217247\n",
      "Iteration 175, loss = 829575.08967171\n",
      "Iteration 176, loss = 829391.83156746\n",
      "Iteration 177, loss = 829194.20657141\n",
      "Iteration 178, loss = 828999.90437901\n",
      "Iteration 179, loss = 828804.03884922\n",
      "Iteration 180, loss = 828592.15974607\n",
      "Iteration 181, loss = 828327.03564669\n",
      "Iteration 182, loss = 828107.04606639\n",
      "Iteration 183, loss = 827820.07314420\n",
      "Iteration 184, loss = 827412.00499028\n",
      "Iteration 185, loss = 827141.83986511\n",
      "Iteration 186, loss = 826953.03779770\n",
      "Iteration 187, loss = 826764.10743936\n",
      "Iteration 188, loss = 826572.65715790\n",
      "Iteration 189, loss = 826375.64278859\n",
      "Iteration 190, loss = 826167.88152121\n",
      "Iteration 191, loss = 825936.86382528\n",
      "Iteration 192, loss = 825649.12213902\n",
      "Iteration 193, loss = 825419.57890131\n",
      "Iteration 194, loss = 825212.60719824\n",
      "Iteration 195, loss = 824998.95018166\n",
      "Iteration 196, loss = 824778.69303073\n",
      "Iteration 197, loss = 824551.74029793\n",
      "Iteration 198, loss = 824315.83252263\n",
      "Iteration 199, loss = 824063.43356762\n",
      "Iteration 200, loss = 823820.71124344\n",
      "Iteration 201, loss = 823592.91875007\n",
      "Iteration 202, loss = 823364.91342689\n",
      "Iteration 203, loss = 823137.21441386\n",
      "Iteration 204, loss = 822913.49912776\n",
      "Iteration 205, loss = 822683.00949552\n",
      "Iteration 206, loss = 822443.57515371\n",
      "Iteration 207, loss = 822213.27517455\n",
      "Iteration 208, loss = 821978.18715989\n",
      "Iteration 209, loss = 821732.59146914\n",
      "Iteration 210, loss = 821461.95328015\n",
      "Iteration 211, loss = 821217.16572815\n",
      "Iteration 212, loss = 820983.56142456\n",
      "Iteration 213, loss = 820748.69947620\n",
      "Iteration 214, loss = 820512.36380937\n",
      "Iteration 215, loss = 820274.70394735\n",
      "Iteration 216, loss = 820035.75257979\n",
      "Iteration 217, loss = 819795.43263929\n",
      "Iteration 218, loss = 819553.82436096\n",
      "Iteration 219, loss = 819310.93203885\n",
      "Iteration 220, loss = 819066.71591088\n",
      "Iteration 221, loss = 818821.11101200\n",
      "Iteration 222, loss = 818574.04349541\n",
      "Iteration 223, loss = 818325.82948300\n",
      "Iteration 224, loss = 818075.65879588\n",
      "Iteration 225, loss = 817823.92259550\n",
      "Iteration 226, loss = 817570.28846318\n",
      "Iteration 227, loss = 817314.48481954\n",
      "Iteration 228, loss = 817056.21780536\n",
      "Iteration 229, loss = 816795.26942562\n",
      "Iteration 230, loss = 816530.57700968\n",
      "Iteration 231, loss = 816260.63551091\n",
      "Iteration 232, loss = 815982.11493954\n",
      "Iteration 233, loss = 815685.24972719\n",
      "Iteration 234, loss = 815346.45779103\n",
      "Iteration 235, loss = 814955.32079677\n",
      "Iteration 236, loss = 814689.09448799\n",
      "Iteration 237, loss = 814420.42441317\n",
      "Iteration 238, loss = 814149.15817658\n",
      "Iteration 239, loss = 813875.50916122\n",
      "Iteration 240, loss = 813599.93173005\n",
      "Iteration 241, loss = 813323.67197732\n",
      "Iteration 242, loss = 813044.94019318\n",
      "Iteration 243, loss = 812765.24411566\n",
      "Iteration 244, loss = 812484.56152662\n",
      "Iteration 245, loss = 812202.36093906\n",
      "Iteration 246, loss = 811917.85605966\n",
      "Iteration 247, loss = 811632.67281880\n",
      "Iteration 248, loss = 811346.72584000\n",
      "Iteration 249, loss = 811058.43026539\n",
      "Iteration 250, loss = 810769.10667843\n",
      "Iteration 251, loss = 810478.07748551\n",
      "Iteration 252, loss = 810185.32465650\n",
      "Iteration 253, loss = 809891.49085500\n",
      "Iteration 254, loss = 809594.87967785\n",
      "Iteration 255, loss = 809296.45291816\n",
      "Iteration 256, loss = 808994.78100970\n",
      "Iteration 257, loss = 808687.02283417\n",
      "Iteration 258, loss = 808355.48242496\n",
      "Iteration 259, loss = 808030.40723134\n",
      "Iteration 260, loss = 807723.52038493\n",
      "Iteration 261, loss = 807413.89122243\n",
      "Iteration 262, loss = 807098.37751710\n",
      "Iteration 263, loss = 806768.63636437\n",
      "Iteration 264, loss = 806380.59282392\n",
      "Iteration 265, loss = 806063.18483145\n",
      "Iteration 266, loss = 805743.86316396\n",
      "Iteration 267, loss = 805422.77562554\n",
      "Iteration 268, loss = 805100.10978924\n",
      "Iteration 269, loss = 804776.00953859\n",
      "Iteration 270, loss = 804451.79204064\n",
      "Iteration 271, loss = 804123.20019347\n",
      "Iteration 272, loss = 803793.52160671\n",
      "Iteration 273, loss = 803450.55123980\n",
      "Iteration 274, loss = 803106.64757165\n",
      "Iteration 275, loss = 802772.41090953\n",
      "Iteration 276, loss = 802436.53119920\n",
      "Iteration 277, loss = 802099.27948724\n",
      "Iteration 278, loss = 801759.95461919\n",
      "Iteration 279, loss = 801419.30316424\n",
      "Iteration 280, loss = 801077.09255995\n",
      "Iteration 281, loss = 800733.68565530\n",
      "Iteration 282, loss = 800388.11982545\n",
      "Iteration 283, loss = 800041.33280335\n",
      "Iteration 284, loss = 799693.00581900\n",
      "Iteration 285, loss = 799345.44978191\n",
      "Iteration 286, loss = 798992.51352780\n",
      "Iteration 287, loss = 798640.49222172\n",
      "Iteration 288, loss = 798286.71762264\n",
      "Iteration 289, loss = 797931.03943074\n",
      "Iteration 290, loss = 797573.64661649\n",
      "Iteration 291, loss = 797214.87618307\n",
      "Iteration 292, loss = 796854.80762341\n",
      "Iteration 293, loss = 796493.60676454\n",
      "Iteration 294, loss = 796130.66247371\n",
      "Iteration 295, loss = 795767.38575237\n",
      "Iteration 296, loss = 795402.30763435\n",
      "Iteration 297, loss = 795035.61433616\n",
      "Iteration 298, loss = 794666.58538162\n",
      "Iteration 299, loss = 794295.52777701\n",
      "Iteration 300, loss = 793924.41279605\n",
      "Iteration 301, loss = 793550.94602386\n",
      "Iteration 302, loss = 793182.94009730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 303, loss = 792801.23026537\n",
      "Iteration 304, loss = 792423.27374633\n",
      "Iteration 305, loss = 792044.95649458\n",
      "Iteration 306, loss = 791664.74124046\n",
      "Iteration 307, loss = 791286.12621958\n",
      "Iteration 308, loss = 790900.23684911\n",
      "Iteration 309, loss = 790515.49139282\n",
      "Iteration 310, loss = 790125.09090807\n",
      "Iteration 311, loss = 789742.32182436\n",
      "Iteration 312, loss = 789346.98422995\n",
      "Iteration 313, loss = 788956.82712864\n",
      "Iteration 314, loss = 788563.16174946\n",
      "Iteration 315, loss = 788166.71257237\n",
      "Iteration 316, loss = 787770.98132364\n",
      "Iteration 317, loss = 787381.93987596\n",
      "Iteration 318, loss = 786968.48853590\n",
      "Iteration 319, loss = 786567.22440903\n",
      "Iteration 320, loss = 786163.92639747\n",
      "Iteration 321, loss = 785758.55567298\n",
      "Iteration 322, loss = 785350.73035226\n",
      "Iteration 323, loss = 784942.23176291\n",
      "Iteration 324, loss = 784532.04570472\n",
      "Iteration 325, loss = 784121.16009324\n",
      "Iteration 326, loss = 783709.08362368\n",
      "Iteration 327, loss = 783294.11645663\n",
      "Iteration 328, loss = 782878.02201986\n",
      "Iteration 329, loss = 782461.80726406\n",
      "Iteration 330, loss = 782044.96146287\n",
      "Iteration 331, loss = 781628.49679145\n",
      "Iteration 332, loss = 781210.46240247\n",
      "Iteration 333, loss = 780786.22829224\n",
      "Iteration 334, loss = 780359.59464786\n",
      "Iteration 335, loss = 779931.28861337\n",
      "Iteration 336, loss = 779504.68070752\n",
      "Iteration 337, loss = 779077.05758354\n",
      "Iteration 338, loss = 778646.04870590\n",
      "Iteration 339, loss = 778211.18187440\n",
      "Iteration 340, loss = 777777.10642421\n",
      "Iteration 341, loss = 777345.67179280\n",
      "Iteration 342, loss = 776911.33960983\n",
      "Iteration 343, loss = 776474.80004127\n",
      "Iteration 344, loss = 776032.85094692\n",
      "Iteration 345, loss = 775590.79819004\n",
      "Iteration 346, loss = 775149.08418634\n",
      "Iteration 347, loss = 774705.75989495\n",
      "Iteration 348, loss = 774260.67193791\n",
      "Iteration 349, loss = 773813.24479110\n",
      "Iteration 350, loss = 773364.76924457\n",
      "Iteration 351, loss = 772915.80158068\n",
      "Iteration 352, loss = 772465.49388850\n",
      "Iteration 353, loss = 772013.02014182\n",
      "Iteration 354, loss = 771558.77517139\n",
      "Iteration 355, loss = 771103.56433269\n",
      "Iteration 356, loss = 770647.40203496\n",
      "Iteration 357, loss = 770189.66045178\n",
      "Iteration 358, loss = 769730.02825952\n",
      "Iteration 359, loss = 769268.94054027\n",
      "Iteration 360, loss = 768806.82728038\n",
      "Iteration 361, loss = 768343.52446917\n",
      "Iteration 362, loss = 767882.16324796\n",
      "Iteration 363, loss = 767413.81092843\n",
      "Iteration 364, loss = 766954.50687465\n",
      "Iteration 365, loss = 766487.17354183\n",
      "Iteration 366, loss = 766019.26834485\n",
      "Iteration 367, loss = 765556.46538172\n",
      "Iteration 368, loss = 765075.13282910\n",
      "Iteration 369, loss = 764600.77029451\n",
      "Iteration 370, loss = 764123.81234757\n",
      "Iteration 371, loss = 763649.86503979\n",
      "Iteration 372, loss = 763170.18936183\n",
      "Iteration 373, loss = 762690.88631616\n",
      "Iteration 374, loss = 762210.68743221\n",
      "Iteration 375, loss = 761729.75011687\n",
      "Iteration 376, loss = 761247.39443838\n",
      "Iteration 377, loss = 760763.38205959\n",
      "Iteration 378, loss = 760277.81543739\n",
      "Iteration 379, loss = 759790.82553734\n",
      "Iteration 380, loss = 759302.38119956\n",
      "Iteration 381, loss = 758812.35117209\n",
      "Iteration 382, loss = 758321.04960848\n",
      "Iteration 383, loss = 757828.68064718\n",
      "Iteration 384, loss = 757335.08655899\n",
      "Iteration 385, loss = 756840.15330991\n",
      "Iteration 386, loss = 756343.66010460\n",
      "Iteration 387, loss = 755845.72543871\n",
      "Iteration 388, loss = 755346.43790856\n",
      "Iteration 389, loss = 754845.76003782\n",
      "Iteration 390, loss = 754343.65667206\n",
      "Iteration 391, loss = 753843.73427664\n",
      "Iteration 392, loss = 753337.58936305\n",
      "Iteration 393, loss = 752838.15711321\n",
      "Iteration 394, loss = 752334.26043920\n",
      "Iteration 395, loss = 751827.61819401\n",
      "Iteration 396, loss = 751314.78948553\n",
      "Iteration 397, loss = 750801.46010300\n",
      "Iteration 398, loss = 750291.64301760\n",
      "Iteration 399, loss = 749781.46777549\n",
      "Iteration 400, loss = 749266.18895587\n",
      "Iteration 401, loss = 748750.19296879\n",
      "Iteration 402, loss = 748235.24272364\n",
      "Iteration 403, loss = 747721.88742581\n",
      "Iteration 404, loss = 747201.29808132\n",
      "Iteration 405, loss = 746689.35550554\n",
      "Iteration 406, loss = 746161.29839307\n",
      "Iteration 407, loss = 745637.83184830\n",
      "Iteration 408, loss = 745109.79748325\n",
      "Iteration 409, loss = 744591.37202263\n",
      "Iteration 410, loss = 744058.13189665\n",
      "Iteration 411, loss = 743530.74919547\n",
      "Iteration 412, loss = 743002.04724122\n",
      "Iteration 413, loss = 742471.25176427\n",
      "Iteration 414, loss = 741938.90672293\n",
      "Iteration 415, loss = 741430.40350528\n",
      "Iteration 416, loss = 740877.92740659\n",
      "Iteration 417, loss = 740349.93034131\n",
      "Iteration 418, loss = 739809.96040913\n",
      "Iteration 419, loss = 739290.07763707\n",
      "Iteration 420, loss = 738738.75727935\n",
      "Iteration 421, loss = 738199.66101222\n",
      "Iteration 422, loss = 737653.81178666\n",
      "Iteration 423, loss = 737138.41693016\n",
      "Iteration 424, loss = 736572.40935289\n",
      "Iteration 425, loss = 736036.89414175\n",
      "Iteration 426, loss = 735495.28501878\n",
      "Iteration 427, loss = 734943.74969825\n",
      "Iteration 428, loss = 734391.52595020\n",
      "Iteration 429, loss = 733848.47791203\n",
      "Iteration 430, loss = 733310.61972147\n",
      "Iteration 431, loss = 732746.90078734\n",
      "Iteration 432, loss = 732204.20544878\n",
      "Iteration 433, loss = 731656.27273472\n",
      "Iteration 434, loss = 731101.83169968\n",
      "Iteration 435, loss = 730567.97421266\n",
      "Iteration 436, loss = 729998.32375321\n",
      "Iteration 437, loss = 729448.35628458\n",
      "Iteration 438, loss = 728905.97141729\n",
      "Iteration 439, loss = 728336.25108845\n",
      "Iteration 440, loss = 727780.37074120\n",
      "Iteration 441, loss = 727216.41897626\n",
      "Iteration 442, loss = 726656.83054334\n",
      "Iteration 443, loss = 726094.42378933\n",
      "Iteration 444, loss = 725534.52492128\n",
      "Iteration 445, loss = 724972.80134683\n",
      "Iteration 446, loss = 724409.88564544\n",
      "Iteration 447, loss = 723846.47992025\n",
      "Iteration 448, loss = 723282.17994486\n",
      "Iteration 449, loss = 722717.17689541\n",
      "Iteration 450, loss = 722150.78947234\n",
      "Iteration 451, loss = 721584.08366690\n",
      "Iteration 452, loss = 721018.02064776\n",
      "Iteration 453, loss = 720448.82352589\n",
      "Iteration 454, loss = 719876.46695520\n",
      "Iteration 455, loss = 719317.50003971\n",
      "Iteration 456, loss = 718736.41397982\n",
      "Iteration 457, loss = 718168.37655435\n",
      "Iteration 458, loss = 717596.48378231\n",
      "Iteration 459, loss = 717017.45928207\n",
      "Iteration 460, loss = 716442.30827314\n",
      "Iteration 461, loss = 715868.42937650\n",
      "Iteration 462, loss = 715291.99104105\n",
      "Iteration 463, loss = 714714.01297020\n",
      "Iteration 464, loss = 714136.90274220\n",
      "Iteration 465, loss = 713558.47580710\n",
      "Iteration 466, loss = 712977.97336416\n",
      "Iteration 467, loss = 712397.74683695\n",
      "Iteration 468, loss = 711819.53998746\n",
      "Iteration 469, loss = 711235.89214014\n",
      "Iteration 470, loss = 710656.80153358\n",
      "Iteration 471, loss = 710072.22307408\n",
      "Iteration 472, loss = 709497.69282199\n",
      "Iteration 473, loss = 708905.60571422\n",
      "Iteration 474, loss = 708322.55132202\n",
      "Iteration 475, loss = 707734.77121476\n",
      "Iteration 476, loss = 707149.12639027\n",
      "Iteration 477, loss = 706564.34169016\n",
      "Iteration 478, loss = 705975.47301454\n",
      "Iteration 479, loss = 705387.27237457\n",
      "Iteration 480, loss = 704800.31441223\n",
      "Iteration 481, loss = 704210.19241673\n",
      "Iteration 482, loss = 703620.04070017\n",
      "Iteration 483, loss = 703043.91921766\n",
      "Iteration 484, loss = 702446.83593781\n",
      "Iteration 485, loss = 701864.41177474\n",
      "Iteration 486, loss = 701265.49102122\n",
      "Iteration 487, loss = 700676.23557226\n",
      "Iteration 488, loss = 700089.81243659\n",
      "Iteration 489, loss = 699496.53838367\n",
      "Iteration 490, loss = 698905.58283475\n",
      "Iteration 491, loss = 698322.84809333\n",
      "Iteration 492, loss = 697713.00128586\n",
      "Iteration 493, loss = 697118.50168391\n",
      "Iteration 494, loss = 696530.58533216\n",
      "Iteration 495, loss = 695930.57822570\n",
      "Iteration 496, loss = 695334.73299220\n",
      "Iteration 497, loss = 694744.26170624\n",
      "Iteration 498, loss = 694144.52486030\n",
      "Iteration 499, loss = 693553.04050574\n",
      "Iteration 500, loss = 692951.65224091\n",
      "Iteration 501, loss = 692357.24073608\n",
      "Iteration 502, loss = 691758.16335099\n",
      "Iteration 503, loss = 691165.92713634\n",
      "Iteration 504, loss = 690563.34017595\n",
      "Iteration 505, loss = 689966.30392087\n",
      "Iteration 506, loss = 689367.63930346\n",
      "Iteration 507, loss = 688768.46516885\n",
      "Iteration 508, loss = 688170.48725314\n",
      "Iteration 509, loss = 687571.80289071\n",
      "Iteration 510, loss = 686972.23497187\n",
      "Iteration 511, loss = 686372.64656840\n",
      "Iteration 512, loss = 685772.37650037\n",
      "Iteration 513, loss = 685172.18719480\n",
      "Iteration 514, loss = 684571.75954997\n",
      "Iteration 515, loss = 683970.87477406\n",
      "Iteration 516, loss = 683369.82372967\n",
      "Iteration 517, loss = 682769.34944873\n",
      "Iteration 518, loss = 682170.90157341\n",
      "Iteration 519, loss = 681572.81361570\n",
      "Iteration 520, loss = 680966.35760444\n",
      "Iteration 521, loss = 680381.37942911\n",
      "Iteration 522, loss = 679800.55817945\n",
      "Iteration 523, loss = 679188.18819976\n",
      "Iteration 524, loss = 678566.66419689\n",
      "Iteration 525, loss = 677981.48811489\n",
      "Iteration 526, loss = 677363.03099445\n",
      "Iteration 527, loss = 676776.85547798\n",
      "Iteration 528, loss = 676170.51385186\n",
      "Iteration 529, loss = 675562.38001318\n",
      "Iteration 530, loss = 674989.34467169\n",
      "Iteration 531, loss = 674405.40090164\n",
      "Iteration 532, loss = 673811.02856211\n",
      "Iteration 533, loss = 673215.80639302\n",
      "Iteration 534, loss = 672598.36661277\n",
      "Iteration 535, loss = 672012.69660689\n",
      "Iteration 536, loss = 671423.06259016\n",
      "Iteration 537, loss = 670808.81394474\n",
      "Iteration 538, loss = 670197.51131372\n",
      "Iteration 539, loss = 669601.36243672\n",
      "Iteration 540, loss = 669005.89781225\n",
      "Iteration 541, loss = 668410.60712654\n",
      "Iteration 542, loss = 667807.90137012\n",
      "Iteration 543, loss = 667213.71548539\n",
      "Iteration 544, loss = 666620.62758240\n",
      "Iteration 545, loss = 666024.30110320\n",
      "Iteration 546, loss = 665428.02131413\n",
      "Iteration 547, loss = 664830.82838727\n",
      "Iteration 548, loss = 664239.68526366\n",
      "Iteration 549, loss = 663639.72615468\n",
      "Iteration 550, loss = 663043.87819568\n",
      "Iteration 551, loss = 662452.46492621\n",
      "Iteration 552, loss = 661852.40758575\n",
      "Iteration 553, loss = 661261.11031869\n",
      "Iteration 554, loss = 660663.36200864\n",
      "Iteration 555, loss = 660088.73153475\n",
      "Iteration 556, loss = 659507.63474973\n",
      "Iteration 557, loss = 658889.93410330\n",
      "Iteration 558, loss = 658294.82491472\n",
      "Iteration 559, loss = 657736.74591257\n",
      "Iteration 560, loss = 657109.20701261\n",
      "Iteration 561, loss = 656552.85466960\n",
      "Iteration 562, loss = 655917.87937191\n",
      "Iteration 563, loss = 655401.84681897\n",
      "Iteration 564, loss = 654781.91185370\n",
      "Iteration 565, loss = 654229.95407512\n",
      "Iteration 566, loss = 653584.01774752\n",
      "Iteration 567, loss = 652984.25087042\n",
      "Iteration 568, loss = 652428.10556691\n",
      "Iteration 569, loss = 651872.51430784\n",
      "Iteration 570, loss = 651258.52777675\n",
      "Iteration 571, loss = 650651.60638492\n",
      "Iteration 572, loss = 650053.82836004\n",
      "Iteration 573, loss = 649475.53431666\n",
      "Iteration 574, loss = 648890.63552627\n",
      "Iteration 575, loss = 648304.58209695\n",
      "Iteration 576, loss = 647716.62067783\n",
      "Iteration 577, loss = 647142.72200389\n",
      "Iteration 578, loss = 646551.40888231\n",
      "Iteration 579, loss = 645974.53816112\n",
      "Iteration 580, loss = 645391.16048990\n",
      "Iteration 581, loss = 644819.58319342\n",
      "Iteration 582, loss = 644226.44252961\n",
      "Iteration 583, loss = 643645.92624680\n",
      "Iteration 584, loss = 643085.15869652\n",
      "Iteration 585, loss = 642498.65881604\n",
      "Iteration 586, loss = 641931.30349797\n",
      "Iteration 587, loss = 641334.84695820\n",
      "Iteration 588, loss = 640777.97233468\n",
      "Iteration 589, loss = 640179.73850289\n",
      "Iteration 590, loss = 639604.11180579\n",
      "Iteration 591, loss = 639047.98831969\n",
      "Iteration 592, loss = 638495.04154865\n",
      "Iteration 593, loss = 637893.31250390\n",
      "Iteration 594, loss = 637407.40260180\n",
      "Iteration 595, loss = 636749.11327530\n",
      "Iteration 596, loss = 636194.28550223\n",
      "Iteration 597, loss = 635590.38617992\n",
      "Iteration 598, loss = 635088.29111752\n",
      "Iteration 599, loss = 634523.78275483\n",
      "Iteration 600, loss = 633981.50174797\n",
      "Iteration 601, loss = 633320.19074279\n",
      "Iteration 602, loss = 632847.87650525\n",
      "Iteration 603, loss = 632197.82576959\n",
      "Iteration 604, loss = 631656.75204866\n",
      "Iteration 605, loss = 631104.64370370\n",
      "Iteration 606, loss = 630502.13560587\n",
      "Iteration 607, loss = 629944.36812922\n",
      "Iteration 608, loss = 629424.55502732\n",
      "Iteration 609, loss = 628838.73054097\n",
      "Iteration 610, loss = 628285.52029876\n",
      "Iteration 611, loss = 627680.33746577\n",
      "Iteration 612, loss = 627137.02691862\n",
      "Iteration 613, loss = 626560.28477748\n",
      "Iteration 614, loss = 625998.92599334\n",
      "Iteration 615, loss = 625483.49559678\n",
      "Iteration 616, loss = 625059.54264585\n",
      "Iteration 617, loss = 624414.49896120\n",
      "Iteration 618, loss = 624124.28415634\n",
      "Iteration 619, loss = 623421.55895993\n",
      "Iteration 620, loss = 622916.33414937\n",
      "Iteration 621, loss = 622137.38133773\n",
      "Iteration 622, loss = 621892.69536244\n",
      "Iteration 623, loss = 621074.19604095\n",
      "Iteration 624, loss = 620811.14772353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 625, loss = 620045.25311700\n",
      "Iteration 626, loss = 619688.33853656\n",
      "Iteration 627, loss = 618920.36888946\n",
      "Iteration 628, loss = 618510.04126769\n",
      "Iteration 629, loss = 617850.67337070\n",
      "Iteration 630, loss = 617412.34692130\n",
      "Iteration 631, loss = 616757.52608261\n",
      "Iteration 632, loss = 616214.72183972\n",
      "Iteration 633, loss = 615696.03866629\n",
      "Iteration 634, loss = 615170.94891081\n",
      "Iteration 635, loss = 614611.04778083\n",
      "Iteration 636, loss = 614068.97286115\n",
      "Iteration 637, loss = 613559.47411581\n",
      "Iteration 638, loss = 613035.51386648\n",
      "Iteration 639, loss = 612496.69757855\n",
      "Iteration 640, loss = 611968.72373166\n",
      "Iteration 641, loss = 611409.25843631\n",
      "Iteration 642, loss = 610878.07424767\n",
      "Iteration 643, loss = 610348.99549012\n",
      "Iteration 644, loss = 609817.80127388\n",
      "Iteration 645, loss = 609287.31961497\n",
      "Iteration 646, loss = 608755.70597905\n",
      "Iteration 647, loss = 608229.04086998\n",
      "Iteration 648, loss = 607695.83546396\n",
      "Iteration 649, loss = 607167.13607803\n",
      "Iteration 650, loss = 606632.87948242\n",
      "Iteration 651, loss = 606116.93078783\n",
      "Iteration 652, loss = 605586.62922776\n",
      "Iteration 653, loss = 605052.51594674\n",
      "Iteration 654, loss = 604519.48489221\n",
      "Iteration 655, loss = 603989.77385256\n",
      "Iteration 656, loss = 603459.74590800\n",
      "Iteration 657, loss = 602932.78480288\n",
      "Iteration 658, loss = 602407.38750107\n",
      "Iteration 659, loss = 601879.59906151\n",
      "Iteration 660, loss = 601349.52480200\n",
      "Iteration 661, loss = 600839.55158289\n",
      "Iteration 662, loss = 600310.13474788\n",
      "Iteration 663, loss = 599783.22831981\n",
      "Iteration 664, loss = 599256.16192691\n",
      "Iteration 665, loss = 598730.63714496\n",
      "Iteration 666, loss = 598213.03138264\n",
      "Iteration 667, loss = 597686.39746642\n",
      "Iteration 668, loss = 597168.16042018\n",
      "Iteration 669, loss = 596647.47884107\n",
      "Iteration 670, loss = 596142.39385821\n",
      "Iteration 671, loss = 595622.57897496\n",
      "Iteration 672, loss = 595118.08364728\n",
      "Iteration 673, loss = 594590.31451706\n",
      "Iteration 674, loss = 594075.05680793\n",
      "Iteration 675, loss = 593583.72380170\n",
      "Iteration 676, loss = 593175.51033866\n",
      "Iteration 677, loss = 592637.58402876\n",
      "Iteration 678, loss = 592106.90402437\n",
      "Iteration 679, loss = 591569.10153112\n",
      "Iteration 680, loss = 591042.83758015\n",
      "Iteration 681, loss = 590573.01498475\n",
      "Iteration 682, loss = 590089.04071968\n",
      "Iteration 683, loss = 589575.03226845\n",
      "Iteration 684, loss = 589062.95660258\n",
      "Iteration 685, loss = 588550.99360070\n",
      "Iteration 686, loss = 588063.10127998\n",
      "Iteration 687, loss = 587555.63826382\n",
      "Iteration 688, loss = 587095.71146347\n",
      "Iteration 689, loss = 586602.42077546\n",
      "Iteration 690, loss = 586084.56694535\n",
      "Iteration 691, loss = 585612.53658743\n",
      "Iteration 692, loss = 585088.98969132\n",
      "Iteration 693, loss = 584604.06835104\n",
      "Iteration 694, loss = 584090.27818788\n",
      "Iteration 695, loss = 583618.05868786\n",
      "Iteration 696, loss = 583121.82891415\n",
      "Iteration 697, loss = 582627.89972283\n",
      "Iteration 698, loss = 582177.35186944\n",
      "Iteration 699, loss = 581791.60165233\n",
      "Iteration 700, loss = 581184.95627447\n",
      "Iteration 701, loss = 580979.82821515\n",
      "Iteration 702, loss = 580626.26367951\n",
      "Iteration 703, loss = 580134.50935864\n",
      "Iteration 704, loss = 579374.16099286\n",
      "Iteration 705, loss = 578962.44611650\n",
      "Iteration 706, loss = 578723.22818339\n",
      "Iteration 707, loss = 578373.10312625\n",
      "Iteration 708, loss = 577351.93099409\n",
      "Iteration 709, loss = 577723.44964579\n",
      "Iteration 710, loss = 576651.44672178\n",
      "Iteration 711, loss = 576875.03445046\n",
      "Iteration 712, loss = 575685.77833814\n",
      "Iteration 713, loss = 575525.70873639\n",
      "Iteration 714, loss = 574710.10523742\n",
      "Iteration 715, loss = 574184.28408355\n",
      "Iteration 716, loss = 573947.92282963\n",
      "Iteration 717, loss = 573296.78278994\n",
      "Iteration 718, loss = 572815.34543214\n",
      "Iteration 719, loss = 572428.40976875\n",
      "Iteration 720, loss = 571830.58120500\n",
      "Iteration 721, loss = 571450.77220791\n",
      "Iteration 722, loss = 570976.52377576\n",
      "Iteration 723, loss = 570429.48273046\n",
      "Iteration 724, loss = 570079.12634099\n",
      "Iteration 725, loss = 569497.54367320\n",
      "Iteration 726, loss = 569052.93726548\n",
      "Iteration 727, loss = 568597.54531753\n",
      "Iteration 728, loss = 568085.15564523\n",
      "Iteration 729, loss = 567685.85090265\n",
      "Iteration 730, loss = 567140.94284452\n",
      "Iteration 731, loss = 566687.13148717\n",
      "Iteration 732, loss = 566215.52917224\n",
      "Iteration 733, loss = 565755.60340507\n",
      "Iteration 734, loss = 565263.79195461\n",
      "Iteration 735, loss = 564810.57888036\n",
      "Iteration 736, loss = 564328.92582959\n",
      "Iteration 737, loss = 563859.08025528\n",
      "Iteration 738, loss = 563402.36529002\n",
      "Iteration 739, loss = 562919.85320325\n",
      "Iteration 740, loss = 562455.48556716\n",
      "Iteration 741, loss = 561984.73384543\n",
      "Iteration 742, loss = 561515.95634780\n",
      "Iteration 743, loss = 561054.85833254\n",
      "Iteration 744, loss = 560577.05234242\n",
      "Iteration 745, loss = 560116.39835654\n",
      "Iteration 746, loss = 559647.61950273\n",
      "Iteration 747, loss = 559187.20328230\n",
      "Iteration 748, loss = 558713.75305609\n",
      "Iteration 749, loss = 558252.86495472\n",
      "Iteration 750, loss = 557802.34173609\n",
      "Iteration 751, loss = 557346.95758119\n",
      "Iteration 752, loss = 556867.10059110\n",
      "Iteration 753, loss = 556404.54025716\n",
      "Iteration 754, loss = 555957.73420616\n",
      "Iteration 755, loss = 555497.98475184\n",
      "Iteration 756, loss = 555029.77701891\n",
      "Iteration 757, loss = 554586.33675563\n",
      "Iteration 758, loss = 554139.82139773\n",
      "Iteration 759, loss = 553697.98439357\n",
      "Iteration 760, loss = 553236.45167198\n",
      "Iteration 761, loss = 552799.66149017\n",
      "Iteration 762, loss = 552345.26814811\n",
      "Iteration 763, loss = 551882.95686380\n",
      "Iteration 764, loss = 551421.30413228\n",
      "Iteration 765, loss = 550977.49377567\n",
      "Iteration 766, loss = 550520.68121048\n",
      "Iteration 767, loss = 550083.83379289\n",
      "Iteration 768, loss = 549641.97703398\n",
      "Iteration 769, loss = 549166.93589069\n",
      "Iteration 770, loss = 548748.24666279\n",
      "Iteration 771, loss = 548283.94722980\n",
      "Iteration 772, loss = 547818.22714784\n",
      "Iteration 773, loss = 547452.22509079\n",
      "Iteration 774, loss = 547093.78254779\n",
      "Iteration 775, loss = 546581.95925962\n",
      "Iteration 776, loss = 546339.17670496\n",
      "Iteration 777, loss = 545718.02064868\n",
      "Iteration 778, loss = 545294.90200594\n",
      "Iteration 779, loss = 544708.65138420\n",
      "Iteration 780, loss = 544539.79855324\n",
      "Iteration 781, loss = 544184.67098961\n",
      "Iteration 782, loss = 543906.98562022\n",
      "Iteration 783, loss = 542973.50479531\n",
      "Iteration 784, loss = 543178.82939560\n",
      "Iteration 785, loss = 542321.78983987\n",
      "Iteration 786, loss = 542336.04383334\n",
      "Iteration 787, loss = 541304.17991279\n",
      "Iteration 788, loss = 541534.44176503\n",
      "Iteration 789, loss = 540379.94435428\n",
      "Iteration 790, loss = 540253.52565631\n",
      "Iteration 791, loss = 539662.32388149\n",
      "Iteration 792, loss = 539096.07261482\n",
      "Iteration 793, loss = 538930.05358032\n",
      "Iteration 794, loss = 538210.49155159\n",
      "Iteration 795, loss = 537976.99875134\n",
      "Iteration 796, loss = 537414.94309156\n",
      "Iteration 797, loss = 536942.55107604\n",
      "Iteration 798, loss = 536494.06237691\n",
      "Iteration 799, loss = 535967.86119641\n",
      "Iteration 800, loss = 535572.16470653\n",
      "Iteration 801, loss = 535092.47719085\n",
      "Iteration 802, loss = 534604.11491068\n",
      "Iteration 803, loss = 534196.45200191\n",
      "Iteration 804, loss = 533679.39043814\n",
      "Iteration 805, loss = 533260.37238127\n",
      "Iteration 806, loss = 532757.70584418\n",
      "Iteration 807, loss = 532352.64716877\n",
      "Iteration 808, loss = 531814.70544701\n",
      "Iteration 809, loss = 531385.23703072\n",
      "Iteration 810, loss = 530922.04561637\n",
      "Iteration 811, loss = 530477.27991886\n",
      "Iteration 812, loss = 529999.43776632\n",
      "Iteration 813, loss = 529531.05052155\n",
      "Iteration 814, loss = 529091.46916617\n",
      "Iteration 815, loss = 528721.68215316\n",
      "Iteration 816, loss = 528214.06294524\n",
      "Iteration 817, loss = 527870.87667674\n",
      "Iteration 818, loss = 527268.99190658\n",
      "Iteration 819, loss = 526831.69381545\n",
      "Iteration 820, loss = 526427.20424212\n",
      "Iteration 821, loss = 525881.79719292\n",
      "Iteration 822, loss = 525445.19485797\n",
      "Iteration 823, loss = 524959.76349233\n",
      "Iteration 824, loss = 524556.39826533\n",
      "Iteration 825, loss = 524110.45398183\n",
      "Iteration 826, loss = 523624.89982445\n",
      "Iteration 827, loss = 523199.75089199\n",
      "Iteration 828, loss = 522668.94771223\n",
      "Iteration 829, loss = 522238.58518473\n",
      "Iteration 830, loss = 521776.51258623\n",
      "Iteration 831, loss = 521302.99510214\n",
      "Iteration 832, loss = 520830.61333707\n",
      "Iteration 833, loss = 520349.72529202\n",
      "Iteration 834, loss = 519881.85854333\n",
      "Iteration 835, loss = 519451.57766220\n",
      "Iteration 836, loss = 518979.49479522\n",
      "Iteration 837, loss = 518527.63932676\n",
      "Iteration 838, loss = 518003.21513992\n",
      "Iteration 839, loss = 517542.48757791\n",
      "Iteration 840, loss = 517064.12423605\n",
      "Iteration 841, loss = 516613.79050878\n",
      "Iteration 842, loss = 516196.97846273\n",
      "Iteration 843, loss = 515681.09960026\n",
      "Iteration 844, loss = 515197.93068994\n",
      "Iteration 845, loss = 514750.45296660\n",
      "Iteration 846, loss = 514272.40537784\n",
      "Iteration 847, loss = 513764.08250498\n",
      "Iteration 848, loss = 513302.16298272\n",
      "Iteration 849, loss = 512856.52627934\n",
      "Iteration 850, loss = 512400.14512197\n",
      "Iteration 851, loss = 511865.71268880\n",
      "Iteration 852, loss = 511520.66448937\n",
      "Iteration 853, loss = 511029.12230875\n",
      "Iteration 854, loss = 510540.41859732\n",
      "Iteration 855, loss = 510122.13716988\n",
      "Iteration 856, loss = 509500.31368090\n",
      "Iteration 857, loss = 509071.69676654\n",
      "Iteration 858, loss = 508582.80511965\n",
      "Iteration 859, loss = 508100.27664749\n",
      "Iteration 860, loss = 507652.54435211\n",
      "Iteration 861, loss = 507105.42677871\n",
      "Iteration 862, loss = 506709.33549067\n",
      "Iteration 863, loss = 506162.29955490\n",
      "Iteration 864, loss = 505669.49774304\n",
      "Iteration 865, loss = 505239.50128018\n",
      "Iteration 866, loss = 504653.29124320\n",
      "Iteration 867, loss = 504168.61047233\n",
      "Iteration 868, loss = 503711.77604286\n",
      "Iteration 869, loss = 503165.06580080\n",
      "Iteration 870, loss = 502648.95981601\n",
      "Iteration 871, loss = 502243.75941312\n",
      "Iteration 872, loss = 501664.57016783\n",
      "Iteration 873, loss = 501161.85698960\n",
      "Iteration 874, loss = 500699.73929233\n",
      "Iteration 875, loss = 500149.16960799\n",
      "Iteration 876, loss = 499641.53240241\n",
      "Iteration 877, loss = 499181.44524921\n",
      "Iteration 878, loss = 498709.87873935\n",
      "Iteration 879, loss = 498171.13145908\n",
      "Iteration 880, loss = 497722.28778037\n",
      "Iteration 881, loss = 497270.13291145\n",
      "Iteration 882, loss = 496648.56016595\n",
      "Iteration 883, loss = 496373.46648208\n",
      "Iteration 884, loss = 495911.88503927\n",
      "Iteration 885, loss = 495367.27041518\n",
      "Iteration 886, loss = 494792.05071419\n",
      "Iteration 887, loss = 494107.89266690\n",
      "Iteration 888, loss = 493673.30622984\n",
      "Iteration 889, loss = 493126.14507615\n",
      "Iteration 890, loss = 492731.20918587\n",
      "Iteration 891, loss = 492172.05127696\n",
      "Iteration 892, loss = 491669.89846048\n",
      "Iteration 893, loss = 491149.57571396\n",
      "Iteration 894, loss = 490589.77371636\n",
      "Iteration 895, loss = 490126.13461755\n",
      "Iteration 896, loss = 489559.21116749\n",
      "Iteration 897, loss = 489114.15671815\n",
      "Iteration 898, loss = 488527.82003080\n",
      "Iteration 899, loss = 488012.84442972\n",
      "Iteration 900, loss = 487542.42407358\n",
      "Iteration 901, loss = 486944.09537271\n",
      "Iteration 902, loss = 486452.23713884\n",
      "Iteration 903, loss = 485902.35367831\n",
      "Iteration 904, loss = 485364.43413537\n",
      "Iteration 905, loss = 484911.69811846\n",
      "Iteration 906, loss = 484372.58002292\n",
      "Iteration 907, loss = 483830.40501696\n",
      "Iteration 908, loss = 483358.96122673\n",
      "Iteration 909, loss = 482830.64593030\n",
      "Iteration 910, loss = 482273.77900197\n",
      "Iteration 911, loss = 481750.63194276\n",
      "Iteration 912, loss = 481253.91473604\n",
      "Iteration 913, loss = 480711.10173229\n",
      "Iteration 914, loss = 480190.43923903\n",
      "Iteration 915, loss = 479703.78815833\n",
      "Iteration 916, loss = 479170.23877883\n",
      "Iteration 917, loss = 478651.52955436\n",
      "Iteration 918, loss = 478173.80154364\n",
      "Iteration 919, loss = 477715.09731461\n",
      "Iteration 920, loss = 477114.49518802\n",
      "Iteration 921, loss = 476701.74541384\n",
      "Iteration 922, loss = 476165.93530194\n",
      "Iteration 923, loss = 475599.68543967\n",
      "Iteration 924, loss = 475184.50352735\n",
      "Iteration 925, loss = 474625.95998929\n",
      "Iteration 926, loss = 474096.51547355\n",
      "Iteration 927, loss = 473565.12581595\n",
      "Iteration 928, loss = 472966.97004948\n",
      "Iteration 929, loss = 472480.08799912\n",
      "Iteration 930, loss = 471943.42200814\n",
      "Iteration 931, loss = 471441.75000888\n",
      "Iteration 932, loss = 470922.63714516\n",
      "Iteration 933, loss = 470391.51063558\n",
      "Iteration 934, loss = 469934.08950875\n",
      "Iteration 935, loss = 469447.82976271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 936, loss = 468891.89178041\n",
      "Iteration 937, loss = 468572.80554651\n",
      "Iteration 938, loss = 468019.84187676\n",
      "Iteration 939, loss = 467495.17491650\n",
      "Iteration 940, loss = 466919.46784991\n",
      "Iteration 941, loss = 466316.90702687\n",
      "Iteration 942, loss = 465844.12467048\n",
      "Iteration 943, loss = 465334.67484966\n",
      "Iteration 944, loss = 464826.29276945\n",
      "Iteration 945, loss = 464299.74642459\n",
      "Iteration 946, loss = 463815.68751766\n",
      "Iteration 947, loss = 463312.87658787\n",
      "Iteration 948, loss = 462827.16295149\n",
      "Iteration 949, loss = 462328.02140532\n",
      "Iteration 950, loss = 461805.73050027\n",
      "Iteration 951, loss = 461313.48368877\n",
      "Iteration 952, loss = 460845.60379107\n",
      "Iteration 953, loss = 460356.33925899\n",
      "Iteration 954, loss = 459847.82913128\n",
      "Iteration 955, loss = 459367.56267595\n",
      "Iteration 956, loss = 458845.83439887\n",
      "Iteration 957, loss = 458340.74528364\n",
      "Iteration 958, loss = 457840.11710704\n",
      "Iteration 959, loss = 457375.71565577\n",
      "Iteration 960, loss = 456876.77178199\n",
      "Iteration 961, loss = 456388.50110700\n",
      "Iteration 962, loss = 455908.03987917\n",
      "Iteration 963, loss = 455402.01051027\n",
      "Iteration 964, loss = 454919.10385006\n",
      "Iteration 965, loss = 454455.83170154\n",
      "Iteration 966, loss = 453961.17511962\n",
      "Iteration 967, loss = 453496.60759432\n",
      "Iteration 968, loss = 452991.72643288\n",
      "Iteration 969, loss = 452527.30421269\n",
      "Iteration 970, loss = 452042.63678784\n",
      "Iteration 971, loss = 451555.82816325\n",
      "Iteration 972, loss = 451082.77854526\n",
      "Iteration 973, loss = 450578.75395855\n",
      "Iteration 974, loss = 450114.44051952\n",
      "Iteration 975, loss = 449651.11022822\n",
      "Iteration 976, loss = 449182.00083439\n",
      "Iteration 977, loss = 448717.51924180\n",
      "Iteration 978, loss = 448207.49640637\n",
      "Iteration 979, loss = 447811.74358512\n",
      "Iteration 980, loss = 447336.82341510\n",
      "Iteration 981, loss = 446863.70562711\n",
      "Iteration 982, loss = 446364.72154102\n",
      "Iteration 983, loss = 445863.89884729\n",
      "Iteration 984, loss = 445402.97206089\n",
      "Iteration 985, loss = 444926.80534634\n",
      "Iteration 986, loss = 444499.53987761\n",
      "Iteration 987, loss = 443978.73373741\n",
      "Iteration 988, loss = 443543.45324725\n",
      "Iteration 989, loss = 443049.66782009\n",
      "Iteration 990, loss = 442670.51104102\n",
      "Iteration 991, loss = 442161.43070447\n",
      "Iteration 992, loss = 441697.01526882\n",
      "Iteration 993, loss = 441228.94023815\n",
      "Iteration 994, loss = 440723.32378014\n",
      "Iteration 995, loss = 440277.08168817\n",
      "Iteration 996, loss = 439798.51404234\n",
      "Iteration 997, loss = 439341.67512946\n",
      "Iteration 998, loss = 438869.97788559\n",
      "Iteration 999, loss = 438406.98303772\n",
      "Iteration 1000, loss = 437944.95101549\n",
      "Iteration 1001, loss = 437492.37211745\n",
      "Iteration 1002, loss = 437042.69303006\n",
      "Iteration 1003, loss = 436574.69909622\n",
      "Iteration 1004, loss = 436109.22067940\n",
      "Iteration 1005, loss = 435654.63100618\n",
      "Iteration 1006, loss = 435189.38428519\n",
      "Iteration 1007, loss = 434728.77154483\n",
      "Iteration 1008, loss = 434254.34780686\n",
      "Iteration 1009, loss = 433815.88032978\n",
      "Iteration 1010, loss = 433388.83797360\n",
      "Iteration 1011, loss = 432921.42865915\n",
      "Iteration 1012, loss = 432442.33578881\n",
      "Iteration 1013, loss = 431996.91020334\n",
      "Iteration 1014, loss = 431518.99029917\n",
      "Iteration 1015, loss = 431084.55127938\n",
      "Iteration 1016, loss = 430566.44017168\n",
      "Iteration 1017, loss = 430268.75951462\n",
      "Iteration 1018, loss = 429778.30380891\n",
      "Iteration 1019, loss = 429381.63223947\n",
      "Iteration 1020, loss = 428752.22141070\n",
      "Iteration 1021, loss = 428608.58199885\n",
      "Iteration 1022, loss = 427975.39354836\n",
      "Iteration 1023, loss = 427745.19070653\n",
      "Iteration 1024, loss = 426948.75401973\n",
      "Iteration 1025, loss = 426802.35806877\n",
      "Iteration 1026, loss = 426053.01528310\n",
      "Iteration 1027, loss = 425736.20883349\n",
      "Iteration 1028, loss = 425253.39678179\n",
      "Iteration 1029, loss = 424700.74767555\n",
      "Iteration 1030, loss = 424387.26760596\n",
      "Iteration 1031, loss = 423777.17598530\n",
      "Iteration 1032, loss = 423428.53297991\n",
      "Iteration 1033, loss = 422905.96616192\n",
      "Iteration 1034, loss = 422439.53416341\n",
      "Iteration 1035, loss = 422046.05273261\n",
      "Iteration 1036, loss = 421500.05009987\n",
      "Iteration 1037, loss = 421125.12807349\n",
      "Iteration 1038, loss = 420604.74589157\n",
      "Iteration 1039, loss = 420172.92584035\n",
      "Iteration 1040, loss = 419691.25234813\n",
      "Iteration 1041, loss = 419230.35217249\n",
      "Iteration 1042, loss = 418794.05710891\n",
      "Iteration 1043, loss = 418313.75230963\n",
      "Iteration 1044, loss = 417896.34423278\n",
      "Iteration 1045, loss = 417405.30113927\n",
      "Iteration 1046, loss = 416966.49693296\n",
      "Iteration 1047, loss = 416505.64778284\n",
      "Iteration 1048, loss = 416071.31599535\n",
      "Iteration 1049, loss = 415601.07405963\n",
      "Iteration 1050, loss = 415157.30463805\n",
      "Iteration 1051, loss = 414710.09611435\n",
      "Iteration 1052, loss = 414253.36682241\n",
      "Iteration 1053, loss = 413799.60680677\n",
      "Iteration 1054, loss = 413352.72476528\n",
      "Iteration 1055, loss = 412903.31806472\n",
      "Iteration 1056, loss = 412456.41981777\n",
      "Iteration 1057, loss = 412008.22630209\n",
      "Iteration 1058, loss = 411561.50561522\n",
      "Iteration 1059, loss = 411122.53264250\n",
      "Iteration 1060, loss = 410681.22986845\n",
      "Iteration 1061, loss = 410233.02790310\n",
      "Iteration 1062, loss = 409782.62732395\n",
      "Iteration 1063, loss = 409336.24247670\n",
      "Iteration 1064, loss = 408888.27317430\n",
      "Iteration 1065, loss = 408444.02379781\n",
      "Iteration 1066, loss = 407997.78728617\n",
      "Iteration 1067, loss = 407554.04519825\n",
      "Iteration 1068, loss = 407109.54534467\n",
      "Iteration 1069, loss = 406664.38596881\n",
      "Iteration 1070, loss = 406219.37528549\n",
      "Iteration 1071, loss = 405773.86686673\n",
      "Iteration 1072, loss = 405329.40647944\n",
      "Iteration 1073, loss = 404884.46676255\n",
      "Iteration 1074, loss = 404439.68347650\n",
      "Iteration 1075, loss = 403995.34263369\n",
      "Iteration 1076, loss = 403552.50607997\n",
      "Iteration 1077, loss = 403107.85485968\n",
      "Iteration 1078, loss = 402666.50105888\n",
      "Iteration 1079, loss = 402217.87339554\n",
      "Iteration 1080, loss = 401773.74467559\n",
      "Iteration 1081, loss = 401330.89194579\n",
      "Iteration 1082, loss = 400890.98610308\n",
      "Iteration 1083, loss = 400447.14064523\n",
      "Iteration 1084, loss = 400001.39704716\n",
      "Iteration 1085, loss = 399556.27168218\n",
      "Iteration 1086, loss = 399108.49925674\n",
      "Iteration 1087, loss = 398663.01461732\n",
      "Iteration 1088, loss = 398217.43083931\n",
      "Iteration 1089, loss = 397772.47755624\n",
      "Iteration 1090, loss = 397327.31842707\n",
      "Iteration 1091, loss = 396882.11392908\n",
      "Iteration 1092, loss = 396440.48133817\n",
      "Iteration 1093, loss = 395992.50952655\n",
      "Iteration 1094, loss = 395546.97982957\n",
      "Iteration 1095, loss = 395104.59796902\n",
      "Iteration 1096, loss = 394654.65882176\n",
      "Iteration 1097, loss = 394209.33807065\n",
      "Iteration 1098, loss = 393764.08708125\n",
      "Iteration 1099, loss = 393317.99549979\n",
      "Iteration 1100, loss = 392870.45886540\n",
      "Iteration 1101, loss = 392424.62673525\n",
      "Iteration 1102, loss = 391976.79826064\n",
      "Iteration 1103, loss = 391530.10393761\n",
      "Iteration 1104, loss = 391082.24779905\n",
      "Iteration 1105, loss = 390634.45973142\n",
      "Iteration 1106, loss = 390186.44297496\n",
      "Iteration 1107, loss = 389739.06109312\n",
      "Iteration 1108, loss = 389290.83183111\n",
      "Iteration 1109, loss = 388841.17505440\n",
      "Iteration 1110, loss = 388393.01930702\n",
      "Iteration 1111, loss = 387944.04425984\n",
      "Iteration 1112, loss = 387493.81206739\n",
      "Iteration 1113, loss = 387043.35277966\n",
      "Iteration 1114, loss = 386591.48342014\n",
      "Iteration 1115, loss = 386139.95199135\n",
      "Iteration 1116, loss = 385687.83669896\n",
      "Iteration 1117, loss = 385234.73015922\n",
      "Iteration 1118, loss = 384780.55912143\n",
      "Iteration 1119, loss = 384325.44661631\n",
      "Iteration 1120, loss = 383871.08996747\n",
      "Iteration 1121, loss = 383416.05735365\n",
      "Iteration 1122, loss = 382961.11119046\n",
      "Iteration 1123, loss = 382504.47699678\n",
      "Iteration 1124, loss = 382049.14093371\n",
      "Iteration 1125, loss = 381593.47716748\n",
      "Iteration 1126, loss = 381136.99036710\n",
      "Iteration 1127, loss = 380679.30349334\n",
      "Iteration 1128, loss = 380222.30237375\n",
      "Iteration 1129, loss = 379764.67404514\n",
      "Iteration 1130, loss = 379306.74500320\n",
      "Iteration 1131, loss = 378847.59537905\n",
      "Iteration 1132, loss = 378389.09332635\n",
      "Iteration 1133, loss = 377929.99945192\n",
      "Iteration 1134, loss = 377470.96222557\n",
      "Iteration 1135, loss = 377012.64503932\n",
      "Iteration 1136, loss = 376552.78093424\n",
      "Iteration 1137, loss = 376093.56973148\n",
      "Iteration 1138, loss = 375633.35275151\n",
      "Iteration 1139, loss = 375173.36259292\n",
      "Iteration 1140, loss = 374713.41841753\n",
      "Iteration 1141, loss = 374252.59405815\n",
      "Iteration 1142, loss = 373791.31477290\n",
      "Iteration 1143, loss = 373330.29873658\n",
      "Iteration 1144, loss = 372868.39900821\n",
      "Iteration 1145, loss = 372406.43161815\n",
      "Iteration 1146, loss = 371943.90323711\n",
      "Iteration 1147, loss = 371480.97400522\n",
      "Iteration 1148, loss = 371017.73139866\n",
      "Iteration 1149, loss = 370553.85571962\n",
      "Iteration 1150, loss = 370089.85841375\n",
      "Iteration 1151, loss = 369626.63883682\n",
      "Iteration 1152, loss = 369163.19418954\n",
      "Iteration 1153, loss = 368697.71956581\n",
      "Iteration 1154, loss = 368231.99365566\n",
      "Iteration 1155, loss = 367767.74726690\n",
      "Iteration 1156, loss = 367303.12625427\n",
      "Iteration 1157, loss = 366837.41827951\n",
      "Iteration 1158, loss = 366371.02890338\n",
      "Iteration 1159, loss = 365903.70652312\n",
      "Iteration 1160, loss = 365435.79763234\n",
      "Iteration 1161, loss = 364968.42462949\n",
      "Iteration 1162, loss = 364501.04498785\n",
      "Iteration 1163, loss = 364032.64472742\n",
      "Iteration 1164, loss = 363563.39769670\n",
      "Iteration 1165, loss = 363094.49133600\n",
      "Iteration 1166, loss = 362626.29176408\n",
      "Iteration 1167, loss = 362156.25589746\n",
      "Iteration 1168, loss = 361686.74382968\n",
      "Iteration 1169, loss = 361216.73305795\n",
      "Iteration 1170, loss = 360747.49276616\n",
      "Iteration 1171, loss = 360277.60616112\n",
      "Iteration 1172, loss = 359806.48813086\n",
      "Iteration 1173, loss = 359334.61612663\n",
      "Iteration 1174, loss = 358862.02697829\n",
      "Iteration 1175, loss = 358389.96451432\n",
      "Iteration 1176, loss = 357919.56141232\n",
      "Iteration 1177, loss = 357445.67103536\n",
      "Iteration 1178, loss = 356970.02314069\n",
      "Iteration 1179, loss = 356493.57420060\n",
      "Iteration 1180, loss = 356018.46517730\n",
      "Iteration 1181, loss = 355542.68720872\n",
      "Iteration 1182, loss = 355065.77104597\n",
      "Iteration 1183, loss = 354589.41362514\n",
      "Iteration 1184, loss = 354112.33134403\n",
      "Iteration 1185, loss = 353634.13222739\n",
      "Iteration 1186, loss = 353156.47718065\n",
      "Iteration 1187, loss = 352678.42241705\n",
      "Iteration 1188, loss = 352199.04155406\n",
      "Iteration 1189, loss = 351720.33773649\n",
      "Iteration 1190, loss = 351241.71969291\n",
      "Iteration 1191, loss = 350762.67493975\n",
      "Iteration 1192, loss = 350283.71285841\n",
      "Iteration 1193, loss = 349804.02544136\n",
      "Iteration 1194, loss = 349323.69365027\n",
      "Iteration 1195, loss = 348843.75267884\n",
      "Iteration 1196, loss = 348362.93100229\n",
      "Iteration 1197, loss = 347882.82456114\n",
      "Iteration 1198, loss = 347401.48999798\n",
      "Iteration 1199, loss = 346920.58680212\n",
      "Iteration 1200, loss = 346438.89157512\n",
      "Iteration 1201, loss = 345957.49069779\n",
      "Iteration 1202, loss = 345475.26908882\n",
      "Iteration 1203, loss = 344993.18851772\n",
      "Iteration 1204, loss = 344510.28970356\n",
      "Iteration 1205, loss = 344027.64539576\n",
      "Iteration 1206, loss = 343544.26543059\n",
      "Iteration 1207, loss = 343061.23188871\n",
      "Iteration 1208, loss = 342578.17875914\n",
      "Iteration 1209, loss = 342094.37268686\n",
      "Iteration 1210, loss = 341610.62774100\n",
      "Iteration 1211, loss = 341127.04329842\n",
      "Iteration 1212, loss = 340642.79759111\n",
      "Iteration 1213, loss = 340158.25790048\n",
      "Iteration 1214, loss = 339673.40152879\n",
      "Iteration 1215, loss = 339188.05893645\n",
      "Iteration 1216, loss = 338703.13097977\n",
      "Iteration 1217, loss = 338217.51230339\n",
      "Iteration 1218, loss = 337731.71006238\n",
      "Iteration 1219, loss = 337245.52751361\n",
      "Iteration 1220, loss = 336759.72533929\n",
      "Iteration 1221, loss = 336273.23811694\n",
      "Iteration 1222, loss = 335786.21021183\n",
      "Iteration 1223, loss = 335299.31041322\n",
      "Iteration 1224, loss = 334812.41849694\n",
      "Iteration 1225, loss = 334325.03957289\n",
      "Iteration 1226, loss = 333838.00862050\n",
      "Iteration 1227, loss = 333350.49498116\n",
      "Iteration 1228, loss = 332862.91227611\n",
      "Iteration 1229, loss = 332375.05747316\n",
      "Iteration 1230, loss = 331886.29113644\n",
      "Iteration 1231, loss = 331398.31609447\n",
      "Iteration 1232, loss = 330911.19627400\n",
      "Iteration 1233, loss = 330420.77881042\n",
      "Iteration 1234, loss = 329930.42400026\n",
      "Iteration 1235, loss = 329438.38191755\n",
      "Iteration 1236, loss = 328947.67517028\n",
      "Iteration 1237, loss = 328455.19379592\n",
      "Iteration 1238, loss = 327964.07840633\n",
      "Iteration 1239, loss = 327470.92728364\n",
      "Iteration 1240, loss = 326977.99220223\n",
      "Iteration 1241, loss = 326485.04606431\n",
      "Iteration 1242, loss = 325992.63416157\n",
      "Iteration 1243, loss = 325498.26768053\n",
      "Iteration 1244, loss = 325006.48860936\n",
      "Iteration 1245, loss = 324512.82523195\n",
      "Iteration 1246, loss = 324019.27459756\n",
      "Iteration 1247, loss = 323525.29652307\n",
      "Iteration 1248, loss = 323031.30475654\n",
      "Iteration 1249, loss = 322538.63426152\n",
      "Iteration 1250, loss = 322043.20891297\n",
      "Iteration 1251, loss = 321550.61847733\n",
      "Iteration 1252, loss = 321056.15115973\n",
      "Iteration 1253, loss = 320562.78820598\n",
      "Iteration 1254, loss = 320067.86711314\n",
      "Iteration 1255, loss = 319574.26714480\n",
      "Iteration 1256, loss = 319079.64168589\n",
      "Iteration 1257, loss = 318585.00287652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1258, loss = 318090.48936996\n",
      "Iteration 1259, loss = 317595.38320862\n",
      "Iteration 1260, loss = 317100.95967648\n",
      "Iteration 1261, loss = 316605.64975219\n",
      "Iteration 1262, loss = 316111.35677316\n",
      "Iteration 1263, loss = 315615.76047011\n",
      "Iteration 1264, loss = 315120.54195329\n",
      "Iteration 1265, loss = 314625.66982351\n",
      "Iteration 1266, loss = 314129.80166509\n",
      "Iteration 1267, loss = 313635.14314205\n",
      "Iteration 1268, loss = 313139.72692721\n",
      "Iteration 1269, loss = 312643.89214632\n",
      "Iteration 1270, loss = 312148.55886221\n",
      "Iteration 1271, loss = 311653.27816471\n",
      "Iteration 1272, loss = 311158.00844392\n",
      "Iteration 1273, loss = 310661.75533396\n",
      "Iteration 1274, loss = 310166.07162578\n",
      "Iteration 1275, loss = 309670.03502455\n",
      "Iteration 1276, loss = 309175.07449775\n",
      "Iteration 1277, loss = 308677.91529738\n",
      "Iteration 1278, loss = 308182.33782344\n",
      "Iteration 1279, loss = 307686.24921587\n",
      "Iteration 1280, loss = 307190.05674716\n",
      "Iteration 1281, loss = 306693.13248498\n",
      "Iteration 1282, loss = 306197.06350406\n",
      "Iteration 1283, loss = 305699.32173783\n",
      "Iteration 1284, loss = 305199.98082392\n",
      "Iteration 1285, loss = 304701.33951708\n",
      "Iteration 1286, loss = 304202.87556711\n",
      "Iteration 1287, loss = 303704.62396965\n",
      "Iteration 1288, loss = 303206.23860127\n",
      "Iteration 1289, loss = 302705.81477718\n",
      "Iteration 1290, loss = 302206.70613325\n",
      "Iteration 1291, loss = 301706.74555351\n",
      "Iteration 1292, loss = 301207.46590146\n",
      "Iteration 1293, loss = 300708.35836082\n",
      "Iteration 1294, loss = 300208.85709904\n",
      "Iteration 1295, loss = 299708.94128230\n",
      "Iteration 1296, loss = 299209.52482148\n",
      "Iteration 1297, loss = 298709.69791913\n",
      "Iteration 1298, loss = 298209.84308736\n",
      "Iteration 1299, loss = 297710.01555265\n",
      "Iteration 1300, loss = 297210.21947849\n",
      "Iteration 1301, loss = 296712.16642472\n",
      "Iteration 1302, loss = 296211.26201672\n",
      "Iteration 1303, loss = 295712.08566377\n",
      "Iteration 1304, loss = 295213.37709296\n",
      "Iteration 1305, loss = 294713.16376429\n",
      "Iteration 1306, loss = 294214.69942164\n",
      "Iteration 1307, loss = 293715.63488765\n",
      "Iteration 1308, loss = 293216.70649962\n",
      "Iteration 1309, loss = 292718.94163277\n",
      "Iteration 1310, loss = 292219.32356340\n",
      "Iteration 1311, loss = 291722.76850861\n",
      "Iteration 1312, loss = 291223.53436983\n",
      "Iteration 1313, loss = 290725.16971350\n",
      "Iteration 1314, loss = 290227.67728015\n",
      "Iteration 1315, loss = 289728.78559639\n",
      "Iteration 1316, loss = 289231.48111017\n",
      "Iteration 1317, loss = 288733.22181114\n",
      "Iteration 1318, loss = 288235.27446443\n",
      "Iteration 1319, loss = 287737.46313752\n",
      "Iteration 1320, loss = 287238.99438858\n",
      "Iteration 1321, loss = 286741.25324755\n",
      "Iteration 1322, loss = 286243.18913796\n",
      "Iteration 1323, loss = 285745.37815469\n",
      "Iteration 1324, loss = 285247.62936097\n",
      "Iteration 1325, loss = 284751.36484260\n",
      "Iteration 1326, loss = 284254.78662411\n",
      "Iteration 1327, loss = 283756.88913591\n",
      "Iteration 1328, loss = 283257.23045737\n",
      "Iteration 1329, loss = 282757.37984675\n",
      "Iteration 1330, loss = 282259.27428846\n",
      "Iteration 1331, loss = 281760.57518196\n",
      "Iteration 1332, loss = 281261.38915774\n",
      "Iteration 1333, loss = 280761.83379410\n",
      "Iteration 1334, loss = 280261.79609680\n",
      "Iteration 1335, loss = 279762.57031417\n",
      "Iteration 1336, loss = 279263.40083816\n",
      "Iteration 1337, loss = 278763.54136668\n",
      "Iteration 1338, loss = 278264.10427587\n",
      "Iteration 1339, loss = 277764.16143292\n",
      "Iteration 1340, loss = 277264.12126275\n",
      "Iteration 1341, loss = 276764.77891688\n",
      "Iteration 1342, loss = 276266.37632931\n",
      "Iteration 1343, loss = 275768.57186932\n",
      "Iteration 1344, loss = 275269.74797560\n",
      "Iteration 1345, loss = 274769.45784879\n",
      "Iteration 1346, loss = 274270.21752006\n",
      "Iteration 1347, loss = 273772.46677103\n",
      "Iteration 1348, loss = 273273.38989327\n",
      "Iteration 1349, loss = 272776.20055787\n",
      "Iteration 1350, loss = 272277.06757372\n",
      "Iteration 1351, loss = 271779.58787809\n",
      "Iteration 1352, loss = 271283.49207156\n",
      "Iteration 1353, loss = 270785.05607719\n",
      "Iteration 1354, loss = 270287.48980706\n",
      "Iteration 1355, loss = 269790.62406810\n",
      "Iteration 1356, loss = 269292.80905969\n",
      "Iteration 1357, loss = 268797.01024302\n",
      "Iteration 1358, loss = 268300.90040414\n",
      "Iteration 1359, loss = 267804.09224129\n",
      "Iteration 1360, loss = 267309.05649554\n",
      "Iteration 1361, loss = 266814.00309118\n",
      "Iteration 1362, loss = 266318.54492326\n",
      "Iteration 1363, loss = 265823.86858990\n",
      "Iteration 1364, loss = 265328.81784286\n",
      "Iteration 1365, loss = 264834.79346902\n",
      "Iteration 1366, loss = 264341.19700322\n",
      "Iteration 1367, loss = 263847.49382584\n",
      "Iteration 1368, loss = 263352.31760949\n",
      "Iteration 1369, loss = 262857.28208837\n",
      "Iteration 1370, loss = 262362.17384998\n",
      "Iteration 1371, loss = 261867.26902253\n",
      "Iteration 1372, loss = 261372.35496073\n",
      "Iteration 1373, loss = 260877.29685479\n",
      "Iteration 1374, loss = 260382.48431160\n",
      "Iteration 1375, loss = 259887.81288244\n",
      "Iteration 1376, loss = 259393.25989998\n",
      "Iteration 1377, loss = 258899.52651853\n",
      "Iteration 1378, loss = 258408.04953610\n",
      "Iteration 1379, loss = 257915.93268027\n",
      "Iteration 1380, loss = 257422.88453740\n",
      "Iteration 1381, loss = 256929.72971189\n",
      "Iteration 1382, loss = 256436.27830596\n",
      "Iteration 1383, loss = 255942.77164647\n",
      "Iteration 1384, loss = 255451.10289099\n",
      "Iteration 1385, loss = 254959.55255752\n",
      "Iteration 1386, loss = 254467.66161038\n",
      "Iteration 1387, loss = 253975.48787207\n",
      "Iteration 1388, loss = 253483.59486436\n",
      "Iteration 1389, loss = 252992.55077678\n",
      "Iteration 1390, loss = 252501.53910939\n",
      "Iteration 1391, loss = 252010.79749689\n",
      "Iteration 1392, loss = 251520.20537984\n",
      "Iteration 1393, loss = 251029.30289930\n",
      "Iteration 1394, loss = 250539.27514574\n",
      "Iteration 1395, loss = 250051.51701573\n",
      "Iteration 1396, loss = 249563.28979774\n",
      "Iteration 1397, loss = 249074.24096793\n",
      "Iteration 1398, loss = 248584.73570479\n",
      "Iteration 1399, loss = 248095.29433526\n",
      "Iteration 1400, loss = 247606.70591052\n",
      "Iteration 1401, loss = 247120.34644028\n",
      "Iteration 1402, loss = 246633.81857851\n",
      "Iteration 1403, loss = 246146.99076888\n",
      "Iteration 1404, loss = 245658.84237447\n",
      "Iteration 1405, loss = 245170.25498982\n",
      "Iteration 1406, loss = 244681.74163637\n",
      "Iteration 1407, loss = 244194.00816273\n",
      "Iteration 1408, loss = 243706.62107769\n",
      "Iteration 1409, loss = 243219.78586094\n",
      "Iteration 1410, loss = 242733.19097475\n",
      "Iteration 1411, loss = 242246.58766052\n",
      "Iteration 1412, loss = 241760.19651539\n",
      "Iteration 1413, loss = 241274.47152067\n",
      "Iteration 1414, loss = 240789.18962615\n",
      "Iteration 1415, loss = 240304.08183549\n",
      "Iteration 1416, loss = 239819.25934376\n",
      "Iteration 1417, loss = 239334.40548279\n",
      "Iteration 1418, loss = 238850.94826636\n",
      "Iteration 1419, loss = 238367.27937111\n",
      "Iteration 1420, loss = 237883.60728834\n",
      "Iteration 1421, loss = 237400.48415583\n",
      "Iteration 1422, loss = 236917.66135957\n",
      "Iteration 1423, loss = 236434.77194196\n",
      "Iteration 1424, loss = 235952.11907712\n",
      "Iteration 1425, loss = 235471.07483954\n",
      "Iteration 1426, loss = 234990.56403809\n",
      "Iteration 1427, loss = 234509.40209024\n",
      "Iteration 1428, loss = 234028.36402897\n",
      "Iteration 1429, loss = 233548.11794470\n",
      "Iteration 1430, loss = 233068.93152204\n",
      "Iteration 1431, loss = 232589.59904724\n",
      "Iteration 1432, loss = 232110.42245035\n",
      "Iteration 1433, loss = 231632.30563046\n",
      "Iteration 1434, loss = 231154.11159374\n",
      "Iteration 1435, loss = 230675.23608702\n",
      "Iteration 1436, loss = 230197.01449541\n",
      "Iteration 1437, loss = 229719.06943908\n",
      "Iteration 1438, loss = 229240.09142494\n",
      "Iteration 1439, loss = 228760.51583436\n",
      "Iteration 1440, loss = 228282.54508623\n",
      "Iteration 1441, loss = 227805.80539209\n",
      "Iteration 1442, loss = 227328.59481089\n",
      "Iteration 1443, loss = 226850.89348568\n",
      "Iteration 1444, loss = 226373.14382543\n",
      "Iteration 1445, loss = 225895.75520791\n",
      "Iteration 1446, loss = 225419.66034059\n",
      "Iteration 1447, loss = 224944.28362438\n",
      "Iteration 1448, loss = 224468.74337561\n",
      "Iteration 1449, loss = 223993.01887111\n",
      "Iteration 1450, loss = 223518.10814879\n",
      "Iteration 1451, loss = 223044.09170300\n",
      "Iteration 1452, loss = 222569.74855707\n",
      "Iteration 1453, loss = 222095.67339355\n",
      "Iteration 1454, loss = 221622.74151677\n",
      "Iteration 1455, loss = 221150.85739415\n",
      "Iteration 1456, loss = 220678.89788272\n",
      "Iteration 1457, loss = 220207.51188513\n",
      "Iteration 1458, loss = 219736.68747757\n",
      "Iteration 1459, loss = 219266.35394333\n",
      "Iteration 1460, loss = 218796.41414343\n",
      "Iteration 1461, loss = 218326.65015318\n",
      "Iteration 1462, loss = 217857.91352729\n",
      "Iteration 1463, loss = 217389.61683128\n",
      "Iteration 1464, loss = 216921.60330188\n",
      "Iteration 1465, loss = 216453.92770098\n",
      "Iteration 1466, loss = 215986.62064628\n",
      "Iteration 1467, loss = 215519.67274132\n",
      "Iteration 1468, loss = 215051.60351926\n",
      "Iteration 1469, loss = 214585.02823659\n",
      "Iteration 1470, loss = 214118.33071837\n",
      "Iteration 1471, loss = 213651.44195627\n",
      "Iteration 1472, loss = 213184.90113293\n",
      "Iteration 1473, loss = 212718.66451501\n",
      "Iteration 1474, loss = 212252.88334123\n",
      "Iteration 1475, loss = 211787.45222101\n",
      "Iteration 1476, loss = 211322.53110411\n",
      "Iteration 1477, loss = 210857.86869702\n",
      "Iteration 1478, loss = 210393.22571194\n",
      "Iteration 1479, loss = 209928.99635107\n",
      "Iteration 1480, loss = 209466.54488029\n",
      "Iteration 1481, loss = 209005.84815766\n",
      "Iteration 1482, loss = 208544.55101346\n",
      "Iteration 1483, loss = 208083.93783770\n",
      "Iteration 1484, loss = 207621.36319581\n",
      "Iteration 1485, loss = 207160.14563321\n",
      "Iteration 1486, loss = 206699.69777924\n",
      "Iteration 1487, loss = 206241.21659883\n",
      "Iteration 1488, loss = 205783.29577515\n",
      "Iteration 1489, loss = 205326.44036708\n",
      "Iteration 1490, loss = 204867.97930335\n",
      "Iteration 1491, loss = 204409.07213681\n",
      "Iteration 1492, loss = 203950.63989391\n",
      "Iteration 1493, loss = 203494.44982672\n",
      "Iteration 1494, loss = 203038.83557348\n",
      "Iteration 1495, loss = 202583.62125088\n",
      "Iteration 1496, loss = 202128.06158903\n",
      "Iteration 1497, loss = 201671.00877616\n",
      "Iteration 1498, loss = 201214.19684032\n",
      "Iteration 1499, loss = 200758.76739848\n",
      "Iteration 1500, loss = 200304.48460182\n",
      "Iteration 1501, loss = 199850.72780078\n",
      "Iteration 1502, loss = 199396.61691580\n",
      "Iteration 1503, loss = 198942.61355958\n",
      "Iteration 1504, loss = 198489.91118369\n",
      "Iteration 1505, loss = 198037.97385793\n",
      "Iteration 1506, loss = 197587.80390182\n",
      "Iteration 1507, loss = 197136.75072369\n",
      "Iteration 1508, loss = 196684.99608353\n",
      "Iteration 1509, loss = 196234.45804054\n",
      "Iteration 1510, loss = 195784.70621176\n",
      "Iteration 1511, loss = 195336.30113869\n",
      "Iteration 1512, loss = 194889.80114288\n",
      "Iteration 1513, loss = 194443.22462981\n",
      "Iteration 1514, loss = 193997.98289744\n",
      "Iteration 1515, loss = 193551.84750511\n",
      "Iteration 1516, loss = 193104.61524761\n",
      "Iteration 1517, loss = 192656.76149759\n",
      "Iteration 1518, loss = 192209.98205657\n",
      "Iteration 1519, loss = 191765.19418492\n",
      "Iteration 1520, loss = 191322.20163968\n",
      "Iteration 1521, loss = 190880.02594641\n",
      "Iteration 1522, loss = 190440.73711538\n",
      "Iteration 1523, loss = 190000.43759638\n",
      "Iteration 1524, loss = 189559.23419029\n",
      "Iteration 1525, loss = 189114.76468314\n",
      "Iteration 1526, loss = 188670.38385116\n",
      "Iteration 1527, loss = 188224.81544882\n",
      "Iteration 1528, loss = 187781.25051531\n",
      "Iteration 1529, loss = 187341.43548714\n",
      "Iteration 1530, loss = 186904.50454194\n",
      "Iteration 1531, loss = 186469.10464619\n",
      "Iteration 1532, loss = 186031.96366950\n",
      "Iteration 1533, loss = 185592.95326643\n",
      "Iteration 1534, loss = 185151.14095098\n",
      "Iteration 1535, loss = 184709.68174836\n",
      "Iteration 1536, loss = 184271.27573174\n",
      "Iteration 1537, loss = 183836.09903630\n",
      "Iteration 1538, loss = 183402.27487409\n",
      "Iteration 1539, loss = 182967.55153154\n",
      "Iteration 1540, loss = 182531.51161775\n",
      "Iteration 1541, loss = 182095.01412927\n",
      "Iteration 1542, loss = 181659.32982232\n",
      "Iteration 1543, loss = 181225.38273589\n",
      "Iteration 1544, loss = 180793.29428029\n",
      "Iteration 1545, loss = 180362.51098219\n",
      "Iteration 1546, loss = 179933.40884425\n",
      "Iteration 1547, loss = 179504.42249562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1548, loss = 179074.48409552\n",
      "Iteration 1549, loss = 178646.79575041\n",
      "Iteration 1550, loss = 178218.81594828\n",
      "Iteration 1551, loss = 177786.74729644\n",
      "Iteration 1552, loss = 177351.19167870\n",
      "Iteration 1553, loss = 176915.89763901\n",
      "Iteration 1554, loss = 176485.12346272\n",
      "Iteration 1555, loss = 176057.33626034\n",
      "Iteration 1556, loss = 175631.41529551\n",
      "Iteration 1557, loss = 175205.95750735\n",
      "Iteration 1558, loss = 174781.29943761\n",
      "Iteration 1559, loss = 174355.93662467\n",
      "Iteration 1560, loss = 173928.97483370\n",
      "Iteration 1561, loss = 173501.29412531\n",
      "Iteration 1562, loss = 173074.22148004\n",
      "Iteration 1563, loss = 172648.35117574\n",
      "Iteration 1564, loss = 172223.90208981\n",
      "Iteration 1565, loss = 171801.04691641\n",
      "Iteration 1566, loss = 171380.23430834\n",
      "Iteration 1567, loss = 170962.38989441\n",
      "Iteration 1568, loss = 170551.61263783\n",
      "Iteration 1569, loss = 170150.89055263\n",
      "Iteration 1570, loss = 169757.68030383\n",
      "Iteration 1571, loss = 169378.68154319\n",
      "Iteration 1572, loss = 168997.20574075\n",
      "Iteration 1573, loss = 168609.20278439\n",
      "Iteration 1574, loss = 168173.70717110\n",
      "Iteration 1575, loss = 167706.44802203\n",
      "Iteration 1576, loss = 167227.97282523\n",
      "Iteration 1577, loss = 166784.98786109\n",
      "Iteration 1578, loss = 166383.49477290\n",
      "Iteration 1579, loss = 166000.96881634\n",
      "Iteration 1580, loss = 165606.13142637\n",
      "Iteration 1581, loss = 165183.59013126\n",
      "Iteration 1582, loss = 164748.80733222\n",
      "Iteration 1583, loss = 164319.75789125\n",
      "Iteration 1584, loss = 163910.15297428\n",
      "Iteration 1585, loss = 163515.98490480\n",
      "Iteration 1586, loss = 163123.42451516\n",
      "Iteration 1587, loss = 162725.91007399\n",
      "Iteration 1588, loss = 162311.61030740\n",
      "Iteration 1589, loss = 161888.06649106\n",
      "Iteration 1590, loss = 161469.34486079\n",
      "Iteration 1591, loss = 161064.57354919\n",
      "Iteration 1592, loss = 160670.58367858\n",
      "Iteration 1593, loss = 160276.48942244\n",
      "Iteration 1594, loss = 159875.62704226\n",
      "Iteration 1595, loss = 159466.54170571\n",
      "Iteration 1596, loss = 159056.05166236\n",
      "Iteration 1597, loss = 158646.61280062\n",
      "Iteration 1598, loss = 158240.43500953\n",
      "Iteration 1599, loss = 157837.75672478\n",
      "Iteration 1600, loss = 157438.09497728\n",
      "Iteration 1601, loss = 157039.88474665\n",
      "Iteration 1602, loss = 156642.15984945\n",
      "Iteration 1603, loss = 156243.63755778\n",
      "Iteration 1604, loss = 155844.28686219\n",
      "Iteration 1605, loss = 155443.67779169\n",
      "Iteration 1606, loss = 155043.45038241\n",
      "Iteration 1607, loss = 154644.96165707\n",
      "Iteration 1608, loss = 154247.83971770\n",
      "Iteration 1609, loss = 153851.86012485\n",
      "Iteration 1610, loss = 153457.17215668\n",
      "Iteration 1611, loss = 153065.71290475\n",
      "Iteration 1612, loss = 152675.06268503\n",
      "Iteration 1613, loss = 152285.38791640\n",
      "Iteration 1614, loss = 151902.53253423\n",
      "Iteration 1615, loss = 151521.00251377\n",
      "Iteration 1616, loss = 151153.83363563\n",
      "Iteration 1617, loss = 150788.11802809\n",
      "Iteration 1618, loss = 150436.00418649\n",
      "Iteration 1619, loss = 150074.40510002\n",
      "Iteration 1620, loss = 149711.81720016\n",
      "Iteration 1621, loss = 149316.63742485\n",
      "Iteration 1622, loss = 148906.62976859\n",
      "Iteration 1623, loss = 148461.48939242\n",
      "Iteration 1624, loss = 148019.46128940\n",
      "Iteration 1625, loss = 147603.91445017\n",
      "Iteration 1626, loss = 147225.00359179\n",
      "Iteration 1627, loss = 146875.20238335\n",
      "Iteration 1628, loss = 146525.91033142\n",
      "Iteration 1629, loss = 146168.52800202\n",
      "Iteration 1630, loss = 145774.80629958\n",
      "Iteration 1631, loss = 145366.08471822\n",
      "Iteration 1632, loss = 144944.58064878\n",
      "Iteration 1633, loss = 144540.41798693\n",
      "Iteration 1634, loss = 144159.53600618\n",
      "Iteration 1635, loss = 143795.80656229\n",
      "Iteration 1636, loss = 143433.25198102\n",
      "Iteration 1637, loss = 143058.25970938\n",
      "Iteration 1638, loss = 142676.34293219\n",
      "Iteration 1639, loss = 142287.40364364\n",
      "Iteration 1640, loss = 141901.78133714\n",
      "Iteration 1641, loss = 141521.16975409\n",
      "Iteration 1642, loss = 141148.43147356\n",
      "Iteration 1643, loss = 140781.70732684\n",
      "Iteration 1644, loss = 140417.06591702\n",
      "Iteration 1645, loss = 140051.43489231\n",
      "Iteration 1646, loss = 139683.32001494\n",
      "Iteration 1647, loss = 139312.18040479\n",
      "Iteration 1648, loss = 138936.53676077\n",
      "Iteration 1649, loss = 138560.34361878\n",
      "Iteration 1650, loss = 138187.71118506\n",
      "Iteration 1651, loss = 137820.20718162\n",
      "Iteration 1652, loss = 137456.71240290\n",
      "Iteration 1653, loss = 137094.64421598\n",
      "Iteration 1654, loss = 136732.27416138\n",
      "Iteration 1655, loss = 136368.24949338\n",
      "Iteration 1656, loss = 136002.79937631\n",
      "Iteration 1657, loss = 135636.38866597\n",
      "Iteration 1658, loss = 135270.85937175\n",
      "Iteration 1659, loss = 134907.72167815\n",
      "Iteration 1660, loss = 134546.26553849\n",
      "Iteration 1661, loss = 134186.39914265\n",
      "Iteration 1662, loss = 133828.13789828\n",
      "Iteration 1663, loss = 133469.93561986\n",
      "Iteration 1664, loss = 133111.62689916\n",
      "Iteration 1665, loss = 132753.23948095\n",
      "Iteration 1666, loss = 132396.58309299\n",
      "Iteration 1667, loss = 132042.95923980\n",
      "Iteration 1668, loss = 131690.65861793\n",
      "Iteration 1669, loss = 131341.94309581\n",
      "Iteration 1670, loss = 130995.21424400\n",
      "Iteration 1671, loss = 130656.63408398\n",
      "Iteration 1672, loss = 130319.22279757\n",
      "Iteration 1673, loss = 129991.58069090\n",
      "Iteration 1674, loss = 129660.80306234\n",
      "Iteration 1675, loss = 129323.33800919\n",
      "Iteration 1676, loss = 128967.38001764\n",
      "Iteration 1677, loss = 128607.98457923\n",
      "Iteration 1678, loss = 128227.42991527\n",
      "Iteration 1679, loss = 127841.39840766\n",
      "Iteration 1680, loss = 127465.92056636\n",
      "Iteration 1681, loss = 127101.98050893\n",
      "Iteration 1682, loss = 126750.58994915\n",
      "Iteration 1683, loss = 126411.11405892\n",
      "Iteration 1684, loss = 126082.97011639\n",
      "Iteration 1685, loss = 125766.28995631\n",
      "Iteration 1686, loss = 125460.12892372\n",
      "Iteration 1687, loss = 125143.16447460\n",
      "Iteration 1688, loss = 124811.57986347\n",
      "Iteration 1689, loss = 124444.15553040\n",
      "Iteration 1690, loss = 124063.47350244\n",
      "Iteration 1691, loss = 123679.63683042\n",
      "Iteration 1692, loss = 123316.35114622\n",
      "Iteration 1693, loss = 122979.11486206\n",
      "Iteration 1694, loss = 122659.57456810\n",
      "Iteration 1695, loss = 122341.82959110\n",
      "Iteration 1696, loss = 122012.34743985\n",
      "Iteration 1697, loss = 121667.67800861\n",
      "Iteration 1698, loss = 121313.44003588\n",
      "Iteration 1699, loss = 120959.37745441\n",
      "Iteration 1700, loss = 120615.36657827\n",
      "Iteration 1701, loss = 120282.77153634\n",
      "Iteration 1702, loss = 119958.29824600\n",
      "Iteration 1703, loss = 119633.63612514\n",
      "Iteration 1704, loss = 119312.77019796\n",
      "Iteration 1705, loss = 118985.36011661\n",
      "Iteration 1706, loss = 118654.16871389\n",
      "Iteration 1707, loss = 118317.15930275\n",
      "Iteration 1708, loss = 117981.20057805\n",
      "Iteration 1709, loss = 117640.78127163\n",
      "Iteration 1710, loss = 117301.51368333\n",
      "Iteration 1711, loss = 116965.96770342\n",
      "Iteration 1712, loss = 116636.12963919\n",
      "Iteration 1713, loss = 116310.94235127\n",
      "Iteration 1714, loss = 115986.90759129\n",
      "Iteration 1715, loss = 115663.36723049\n",
      "Iteration 1716, loss = 115344.56367100\n",
      "Iteration 1717, loss = 115030.06627239\n",
      "Iteration 1718, loss = 114718.55994795\n",
      "Iteration 1719, loss = 114416.39766714\n",
      "Iteration 1720, loss = 114107.33893451\n",
      "Iteration 1721, loss = 113795.63671957\n",
      "Iteration 1722, loss = 113471.90722195\n",
      "Iteration 1723, loss = 113138.61113747\n",
      "Iteration 1724, loss = 112797.60980846\n",
      "Iteration 1725, loss = 112463.66711143\n",
      "Iteration 1726, loss = 112130.65102549\n",
      "Iteration 1727, loss = 111803.28724591\n",
      "Iteration 1728, loss = 111482.85325975\n",
      "Iteration 1729, loss = 111167.69399770\n",
      "Iteration 1730, loss = 110856.81419843\n",
      "Iteration 1731, loss = 110553.43794276\n",
      "Iteration 1732, loss = 110260.39000798\n",
      "Iteration 1733, loss = 109969.04024056\n",
      "Iteration 1734, loss = 109692.00649169\n",
      "Iteration 1735, loss = 109401.51431751\n",
      "Iteration 1736, loss = 109115.67379953\n",
      "Iteration 1737, loss = 108799.87444805\n",
      "Iteration 1738, loss = 108475.46341609\n",
      "Iteration 1739, loss = 108124.95005345\n",
      "Iteration 1740, loss = 107772.20530571\n",
      "Iteration 1741, loss = 107436.70508665\n",
      "Iteration 1742, loss = 107128.32115035\n",
      "Iteration 1743, loss = 106840.44061694\n",
      "Iteration 1744, loss = 106558.67900417\n",
      "Iteration 1745, loss = 106274.07013744\n",
      "Iteration 1746, loss = 105973.31776679\n",
      "Iteration 1747, loss = 105660.30577181\n",
      "Iteration 1748, loss = 105335.38694032\n",
      "Iteration 1749, loss = 105007.43388569\n",
      "Iteration 1750, loss = 104687.92819154\n",
      "Iteration 1751, loss = 104381.21497946\n",
      "Iteration 1752, loss = 104085.25117657\n",
      "Iteration 1753, loss = 103794.11810148\n",
      "Iteration 1754, loss = 103501.79333717\n",
      "Iteration 1755, loss = 103204.83190368\n",
      "Iteration 1756, loss = 102902.17476560\n",
      "Iteration 1757, loss = 102596.50295834\n",
      "Iteration 1758, loss = 102293.64193218\n",
      "Iteration 1759, loss = 101990.50649356\n",
      "Iteration 1760, loss = 101688.82671358\n",
      "Iteration 1761, loss = 101388.01453047\n",
      "Iteration 1762, loss = 101088.45942855\n",
      "Iteration 1763, loss = 100790.23461152\n",
      "Iteration 1764, loss = 100493.98392942\n",
      "Iteration 1765, loss = 100199.58224105\n",
      "Iteration 1766, loss = 99906.58835418\n",
      "Iteration 1767, loss = 99614.76745946\n",
      "Iteration 1768, loss = 99324.36370857\n",
      "Iteration 1769, loss = 99037.80534204\n",
      "Iteration 1770, loss = 98752.44511836\n",
      "Iteration 1771, loss = 98473.44841123\n",
      "Iteration 1772, loss = 98195.83848830\n",
      "Iteration 1773, loss = 97928.06191110\n",
      "Iteration 1774, loss = 97662.35469918\n",
      "Iteration 1775, loss = 97397.71613247\n",
      "Iteration 1776, loss = 97145.49088346\n",
      "Iteration 1777, loss = 96900.99824410\n",
      "Iteration 1778, loss = 96637.69493561\n",
      "Iteration 1779, loss = 96354.87831888\n",
      "Iteration 1780, loss = 96018.10604135\n",
      "Iteration 1781, loss = 95643.51151476\n",
      "Iteration 1782, loss = 95277.21710930\n",
      "Iteration 1783, loss = 94949.83054328\n",
      "Iteration 1784, loss = 94669.93501535\n",
      "Iteration 1785, loss = 94418.95588488\n",
      "Iteration 1786, loss = 94173.24308470\n",
      "Iteration 1787, loss = 93908.96628523\n",
      "Iteration 1788, loss = 93615.15913564\n",
      "Iteration 1789, loss = 93289.82527456\n",
      "Iteration 1790, loss = 92961.55584545\n",
      "Iteration 1791, loss = 92645.66263767\n",
      "Iteration 1792, loss = 92355.56805449\n",
      "Iteration 1793, loss = 92089.98367706\n",
      "Iteration 1794, loss = 91833.43032368\n",
      "Iteration 1795, loss = 91569.80608983\n",
      "Iteration 1796, loss = 91292.33761414\n",
      "Iteration 1797, loss = 91008.06910557\n",
      "Iteration 1798, loss = 90710.25028312\n",
      "Iteration 1799, loss = 90412.42188098\n",
      "Iteration 1800, loss = 90116.10422050\n",
      "Iteration 1801, loss = 89829.88799239\n",
      "Iteration 1802, loss = 89555.40556974\n",
      "Iteration 1803, loss = 89286.65939337\n",
      "Iteration 1804, loss = 89022.29722707\n",
      "Iteration 1805, loss = 88749.75741624\n",
      "Iteration 1806, loss = 88473.22916642\n",
      "Iteration 1807, loss = 88187.83715854\n",
      "Iteration 1808, loss = 87901.88827057\n",
      "Iteration 1809, loss = 87615.90850195\n",
      "Iteration 1810, loss = 87335.21993203\n",
      "Iteration 1811, loss = 87060.94978343\n",
      "Iteration 1812, loss = 86793.38142048\n",
      "Iteration 1813, loss = 86531.99329091\n",
      "Iteration 1814, loss = 86270.98737262\n",
      "Iteration 1815, loss = 86010.17066982\n",
      "Iteration 1816, loss = 85741.88117665\n",
      "Iteration 1817, loss = 85468.63504221\n",
      "Iteration 1818, loss = 85187.68886424\n",
      "Iteration 1819, loss = 84905.65081346\n",
      "Iteration 1820, loss = 84627.16323680\n",
      "Iteration 1821, loss = 84353.97191760\n",
      "Iteration 1822, loss = 84086.42945137\n",
      "Iteration 1823, loss = 83822.83627144\n",
      "Iteration 1824, loss = 83562.36238011\n",
      "Iteration 1825, loss = 83304.23513996\n",
      "Iteration 1826, loss = 83053.77680642\n",
      "Iteration 1827, loss = 82804.74511040\n",
      "Iteration 1828, loss = 82588.40092239\n",
      "Iteration 1829, loss = 82372.88597087\n",
      "Iteration 1830, loss = 82182.16019332\n",
      "Iteration 1831, loss = 81955.14513485\n",
      "Iteration 1832, loss = 81706.01742160\n",
      "Iteration 1833, loss = 81396.23970873\n",
      "Iteration 1834, loss = 81064.92390754\n",
      "Iteration 1835, loss = 80720.52558360\n",
      "Iteration 1836, loss = 80406.85350371\n",
      "Iteration 1837, loss = 80146.58509516\n",
      "Iteration 1838, loss = 79927.16608826\n",
      "Iteration 1839, loss = 79718.42246510\n",
      "Iteration 1840, loss = 79487.27423671\n",
      "Iteration 1841, loss = 79217.95517052\n",
      "Iteration 1842, loss = 78923.65685211\n",
      "Iteration 1843, loss = 78627.63285481\n",
      "Iteration 1844, loss = 78353.61071367\n",
      "Iteration 1845, loss = 78103.98900461\n",
      "Iteration 1846, loss = 77871.78439976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1847, loss = 77643.60869684\n",
      "Iteration 1848, loss = 77416.38901760\n",
      "Iteration 1849, loss = 77169.42803969\n",
      "Iteration 1850, loss = 76918.37698378\n",
      "Iteration 1851, loss = 76650.04519766\n",
      "Iteration 1852, loss = 76372.02396375\n",
      "Iteration 1853, loss = 76101.00156292\n",
      "Iteration 1854, loss = 75848.10856198\n",
      "Iteration 1855, loss = 75611.39978912\n",
      "Iteration 1856, loss = 75388.71817022\n",
      "Iteration 1857, loss = 75172.19874681\n",
      "Iteration 1858, loss = 74940.95968806\n",
      "Iteration 1859, loss = 74699.14150875\n",
      "Iteration 1860, loss = 74430.10323974\n",
      "Iteration 1861, loss = 74158.73909088\n",
      "Iteration 1862, loss = 73890.28700933\n",
      "Iteration 1863, loss = 73640.46018427\n",
      "Iteration 1864, loss = 73409.35538159\n",
      "Iteration 1865, loss = 73184.05693921\n",
      "Iteration 1866, loss = 72951.66562929\n",
      "Iteration 1867, loss = 72709.25008270\n",
      "Iteration 1868, loss = 72458.10581760\n",
      "Iteration 1869, loss = 72206.53215257\n",
      "Iteration 1870, loss = 71959.75603242\n",
      "Iteration 1871, loss = 71719.59633712\n",
      "Iteration 1872, loss = 71485.81991377\n",
      "Iteration 1873, loss = 71259.19255821\n",
      "Iteration 1874, loss = 71033.20762076\n",
      "Iteration 1875, loss = 70816.07664287\n",
      "Iteration 1876, loss = 70593.00950208\n",
      "Iteration 1877, loss = 70371.04107765\n",
      "Iteration 1878, loss = 70140.52651642\n",
      "Iteration 1879, loss = 69916.52434119\n",
      "Iteration 1880, loss = 69684.19148902\n",
      "Iteration 1881, loss = 69457.53401757\n",
      "Iteration 1882, loss = 69217.59028058\n",
      "Iteration 1883, loss = 68964.29576848\n",
      "Iteration 1884, loss = 68715.57635012\n",
      "Iteration 1885, loss = 68468.39932277\n",
      "Iteration 1886, loss = 68229.85662801\n",
      "Iteration 1887, loss = 67996.43555795\n",
      "Iteration 1888, loss = 67768.78488046\n",
      "Iteration 1889, loss = 67549.54112817\n",
      "Iteration 1890, loss = 67343.93334066\n",
      "Iteration 1891, loss = 67144.15745049\n",
      "Iteration 1892, loss = 66959.54942924\n",
      "Iteration 1893, loss = 66758.60072540\n",
      "Iteration 1894, loss = 66547.49557137\n",
      "Iteration 1895, loss = 66302.74930259\n",
      "Iteration 1896, loss = 66049.38095841\n",
      "Iteration 1897, loss = 65786.41617563\n",
      "Iteration 1898, loss = 65535.63832490\n",
      "Iteration 1899, loss = 65309.23701164\n",
      "Iteration 1900, loss = 65104.55242490\n",
      "Iteration 1901, loss = 64917.59637278\n",
      "Iteration 1902, loss = 64730.07812786\n",
      "Iteration 1903, loss = 64557.11063980\n",
      "Iteration 1904, loss = 64358.13972822\n",
      "Iteration 1905, loss = 64160.56731296\n",
      "Iteration 1906, loss = 63932.71334596\n",
      "Iteration 1907, loss = 63674.28823371\n",
      "Iteration 1908, loss = 63406.26101112\n",
      "Iteration 1909, loss = 63151.59720780\n",
      "Iteration 1910, loss = 62925.14460127\n",
      "Iteration 1911, loss = 62726.88747008\n",
      "Iteration 1912, loss = 62541.03146868\n",
      "Iteration 1913, loss = 62354.85616440\n",
      "Iteration 1914, loss = 62168.08376579\n",
      "Iteration 1915, loss = 61957.74163708\n",
      "Iteration 1916, loss = 61741.55154633\n",
      "Iteration 1917, loss = 61502.19419072\n",
      "Iteration 1918, loss = 61266.36617221\n",
      "Iteration 1919, loss = 61038.12367459\n",
      "Iteration 1920, loss = 60827.79122132\n",
      "Iteration 1921, loss = 60634.02468145\n",
      "Iteration 1922, loss = 60449.04281848\n",
      "Iteration 1923, loss = 60272.05057630\n",
      "Iteration 1924, loss = 60085.63571809\n",
      "Iteration 1925, loss = 59894.33904086\n",
      "Iteration 1926, loss = 59678.85768825\n",
      "Iteration 1927, loss = 59461.38419144\n",
      "Iteration 1928, loss = 59228.56280204\n",
      "Iteration 1929, loss = 59002.45278697\n",
      "Iteration 1930, loss = 58786.06966910\n",
      "Iteration 1931, loss = 58584.57466217\n",
      "Iteration 1932, loss = 58394.88745485\n",
      "Iteration 1933, loss = 58209.36828514\n",
      "Iteration 1934, loss = 58026.53382712\n",
      "Iteration 1935, loss = 57838.63986108\n",
      "Iteration 1936, loss = 57656.76085078\n",
      "Iteration 1937, loss = 57460.25411850\n",
      "Iteration 1938, loss = 57272.26707471\n",
      "Iteration 1939, loss = 57063.08826051\n",
      "Iteration 1940, loss = 56845.29982429\n",
      "Iteration 1941, loss = 56624.07117041\n",
      "Iteration 1942, loss = 56412.96242778\n",
      "Iteration 1943, loss = 56217.78839136\n",
      "Iteration 1944, loss = 56034.59811985\n",
      "Iteration 1945, loss = 55855.21763392\n",
      "Iteration 1946, loss = 55673.27794848\n",
      "Iteration 1947, loss = 55490.49443835\n",
      "Iteration 1948, loss = 55298.85350700\n",
      "Iteration 1949, loss = 55136.90425422\n",
      "Iteration 1950, loss = 54962.14275246\n",
      "Iteration 1951, loss = 54827.33193425\n",
      "Iteration 1952, loss = 54665.55805332\n",
      "Iteration 1953, loss = 54536.79941694\n",
      "Iteration 1954, loss = 54349.31003021\n",
      "Iteration 1955, loss = 54176.73775314\n",
      "Iteration 1956, loss = 53918.36391932\n",
      "Iteration 1957, loss = 53642.85010701\n",
      "Iteration 1958, loss = 53387.46765282\n",
      "Iteration 1959, loss = 53191.09041427\n",
      "Iteration 1960, loss = 53047.32539244\n",
      "Iteration 1961, loss = 52914.95795761\n",
      "Iteration 1962, loss = 52761.54972640\n",
      "Iteration 1963, loss = 52555.43441305\n",
      "Iteration 1964, loss = 52321.45324066\n",
      "Iteration 1965, loss = 52099.44523077\n",
      "Iteration 1966, loss = 51914.13321354\n",
      "Iteration 1967, loss = 51759.62046127\n",
      "Iteration 1968, loss = 51609.06168519\n",
      "Iteration 1969, loss = 51459.58467779\n",
      "Iteration 1970, loss = 51278.60944038\n",
      "Iteration 1971, loss = 51101.24300011\n",
      "Iteration 1972, loss = 50891.44987044\n",
      "Iteration 1973, loss = 50678.66956864\n",
      "Iteration 1974, loss = 50481.47149004\n",
      "Iteration 1975, loss = 50310.95438060\n",
      "Iteration 1976, loss = 50162.52572096\n",
      "Iteration 1977, loss = 50015.65466159\n",
      "Iteration 1978, loss = 49858.61232419\n",
      "Iteration 1979, loss = 49673.56650735\n",
      "Iteration 1980, loss = 49486.69963223\n",
      "Iteration 1981, loss = 49286.22471182\n",
      "Iteration 1982, loss = 49098.45377087\n",
      "Iteration 1983, loss = 48916.28653118\n",
      "Iteration 1984, loss = 48747.14436808\n",
      "Iteration 1985, loss = 48592.15187818\n",
      "Iteration 1986, loss = 48447.56889646\n",
      "Iteration 1987, loss = 48315.37717959\n",
      "Iteration 1988, loss = 48172.57767749\n",
      "Iteration 1989, loss = 48052.60722097\n",
      "Iteration 1990, loss = 47882.30631568\n",
      "Iteration 1991, loss = 47764.44815380\n",
      "Iteration 1992, loss = 47560.44846481\n",
      "Iteration 1993, loss = 47310.92934089\n",
      "Iteration 1994, loss = 47081.67770767\n",
      "Iteration 1995, loss = 46922.25842520\n",
      "Iteration 1996, loss = 46808.90539542\n",
      "Iteration 1997, loss = 46686.79070316\n",
      "Iteration 1998, loss = 46557.12453735\n",
      "Iteration 1999, loss = 46366.88763102\n",
      "Iteration 2000, loss = 46151.68593181\n",
      "Iteration 2001, loss = 45941.87860484\n",
      "Iteration 2002, loss = 45774.13799776\n",
      "Iteration 2003, loss = 45643.44364430\n",
      "Iteration 2004, loss = 45512.26066793\n",
      "Iteration 2005, loss = 45360.20751611\n",
      "Iteration 2006, loss = 45179.05181254\n",
      "Iteration 2007, loss = 45000.41801767\n",
      "Iteration 2008, loss = 44820.95400862\n",
      "Iteration 2009, loss = 44655.56903191\n",
      "Iteration 2010, loss = 44505.45734997\n",
      "Iteration 2011, loss = 44363.69258060\n",
      "Iteration 2012, loss = 44239.41924739\n",
      "Iteration 2013, loss = 44107.54560765\n",
      "Iteration 2014, loss = 43985.70487941\n",
      "Iteration 2015, loss = 43827.71296560\n",
      "Iteration 2016, loss = 43691.27592814\n",
      "Iteration 2017, loss = 43502.36352126\n",
      "Iteration 2018, loss = 43307.20956378\n",
      "Iteration 2019, loss = 43113.77325180\n",
      "Iteration 2020, loss = 42952.09694915\n",
      "Iteration 2021, loss = 42822.39506562\n",
      "Iteration 2022, loss = 42714.44792820\n",
      "Iteration 2023, loss = 42609.34045715\n",
      "Iteration 2024, loss = 42490.36599760\n",
      "Iteration 2025, loss = 42355.83225819\n",
      "Iteration 2026, loss = 42168.46776880\n",
      "Iteration 2027, loss = 41970.19711351\n",
      "Iteration 2028, loss = 41765.60567355\n",
      "Iteration 2029, loss = 41598.32779072\n",
      "Iteration 2030, loss = 41472.99589658\n",
      "Iteration 2031, loss = 41361.46205218\n",
      "Iteration 2032, loss = 41259.63077954\n",
      "Iteration 2033, loss = 41128.42043644\n",
      "Iteration 2034, loss = 41013.40943822\n",
      "Iteration 2035, loss = 40837.59347322\n",
      "Iteration 2036, loss = 40680.91970918\n",
      "Iteration 2037, loss = 40480.31624839\n",
      "Iteration 2038, loss = 40291.41987447\n",
      "Iteration 2039, loss = 40143.63333207\n",
      "Iteration 2040, loss = 40028.38658331\n",
      "Iteration 2041, loss = 39911.71144303\n",
      "Iteration 2042, loss = 39767.03823474\n",
      "Iteration 2043, loss = 39618.94038343\n",
      "Iteration 2044, loss = 39448.78697668\n",
      "Iteration 2045, loss = 39284.47352586\n",
      "Iteration 2046, loss = 39146.03539441\n",
      "Iteration 2047, loss = 39026.58508907\n",
      "Iteration 2048, loss = 38909.70680881\n",
      "Iteration 2049, loss = 38779.32707663\n",
      "Iteration 2050, loss = 38661.57770950\n",
      "Iteration 2051, loss = 38521.41991386\n",
      "Iteration 2052, loss = 38411.72594592\n",
      "Iteration 2053, loss = 38265.60336619\n",
      "Iteration 2054, loss = 38162.08485403\n",
      "Iteration 2055, loss = 37998.85679090\n",
      "Iteration 2056, loss = 37810.97487680\n",
      "Iteration 2057, loss = 37631.57834585\n",
      "Iteration 2058, loss = 37488.16841277\n",
      "Iteration 2059, loss = 37376.44340560\n",
      "Iteration 2060, loss = 37268.97636893\n",
      "Iteration 2061, loss = 37146.92796018\n",
      "Iteration 2062, loss = 36996.80951054\n",
      "Iteration 2063, loss = 36845.33739718\n",
      "Iteration 2064, loss = 36691.65891044\n",
      "Iteration 2065, loss = 36552.34238707\n",
      "Iteration 2066, loss = 36422.87902810\n",
      "Iteration 2067, loss = 36301.35068893\n",
      "Iteration 2068, loss = 36186.11025770\n",
      "Iteration 2069, loss = 36072.08968302\n",
      "Iteration 2070, loss = 35983.43397922\n",
      "Iteration 2071, loss = 35873.33560923\n",
      "Iteration 2072, loss = 35784.55837372\n",
      "Iteration 2073, loss = 35637.26044832\n",
      "Iteration 2074, loss = 35475.47151005\n",
      "Iteration 2075, loss = 35288.22578043\n",
      "Iteration 2076, loss = 35130.53397683\n",
      "Iteration 2077, loss = 34999.75118480\n",
      "Iteration 2078, loss = 34893.73647626\n",
      "Iteration 2079, loss = 34795.49767515\n",
      "Iteration 2080, loss = 34679.38365042\n",
      "Iteration 2081, loss = 34538.95266759\n",
      "Iteration 2082, loss = 34385.35922420\n",
      "Iteration 2083, loss = 34241.80532005\n",
      "Iteration 2084, loss = 34115.66322950\n",
      "Iteration 2085, loss = 34005.67944530\n",
      "Iteration 2086, loss = 33908.79401924\n",
      "Iteration 2087, loss = 33810.57483564\n",
      "Iteration 2088, loss = 33736.48152727\n",
      "Iteration 2089, loss = 33631.13205922\n",
      "Iteration 2090, loss = 33580.89854196\n",
      "Iteration 2091, loss = 33448.76293986\n",
      "Iteration 2092, loss = 33318.77058038\n",
      "Iteration 2093, loss = 33106.33950834\n",
      "Iteration 2094, loss = 32914.90824340\n",
      "Iteration 2095, loss = 32770.75622911\n",
      "Iteration 2096, loss = 32683.35750849\n",
      "Iteration 2097, loss = 32601.45849061\n",
      "Iteration 2098, loss = 32478.15428536\n",
      "Iteration 2099, loss = 32326.72174220\n",
      "Iteration 2100, loss = 32176.54428705\n",
      "Iteration 2101, loss = 32057.67031805\n",
      "Iteration 2102, loss = 31960.76656685\n",
      "Iteration 2103, loss = 31857.26836404\n",
      "Iteration 2104, loss = 31735.84412157\n",
      "Iteration 2105, loss = 31598.36798580\n",
      "Iteration 2106, loss = 31465.16438143\n",
      "Iteration 2107, loss = 31350.37436607\n",
      "Iteration 2108, loss = 31246.58851841\n",
      "Iteration 2109, loss = 31142.91788317\n",
      "Iteration 2110, loss = 31026.38559000\n",
      "Iteration 2111, loss = 30915.90417134\n",
      "Iteration 2112, loss = 30790.77632105\n",
      "Iteration 2113, loss = 30671.92339856\n",
      "Iteration 2114, loss = 30546.94528788\n",
      "Iteration 2115, loss = 30426.36899094\n",
      "Iteration 2116, loss = 30308.50503431\n",
      "Iteration 2117, loss = 30193.77464396\n",
      "Iteration 2118, loss = 30081.59096452\n",
      "Iteration 2119, loss = 29968.96969494\n",
      "Iteration 2120, loss = 29856.57884262\n",
      "Iteration 2121, loss = 29748.41390343\n",
      "Iteration 2122, loss = 29649.58322326\n",
      "Iteration 2123, loss = 29568.95752634\n",
      "Iteration 2124, loss = 29542.53348402\n",
      "Iteration 2125, loss = 29532.07115716\n",
      "Iteration 2126, loss = 29614.29007594\n",
      "Iteration 2127, loss = 29593.31097182\n",
      "Iteration 2128, loss = 29532.43491370\n",
      "Iteration 2129, loss = 29207.69663826\n",
      "Iteration 2130, loss = 28877.30716113\n",
      "Iteration 2131, loss = 28653.75277337\n",
      "Iteration 2132, loss = 28619.09379861\n",
      "Iteration 2133, loss = 28640.27034949\n",
      "Iteration 2134, loss = 28538.02452629\n",
      "Iteration 2135, loss = 28320.57560169\n",
      "Iteration 2136, loss = 28124.10437276\n",
      "Iteration 2137, loss = 28042.01694989\n",
      "Iteration 2138, loss = 28013.01762702\n",
      "Iteration 2139, loss = 27931.27859989\n",
      "Iteration 2140, loss = 27772.65342635\n",
      "Iteration 2141, loss = 27607.43386116\n",
      "Iteration 2142, loss = 27493.93243448\n",
      "Iteration 2143, loss = 27428.43453999\n",
      "Iteration 2144, loss = 27349.67972771\n",
      "Iteration 2145, loss = 27236.12258417\n",
      "Iteration 2146, loss = 27092.64049997\n",
      "Iteration 2147, loss = 26971.06717773\n",
      "Iteration 2148, loss = 26886.18843316\n",
      "Iteration 2149, loss = 26805.92408238\n",
      "Iteration 2150, loss = 26708.94095829\n",
      "Iteration 2151, loss = 26584.22039343\n",
      "Iteration 2152, loss = 26462.76464301\n",
      "Iteration 2153, loss = 26366.28645544\n",
      "Iteration 2154, loss = 26284.43968436\n",
      "Iteration 2155, loss = 26198.19942407\n",
      "Iteration 2156, loss = 26090.44152581\n",
      "Iteration 2157, loss = 25981.83660236\n",
      "Iteration 2158, loss = 25867.55480799\n",
      "Iteration 2159, loss = 25763.74933650\n",
      "Iteration 2160, loss = 25675.10339394\n",
      "Iteration 2161, loss = 25593.40286033\n",
      "Iteration 2162, loss = 25528.47274166\n",
      "Iteration 2163, loss = 25449.70048840\n",
      "Iteration 2164, loss = 25394.85619148\n",
      "Iteration 2165, loss = 25289.71431077\n",
      "Iteration 2166, loss = 25194.10772945\n",
      "Iteration 2167, loss = 25049.33161683\n",
      "Iteration 2168, loss = 24916.75570112\n",
      "Iteration 2169, loss = 24805.95171466\n",
      "Iteration 2170, loss = 24726.70753546\n",
      "Iteration 2171, loss = 24652.87942045\n",
      "Iteration 2172, loss = 24559.66439753\n",
      "Iteration 2173, loss = 24466.42758416\n",
      "Iteration 2174, loss = 24355.69398313\n",
      "Iteration 2175, loss = 24248.98239482\n",
      "Iteration 2176, loss = 24151.09390676\n",
      "Iteration 2177, loss = 24063.36060578\n",
      "Iteration 2178, loss = 23978.30728144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2179, loss = 23888.52920715\n",
      "Iteration 2180, loss = 23801.00040855\n",
      "Iteration 2181, loss = 23709.11365581\n",
      "Iteration 2182, loss = 23612.19257759\n",
      "Iteration 2183, loss = 23515.25326007\n",
      "Iteration 2184, loss = 23423.03262502\n",
      "Iteration 2185, loss = 23334.36753769\n",
      "Iteration 2186, loss = 23250.14707292\n",
      "Iteration 2187, loss = 23167.81932752\n",
      "Iteration 2188, loss = 23089.23435533\n",
      "Iteration 2189, loss = 23027.58904827\n",
      "Iteration 2190, loss = 22966.49547438\n",
      "Iteration 2191, loss = 22956.70209284\n",
      "Iteration 2192, loss = 22913.21999027\n",
      "Iteration 2193, loss = 22856.32025171\n",
      "Iteration 2194, loss = 22715.33310824\n",
      "Iteration 2195, loss = 22555.17521353\n",
      "Iteration 2196, loss = 22394.44592928\n",
      "Iteration 2197, loss = 22290.21220249\n",
      "Iteration 2198, loss = 22240.07322125\n",
      "Iteration 2199, loss = 22201.28771623\n",
      "Iteration 2200, loss = 22137.40344668\n",
      "Iteration 2201, loss = 22024.30539775\n",
      "Iteration 2202, loss = 21894.97979617\n",
      "Iteration 2203, loss = 21784.17572875\n",
      "Iteration 2204, loss = 21707.01445268\n",
      "Iteration 2205, loss = 21648.50700724\n",
      "Iteration 2206, loss = 21588.48070913\n",
      "Iteration 2207, loss = 21511.41513825\n",
      "Iteration 2208, loss = 21413.59950676\n",
      "Iteration 2209, loss = 21314.02946614\n",
      "Iteration 2210, loss = 21213.93681627\n",
      "Iteration 2211, loss = 21124.12463689\n",
      "Iteration 2212, loss = 21043.17680618\n",
      "Iteration 2213, loss = 20969.83654642\n",
      "Iteration 2214, loss = 20905.24250136\n",
      "Iteration 2215, loss = 20842.58465006\n",
      "Iteration 2216, loss = 20791.56038728\n",
      "Iteration 2217, loss = 20728.69536195\n",
      "Iteration 2218, loss = 20693.56073851\n",
      "Iteration 2219, loss = 20619.73172366\n",
      "Iteration 2220, loss = 20545.48608063\n",
      "Iteration 2221, loss = 20421.40425218\n",
      "Iteration 2222, loss = 20291.22857242\n",
      "Iteration 2223, loss = 20180.02630709\n",
      "Iteration 2224, loss = 20110.07528895\n",
      "Iteration 2225, loss = 20064.73169051\n",
      "Iteration 2226, loss = 20014.29270441\n",
      "Iteration 2227, loss = 19958.14094045\n",
      "Iteration 2228, loss = 19865.14351185\n",
      "Iteration 2229, loss = 19762.76616295\n",
      "Iteration 2230, loss = 19658.21862789\n",
      "Iteration 2231, loss = 19572.46515075\n",
      "Iteration 2232, loss = 19509.91320681\n",
      "Iteration 2233, loss = 19453.02819078\n",
      "Iteration 2234, loss = 19383.53058360\n",
      "Iteration 2235, loss = 19300.08152466\n",
      "Iteration 2236, loss = 19215.29743840\n",
      "Iteration 2237, loss = 19131.40977154\n",
      "Iteration 2238, loss = 19054.95475155\n",
      "Iteration 2239, loss = 18987.01812787\n",
      "Iteration 2240, loss = 18926.55540563\n",
      "Iteration 2241, loss = 18871.13542241\n",
      "Iteration 2242, loss = 18814.83482559\n",
      "Iteration 2243, loss = 18760.92006770\n",
      "Iteration 2244, loss = 18692.19492014\n",
      "Iteration 2245, loss = 18660.34676625\n",
      "Iteration 2246, loss = 18593.02472293\n",
      "Iteration 2247, loss = 18537.67493087\n",
      "Iteration 2248, loss = 18433.48902879\n",
      "Iteration 2249, loss = 18320.44972793\n",
      "Iteration 2250, loss = 18213.97488298\n",
      "Iteration 2251, loss = 18139.08996902\n",
      "Iteration 2252, loss = 18091.89609287\n",
      "Iteration 2253, loss = 18050.24782067\n",
      "Iteration 2254, loss = 17998.89873018\n",
      "Iteration 2255, loss = 17923.12597288\n",
      "Iteration 2256, loss = 17835.44397369\n",
      "Iteration 2257, loss = 17743.52610751\n",
      "Iteration 2258, loss = 17663.14474548\n",
      "Iteration 2259, loss = 17600.66925179\n",
      "Iteration 2260, loss = 17548.21722794\n",
      "Iteration 2261, loss = 17500.70967561\n",
      "Iteration 2262, loss = 17441.69392474\n",
      "Iteration 2263, loss = 17377.83856834\n",
      "Iteration 2264, loss = 17298.62953207\n",
      "Iteration 2265, loss = 17217.99031913\n",
      "Iteration 2266, loss = 17139.66168110\n",
      "Iteration 2267, loss = 17070.45163493\n",
      "Iteration 2268, loss = 17010.65269405\n",
      "Iteration 2269, loss = 16955.64042662\n",
      "Iteration 2270, loss = 16900.39519444\n",
      "Iteration 2271, loss = 16839.30087617\n",
      "Iteration 2272, loss = 16772.90190394\n",
      "Iteration 2273, loss = 16702.41959281\n",
      "Iteration 2274, loss = 16632.62250782\n",
      "Iteration 2275, loss = 16564.46610005\n",
      "Iteration 2276, loss = 16499.63360115\n",
      "Iteration 2277, loss = 16438.38829119\n",
      "Iteration 2278, loss = 16379.33343774\n",
      "Iteration 2279, loss = 16322.23132923\n",
      "Iteration 2280, loss = 16264.14366700\n",
      "Iteration 2281, loss = 16203.29893110\n",
      "Iteration 2282, loss = 16140.25571247\n",
      "Iteration 2283, loss = 16078.55749230\n",
      "Iteration 2284, loss = 16015.65586418\n",
      "Iteration 2285, loss = 15952.85906427\n",
      "Iteration 2286, loss = 15891.36092259\n",
      "Iteration 2287, loss = 15831.79674732\n",
      "Iteration 2288, loss = 15773.77275811\n",
      "Iteration 2289, loss = 15716.96414733\n",
      "Iteration 2290, loss = 15662.25328182\n",
      "Iteration 2291, loss = 15609.77415097\n",
      "Iteration 2292, loss = 15577.86796765\n",
      "Iteration 2293, loss = 15553.21066796\n",
      "Iteration 2294, loss = 15576.30249600\n",
      "Iteration 2295, loss = 15589.17932924\n",
      "Iteration 2296, loss = 15685.03332165\n",
      "Iteration 2297, loss = 15693.27344586\n",
      "Iteration 2298, loss = 15683.40632038\n",
      "Iteration 2299, loss = 15491.82368491\n",
      "Iteration 2300, loss = 15258.23184134\n",
      "Iteration 2301, loss = 15052.75939214\n",
      "Iteration 2302, loss = 14985.62696552\n",
      "Iteration 2303, loss = 15028.69343968\n",
      "Iteration 2304, loss = 15059.49157686\n",
      "Iteration 2305, loss = 15004.13553647\n",
      "Iteration 2306, loss = 14855.21588892\n",
      "Iteration 2307, loss = 14712.24610120\n",
      "Iteration 2308, loss = 14648.24959255\n",
      "Iteration 2309, loss = 14649.65152061\n",
      "Iteration 2310, loss = 14645.45091026\n",
      "Iteration 2311, loss = 14579.55691258\n",
      "Iteration 2312, loss = 14470.65887335\n",
      "Iteration 2313, loss = 14372.61561594\n",
      "Iteration 2314, loss = 14321.96872741\n",
      "Iteration 2315, loss = 14302.08992117\n",
      "Iteration 2316, loss = 14270.44128680\n",
      "Iteration 2317, loss = 14205.41427852\n",
      "Iteration 2318, loss = 14120.33885944\n",
      "Iteration 2319, loss = 14045.77282475\n",
      "Iteration 2320, loss = 13996.66413031\n",
      "Iteration 2321, loss = 13962.03512320\n",
      "Iteration 2322, loss = 13920.20880384\n",
      "Iteration 2323, loss = 13861.93862712\n",
      "Iteration 2324, loss = 13793.79622914\n",
      "Iteration 2325, loss = 13727.86224197\n",
      "Iteration 2326, loss = 13673.65765601\n",
      "Iteration 2327, loss = 13629.23832197\n",
      "Iteration 2328, loss = 13584.88486606\n",
      "Iteration 2329, loss = 13533.09451357\n",
      "Iteration 2330, loss = 13474.33126560\n",
      "Iteration 2331, loss = 13414.38719612\n",
      "Iteration 2332, loss = 13358.99780500\n",
      "Iteration 2333, loss = 13309.51844447\n",
      "Iteration 2334, loss = 13264.04957460\n",
      "Iteration 2335, loss = 13217.35147636\n",
      "Iteration 2336, loss = 13166.67216788\n",
      "Iteration 2337, loss = 13111.19694279\n",
      "Iteration 2338, loss = 13054.15147779\n",
      "Iteration 2339, loss = 12999.78274196\n",
      "Iteration 2340, loss = 12949.48584296\n",
      "Iteration 2341, loss = 12902.00128036\n",
      "Iteration 2342, loss = 12854.80288782\n",
      "Iteration 2343, loss = 12805.90284972\n",
      "Iteration 2344, loss = 12754.35822121\n",
      "Iteration 2345, loss = 12701.47505904\n",
      "Iteration 2346, loss = 12648.82915666\n",
      "Iteration 2347, loss = 12597.96851083\n",
      "Iteration 2348, loss = 12549.22362822\n",
      "Iteration 2349, loss = 12501.65599896\n",
      "Iteration 2350, loss = 12453.89400084\n",
      "Iteration 2351, loss = 12405.07725959\n",
      "Iteration 2352, loss = 12355.25819772\n",
      "Iteration 2353, loss = 12305.18646255\n",
      "Iteration 2354, loss = 12255.56289428\n",
      "Iteration 2355, loss = 12206.92207809\n",
      "Iteration 2356, loss = 12158.91832379\n",
      "Iteration 2357, loss = 12111.25355399\n",
      "Iteration 2358, loss = 12063.95667276\n",
      "Iteration 2359, loss = 12016.76079726\n",
      "Iteration 2360, loss = 11969.93219544\n",
      "Iteration 2361, loss = 11923.45642765\n",
      "Iteration 2362, loss = 11876.77653684\n",
      "Iteration 2363, loss = 11829.61549088\n",
      "Iteration 2364, loss = 11782.52960271\n",
      "Iteration 2365, loss = 11735.34717672\n",
      "Iteration 2366, loss = 11688.56446343\n",
      "Iteration 2367, loss = 11641.88635730\n",
      "Iteration 2368, loss = 11595.45425965\n",
      "Iteration 2369, loss = 11549.37260186\n",
      "Iteration 2370, loss = 11503.65496371\n",
      "Iteration 2371, loss = 11458.16535390\n",
      "Iteration 2372, loss = 11412.92114379\n",
      "Iteration 2373, loss = 11367.89585765\n",
      "Iteration 2374, loss = 11323.22840470\n",
      "Iteration 2375, loss = 11278.91600059\n",
      "Iteration 2376, loss = 11234.78872341\n",
      "Iteration 2377, loss = 11190.98033632\n",
      "Iteration 2378, loss = 11147.18529985\n",
      "Iteration 2379, loss = 11103.83025979\n",
      "Iteration 2380, loss = 11061.36680763\n",
      "Iteration 2381, loss = 11019.37486250\n",
      "Iteration 2382, loss = 10977.32089424\n",
      "Iteration 2383, loss = 10935.43916313\n",
      "Iteration 2384, loss = 10893.20272600\n",
      "Iteration 2385, loss = 10851.10946557\n",
      "Iteration 2386, loss = 10808.71610181\n",
      "Iteration 2387, loss = 10766.69563398\n",
      "Iteration 2388, loss = 10726.43031390\n",
      "Iteration 2389, loss = 10687.30372638\n",
      "Iteration 2390, loss = 10650.53357956\n",
      "Iteration 2391, loss = 10615.03939774\n",
      "Iteration 2392, loss = 10583.74961193\n",
      "Iteration 2393, loss = 10554.25663028\n",
      "Iteration 2394, loss = 10526.04818455\n",
      "Iteration 2395, loss = 10498.50964802\n",
      "Iteration 2396, loss = 10477.24545404\n",
      "Iteration 2397, loss = 10455.00096363\n",
      "Iteration 2398, loss = 10442.67314419\n",
      "Iteration 2399, loss = 10424.39838322\n",
      "Iteration 2400, loss = 10434.57777490\n",
      "Iteration 2401, loss = 10426.68566469\n",
      "Iteration 2402, loss = 10426.30323645\n",
      "Iteration 2403, loss = 10380.71794163\n",
      "Iteration 2404, loss = 10308.37323890\n",
      "Iteration 2405, loss = 10192.44945437\n",
      "Iteration 2406, loss = 10066.28056057\n",
      "Iteration 2407, loss = 9960.41852428\n",
      "Iteration 2408, loss = 9897.22711625\n",
      "Iteration 2409, loss = 9875.30369853\n",
      "Iteration 2410, loss = 9875.62774793\n",
      "Iteration 2411, loss = 9874.08605503\n",
      "Iteration 2412, loss = 9851.43267145\n",
      "Iteration 2413, loss = 9804.55260538\n",
      "Iteration 2414, loss = 9736.66162859\n",
      "Iteration 2415, loss = 9662.90527680\n",
      "Iteration 2416, loss = 9598.82704882\n",
      "Iteration 2417, loss = 9552.52839148\n",
      "Iteration 2418, loss = 9522.66330468\n",
      "Iteration 2419, loss = 9501.66554088\n",
      "Iteration 2420, loss = 9480.39898156\n",
      "Iteration 2421, loss = 9451.47926368\n",
      "Iteration 2422, loss = 9412.55890860\n",
      "Iteration 2423, loss = 9364.69602893\n",
      "Iteration 2424, loss = 9314.05921500\n",
      "Iteration 2425, loss = 9264.81953270\n",
      "Iteration 2426, loss = 9221.37581467\n",
      "Iteration 2427, loss = 9184.50125917\n",
      "Iteration 2428, loss = 9152.70254340\n",
      "Iteration 2429, loss = 9122.97612147\n",
      "Iteration 2430, loss = 9092.33965771\n",
      "Iteration 2431, loss = 9060.28376801\n",
      "Iteration 2432, loss = 9024.51790723\n",
      "Iteration 2433, loss = 8987.17429432\n",
      "Iteration 2434, loss = 8947.46751162\n",
      "Iteration 2435, loss = 8907.49506944\n",
      "Iteration 2436, loss = 8868.42248995\n",
      "Iteration 2437, loss = 8831.15426443\n",
      "Iteration 2438, loss = 8795.95113540\n",
      "Iteration 2439, loss = 8762.46124437\n",
      "Iteration 2440, loss = 8730.14749646\n",
      "Iteration 2441, loss = 8698.52265442\n",
      "Iteration 2442, loss = 8667.07315870\n",
      "Iteration 2443, loss = 8635.42418271\n",
      "Iteration 2444, loss = 8605.29701007\n",
      "Iteration 2445, loss = 8574.00330582\n",
      "Iteration 2446, loss = 8544.07136217\n",
      "Iteration 2447, loss = 8512.04306041\n",
      "Iteration 2448, loss = 8479.09087667\n",
      "Iteration 2449, loss = 8444.76968831\n",
      "Iteration 2450, loss = 8409.49630376\n",
      "Iteration 2451, loss = 8373.60435538\n",
      "Iteration 2452, loss = 8337.86866170\n",
      "Iteration 2453, loss = 8302.28718413\n",
      "Iteration 2454, loss = 8267.42953689\n",
      "Iteration 2455, loss = 8233.15424713\n",
      "Iteration 2456, loss = 8199.59544920\n",
      "Iteration 2457, loss = 8166.79261618\n",
      "Iteration 2458, loss = 8134.68602654\n",
      "Iteration 2459, loss = 8103.16354757\n",
      "Iteration 2460, loss = 8072.11092318\n",
      "Iteration 2461, loss = 8041.39013408\n",
      "Iteration 2462, loss = 8010.89764373\n",
      "Iteration 2463, loss = 7980.56648458\n",
      "Iteration 2464, loss = 7950.39503717\n",
      "Iteration 2465, loss = 7921.58818176\n",
      "Iteration 2466, loss = 7893.55801941\n",
      "Iteration 2467, loss = 7867.68573327\n",
      "Iteration 2468, loss = 7843.50408743\n",
      "Iteration 2469, loss = 7828.78521688\n",
      "Iteration 2470, loss = 7820.08257001\n",
      "Iteration 2471, loss = 7847.42781000\n",
      "Iteration 2472, loss = 7897.88505740\n",
      "Iteration 2473, loss = 8048.96374411\n",
      "Iteration 2474, loss = 8243.86884138\n",
      "Iteration 2475, loss = 8543.02478694\n",
      "Iteration 2476, loss = 8696.21214389\n",
      "Iteration 2477, loss = 8623.94966156\n",
      "Iteration 2478, loss = 8149.42392855\n",
      "Iteration 2479, loss = 7672.97130275\n",
      "Iteration 2480, loss = 7472.97305204\n",
      "Iteration 2481, loss = 7634.84516584\n",
      "Iteration 2482, loss = 7868.07215098\n",
      "Iteration 2483, loss = 7834.23011684\n",
      "Iteration 2484, loss = 7568.74863520\n",
      "Iteration 2485, loss = 7342.45274778\n",
      "Iteration 2486, loss = 7365.09082396\n",
      "Iteration 2487, loss = 7504.90994285\n",
      "Iteration 2488, loss = 7509.93104139\n",
      "Iteration 2489, loss = 7351.31022982\n",
      "Iteration 2490, loss = 7201.45399353\n",
      "Iteration 2491, loss = 7201.88827735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2492, loss = 7274.72627513\n",
      "Iteration 2493, loss = 7263.38561754\n",
      "Iteration 2494, loss = 7151.93445824\n",
      "Iteration 2495, loss = 7059.95048202\n",
      "Iteration 2496, loss = 7060.56628881\n",
      "Iteration 2497, loss = 7092.41831714\n",
      "Iteration 2498, loss = 7065.59273953\n",
      "Iteration 2499, loss = 6985.29238490\n",
      "Iteration 2500, loss = 6925.73232865\n",
      "Iteration 2501, loss = 6920.90588576\n",
      "Iteration 2502, loss = 6927.98883230\n",
      "Iteration 2503, loss = 6897.38051626\n",
      "Iteration 2504, loss = 6838.59720180\n",
      "Iteration 2505, loss = 6795.60705288\n",
      "Iteration 2506, loss = 6784.52139726\n",
      "Iteration 2507, loss = 6777.87817351\n",
      "Iteration 2508, loss = 6748.41299770\n",
      "Iteration 2509, loss = 6703.25670455\n",
      "Iteration 2510, loss = 6668.20750765\n",
      "Iteration 2511, loss = 6651.86046446\n",
      "Iteration 2512, loss = 6638.45630482\n",
      "Iteration 2513, loss = 6611.64258725\n",
      "Iteration 2514, loss = 6575.13156963\n",
      "Iteration 2515, loss = 6543.50706861\n",
      "Iteration 2516, loss = 6523.19198861\n",
      "Iteration 2517, loss = 6506.22895087\n",
      "Iteration 2518, loss = 6482.15215034\n",
      "Iteration 2519, loss = 6451.22471975\n",
      "Iteration 2520, loss = 6421.72469054\n",
      "Iteration 2521, loss = 6399.03937245\n",
      "Iteration 2522, loss = 6379.64707671\n",
      "Iteration 2523, loss = 6357.05631141\n",
      "Iteration 2524, loss = 6329.88410461\n",
      "Iteration 2525, loss = 6302.50022985\n",
      "Iteration 2526, loss = 6278.76902449\n",
      "Iteration 2527, loss = 6257.77050692\n",
      "Iteration 2528, loss = 6235.87083203\n",
      "Iteration 2529, loss = 6211.35434073\n",
      "Iteration 2530, loss = 6185.77110282\n",
      "Iteration 2531, loss = 6161.71201777\n",
      "Iteration 2532, loss = 6139.70579401\n",
      "Iteration 2533, loss = 6118.06676941\n",
      "Iteration 2534, loss = 6095.18296252\n",
      "Iteration 2535, loss = 6071.19015836\n",
      "Iteration 2536, loss = 6047.48774117\n",
      "Iteration 2537, loss = 6024.99790812\n",
      "Iteration 2538, loss = 6003.30526524\n",
      "Iteration 2539, loss = 5981.36151306\n",
      "Iteration 2540, loss = 5958.68085964\n",
      "Iteration 2541, loss = 5935.71286526\n",
      "Iteration 2542, loss = 5913.19614648\n",
      "Iteration 2543, loss = 5891.37201360\n",
      "Iteration 2544, loss = 5869.88431641\n",
      "Iteration 2545, loss = 5848.21161265\n",
      "Iteration 2546, loss = 5826.48815786\n",
      "Iteration 2547, loss = 5804.47359582\n",
      "Iteration 2548, loss = 5782.68140630\n",
      "Iteration 2549, loss = 5761.00360045\n",
      "Iteration 2550, loss = 5739.57751140\n",
      "Iteration 2551, loss = 5718.40893255\n",
      "Iteration 2552, loss = 5697.35963992\n",
      "Iteration 2553, loss = 5676.34360710\n",
      "Iteration 2554, loss = 5655.28794310\n",
      "Iteration 2555, loss = 5634.26033474\n",
      "Iteration 2556, loss = 5613.36602662\n",
      "Iteration 2557, loss = 5592.71225365\n",
      "Iteration 2558, loss = 5572.19250751\n",
      "Iteration 2559, loss = 5551.71105327\n",
      "Iteration 2560, loss = 5531.23345777\n",
      "Iteration 2561, loss = 5510.77676878\n",
      "Iteration 2562, loss = 5490.41127131\n",
      "Iteration 2563, loss = 5470.18349645\n",
      "Iteration 2564, loss = 5450.09010133\n",
      "Iteration 2565, loss = 5430.08557406\n",
      "Iteration 2566, loss = 5410.15832267\n",
      "Iteration 2567, loss = 5390.30702600\n",
      "Iteration 2568, loss = 5370.53232838\n",
      "Iteration 2569, loss = 5350.83772552\n",
      "Iteration 2570, loss = 5331.22317656\n",
      "Iteration 2571, loss = 5311.68769301\n",
      "Iteration 2572, loss = 5292.24532879\n",
      "Iteration 2573, loss = 5272.88997606\n",
      "Iteration 2574, loss = 5253.60973933\n",
      "Iteration 2575, loss = 5234.45879598\n",
      "Iteration 2576, loss = 5215.57449074\n",
      "Iteration 2577, loss = 5196.93289582\n",
      "Iteration 2578, loss = 5179.08849016\n",
      "Iteration 2579, loss = 5163.54802444\n",
      "Iteration 2580, loss = 5148.82242853\n",
      "Iteration 2581, loss = 5139.61597226\n",
      "Iteration 2582, loss = 5127.80822187\n",
      "Iteration 2583, loss = 5123.23676907\n",
      "Iteration 2584, loss = 5110.20428466\n",
      "Iteration 2585, loss = 5102.48095470\n",
      "Iteration 2586, loss = 5081.03398527\n",
      "Iteration 2587, loss = 5057.65960712\n",
      "Iteration 2588, loss = 5023.45227076\n",
      "Iteration 2589, loss = 4988.26996547\n",
      "Iteration 2590, loss = 4958.73990351\n",
      "Iteration 2591, loss = 4939.10923509\n",
      "Iteration 2592, loss = 4926.91725879\n",
      "Iteration 2593, loss = 4916.96357815\n",
      "Iteration 2594, loss = 4904.92279882\n",
      "Iteration 2595, loss = 4887.61048550\n",
      "Iteration 2596, loss = 4866.06977218\n",
      "Iteration 2597, loss = 4841.77843422\n",
      "Iteration 2598, loss = 4818.69120918\n",
      "Iteration 2599, loss = 4798.30473567\n",
      "Iteration 2600, loss = 4781.37201964\n",
      "Iteration 2601, loss = 4766.81072501\n",
      "Iteration 2602, loss = 4752.67224605\n",
      "Iteration 2603, loss = 4738.35027601\n",
      "Iteration 2604, loss = 4721.97510005\n",
      "Iteration 2605, loss = 4704.37611176\n",
      "Iteration 2606, loss = 4685.01990510\n",
      "Iteration 2607, loss = 4665.16368255\n",
      "Iteration 2608, loss = 4646.19731255\n",
      "Iteration 2609, loss = 4628.85246999\n",
      "Iteration 2610, loss = 4613.02232433\n",
      "Iteration 2611, loss = 4598.16090472\n",
      "Iteration 2612, loss = 4583.78210391\n",
      "Iteration 2613, loss = 4569.29734467\n",
      "Iteration 2614, loss = 4554.71993953\n",
      "Iteration 2615, loss = 4539.05322227\n",
      "Iteration 2616, loss = 4524.54851634\n",
      "Iteration 2617, loss = 4508.74517206\n",
      "Iteration 2618, loss = 4493.35439259\n",
      "Iteration 2619, loss = 4476.42376301\n",
      "Iteration 2620, loss = 4459.11922587\n",
      "Iteration 2621, loss = 4441.06437536\n",
      "Iteration 2622, loss = 4422.96602691\n",
      "Iteration 2623, loss = 4405.55292041\n",
      "Iteration 2624, loss = 4389.16953917\n",
      "Iteration 2625, loss = 4373.79494831\n",
      "Iteration 2626, loss = 4359.26750530\n",
      "Iteration 2627, loss = 4345.39386406\n",
      "Iteration 2628, loss = 4332.30135938\n",
      "Iteration 2629, loss = 4324.06842850\n",
      "Iteration 2630, loss = 4318.73371937\n",
      "Iteration 2631, loss = 4330.40462177\n",
      "Iteration 2632, loss = 4348.49558352\n",
      "Iteration 2633, loss = 4393.04953360\n",
      "Iteration 2634, loss = 4435.69780338\n",
      "Iteration 2635, loss = 4504.94633227\n",
      "Iteration 2636, loss = 4538.60344497\n",
      "Iteration 2637, loss = 4564.38361312\n",
      "Iteration 2638, loss = 4507.99228447\n",
      "Iteration 2639, loss = 4436.56079587\n",
      "Iteration 2640, loss = 4306.37525809\n",
      "Iteration 2641, loss = 4195.21941438\n",
      "Iteration 2642, loss = 4127.11543605\n",
      "Iteration 2643, loss = 4122.22231820\n",
      "Iteration 2644, loss = 4157.40685079\n",
      "Iteration 2645, loss = 4188.40068252\n",
      "Iteration 2646, loss = 4187.78393842\n",
      "Iteration 2647, loss = 4145.11573892\n",
      "Iteration 2648, loss = 4083.69303851\n",
      "Iteration 2649, loss = 4033.53286988\n",
      "Iteration 2650, loss = 4013.40324249\n",
      "Iteration 2651, loss = 4019.01656382\n",
      "Iteration 2652, loss = 4030.76299627\n",
      "Iteration 2653, loss = 4029.12479131\n",
      "Iteration 2654, loss = 4006.94213147\n",
      "Iteration 2655, loss = 3972.04913442\n",
      "Iteration 2656, loss = 3938.39013435\n",
      "Iteration 2657, loss = 3916.83177109\n",
      "Iteration 2658, loss = 3908.61003105\n",
      "Iteration 2659, loss = 3906.75844506\n",
      "Iteration 2660, loss = 3902.58745739\n",
      "Iteration 2661, loss = 3890.13062410\n",
      "Iteration 2662, loss = 3870.15287305\n",
      "Iteration 2663, loss = 3846.84918927\n",
      "Iteration 2664, loss = 3826.21652327\n",
      "Iteration 2665, loss = 3811.44808558\n",
      "Iteration 2666, loss = 3801.93471320\n",
      "Iteration 2667, loss = 3794.19153082\n",
      "Iteration 2668, loss = 3784.39041987\n",
      "Iteration 2669, loss = 3770.82404662\n",
      "Iteration 2670, loss = 3754.45750877\n",
      "Iteration 2671, loss = 3737.45634159\n",
      "Iteration 2672, loss = 3721.99670453\n",
      "Iteration 2673, loss = 3709.02876698\n",
      "Iteration 2674, loss = 3698.04353181\n",
      "Iteration 2675, loss = 3687.79310286\n",
      "Iteration 2676, loss = 3677.39658437\n",
      "Iteration 2677, loss = 3665.92408564\n",
      "Iteration 2678, loss = 3654.29414385\n",
      "Iteration 2679, loss = 3640.96542360\n",
      "Iteration 2680, loss = 3626.61294364\n",
      "Iteration 2681, loss = 3611.96823106\n",
      "Iteration 2682, loss = 3598.08770944\n",
      "Iteration 2683, loss = 3585.51850245\n",
      "Iteration 2684, loss = 3574.35609065\n",
      "Iteration 2685, loss = 3564.55306559\n",
      "Iteration 2686, loss = 3556.07654791\n",
      "Iteration 2687, loss = 3553.44487650\n",
      "Iteration 2688, loss = 3552.80100090\n",
      "Iteration 2689, loss = 3565.20406692\n",
      "Iteration 2690, loss = 3576.92112905\n",
      "Iteration 2691, loss = 3601.20971272\n",
      "Iteration 2692, loss = 3612.54101296\n",
      "Iteration 2693, loss = 3626.21645776\n",
      "Iteration 2694, loss = 3610.86111103\n",
      "Iteration 2695, loss = 3587.01045496\n",
      "Iteration 2696, loss = 3536.23642627\n",
      "Iteration 2697, loss = 3485.40198255\n",
      "Iteration 2698, loss = 3435.90225187\n",
      "Iteration 2699, loss = 3403.28824849\n",
      "Iteration 2700, loss = 3393.30436883\n",
      "Iteration 2701, loss = 3399.25312215\n",
      "Iteration 2702, loss = 3407.95212988\n",
      "Iteration 2703, loss = 3408.15406289\n",
      "Iteration 2704, loss = 3394.58773698\n",
      "Iteration 2705, loss = 3370.25408536\n",
      "Iteration 2706, loss = 3342.17116537\n",
      "Iteration 2707, loss = 3318.07806137\n",
      "Iteration 2708, loss = 3302.54610959\n",
      "Iteration 2709, loss = 3295.19331624\n",
      "Iteration 2710, loss = 3292.22144010\n",
      "Iteration 2711, loss = 3288.91572254\n",
      "Iteration 2712, loss = 3281.60592980\n",
      "Iteration 2713, loss = 3269.36517850\n",
      "Iteration 2714, loss = 3253.35152944\n",
      "Iteration 2715, loss = 3236.22911456\n",
      "Iteration 2716, loss = 3220.32755261\n",
      "Iteration 2717, loss = 3207.18041914\n",
      "Iteration 2718, loss = 3197.05823150\n",
      "Iteration 2719, loss = 3189.05841517\n",
      "Iteration 2720, loss = 3181.92269151\n",
      "Iteration 2721, loss = 3173.99074179\n",
      "Iteration 2722, loss = 3164.43886402\n",
      "Iteration 2723, loss = 3153.12385917\n",
      "Iteration 2724, loss = 3141.32526576\n",
      "Iteration 2725, loss = 3129.12763694\n",
      "Iteration 2726, loss = 3117.44649386\n",
      "Iteration 2727, loss = 3106.14543302\n",
      "Iteration 2728, loss = 3096.19847320\n",
      "Iteration 2729, loss = 3086.38268277\n",
      "Iteration 2730, loss = 3077.11771853\n",
      "Iteration 2731, loss = 3068.66071030\n",
      "Iteration 2732, loss = 3064.50625964\n",
      "Iteration 2733, loss = 3065.12794416\n",
      "Iteration 2734, loss = 3077.71599439\n",
      "Iteration 2735, loss = 3098.12568634\n",
      "Iteration 2736, loss = 3129.97743417\n",
      "Iteration 2737, loss = 3158.35685623\n",
      "Iteration 2738, loss = 3185.81912432\n",
      "Iteration 2739, loss = 3188.22357534\n",
      "Iteration 2740, loss = 3179.52436688\n",
      "Iteration 2741, loss = 3135.99257733\n",
      "Iteration 2742, loss = 3088.52381824\n",
      "Iteration 2743, loss = 3025.94521046\n",
      "Iteration 2744, loss = 2974.45707409\n",
      "Iteration 2745, loss = 2939.70638806\n",
      "Iteration 2746, loss = 2927.94779249\n",
      "Iteration 2747, loss = 2934.22000104\n",
      "Iteration 2748, loss = 2946.25130014\n",
      "Iteration 2749, loss = 2951.88597678\n",
      "Iteration 2750, loss = 2943.83163791\n",
      "Iteration 2751, loss = 2923.31756923\n",
      "Iteration 2752, loss = 2896.49881501\n",
      "Iteration 2753, loss = 2871.93329394\n",
      "Iteration 2754, loss = 2855.56139463\n",
      "Iteration 2755, loss = 2848.42043763\n",
      "Iteration 2756, loss = 2847.19497482\n",
      "Iteration 2757, loss = 2846.83841607\n",
      "Iteration 2758, loss = 2843.06695616\n",
      "Iteration 2759, loss = 2833.85032236\n",
      "Iteration 2760, loss = 2820.10891950\n",
      "Iteration 2761, loss = 2804.20757159\n",
      "Iteration 2762, loss = 2789.18241516\n",
      "Iteration 2763, loss = 2777.11180200\n",
      "Iteration 2764, loss = 2768.48066935\n",
      "Iteration 2765, loss = 2762.38236475\n",
      "Iteration 2766, loss = 2757.21587878\n",
      "Iteration 2767, loss = 2751.94052171\n",
      "Iteration 2768, loss = 2745.12906764\n",
      "Iteration 2769, loss = 2739.60053299\n",
      "Iteration 2770, loss = 2731.98082413\n",
      "Iteration 2771, loss = 2727.53499952\n",
      "Iteration 2772, loss = 2720.62167846\n",
      "Iteration 2773, loss = 2718.81101071\n",
      "Iteration 2774, loss = 2713.96634440\n",
      "Iteration 2775, loss = 2712.88970992\n",
      "Iteration 2776, loss = 2707.82647752\n",
      "Iteration 2777, loss = 2706.70189524\n",
      "Iteration 2778, loss = 2700.02238281\n",
      "Iteration 2779, loss = 2699.11549402\n",
      "Iteration 2780, loss = 2691.04878550\n",
      "Iteration 2781, loss = 2687.54130047\n",
      "Iteration 2782, loss = 2675.23693139\n",
      "Iteration 2783, loss = 2659.11783345\n",
      "Iteration 2784, loss = 2637.90997746\n",
      "Iteration 2785, loss = 2616.44518311\n",
      "Iteration 2786, loss = 2597.45453275\n",
      "Iteration 2787, loss = 2583.31569871\n",
      "Iteration 2788, loss = 2574.35746987\n",
      "Iteration 2789, loss = 2569.55476415\n",
      "Iteration 2790, loss = 2567.07665728\n",
      "Iteration 2791, loss = 2564.86756811\n",
      "Iteration 2792, loss = 2562.60212021\n",
      "Iteration 2793, loss = 2558.23194515\n",
      "Iteration 2794, loss = 2553.83400120\n",
      "Iteration 2795, loss = 2547.03345227\n",
      "Iteration 2796, loss = 2542.07284920\n",
      "Iteration 2797, loss = 2534.54187261\n",
      "Iteration 2798, loss = 2529.96502219\n",
      "Iteration 2799, loss = 2522.88301904\n",
      "Iteration 2800, loss = 2521.59383397\n",
      "Iteration 2801, loss = 2517.55220039\n",
      "Iteration 2802, loss = 2519.98902680\n",
      "Iteration 2803, loss = 2518.62741184\n",
      "Iteration 2804, loss = 2525.23028115\n",
      "Iteration 2805, loss = 2525.63614648\n",
      "Iteration 2806, loss = 2531.69304342\n",
      "Iteration 2807, loss = 2527.68817973\n",
      "Iteration 2808, loss = 2529.42023482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2809, loss = 2517.40719099\n",
      "Iteration 2810, loss = 2506.97363806\n",
      "Iteration 2811, loss = 2483.16770285\n",
      "Iteration 2812, loss = 2456.89841565\n",
      "Iteration 2813, loss = 2426.76451449\n",
      "Iteration 2814, loss = 2400.21006439\n",
      "Iteration 2815, loss = 2381.37735384\n",
      "Iteration 2816, loss = 2371.92233123\n",
      "Iteration 2817, loss = 2370.15445375\n",
      "Iteration 2818, loss = 2372.35478113\n",
      "Iteration 2819, loss = 2374.98025430\n",
      "Iteration 2820, loss = 2374.67141162\n",
      "Iteration 2821, loss = 2370.15212016\n",
      "Iteration 2822, loss = 2361.10532594\n",
      "Iteration 2823, loss = 2351.25545399\n",
      "Iteration 2824, loss = 2338.79006216\n",
      "Iteration 2825, loss = 2328.14468781\n",
      "Iteration 2826, loss = 2316.49566134\n",
      "Iteration 2827, loss = 2305.00788910\n",
      "Iteration 2828, loss = 2294.55424426\n",
      "Iteration 2829, loss = 2285.45071106\n",
      "Iteration 2830, loss = 2277.85070545\n",
      "Iteration 2831, loss = 2271.47898120\n",
      "Iteration 2832, loss = 2266.18232579\n",
      "Iteration 2833, loss = 2262.39947335\n",
      "Iteration 2834, loss = 2262.08714651\n",
      "Iteration 2835, loss = 2266.34379913\n",
      "Iteration 2836, loss = 2280.50842008\n",
      "Iteration 2837, loss = 2301.94205788\n",
      "Iteration 2838, loss = 2331.95351606\n",
      "Iteration 2839, loss = 2364.05511625\n",
      "Iteration 2840, loss = 2392.26831262\n",
      "Iteration 2841, loss = 2406.31261611\n",
      "Iteration 2842, loss = 2402.62102635\n",
      "Iteration 2843, loss = 2374.59617599\n",
      "Iteration 2844, loss = 2333.76119163\n",
      "Iteration 2845, loss = 2280.74268937\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#folosim MLP regressor pentru predictii\n",
    "#MLP Regressor pentru NN Multy Layer\n",
    "regr = MLPRegressor(solver='adam', hidden_layer_sizes=(200,100), max_iter=10000, verbose = 'true',activation='relu')\n",
    "\n",
    "#Antrenam modelul folosind setul de train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Facem predictii folosind setul de test\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-84,  -3,  -6,   0]),\n",
       " array([9788,  539,  360,   24]),\n",
       " array([74,  5,  9, -1]),\n",
       " array([-225,  -21,  -10,    0]),\n",
       " array([28,  0,  0,  0]),\n",
       " array([-40,   6,   2,   0]),\n",
       " array([2162,   64,  260,   11]),\n",
       " array([99,  6, 11, -1]),\n",
       " array([-54,  -1,  -3,   0]),\n",
       " array([5022,  242,  298,   16]),\n",
       " array([8835,  480,  348,   22]),\n",
       " array([-36,  -1,  -3,   0]),\n",
       " array([4704,  222,  294,   15]),\n",
       " array([322, -13,  84,   4]),\n",
       " array([4069,  183,  285,   14]),\n",
       " array([-6,  0,  1,  0]),\n",
       " array([6293,  321,  315,   18]),\n",
       " array([6929,  361,  323,   19]),\n",
       " array([566, -22, 138,   7]),\n",
       " array([43,  0,  1,  0]),\n",
       " array([5, 0, 0, 0])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertim datele din float in int\n",
    "result_int = []\n",
    "for x in y_pred:\n",
    "    result_int.append(x.astype(int))\n",
    "\n",
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Folosim diferite scalere pentru a puteam face operatii de normalizare, standardizare si scalare\n",
    "std_scaler = StandardScaler() \n",
    "std_scaler2 = StandardScaler()\n",
    "minMaxScaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxScaler.fit(X_train)  \n",
    "X_train = minMaxScaler.transform(X_train)  \n",
    "\n",
    "#Normalizam si scalam setul de train\n",
    "std_scaler.fit(X_train)  \n",
    "X_train = std_scaler.transform(X_train) \n",
    "std_scaler2.fit(X_train)  \n",
    "X_train = std_scaler2.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizam si scalam setul de test\n",
    "minMaxScaler.fit(X_test) \n",
    "X_test = minMaxScaler.transform(X_test)  \n",
    "std_scaler.fit(X_test) \n",
    "X_test = std_scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalam si standardizam datele de test\n",
    "std_scaler2.fit(X_test) \n",
    "X_test = std_scaler2.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1833195.37882938\n",
      "Iteration 2, loss = 1833153.89234287\n",
      "Iteration 3, loss = 1833113.94243257\n",
      "Iteration 4, loss = 1833074.27630860\n",
      "Iteration 5, loss = 1833034.58958992\n",
      "Iteration 6, loss = 1832994.55351398\n",
      "Iteration 7, loss = 1832953.40295304\n",
      "Iteration 8, loss = 1832911.26698304\n",
      "Iteration 9, loss = 1832869.18554322\n",
      "Iteration 10, loss = 1832827.59911407\n",
      "Iteration 11, loss = 1832784.84732215\n",
      "Iteration 12, loss = 1832740.57127443\n",
      "Iteration 13, loss = 1832695.25256372\n",
      "Iteration 14, loss = 1832648.80774103\n",
      "Iteration 15, loss = 1832600.87711414\n",
      "Iteration 16, loss = 1832551.61039381\n",
      "Iteration 17, loss = 1832501.14342022\n",
      "Iteration 18, loss = 1832448.99629568\n",
      "Iteration 19, loss = 1832395.08368952\n",
      "Iteration 20, loss = 1832339.56552889\n",
      "Iteration 21, loss = 1832282.11398072\n",
      "Iteration 22, loss = 1832222.53883367\n",
      "Iteration 23, loss = 1832160.70536664\n",
      "Iteration 24, loss = 1832096.93021488\n",
      "Iteration 25, loss = 1832031.32129817\n",
      "Iteration 26, loss = 1831963.31828030\n",
      "Iteration 27, loss = 1831892.56328695\n",
      "Iteration 28, loss = 1831818.84502993\n",
      "Iteration 29, loss = 1831742.01181300\n",
      "Iteration 30, loss = 1831661.91771949\n",
      "Iteration 31, loss = 1831578.42973171\n",
      "Iteration 32, loss = 1831491.47709096\n",
      "Iteration 33, loss = 1831400.90977001\n",
      "Iteration 34, loss = 1831306.58038009\n",
      "Iteration 35, loss = 1831208.32180298\n",
      "Iteration 36, loss = 1831105.97266754\n",
      "Iteration 37, loss = 1830999.36147717\n",
      "Iteration 38, loss = 1830888.38208250\n",
      "Iteration 39, loss = 1830772.89904652\n",
      "Iteration 40, loss = 1830652.71616295\n",
      "Iteration 41, loss = 1830527.58478701\n",
      "Iteration 42, loss = 1830397.35905293\n",
      "Iteration 43, loss = 1830261.86259667\n",
      "Iteration 44, loss = 1830120.90078444\n",
      "Iteration 45, loss = 1829974.34564612\n",
      "Iteration 46, loss = 1829821.98894735\n",
      "Iteration 47, loss = 1829663.40438298\n",
      "Iteration 48, loss = 1829498.44920980\n",
      "Iteration 49, loss = 1829326.89174464\n",
      "Iteration 50, loss = 1829148.64764319\n",
      "Iteration 51, loss = 1828963.47983257\n",
      "Iteration 52, loss = 1828771.17637575\n",
      "Iteration 53, loss = 1828571.61800959\n",
      "Iteration 54, loss = 1828364.68905116\n",
      "Iteration 55, loss = 1828150.20958304\n",
      "Iteration 56, loss = 1827928.03772910\n",
      "Iteration 57, loss = 1827697.98452115\n",
      "Iteration 58, loss = 1827459.85708161\n",
      "Iteration 59, loss = 1827213.43519300\n",
      "Iteration 60, loss = 1826958.53044754\n",
      "Iteration 61, loss = 1826694.93722644\n",
      "Iteration 62, loss = 1826422.44166567\n",
      "Iteration 63, loss = 1826140.82085778\n",
      "Iteration 64, loss = 1825849.83488219\n",
      "Iteration 65, loss = 1825549.29333506\n",
      "Iteration 66, loss = 1825238.94040967\n",
      "Iteration 67, loss = 1824918.60209700\n",
      "Iteration 68, loss = 1824587.99401922\n",
      "Iteration 69, loss = 1824246.84876172\n",
      "Iteration 70, loss = 1823894.88094880\n",
      "Iteration 71, loss = 1823531.83026798\n",
      "Iteration 72, loss = 1823157.60525173\n",
      "Iteration 73, loss = 1822772.07449670\n",
      "Iteration 74, loss = 1822375.03485007\n",
      "Iteration 75, loss = 1821966.25753410\n",
      "Iteration 76, loss = 1821545.50064398\n",
      "Iteration 77, loss = 1821112.51772028\n",
      "Iteration 78, loss = 1820667.05703155\n",
      "Iteration 79, loss = 1820208.90582124\n",
      "Iteration 80, loss = 1819737.79023201\n",
      "Iteration 81, loss = 1819253.42910060\n",
      "Iteration 82, loss = 1818755.48087129\n",
      "Iteration 83, loss = 1818243.68164469\n",
      "Iteration 84, loss = 1817717.89436633\n",
      "Iteration 85, loss = 1817177.88975053\n",
      "Iteration 86, loss = 1816623.36517780\n",
      "Iteration 87, loss = 1816054.14413718\n",
      "Iteration 88, loss = 1815469.97440989\n",
      "Iteration 89, loss = 1814870.64042253\n",
      "Iteration 90, loss = 1814256.00714074\n",
      "Iteration 91, loss = 1813625.84493728\n",
      "Iteration 92, loss = 1812979.92870333\n",
      "Iteration 93, loss = 1812318.03713407\n",
      "Iteration 94, loss = 1811639.95047575\n",
      "Iteration 95, loss = 1810945.44737558\n",
      "Iteration 96, loss = 1810234.30729407\n",
      "Iteration 97, loss = 1809506.31531702\n",
      "Iteration 98, loss = 1808761.25766163\n",
      "Iteration 99, loss = 1807998.91702411\n",
      "Iteration 100, loss = 1807219.08101467\n",
      "Iteration 101, loss = 1806421.53702713\n",
      "Iteration 102, loss = 1805606.07675214\n",
      "Iteration 103, loss = 1804772.49291802\n",
      "Iteration 104, loss = 1803920.58422904\n",
      "Iteration 105, loss = 1803050.14365299\n",
      "Iteration 106, loss = 1802160.97187312\n",
      "Iteration 107, loss = 1801252.86937364\n",
      "Iteration 108, loss = 1800325.64346843\n",
      "Iteration 109, loss = 1799379.09712848\n",
      "Iteration 110, loss = 1798413.04087334\n",
      "Iteration 111, loss = 1797427.28953831\n",
      "Iteration 112, loss = 1796421.64908313\n",
      "Iteration 113, loss = 1795395.93323600\n",
      "Iteration 114, loss = 1794349.96530601\n",
      "Iteration 115, loss = 1793283.56892790\n",
      "Iteration 116, loss = 1792196.56220002\n",
      "Iteration 117, loss = 1791088.77305458\n",
      "Iteration 118, loss = 1789960.02880914\n",
      "Iteration 119, loss = 1788810.16080551\n",
      "Iteration 120, loss = 1787639.00829273\n",
      "Iteration 121, loss = 1786446.40339263\n",
      "Iteration 122, loss = 1785232.18635168\n",
      "Iteration 123, loss = 1783996.20164971\n",
      "Iteration 124, loss = 1782738.29544946\n",
      "Iteration 125, loss = 1781458.33223291\n",
      "Iteration 126, loss = 1780156.14981443\n",
      "Iteration 127, loss = 1778831.59896584\n",
      "Iteration 128, loss = 1777484.54243591\n",
      "Iteration 129, loss = 1776114.85089412\n",
      "Iteration 130, loss = 1774722.38662490\n",
      "Iteration 131, loss = 1773307.01449445\n",
      "Iteration 132, loss = 1771868.61707613\n",
      "Iteration 133, loss = 1770407.07346907\n",
      "Iteration 134, loss = 1768922.25655140\n",
      "Iteration 135, loss = 1767414.05843720\n",
      "Iteration 136, loss = 1765882.32304996\n",
      "Iteration 137, loss = 1764326.93996812\n",
      "Iteration 138, loss = 1762747.84887549\n",
      "Iteration 139, loss = 1761144.94120006\n",
      "Iteration 140, loss = 1759518.07920477\n",
      "Iteration 141, loss = 1757867.17574796\n",
      "Iteration 142, loss = 1756192.13917492\n",
      "Iteration 143, loss = 1754492.88537763\n",
      "Iteration 144, loss = 1752769.32056803\n",
      "Iteration 145, loss = 1751021.39066127\n",
      "Iteration 146, loss = 1749249.05224497\n",
      "Iteration 147, loss = 1747452.23739781\n",
      "Iteration 148, loss = 1745630.83094017\n",
      "Iteration 149, loss = 1743784.77429321\n",
      "Iteration 150, loss = 1741913.99960686\n",
      "Iteration 151, loss = 1740018.48982264\n",
      "Iteration 152, loss = 1738098.18983613\n",
      "Iteration 153, loss = 1736153.01549670\n",
      "Iteration 154, loss = 1734182.95856935\n",
      "Iteration 155, loss = 1732187.97512250\n",
      "Iteration 156, loss = 1730168.02049939\n",
      "Iteration 157, loss = 1728123.05261829\n",
      "Iteration 158, loss = 1726053.03596005\n",
      "Iteration 159, loss = 1723957.95987916\n",
      "Iteration 160, loss = 1721837.71064397\n",
      "Iteration 161, loss = 1719692.35242116\n",
      "Iteration 162, loss = 1717521.86293226\n",
      "Iteration 163, loss = 1715326.23451324\n",
      "Iteration 164, loss = 1713105.41755747\n",
      "Iteration 165, loss = 1710859.42792214\n",
      "Iteration 166, loss = 1708588.38390761\n",
      "Iteration 167, loss = 1706292.17609078\n",
      "Iteration 168, loss = 1703970.73291694\n",
      "Iteration 169, loss = 1701624.06903999\n",
      "Iteration 170, loss = 1699252.25900827\n",
      "Iteration 171, loss = 1696855.23960110\n",
      "Iteration 172, loss = 1694433.05574563\n",
      "Iteration 173, loss = 1691985.67485260\n",
      "Iteration 174, loss = 1689513.15955467\n",
      "Iteration 175, loss = 1687015.39310751\n",
      "Iteration 176, loss = 1684492.60742735\n",
      "Iteration 177, loss = 1681944.76514877\n",
      "Iteration 178, loss = 1679371.76635808\n",
      "Iteration 179, loss = 1676773.62886519\n",
      "Iteration 180, loss = 1674150.36708890\n",
      "Iteration 181, loss = 1671501.88429997\n",
      "Iteration 182, loss = 1668828.20662135\n",
      "Iteration 183, loss = 1666129.35334523\n",
      "Iteration 184, loss = 1663405.36684047\n",
      "Iteration 185, loss = 1660656.19975727\n",
      "Iteration 186, loss = 1657881.74919772\n",
      "Iteration 187, loss = 1655082.23261604\n",
      "Iteration 188, loss = 1652257.54449319\n",
      "Iteration 189, loss = 1649407.59673254\n",
      "Iteration 190, loss = 1646532.30699846\n",
      "Iteration 191, loss = 1643631.65225614\n",
      "Iteration 192, loss = 1640705.51578983\n",
      "Iteration 193, loss = 1637753.78073676\n",
      "Iteration 194, loss = 1634776.51193077\n",
      "Iteration 195, loss = 1631773.57490850\n",
      "Iteration 196, loss = 1628744.82761487\n",
      "Iteration 197, loss = 1625690.40239518\n",
      "Iteration 198, loss = 1622610.23969941\n",
      "Iteration 199, loss = 1619504.17251115\n",
      "Iteration 200, loss = 1616372.12279697\n",
      "Iteration 201, loss = 1613213.81794003\n",
      "Iteration 202, loss = 1610029.24422735\n",
      "Iteration 203, loss = 1606818.16784142\n",
      "Iteration 204, loss = 1603580.48460803\n",
      "Iteration 205, loss = 1600316.15291284\n",
      "Iteration 206, loss = 1597025.02738112\n",
      "Iteration 207, loss = 1593706.89884858\n",
      "Iteration 208, loss = 1590361.55575566\n",
      "Iteration 209, loss = 1586989.21897829\n",
      "Iteration 210, loss = 1583589.33792568\n",
      "Iteration 211, loss = 1580162.02890645\n",
      "Iteration 212, loss = 1576707.05670255\n",
      "Iteration 213, loss = 1573224.18967417\n",
      "Iteration 214, loss = 1569713.63363978\n",
      "Iteration 215, loss = 1566174.87410957\n",
      "Iteration 216, loss = 1562607.98313631\n",
      "Iteration 217, loss = 1559013.07406592\n",
      "Iteration 218, loss = 1555390.32336703\n",
      "Iteration 219, loss = 1551740.28583213\n",
      "Iteration 220, loss = 1548062.39840594\n",
      "Iteration 221, loss = 1544356.00352648\n",
      "Iteration 222, loss = 1540621.40845002\n",
      "Iteration 223, loss = 1536858.59313066\n",
      "Iteration 224, loss = 1533067.48229159\n",
      "Iteration 225, loss = 1529248.39241300\n",
      "Iteration 226, loss = 1525401.17816756\n",
      "Iteration 227, loss = 1521525.77980452\n",
      "Iteration 228, loss = 1517622.41327497\n",
      "Iteration 229, loss = 1513690.75294551\n",
      "Iteration 230, loss = 1509731.05367532\n",
      "Iteration 231, loss = 1505743.85137251\n",
      "Iteration 232, loss = 1501728.82751658\n",
      "Iteration 233, loss = 1497686.03372605\n",
      "Iteration 234, loss = 1493615.93140033\n",
      "Iteration 235, loss = 1489518.13742157\n",
      "Iteration 236, loss = 1485393.04361015\n",
      "Iteration 237, loss = 1481240.73319281\n",
      "Iteration 238, loss = 1477061.44532659\n",
      "Iteration 239, loss = 1472854.99868337\n",
      "Iteration 240, loss = 1468621.88726408\n",
      "Iteration 241, loss = 1464361.93130805\n",
      "Iteration 242, loss = 1460075.23377535\n",
      "Iteration 243, loss = 1455762.35225065\n",
      "Iteration 244, loss = 1451423.54643061\n",
      "Iteration 245, loss = 1447058.18528279\n",
      "Iteration 246, loss = 1442666.89436944\n",
      "Iteration 247, loss = 1438250.14949769\n",
      "Iteration 248, loss = 1433807.91177584\n",
      "Iteration 249, loss = 1429339.98327131\n",
      "Iteration 250, loss = 1424847.08301594\n",
      "Iteration 251, loss = 1420329.24301960\n",
      "Iteration 252, loss = 1415786.69564463\n",
      "Iteration 253, loss = 1411219.38342227\n",
      "Iteration 254, loss = 1406628.01713171\n",
      "Iteration 255, loss = 1402012.68282525\n",
      "Iteration 256, loss = 1397373.56842343\n",
      "Iteration 257, loss = 1392711.91027314\n",
      "Iteration 258, loss = 1388026.99975352\n",
      "Iteration 259, loss = 1383319.05784990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 260, loss = 1378588.23529209\n",
      "Iteration 261, loss = 1373835.30940339\n",
      "Iteration 262, loss = 1369060.26118085\n",
      "Iteration 263, loss = 1364262.97159673\n",
      "Iteration 264, loss = 1359444.62103206\n",
      "Iteration 265, loss = 1354604.67491244\n",
      "Iteration 266, loss = 1349743.42959778\n",
      "Iteration 267, loss = 1344861.90729091\n",
      "Iteration 268, loss = 1339960.25154626\n",
      "Iteration 269, loss = 1335038.05390281\n",
      "Iteration 270, loss = 1330095.60756875\n",
      "Iteration 271, loss = 1325134.14060077\n",
      "Iteration 272, loss = 1320153.75833376\n",
      "Iteration 273, loss = 1315154.13604489\n",
      "Iteration 274, loss = 1310136.30709000\n",
      "Iteration 275, loss = 1305100.21581413\n",
      "Iteration 276, loss = 1300047.43454205\n",
      "Iteration 277, loss = 1294977.68194410\n",
      "Iteration 278, loss = 1289890.75431549\n",
      "Iteration 279, loss = 1284786.80950550\n",
      "Iteration 280, loss = 1279666.65645506\n",
      "Iteration 281, loss = 1274530.74073202\n",
      "Iteration 282, loss = 1269379.14186307\n",
      "Iteration 283, loss = 1264212.11627927\n",
      "Iteration 284, loss = 1259030.51592040\n",
      "Iteration 285, loss = 1253834.83498742\n",
      "Iteration 286, loss = 1248624.83995300\n",
      "Iteration 287, loss = 1243401.21796261\n",
      "Iteration 288, loss = 1238164.27274259\n",
      "Iteration 289, loss = 1232914.08644194\n",
      "Iteration 290, loss = 1227651.40788671\n",
      "Iteration 291, loss = 1222376.78926584\n",
      "Iteration 292, loss = 1217089.51941018\n",
      "Iteration 293, loss = 1211790.92390085\n",
      "Iteration 294, loss = 1206480.74882880\n",
      "Iteration 295, loss = 1201159.56322287\n",
      "Iteration 296, loss = 1195828.37361133\n",
      "Iteration 297, loss = 1190487.78461759\n",
      "Iteration 298, loss = 1185138.39760222\n",
      "Iteration 299, loss = 1179778.84635860\n",
      "Iteration 300, loss = 1174413.33562990\n",
      "Iteration 301, loss = 1169038.32964781\n",
      "Iteration 302, loss = 1163655.22908806\n",
      "Iteration 303, loss = 1158264.03479703\n",
      "Iteration 304, loss = 1152866.06645077\n",
      "Iteration 305, loss = 1147460.23081007\n",
      "Iteration 306, loss = 1142049.66040261\n",
      "Iteration 307, loss = 1136631.87590167\n",
      "Iteration 308, loss = 1131208.49999963\n",
      "Iteration 309, loss = 1125779.22742790\n",
      "Iteration 310, loss = 1120345.26120516\n",
      "Iteration 311, loss = 1114906.79658615\n",
      "Iteration 312, loss = 1109461.22092315\n",
      "Iteration 313, loss = 1104012.80763838\n",
      "Iteration 314, loss = 1098560.62347440\n",
      "Iteration 315, loss = 1093103.69220867\n",
      "Iteration 316, loss = 1087641.84668933\n",
      "Iteration 317, loss = 1082182.59264204\n",
      "Iteration 318, loss = 1076723.81107375\n",
      "Iteration 319, loss = 1071263.01042208\n",
      "Iteration 320, loss = 1065801.63724040\n",
      "Iteration 321, loss = 1060339.33785612\n",
      "Iteration 322, loss = 1054874.78181619\n",
      "Iteration 323, loss = 1049410.14293626\n",
      "Iteration 324, loss = 1043947.12683312\n",
      "Iteration 325, loss = 1038483.83736584\n",
      "Iteration 326, loss = 1033020.35895586\n",
      "Iteration 327, loss = 1027558.15002625\n",
      "Iteration 328, loss = 1022096.48350852\n",
      "Iteration 329, loss = 1016635.86964787\n",
      "Iteration 330, loss = 1011175.55761067\n",
      "Iteration 331, loss = 1005717.67767411\n",
      "Iteration 332, loss = 1000260.36119176\n",
      "Iteration 333, loss = 994807.53926242\n",
      "Iteration 334, loss = 989363.91210306\n",
      "Iteration 335, loss = 983929.92280536\n",
      "Iteration 336, loss = 978503.73984429\n",
      "Iteration 337, loss = 973080.08970134\n",
      "Iteration 338, loss = 967662.28732627\n",
      "Iteration 339, loss = 962252.24166826\n",
      "Iteration 340, loss = 956850.27263823\n",
      "Iteration 341, loss = 951454.80871076\n",
      "Iteration 342, loss = 946066.37186858\n",
      "Iteration 343, loss = 940685.42625241\n",
      "Iteration 344, loss = 935313.36238859\n",
      "Iteration 345, loss = 929952.30146375\n",
      "Iteration 346, loss = 924602.05481707\n",
      "Iteration 347, loss = 919262.53249472\n",
      "Iteration 348, loss = 913934.24629081\n",
      "Iteration 349, loss = 908617.77963959\n",
      "Iteration 350, loss = 903312.64378282\n",
      "Iteration 351, loss = 898020.84672321\n",
      "Iteration 352, loss = 892742.26851703\n",
      "Iteration 353, loss = 887476.94621602\n",
      "Iteration 354, loss = 882224.67934005\n",
      "Iteration 355, loss = 876986.20638139\n",
      "Iteration 356, loss = 871761.19354451\n",
      "Iteration 357, loss = 866551.88405354\n",
      "Iteration 358, loss = 861356.85347035\n",
      "Iteration 359, loss = 856175.62814640\n",
      "Iteration 360, loss = 851009.57174215\n",
      "Iteration 361, loss = 845857.31488100\n",
      "Iteration 362, loss = 840719.98382608\n",
      "Iteration 363, loss = 835598.79130979\n",
      "Iteration 364, loss = 830493.43335564\n",
      "Iteration 365, loss = 825405.77569112\n",
      "Iteration 366, loss = 820339.78900231\n",
      "Iteration 367, loss = 815294.18305559\n",
      "Iteration 368, loss = 810265.48388819\n",
      "Iteration 369, loss = 805254.89276593\n",
      "Iteration 370, loss = 800263.14152051\n",
      "Iteration 371, loss = 795288.59412703\n",
      "Iteration 372, loss = 790333.12189915\n",
      "Iteration 373, loss = 785397.40644672\n",
      "Iteration 374, loss = 780480.77529305\n",
      "Iteration 375, loss = 775581.22962475\n",
      "Iteration 376, loss = 770703.59201392\n",
      "Iteration 377, loss = 765844.94833262\n",
      "Iteration 378, loss = 761003.14145502\n",
      "Iteration 379, loss = 756183.45596178\n",
      "Iteration 380, loss = 751380.00756420\n",
      "Iteration 381, loss = 746595.45894522\n",
      "Iteration 382, loss = 741832.57013947\n",
      "Iteration 383, loss = 737098.23820200\n",
      "Iteration 384, loss = 732388.55199074\n",
      "Iteration 385, loss = 727701.63795074\n",
      "Iteration 386, loss = 723039.70350175\n",
      "Iteration 387, loss = 718401.76715847\n",
      "Iteration 388, loss = 713782.75161310\n",
      "Iteration 389, loss = 709186.65456965\n",
      "Iteration 390, loss = 704616.89753607\n",
      "Iteration 391, loss = 700066.28507941\n",
      "Iteration 392, loss = 695538.75930380\n",
      "Iteration 393, loss = 691035.69236844\n",
      "Iteration 394, loss = 686554.79295290\n",
      "Iteration 395, loss = 682097.22714543\n",
      "Iteration 396, loss = 677661.64497754\n",
      "Iteration 397, loss = 673247.71399465\n",
      "Iteration 398, loss = 668859.84779087\n",
      "Iteration 399, loss = 664500.15681669\n",
      "Iteration 400, loss = 660169.35990552\n",
      "Iteration 401, loss = 655870.51632400\n",
      "Iteration 402, loss = 651595.79083509\n",
      "Iteration 403, loss = 647344.40907015\n",
      "Iteration 404, loss = 643121.88085912\n",
      "Iteration 405, loss = 638922.15593554\n",
      "Iteration 406, loss = 634749.22523013\n",
      "Iteration 407, loss = 630603.10651943\n",
      "Iteration 408, loss = 626482.49129062\n",
      "Iteration 409, loss = 622390.47527761\n",
      "Iteration 410, loss = 618325.47708143\n",
      "Iteration 411, loss = 614287.81317545\n",
      "Iteration 412, loss = 610278.06252465\n",
      "Iteration 413, loss = 606297.68502034\n",
      "Iteration 414, loss = 602344.54464003\n",
      "Iteration 415, loss = 598422.15130280\n",
      "Iteration 416, loss = 594528.55487359\n",
      "Iteration 417, loss = 590663.57646872\n",
      "Iteration 418, loss = 586827.05800329\n",
      "Iteration 419, loss = 583019.83915196\n",
      "Iteration 420, loss = 579242.99844513\n",
      "Iteration 421, loss = 575493.42867363\n",
      "Iteration 422, loss = 571775.94611987\n",
      "Iteration 423, loss = 568086.45112300\n",
      "Iteration 424, loss = 564423.72347487\n",
      "Iteration 425, loss = 560791.46945769\n",
      "Iteration 426, loss = 557185.71307925\n",
      "Iteration 427, loss = 553608.41077469\n",
      "Iteration 428, loss = 550056.84809760\n",
      "Iteration 429, loss = 546532.31777758\n",
      "Iteration 430, loss = 543034.33201082\n",
      "Iteration 431, loss = 539558.88043863\n",
      "Iteration 432, loss = 536109.86409333\n",
      "Iteration 433, loss = 532692.93464081\n",
      "Iteration 434, loss = 529308.96626360\n",
      "Iteration 435, loss = 525960.06360089\n",
      "Iteration 436, loss = 522638.81123270\n",
      "Iteration 437, loss = 519342.45722909\n",
      "Iteration 438, loss = 516073.11503366\n",
      "Iteration 439, loss = 512830.19926230\n",
      "Iteration 440, loss = 509614.71757952\n",
      "Iteration 441, loss = 506426.09416234\n",
      "Iteration 442, loss = 503263.50933582\n",
      "Iteration 443, loss = 500128.63632272\n",
      "Iteration 444, loss = 497019.53788097\n",
      "Iteration 445, loss = 493938.69180430\n",
      "Iteration 446, loss = 490887.03361776\n",
      "Iteration 447, loss = 487861.95033301\n",
      "Iteration 448, loss = 484865.12263589\n",
      "Iteration 449, loss = 481895.85939079\n",
      "Iteration 450, loss = 478953.61583103\n",
      "Iteration 451, loss = 476038.04518947\n",
      "Iteration 452, loss = 473151.11996138\n",
      "Iteration 453, loss = 470291.23472972\n",
      "Iteration 454, loss = 467457.47805080\n",
      "Iteration 455, loss = 464652.08161887\n",
      "Iteration 456, loss = 461871.97794569\n",
      "Iteration 457, loss = 459120.36509513\n",
      "Iteration 458, loss = 456394.66747375\n",
      "Iteration 459, loss = 453693.61193447\n",
      "Iteration 460, loss = 451016.92221728\n",
      "Iteration 461, loss = 448364.41430511\n",
      "Iteration 462, loss = 445736.34820155\n",
      "Iteration 463, loss = 443130.96331135\n",
      "Iteration 464, loss = 440546.49076543\n",
      "Iteration 465, loss = 437984.20125191\n",
      "Iteration 466, loss = 435442.06857570\n",
      "Iteration 467, loss = 432922.34729155\n",
      "Iteration 468, loss = 430434.50672022\n",
      "Iteration 469, loss = 427973.51736829\n",
      "Iteration 470, loss = 425539.03911883\n",
      "Iteration 471, loss = 423126.25879226\n",
      "Iteration 472, loss = 420735.53415846\n",
      "Iteration 473, loss = 418367.02594506\n",
      "Iteration 474, loss = 416020.44264816\n",
      "Iteration 475, loss = 413694.66425942\n",
      "Iteration 476, loss = 411387.46427844\n",
      "Iteration 477, loss = 409104.44311843\n",
      "Iteration 478, loss = 406843.11230679\n",
      "Iteration 479, loss = 404597.58163321\n",
      "Iteration 480, loss = 402374.54154600\n",
      "Iteration 481, loss = 400170.42926401\n",
      "Iteration 482, loss = 397984.55931111\n",
      "Iteration 483, loss = 395815.17550959\n",
      "Iteration 484, loss = 393663.47126156\n",
      "Iteration 485, loss = 391528.58372983\n",
      "Iteration 486, loss = 389411.20791279\n",
      "Iteration 487, loss = 387306.08920304\n",
      "Iteration 488, loss = 385222.94227223\n",
      "Iteration 489, loss = 383168.94373077\n",
      "Iteration 490, loss = 381135.87768131\n",
      "Iteration 491, loss = 379126.41462195\n",
      "Iteration 492, loss = 377135.20658958\n",
      "Iteration 493, loss = 375158.43620525\n",
      "Iteration 494, loss = 373198.61878340\n",
      "Iteration 495, loss = 371254.52920777\n",
      "Iteration 496, loss = 369327.16888562\n",
      "Iteration 497, loss = 367414.82711005\n",
      "Iteration 498, loss = 365522.59916103\n",
      "Iteration 499, loss = 363648.62191831\n",
      "Iteration 500, loss = 361787.23854988\n",
      "Iteration 501, loss = 359945.65859654\n",
      "Iteration 502, loss = 358121.32109216\n",
      "Iteration 503, loss = 356310.20044948\n",
      "Iteration 504, loss = 354516.08761882\n",
      "Iteration 505, loss = 352742.28286723\n",
      "Iteration 506, loss = 350983.98843610\n",
      "Iteration 507, loss = 349241.27871704\n",
      "Iteration 508, loss = 347514.77308201\n",
      "Iteration 509, loss = 345805.62758011\n",
      "Iteration 510, loss = 344112.00184483\n",
      "Iteration 511, loss = 342437.05787833\n",
      "Iteration 512, loss = 340773.50936745\n",
      "Iteration 513, loss = 339123.97550995\n",
      "Iteration 514, loss = 337495.50959398\n",
      "Iteration 515, loss = 335879.04315044\n",
      "Iteration 516, loss = 334273.49593379\n",
      "Iteration 517, loss = 332690.33648538\n",
      "Iteration 518, loss = 331118.02002519\n",
      "Iteration 519, loss = 329556.71873902\n",
      "Iteration 520, loss = 328015.42310365\n",
      "Iteration 521, loss = 326483.59114670\n",
      "Iteration 522, loss = 324963.53478062\n",
      "Iteration 523, loss = 323460.27303858\n",
      "Iteration 524, loss = 321966.55104310\n",
      "Iteration 525, loss = 320484.79932317\n",
      "Iteration 526, loss = 319016.70125897\n",
      "Iteration 527, loss = 317557.87282982\n",
      "Iteration 528, loss = 316108.15331689\n",
      "Iteration 529, loss = 314672.29993016\n",
      "Iteration 530, loss = 313240.50734017\n",
      "Iteration 531, loss = 311820.94219132\n",
      "Iteration 532, loss = 310410.69227871\n",
      "Iteration 533, loss = 309005.82596405\n",
      "Iteration 534, loss = 307611.49546625\n",
      "Iteration 535, loss = 306223.11331673\n",
      "Iteration 536, loss = 304838.84877880\n",
      "Iteration 537, loss = 303462.92694716\n",
      "Iteration 538, loss = 302095.74951656\n",
      "Iteration 539, loss = 300738.36780313\n",
      "Iteration 540, loss = 299398.22924021\n",
      "Iteration 541, loss = 298077.35168711\n",
      "Iteration 542, loss = 296770.37470407\n",
      "Iteration 543, loss = 295479.93837212\n",
      "Iteration 544, loss = 294195.96342643\n",
      "Iteration 545, loss = 292914.13792646\n",
      "Iteration 546, loss = 291639.53693672\n",
      "Iteration 547, loss = 290376.13258959\n",
      "Iteration 548, loss = 289118.13536173\n",
      "Iteration 549, loss = 287864.73089098\n",
      "Iteration 550, loss = 286625.04340292\n",
      "Iteration 551, loss = 285393.17637092\n",
      "Iteration 552, loss = 284170.72086249\n",
      "Iteration 553, loss = 282954.90781251\n",
      "Iteration 554, loss = 281749.84155076\n",
      "Iteration 555, loss = 280555.95170648\n",
      "Iteration 556, loss = 279366.57205376\n",
      "Iteration 557, loss = 278186.82737638\n",
      "Iteration 558, loss = 277018.17403159\n",
      "Iteration 559, loss = 275856.39957181\n",
      "Iteration 560, loss = 274700.56820992\n",
      "Iteration 561, loss = 273555.51022331\n",
      "Iteration 562, loss = 272418.72761592\n",
      "Iteration 563, loss = 271285.66339196\n",
      "Iteration 564, loss = 270161.83444885\n",
      "Iteration 565, loss = 269046.46167689\n",
      "Iteration 566, loss = 267934.36590813\n",
      "Iteration 567, loss = 266827.19539498\n",
      "Iteration 568, loss = 265727.24946457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 569, loss = 264634.62833122\n",
      "Iteration 570, loss = 263548.30202217\n",
      "Iteration 571, loss = 262466.27776239\n",
      "Iteration 572, loss = 261392.37944261\n",
      "Iteration 573, loss = 260324.98164849\n",
      "Iteration 574, loss = 259267.35065955\n",
      "Iteration 575, loss = 258216.76393096\n",
      "Iteration 576, loss = 257172.02736495\n",
      "Iteration 577, loss = 256136.55419556\n",
      "Iteration 578, loss = 255104.32404098\n",
      "Iteration 579, loss = 254076.52710093\n",
      "Iteration 580, loss = 253055.26197362\n",
      "Iteration 581, loss = 252040.34769654\n",
      "Iteration 582, loss = 251032.54559972\n",
      "Iteration 583, loss = 250033.49058611\n",
      "Iteration 584, loss = 249039.33043149\n",
      "Iteration 585, loss = 248050.62466088\n",
      "Iteration 586, loss = 247068.45197280\n",
      "Iteration 587, loss = 246092.07476232\n",
      "Iteration 588, loss = 245121.32612619\n",
      "Iteration 589, loss = 244155.67183315\n",
      "Iteration 590, loss = 243198.26468310\n",
      "Iteration 591, loss = 242244.41537373\n",
      "Iteration 592, loss = 241296.41861236\n",
      "Iteration 593, loss = 240351.88258703\n",
      "Iteration 594, loss = 239416.12167724\n",
      "Iteration 595, loss = 238485.73782581\n",
      "Iteration 596, loss = 237557.17556700\n",
      "Iteration 597, loss = 236635.56738272\n",
      "Iteration 598, loss = 235720.58386777\n",
      "Iteration 599, loss = 234808.36199680\n",
      "Iteration 600, loss = 233899.10373752\n",
      "Iteration 601, loss = 232996.10377376\n",
      "Iteration 602, loss = 232097.04393572\n",
      "Iteration 603, loss = 231203.26726498\n",
      "Iteration 604, loss = 230312.97121247\n",
      "Iteration 605, loss = 229426.43158953\n",
      "Iteration 606, loss = 228544.80350208\n",
      "Iteration 607, loss = 227667.17519888\n",
      "Iteration 608, loss = 226791.54584144\n",
      "Iteration 609, loss = 225918.67040045\n",
      "Iteration 610, loss = 225051.75615809\n",
      "Iteration 611, loss = 224188.07154463\n",
      "Iteration 612, loss = 223325.28750987\n",
      "Iteration 613, loss = 222467.58335283\n",
      "Iteration 614, loss = 221615.31083484\n",
      "Iteration 615, loss = 220763.87711042\n",
      "Iteration 616, loss = 219917.21306033\n",
      "Iteration 617, loss = 219077.13178022\n",
      "Iteration 618, loss = 218239.70803046\n",
      "Iteration 619, loss = 217404.60648317\n",
      "Iteration 620, loss = 216576.44653605\n",
      "Iteration 621, loss = 215754.05731467\n",
      "Iteration 622, loss = 214933.83875227\n",
      "Iteration 623, loss = 214115.76758556\n",
      "Iteration 624, loss = 213300.41510836\n",
      "Iteration 625, loss = 212489.21537546\n",
      "Iteration 626, loss = 211680.63309703\n",
      "Iteration 627, loss = 210874.73640422\n",
      "Iteration 628, loss = 210076.67552615\n",
      "Iteration 629, loss = 209282.11630651\n",
      "Iteration 630, loss = 208490.59421079\n",
      "Iteration 631, loss = 207699.59065371\n",
      "Iteration 632, loss = 206913.38764311\n",
      "Iteration 633, loss = 206131.46067950\n",
      "Iteration 634, loss = 205352.07608663\n",
      "Iteration 635, loss = 204575.47526934\n",
      "Iteration 636, loss = 203804.42573011\n",
      "Iteration 637, loss = 203037.47947083\n",
      "Iteration 638, loss = 202272.68336082\n",
      "Iteration 639, loss = 201508.83593994\n",
      "Iteration 640, loss = 200748.65109814\n",
      "Iteration 641, loss = 199995.37263531\n",
      "Iteration 642, loss = 199243.20930960\n",
      "Iteration 643, loss = 198493.51997504\n",
      "Iteration 644, loss = 197745.84834165\n",
      "Iteration 645, loss = 197002.45012954\n",
      "Iteration 646, loss = 196262.22787632\n",
      "Iteration 647, loss = 195525.65215680\n",
      "Iteration 648, loss = 194789.95526705\n",
      "Iteration 649, loss = 194058.79741007\n",
      "Iteration 650, loss = 193333.16839686\n",
      "Iteration 651, loss = 192608.58445237\n",
      "Iteration 652, loss = 191886.40408486\n",
      "Iteration 653, loss = 191166.51366673\n",
      "Iteration 654, loss = 190451.27443166\n",
      "Iteration 655, loss = 189740.14001165\n",
      "Iteration 656, loss = 189028.80782709\n",
      "Iteration 657, loss = 188319.30268739\n",
      "Iteration 658, loss = 187615.10964525\n",
      "Iteration 659, loss = 186911.59636492\n",
      "Iteration 660, loss = 186210.42517185\n",
      "Iteration 661, loss = 185513.61167648\n",
      "Iteration 662, loss = 184819.27350086\n",
      "Iteration 663, loss = 184127.51616472\n",
      "Iteration 664, loss = 183438.53193152\n",
      "Iteration 665, loss = 182752.23594520\n",
      "Iteration 666, loss = 182070.16019683\n",
      "Iteration 667, loss = 181391.23835615\n",
      "Iteration 668, loss = 180713.55698325\n",
      "Iteration 669, loss = 180038.54723963\n",
      "Iteration 670, loss = 179367.62096417\n",
      "Iteration 671, loss = 178697.44123669\n",
      "Iteration 672, loss = 178030.04590302\n",
      "Iteration 673, loss = 177365.10947112\n",
      "Iteration 674, loss = 176704.08089642\n",
      "Iteration 675, loss = 176043.38385091\n",
      "Iteration 676, loss = 175385.88749043\n",
      "Iteration 677, loss = 174732.16244941\n",
      "Iteration 678, loss = 174079.43411053\n",
      "Iteration 679, loss = 173429.01749594\n",
      "Iteration 680, loss = 172781.67603685\n",
      "Iteration 681, loss = 172136.40841029\n",
      "Iteration 682, loss = 171493.42313836\n",
      "Iteration 683, loss = 170853.45864196\n",
      "Iteration 684, loss = 170216.19213282\n",
      "Iteration 685, loss = 169581.43851628\n",
      "Iteration 686, loss = 168949.11084817\n",
      "Iteration 687, loss = 168317.93408271\n",
      "Iteration 688, loss = 167689.84096023\n",
      "Iteration 689, loss = 167063.57202787\n",
      "Iteration 690, loss = 166439.44400454\n",
      "Iteration 691, loss = 165816.75670924\n",
      "Iteration 692, loss = 165196.99732031\n",
      "Iteration 693, loss = 164579.69803526\n",
      "Iteration 694, loss = 163964.47192715\n",
      "Iteration 695, loss = 163351.52982346\n",
      "Iteration 696, loss = 162741.08283022\n",
      "Iteration 697, loss = 162131.97499960\n",
      "Iteration 698, loss = 161524.67685273\n",
      "Iteration 699, loss = 160919.61205649\n",
      "Iteration 700, loss = 160316.71684432\n",
      "Iteration 701, loss = 159716.32688737\n",
      "Iteration 702, loss = 159117.39063254\n",
      "Iteration 703, loss = 158519.61987409\n",
      "Iteration 704, loss = 157924.59764485\n",
      "Iteration 705, loss = 157332.17922047\n",
      "Iteration 706, loss = 156741.30119351\n",
      "Iteration 707, loss = 156151.73303800\n",
      "Iteration 708, loss = 155564.99633105\n",
      "Iteration 709, loss = 154980.44982334\n",
      "Iteration 710, loss = 154397.35799321\n",
      "Iteration 711, loss = 153816.50741371\n",
      "Iteration 712, loss = 153237.94948247\n",
      "Iteration 713, loss = 152661.33008115\n",
      "Iteration 714, loss = 152086.15451618\n",
      "Iteration 715, loss = 151514.34722319\n",
      "Iteration 716, loss = 150944.48256828\n",
      "Iteration 717, loss = 150376.17544832\n",
      "Iteration 718, loss = 149809.72979437\n",
      "Iteration 719, loss = 149244.68949815\n",
      "Iteration 720, loss = 148681.14813440\n",
      "Iteration 721, loss = 148120.05865239\n",
      "Iteration 722, loss = 147561.33794574\n",
      "Iteration 723, loss = 147003.92289414\n",
      "Iteration 724, loss = 146447.51070099\n",
      "Iteration 725, loss = 145894.61598342\n",
      "Iteration 726, loss = 145344.34417971\n",
      "Iteration 727, loss = 144795.98427077\n",
      "Iteration 728, loss = 144249.05453637\n",
      "Iteration 729, loss = 143704.69789621\n",
      "Iteration 730, loss = 143162.64710211\n",
      "Iteration 731, loss = 142621.16568139\n",
      "Iteration 732, loss = 142082.23596913\n",
      "Iteration 733, loss = 141546.15209287\n",
      "Iteration 734, loss = 141011.59272983\n",
      "Iteration 735, loss = 140478.28769109\n",
      "Iteration 736, loss = 139945.65094021\n",
      "Iteration 737, loss = 139415.31934048\n",
      "Iteration 738, loss = 138886.73342003\n",
      "Iteration 739, loss = 138361.08571325\n",
      "Iteration 740, loss = 137836.86430055\n",
      "Iteration 741, loss = 137314.29319521\n",
      "Iteration 742, loss = 136793.46790689\n",
      "Iteration 743, loss = 136276.03473391\n",
      "Iteration 744, loss = 135759.91475898\n",
      "Iteration 745, loss = 135245.03625400\n",
      "Iteration 746, loss = 134732.01444652\n",
      "Iteration 747, loss = 134220.25839039\n",
      "Iteration 748, loss = 133709.23915361\n",
      "Iteration 749, loss = 133200.98632071\n",
      "Iteration 750, loss = 132694.54334637\n",
      "Iteration 751, loss = 132190.13414837\n",
      "Iteration 752, loss = 131686.94441013\n",
      "Iteration 753, loss = 131184.96835858\n",
      "Iteration 754, loss = 130684.28052202\n",
      "Iteration 755, loss = 130185.58964479\n",
      "Iteration 756, loss = 129690.93736308\n",
      "Iteration 757, loss = 129197.55759634\n",
      "Iteration 758, loss = 128705.44448992\n",
      "Iteration 759, loss = 128214.81814924\n",
      "Iteration 760, loss = 127726.94903037\n",
      "Iteration 761, loss = 127240.09633299\n",
      "Iteration 762, loss = 126754.95459116\n",
      "Iteration 763, loss = 126272.17654701\n",
      "Iteration 764, loss = 125791.04618244\n",
      "Iteration 765, loss = 125311.01223978\n",
      "Iteration 766, loss = 124832.71615617\n",
      "Iteration 767, loss = 124355.99666909\n",
      "Iteration 768, loss = 123880.61659777\n",
      "Iteration 769, loss = 123406.37595758\n",
      "Iteration 770, loss = 122934.54227425\n",
      "Iteration 771, loss = 122464.21678592\n",
      "Iteration 772, loss = 121994.95648943\n",
      "Iteration 773, loss = 121527.89190158\n",
      "Iteration 774, loss = 121062.05708437\n",
      "Iteration 775, loss = 120597.36815996\n",
      "Iteration 776, loss = 120134.94281300\n",
      "Iteration 777, loss = 119673.63098745\n",
      "Iteration 778, loss = 119213.75553898\n",
      "Iteration 779, loss = 118754.84585628\n",
      "Iteration 780, loss = 118298.42076795\n",
      "Iteration 781, loss = 117844.02132757\n",
      "Iteration 782, loss = 117390.58487004\n",
      "Iteration 783, loss = 116938.55213655\n",
      "Iteration 784, loss = 116487.85914464\n",
      "Iteration 785, loss = 116039.07893473\n",
      "Iteration 786, loss = 115590.76191978\n",
      "Iteration 787, loss = 115144.64859116\n",
      "Iteration 788, loss = 114701.42803785\n",
      "Iteration 789, loss = 114259.18683653\n",
      "Iteration 790, loss = 113817.50790163\n",
      "Iteration 791, loss = 113376.71489749\n",
      "Iteration 792, loss = 112937.75398201\n",
      "Iteration 793, loss = 112500.34245735\n",
      "Iteration 794, loss = 112064.95226771\n",
      "Iteration 795, loss = 111630.51733357\n",
      "Iteration 796, loss = 111197.90232058\n",
      "Iteration 797, loss = 110766.29256763\n",
      "Iteration 798, loss = 110335.78884991\n",
      "Iteration 799, loss = 109907.36515212\n",
      "Iteration 800, loss = 109481.65624666\n",
      "Iteration 801, loss = 109056.67177223\n",
      "Iteration 802, loss = 108633.33121943\n",
      "Iteration 803, loss = 108211.36920833\n",
      "Iteration 804, loss = 107791.76493195\n",
      "Iteration 805, loss = 107372.92097269\n",
      "Iteration 806, loss = 106955.13059170\n",
      "Iteration 807, loss = 106538.64683290\n",
      "Iteration 808, loss = 106124.14941723\n",
      "Iteration 809, loss = 105711.44535052\n",
      "Iteration 810, loss = 105299.86456330\n",
      "Iteration 811, loss = 104889.64510604\n",
      "Iteration 812, loss = 104481.70253188\n",
      "Iteration 813, loss = 104074.41808634\n",
      "Iteration 814, loss = 103668.76747844\n",
      "Iteration 815, loss = 103264.55610511\n",
      "Iteration 816, loss = 102861.54504765\n",
      "Iteration 817, loss = 102460.74274563\n",
      "Iteration 818, loss = 102061.89143984\n",
      "Iteration 819, loss = 101664.02270795\n",
      "Iteration 820, loss = 101267.27493389\n",
      "Iteration 821, loss = 100872.86732138\n",
      "Iteration 822, loss = 100479.21547620\n",
      "Iteration 823, loss = 100087.35742458\n",
      "Iteration 824, loss = 99697.13045010\n",
      "Iteration 825, loss = 99308.50943543\n",
      "Iteration 826, loss = 98920.70528221\n",
      "Iteration 827, loss = 98534.21437655\n",
      "Iteration 828, loss = 98149.28356591\n",
      "Iteration 829, loss = 97765.89419035\n",
      "Iteration 830, loss = 97383.84494005\n",
      "Iteration 831, loss = 97002.26177766\n",
      "Iteration 832, loss = 96623.21464044\n",
      "Iteration 833, loss = 96245.41902708\n",
      "Iteration 834, loss = 95868.57994849\n",
      "Iteration 835, loss = 95492.73671670\n",
      "Iteration 836, loss = 95119.61758318\n",
      "Iteration 837, loss = 94748.46093073\n",
      "Iteration 838, loss = 94379.03146113\n",
      "Iteration 839, loss = 94011.37968792\n",
      "Iteration 840, loss = 93644.55549112\n",
      "Iteration 841, loss = 93279.84384831\n",
      "Iteration 842, loss = 92915.93161009\n",
      "Iteration 843, loss = 92553.20382900\n",
      "Iteration 844, loss = 92192.09972189\n",
      "Iteration 845, loss = 91832.13639072\n",
      "Iteration 846, loss = 91474.07970879\n",
      "Iteration 847, loss = 91117.00167808\n",
      "Iteration 848, loss = 90761.18847769\n",
      "Iteration 849, loss = 90406.90091393\n",
      "Iteration 850, loss = 90053.38557912\n",
      "Iteration 851, loss = 89701.52038759\n",
      "Iteration 852, loss = 89351.25143166\n",
      "Iteration 853, loss = 89002.09209729\n",
      "Iteration 854, loss = 88654.01879015\n",
      "Iteration 855, loss = 88306.95085116\n",
      "Iteration 856, loss = 87961.30545597\n",
      "Iteration 857, loss = 87617.29992061\n",
      "Iteration 858, loss = 87274.33745966\n",
      "Iteration 859, loss = 86932.74915671\n",
      "Iteration 860, loss = 86592.47814548\n",
      "Iteration 861, loss = 86252.90613689\n",
      "Iteration 862, loss = 85914.70058119\n",
      "Iteration 863, loss = 85578.30158483\n",
      "Iteration 864, loss = 85242.67775682\n",
      "Iteration 865, loss = 84907.56811652\n",
      "Iteration 866, loss = 84574.15802845\n",
      "Iteration 867, loss = 84241.92655475\n",
      "Iteration 868, loss = 83910.17099979\n",
      "Iteration 869, loss = 83579.59691952\n",
      "Iteration 870, loss = 83250.37599828\n",
      "Iteration 871, loss = 82921.78470656\n",
      "Iteration 872, loss = 82594.64540650\n",
      "Iteration 873, loss = 82268.52023176\n",
      "Iteration 874, loss = 81943.96241188\n",
      "Iteration 875, loss = 81620.48909620\n",
      "Iteration 876, loss = 81297.32495428\n",
      "Iteration 877, loss = 80975.07318896\n",
      "Iteration 878, loss = 80654.08354263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 879, loss = 80334.08715216\n",
      "Iteration 880, loss = 80014.24099158\n",
      "Iteration 881, loss = 79696.95275923\n",
      "Iteration 882, loss = 79381.91707439\n",
      "Iteration 883, loss = 79067.27669443\n",
      "Iteration 884, loss = 78753.42933365\n",
      "Iteration 885, loss = 78440.77611659\n",
      "Iteration 886, loss = 78128.47860505\n",
      "Iteration 887, loss = 77817.21460193\n",
      "Iteration 888, loss = 77507.83333661\n",
      "Iteration 889, loss = 77199.97009945\n",
      "Iteration 890, loss = 76892.23083464\n",
      "Iteration 891, loss = 76587.13321041\n",
      "Iteration 892, loss = 76283.72520193\n",
      "Iteration 893, loss = 75981.06782774\n",
      "Iteration 894, loss = 75679.61120079\n",
      "Iteration 895, loss = 75379.59967012\n",
      "Iteration 896, loss = 75080.20020220\n",
      "Iteration 897, loss = 74781.60371005\n",
      "Iteration 898, loss = 74484.72898558\n",
      "Iteration 899, loss = 74188.15258182\n",
      "Iteration 900, loss = 73893.20543612\n",
      "Iteration 901, loss = 73598.98483882\n",
      "Iteration 902, loss = 73306.16686117\n",
      "Iteration 903, loss = 73013.82735743\n",
      "Iteration 904, loss = 72723.00000666\n",
      "Iteration 905, loss = 72433.35350609\n",
      "Iteration 906, loss = 72144.94307835\n",
      "Iteration 907, loss = 71857.69444313\n",
      "Iteration 908, loss = 71571.35982298\n",
      "Iteration 909, loss = 71285.69334292\n",
      "Iteration 910, loss = 71001.53230209\n",
      "Iteration 911, loss = 70719.01853903\n",
      "Iteration 912, loss = 70437.14133121\n",
      "Iteration 913, loss = 70156.45975394\n",
      "Iteration 914, loss = 69876.58728356\n",
      "Iteration 915, loss = 69597.81651806\n",
      "Iteration 916, loss = 69319.59897934\n",
      "Iteration 917, loss = 69042.59533324\n",
      "Iteration 918, loss = 68766.49162678\n",
      "Iteration 919, loss = 68491.74090902\n",
      "Iteration 920, loss = 68217.93620946\n",
      "Iteration 921, loss = 67944.67864078\n",
      "Iteration 922, loss = 67672.68470141\n",
      "Iteration 923, loss = 67401.90715429\n",
      "Iteration 924, loss = 67131.47301758\n",
      "Iteration 925, loss = 66862.28052441\n",
      "Iteration 926, loss = 66595.28514147\n",
      "Iteration 927, loss = 66329.45940790\n",
      "Iteration 928, loss = 66064.42720125\n",
      "Iteration 929, loss = 65799.68473129\n",
      "Iteration 930, loss = 65535.82483837\n",
      "Iteration 931, loss = 65274.04639188\n",
      "Iteration 932, loss = 65012.73324870\n",
      "Iteration 933, loss = 64751.96617251\n",
      "Iteration 934, loss = 64492.87299235\n",
      "Iteration 935, loss = 64234.63925157\n",
      "Iteration 936, loss = 63977.42987511\n",
      "Iteration 937, loss = 63721.19363665\n",
      "Iteration 938, loss = 63465.79226843\n",
      "Iteration 939, loss = 63211.62187448\n",
      "Iteration 940, loss = 62958.82094125\n",
      "Iteration 941, loss = 62706.69993395\n",
      "Iteration 942, loss = 62455.86223083\n",
      "Iteration 943, loss = 62205.86568356\n",
      "Iteration 944, loss = 61956.85956936\n",
      "Iteration 945, loss = 61709.44201094\n",
      "Iteration 946, loss = 61462.86541042\n",
      "Iteration 947, loss = 61217.17176042\n",
      "Iteration 948, loss = 60972.54638128\n",
      "Iteration 949, loss = 60728.94542134\n",
      "Iteration 950, loss = 60486.66267857\n",
      "Iteration 951, loss = 60245.25608416\n",
      "Iteration 952, loss = 60004.87756080\n",
      "Iteration 953, loss = 59765.65733521\n",
      "Iteration 954, loss = 59527.17766517\n",
      "Iteration 955, loss = 59289.78701602\n",
      "Iteration 956, loss = 59053.19838940\n",
      "Iteration 957, loss = 58817.56934091\n",
      "Iteration 958, loss = 58582.84939194\n",
      "Iteration 959, loss = 58349.02114976\n",
      "Iteration 960, loss = 58115.97733204\n",
      "Iteration 961, loss = 57883.77814222\n",
      "Iteration 962, loss = 57652.61967815\n",
      "Iteration 963, loss = 57422.39978149\n",
      "Iteration 964, loss = 57193.04247320\n",
      "Iteration 965, loss = 56964.55818389\n",
      "Iteration 966, loss = 56736.53738760\n",
      "Iteration 967, loss = 56509.78226367\n",
      "Iteration 968, loss = 56283.81920810\n",
      "Iteration 969, loss = 56058.63272440\n",
      "Iteration 970, loss = 55833.98785642\n",
      "Iteration 971, loss = 55609.94883571\n",
      "Iteration 972, loss = 55386.54875027\n",
      "Iteration 973, loss = 55164.23411832\n",
      "Iteration 974, loss = 54942.51722559\n",
      "Iteration 975, loss = 54721.64748635\n",
      "Iteration 976, loss = 54501.57374435\n",
      "Iteration 977, loss = 54282.52351002\n",
      "Iteration 978, loss = 54063.90331536\n",
      "Iteration 979, loss = 53845.89675222\n",
      "Iteration 980, loss = 53628.82931822\n",
      "Iteration 981, loss = 53412.41466138\n",
      "Iteration 982, loss = 53196.50089126\n",
      "Iteration 983, loss = 52981.36060073\n",
      "Iteration 984, loss = 52766.85524029\n",
      "Iteration 985, loss = 52553.03748318\n",
      "Iteration 986, loss = 52339.97337923\n",
      "Iteration 987, loss = 52129.08623802\n",
      "Iteration 988, loss = 51918.98595310\n",
      "Iteration 989, loss = 51710.42238721\n",
      "Iteration 990, loss = 51503.26946830\n",
      "Iteration 991, loss = 51296.68334929\n",
      "Iteration 992, loss = 51090.92109363\n",
      "Iteration 993, loss = 50885.70717782\n",
      "Iteration 994, loss = 50681.08843002\n",
      "Iteration 995, loss = 50477.37388499\n",
      "Iteration 996, loss = 50274.06345033\n",
      "Iteration 997, loss = 50071.70908479\n",
      "Iteration 998, loss = 49870.97336286\n",
      "Iteration 999, loss = 49671.68486799\n",
      "Iteration 1000, loss = 49473.15437721\n",
      "Iteration 1001, loss = 49275.42257470\n",
      "Iteration 1002, loss = 49078.50289167\n",
      "Iteration 1003, loss = 48882.19727843\n",
      "Iteration 1004, loss = 48686.66014075\n",
      "Iteration 1005, loss = 48492.05219880\n",
      "Iteration 1006, loss = 48298.18737120\n",
      "Iteration 1007, loss = 48105.01414996\n",
      "Iteration 1008, loss = 47912.74052353\n",
      "Iteration 1009, loss = 47721.23923287\n",
      "Iteration 1010, loss = 47530.46099941\n",
      "Iteration 1011, loss = 47340.22167367\n",
      "Iteration 1012, loss = 47150.71120009\n",
      "Iteration 1013, loss = 46961.88108213\n",
      "Iteration 1014, loss = 46773.92043083\n",
      "Iteration 1015, loss = 46586.69752774\n",
      "Iteration 1016, loss = 46400.25148197\n",
      "Iteration 1017, loss = 46214.46417836\n",
      "Iteration 1018, loss = 46029.35647644\n",
      "Iteration 1019, loss = 45845.01437121\n",
      "Iteration 1020, loss = 45661.45982437\n",
      "Iteration 1021, loss = 45478.82945154\n",
      "Iteration 1022, loss = 45297.37295843\n",
      "Iteration 1023, loss = 45116.57859706\n",
      "Iteration 1024, loss = 44936.34848420\n",
      "Iteration 1025, loss = 44756.69666492\n",
      "Iteration 1026, loss = 44577.69413210\n",
      "Iteration 1027, loss = 44399.28507335\n",
      "Iteration 1028, loss = 44221.83808806\n",
      "Iteration 1029, loss = 44045.34986253\n",
      "Iteration 1030, loss = 43869.89992526\n",
      "Iteration 1031, loss = 43695.56704629\n",
      "Iteration 1032, loss = 43521.84055588\n",
      "Iteration 1033, loss = 43348.82268321\n",
      "Iteration 1034, loss = 43176.74706040\n",
      "Iteration 1035, loss = 43005.30072210\n",
      "Iteration 1036, loss = 42834.49908167\n",
      "Iteration 1037, loss = 42664.20714905\n",
      "Iteration 1038, loss = 42494.65023405\n",
      "Iteration 1039, loss = 42326.24580341\n",
      "Iteration 1040, loss = 42158.74384600\n",
      "Iteration 1041, loss = 41992.11022544\n",
      "Iteration 1042, loss = 41826.12824077\n",
      "Iteration 1043, loss = 41660.76584855\n",
      "Iteration 1044, loss = 41496.41985901\n",
      "Iteration 1045, loss = 41333.10769315\n",
      "Iteration 1046, loss = 41170.32422249\n",
      "Iteration 1047, loss = 41008.10137210\n",
      "Iteration 1048, loss = 40846.45069114\n",
      "Iteration 1049, loss = 40685.53422042\n",
      "Iteration 1050, loss = 40525.27961311\n",
      "Iteration 1051, loss = 40365.69495674\n",
      "Iteration 1052, loss = 40206.79906855\n",
      "Iteration 1053, loss = 40048.69130082\n",
      "Iteration 1054, loss = 39891.12025202\n",
      "Iteration 1055, loss = 39734.37935760\n",
      "Iteration 1056, loss = 39578.30827381\n",
      "Iteration 1057, loss = 39422.93410278\n",
      "Iteration 1058, loss = 39268.35146837\n",
      "Iteration 1059, loss = 39114.25871639\n",
      "Iteration 1060, loss = 38960.79243550\n",
      "Iteration 1061, loss = 38807.99907327\n",
      "Iteration 1062, loss = 38655.74237093\n",
      "Iteration 1063, loss = 38503.99798307\n",
      "Iteration 1064, loss = 38352.62720439\n",
      "Iteration 1065, loss = 38201.87472158\n",
      "Iteration 1066, loss = 38051.83217142\n",
      "Iteration 1067, loss = 37902.29610444\n",
      "Iteration 1068, loss = 37753.45108559\n",
      "Iteration 1069, loss = 37605.01144485\n",
      "Iteration 1070, loss = 37456.86118359\n",
      "Iteration 1071, loss = 37309.51495990\n",
      "Iteration 1072, loss = 37162.82395157\n",
      "Iteration 1073, loss = 37016.72815643\n",
      "Iteration 1074, loss = 36871.00210958\n",
      "Iteration 1075, loss = 36725.72692602\n",
      "Iteration 1076, loss = 36581.18483518\n",
      "Iteration 1077, loss = 36437.11062408\n",
      "Iteration 1078, loss = 36293.60121503\n",
      "Iteration 1079, loss = 36150.73325051\n",
      "Iteration 1080, loss = 36008.00407056\n",
      "Iteration 1081, loss = 35865.96677908\n",
      "Iteration 1082, loss = 35724.60222771\n",
      "Iteration 1083, loss = 35584.73275559\n",
      "Iteration 1084, loss = 35445.38254237\n",
      "Iteration 1085, loss = 35307.25383491\n",
      "Iteration 1086, loss = 35169.39973741\n",
      "Iteration 1087, loss = 35032.19042160\n",
      "Iteration 1088, loss = 34895.49766267\n",
      "Iteration 1089, loss = 34758.94650775\n",
      "Iteration 1090, loss = 34623.23945482\n",
      "Iteration 1091, loss = 34487.86307364\n",
      "Iteration 1092, loss = 34353.57032738\n",
      "Iteration 1093, loss = 34220.42208682\n",
      "Iteration 1094, loss = 34087.89524179\n",
      "Iteration 1095, loss = 33955.89103615\n",
      "Iteration 1096, loss = 33824.65094147\n",
      "Iteration 1097, loss = 33693.74507191\n",
      "Iteration 1098, loss = 33563.27736694\n",
      "Iteration 1099, loss = 33433.25261287\n",
      "Iteration 1100, loss = 33303.91192770\n",
      "Iteration 1101, loss = 33175.13081897\n",
      "Iteration 1102, loss = 33046.92787789\n",
      "Iteration 1103, loss = 32919.54704047\n",
      "Iteration 1104, loss = 32792.48154064\n",
      "Iteration 1105, loss = 32665.81191702\n",
      "Iteration 1106, loss = 32539.87695735\n",
      "Iteration 1107, loss = 32414.62721174\n",
      "Iteration 1108, loss = 32289.65116941\n",
      "Iteration 1109, loss = 32165.09876591\n",
      "Iteration 1110, loss = 32041.49897998\n",
      "Iteration 1111, loss = 31918.22416403\n",
      "Iteration 1112, loss = 31795.40532347\n",
      "Iteration 1113, loss = 31673.04046877\n",
      "Iteration 1114, loss = 31551.68616408\n",
      "Iteration 1115, loss = 31430.77251765\n",
      "Iteration 1116, loss = 31310.11027525\n",
      "Iteration 1117, loss = 31189.89335974\n",
      "Iteration 1118, loss = 31070.33775420\n",
      "Iteration 1119, loss = 30951.39901944\n",
      "Iteration 1120, loss = 30832.86654221\n",
      "Iteration 1121, loss = 30714.78278732\n",
      "Iteration 1122, loss = 30597.20290041\n",
      "Iteration 1123, loss = 30479.61041913\n",
      "Iteration 1124, loss = 30362.95358186\n",
      "Iteration 1125, loss = 30246.54293842\n",
      "Iteration 1126, loss = 30130.94421624\n",
      "Iteration 1127, loss = 30015.74576355\n",
      "Iteration 1128, loss = 29900.82696539\n",
      "Iteration 1129, loss = 29786.18166690\n",
      "Iteration 1130, loss = 29671.91731237\n",
      "Iteration 1131, loss = 29557.87989921\n",
      "Iteration 1132, loss = 29444.48294607\n",
      "Iteration 1133, loss = 29331.29583393\n",
      "Iteration 1134, loss = 29218.63320676\n",
      "Iteration 1135, loss = 29106.57078314\n",
      "Iteration 1136, loss = 28994.59391259\n",
      "Iteration 1137, loss = 28883.00582822\n",
      "Iteration 1138, loss = 28771.58035767\n",
      "Iteration 1139, loss = 28660.85399945\n",
      "Iteration 1140, loss = 28550.91141788\n",
      "Iteration 1141, loss = 28441.14456684\n",
      "Iteration 1142, loss = 28332.19686717\n",
      "Iteration 1143, loss = 28224.63845013\n",
      "Iteration 1144, loss = 28117.33189373\n",
      "Iteration 1145, loss = 28010.24295432\n",
      "Iteration 1146, loss = 27903.85009466\n",
      "Iteration 1147, loss = 27797.42425213\n",
      "Iteration 1148, loss = 27691.51817513\n",
      "Iteration 1149, loss = 27586.02359781\n",
      "Iteration 1150, loss = 27480.74909249\n",
      "Iteration 1151, loss = 27376.38656682\n",
      "Iteration 1152, loss = 27273.05771409\n",
      "Iteration 1153, loss = 27169.86849958\n",
      "Iteration 1154, loss = 27067.10144793\n",
      "Iteration 1155, loss = 26964.88755792\n",
      "Iteration 1156, loss = 26863.14508758\n",
      "Iteration 1157, loss = 26761.87519295\n",
      "Iteration 1158, loss = 26660.79816814\n",
      "Iteration 1159, loss = 26560.50275534\n",
      "Iteration 1160, loss = 26460.72206126\n",
      "Iteration 1161, loss = 26361.29965812\n",
      "Iteration 1162, loss = 26262.55910306\n",
      "Iteration 1163, loss = 26164.14036699\n",
      "Iteration 1164, loss = 26066.40415020\n",
      "Iteration 1165, loss = 25968.96530379\n",
      "Iteration 1166, loss = 25871.88031045\n",
      "Iteration 1167, loss = 25775.22577141\n",
      "Iteration 1168, loss = 25679.22168995\n",
      "Iteration 1169, loss = 25583.43927179\n",
      "Iteration 1170, loss = 25488.22605850\n",
      "Iteration 1171, loss = 25393.40075691\n",
      "Iteration 1172, loss = 25299.20792516\n",
      "Iteration 1173, loss = 25204.82232426\n",
      "Iteration 1174, loss = 25110.88781409\n",
      "Iteration 1175, loss = 25017.53845532\n",
      "Iteration 1176, loss = 24924.59700320\n",
      "Iteration 1177, loss = 24831.73310475\n",
      "Iteration 1178, loss = 24739.18267334\n",
      "Iteration 1179, loss = 24647.27069173\n",
      "Iteration 1180, loss = 24555.76709839\n",
      "Iteration 1181, loss = 24464.63981402\n",
      "Iteration 1182, loss = 24373.70326800\n",
      "Iteration 1183, loss = 24282.95688157\n",
      "Iteration 1184, loss = 24192.84421894\n",
      "Iteration 1185, loss = 24103.31011378\n",
      "Iteration 1186, loss = 24013.72727111\n",
      "Iteration 1187, loss = 23924.23525931\n",
      "Iteration 1188, loss = 23835.31749427\n",
      "Iteration 1189, loss = 23746.57882010\n",
      "Iteration 1190, loss = 23658.19823226\n",
      "Iteration 1191, loss = 23570.15108228\n",
      "Iteration 1192, loss = 23482.05079310\n",
      "Iteration 1193, loss = 23394.15477103\n",
      "Iteration 1194, loss = 23306.66801079\n",
      "Iteration 1195, loss = 23219.75222555\n",
      "Iteration 1196, loss = 23132.78254748\n",
      "Iteration 1197, loss = 23046.04542234\n",
      "Iteration 1198, loss = 22959.85862650\n",
      "Iteration 1199, loss = 22873.66513073\n",
      "Iteration 1200, loss = 22788.74844128\n",
      "Iteration 1201, loss = 22704.53266916\n",
      "Iteration 1202, loss = 22620.49927765\n",
      "Iteration 1203, loss = 22536.82888571\n",
      "Iteration 1204, loss = 22453.42217855\n",
      "Iteration 1205, loss = 22370.20653911\n",
      "Iteration 1206, loss = 22287.10063910\n",
      "Iteration 1207, loss = 22204.22783594\n",
      "Iteration 1208, loss = 22122.26353729\n",
      "Iteration 1209, loss = 22041.15230234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1210, loss = 21960.11639737\n",
      "Iteration 1211, loss = 21879.29642124\n",
      "Iteration 1212, loss = 21798.96494002\n",
      "Iteration 1213, loss = 21719.10393229\n",
      "Iteration 1214, loss = 21639.42995656\n",
      "Iteration 1215, loss = 21560.07573950\n",
      "Iteration 1216, loss = 21481.24366346\n",
      "Iteration 1217, loss = 21402.68313860\n",
      "Iteration 1218, loss = 21324.34822587\n",
      "Iteration 1219, loss = 21246.46119728\n",
      "Iteration 1220, loss = 21168.88680154\n",
      "Iteration 1221, loss = 21091.76893158\n",
      "Iteration 1222, loss = 21015.07356875\n",
      "Iteration 1223, loss = 20938.82094342\n",
      "Iteration 1224, loss = 20862.88525603\n",
      "Iteration 1225, loss = 20787.22694831\n",
      "Iteration 1226, loss = 20711.77024865\n",
      "Iteration 1227, loss = 20636.85067180\n",
      "Iteration 1228, loss = 20562.11693565\n",
      "Iteration 1229, loss = 20487.96564994\n",
      "Iteration 1230, loss = 20414.25484268\n",
      "Iteration 1231, loss = 20340.85710172\n",
      "Iteration 1232, loss = 20267.53082290\n",
      "Iteration 1233, loss = 20194.76953374\n",
      "Iteration 1234, loss = 20122.13139170\n",
      "Iteration 1235, loss = 20049.91522843\n",
      "Iteration 1236, loss = 19978.16653651\n",
      "Iteration 1237, loss = 19906.44316581\n",
      "Iteration 1238, loss = 19835.11912794\n",
      "Iteration 1239, loss = 19764.07387084\n",
      "Iteration 1240, loss = 19693.27718252\n",
      "Iteration 1241, loss = 19622.79881265\n",
      "Iteration 1242, loss = 19552.36031705\n",
      "Iteration 1243, loss = 19482.14179024\n",
      "Iteration 1244, loss = 19412.22287678\n",
      "Iteration 1245, loss = 19342.56447833\n",
      "Iteration 1246, loss = 19273.20845711\n",
      "Iteration 1247, loss = 19204.09674815\n",
      "Iteration 1248, loss = 19135.15765365\n",
      "Iteration 1249, loss = 19066.06624655\n",
      "Iteration 1250, loss = 18997.17073950\n",
      "Iteration 1251, loss = 18928.62434461\n",
      "Iteration 1252, loss = 18860.17738715\n",
      "Iteration 1253, loss = 18791.92523034\n",
      "Iteration 1254, loss = 18723.90870777\n",
      "Iteration 1255, loss = 18656.11424165\n",
      "Iteration 1256, loss = 18588.56053203\n",
      "Iteration 1257, loss = 18521.05501482\n",
      "Iteration 1258, loss = 18453.97959747\n",
      "Iteration 1259, loss = 18387.64293235\n",
      "Iteration 1260, loss = 18321.47058367\n",
      "Iteration 1261, loss = 18255.79603227\n",
      "Iteration 1262, loss = 18190.52623977\n",
      "Iteration 1263, loss = 18125.54325885\n",
      "Iteration 1264, loss = 18060.82428024\n",
      "Iteration 1265, loss = 17995.99442604\n",
      "Iteration 1266, loss = 17931.52979629\n",
      "Iteration 1267, loss = 17867.23052248\n",
      "Iteration 1268, loss = 17803.22718488\n",
      "Iteration 1269, loss = 17739.19813675\n",
      "Iteration 1270, loss = 17675.28929718\n",
      "Iteration 1271, loss = 17611.97714127\n",
      "Iteration 1272, loss = 17549.40448885\n",
      "Iteration 1273, loss = 17486.85790362\n",
      "Iteration 1274, loss = 17424.42043260\n",
      "Iteration 1275, loss = 17362.31366888\n",
      "Iteration 1276, loss = 17300.53990719\n",
      "Iteration 1277, loss = 17238.87007424\n",
      "Iteration 1278, loss = 17177.49992796\n",
      "Iteration 1279, loss = 17116.46194036\n",
      "Iteration 1280, loss = 17055.84156540\n",
      "Iteration 1281, loss = 16995.37589382\n",
      "Iteration 1282, loss = 16935.15969326\n",
      "Iteration 1283, loss = 16875.14666332\n",
      "Iteration 1284, loss = 16815.45819762\n",
      "Iteration 1285, loss = 16755.99566044\n",
      "Iteration 1286, loss = 16696.63670079\n",
      "Iteration 1287, loss = 16637.57865954\n",
      "Iteration 1288, loss = 16578.78202722\n",
      "Iteration 1289, loss = 16520.27655612\n",
      "Iteration 1290, loss = 16462.13798664\n",
      "Iteration 1291, loss = 16404.22841785\n",
      "Iteration 1292, loss = 16346.42839306\n",
      "Iteration 1293, loss = 16288.76478186\n",
      "Iteration 1294, loss = 16231.42798587\n",
      "Iteration 1295, loss = 16174.35251997\n",
      "Iteration 1296, loss = 16117.53945575\n",
      "Iteration 1297, loss = 16060.82629459\n",
      "Iteration 1298, loss = 16004.27131644\n",
      "Iteration 1299, loss = 15948.04075171\n",
      "Iteration 1300, loss = 15892.13205403\n",
      "Iteration 1301, loss = 15836.20918127\n",
      "Iteration 1302, loss = 15780.56037904\n",
      "Iteration 1303, loss = 15725.06511374\n",
      "Iteration 1304, loss = 15669.82709193\n",
      "Iteration 1305, loss = 15614.85888217\n",
      "Iteration 1306, loss = 15559.94572140\n",
      "Iteration 1307, loss = 15505.20608569\n",
      "Iteration 1308, loss = 15450.73284266\n",
      "Iteration 1309, loss = 15396.30313085\n",
      "Iteration 1310, loss = 15342.03358253\n",
      "Iteration 1311, loss = 15287.96056413\n",
      "Iteration 1312, loss = 15234.04974946\n",
      "Iteration 1313, loss = 15180.30980867\n",
      "Iteration 1314, loss = 15126.67330392\n",
      "Iteration 1315, loss = 15073.33131085\n",
      "Iteration 1316, loss = 15019.96456566\n",
      "Iteration 1317, loss = 14966.81917947\n",
      "Iteration 1318, loss = 14913.77646138\n",
      "Iteration 1319, loss = 14860.84824746\n",
      "Iteration 1320, loss = 14808.06234120\n",
      "Iteration 1321, loss = 14755.47757957\n",
      "Iteration 1322, loss = 14703.07121681\n",
      "Iteration 1323, loss = 14650.58807239\n",
      "Iteration 1324, loss = 14598.30179283\n",
      "Iteration 1325, loss = 14546.13823598\n",
      "Iteration 1326, loss = 14494.05052310\n",
      "Iteration 1327, loss = 14442.18324834\n",
      "Iteration 1328, loss = 14390.40809827\n",
      "Iteration 1329, loss = 14338.80906748\n",
      "Iteration 1330, loss = 14287.41650395\n",
      "Iteration 1331, loss = 14236.17565447\n",
      "Iteration 1332, loss = 14185.05606005\n",
      "Iteration 1333, loss = 14133.99831944\n",
      "Iteration 1334, loss = 14083.06595949\n",
      "Iteration 1335, loss = 14032.31500318\n",
      "Iteration 1336, loss = 13981.66956635\n",
      "Iteration 1337, loss = 13931.10426047\n",
      "Iteration 1338, loss = 13880.73468678\n",
      "Iteration 1339, loss = 13830.68686229\n",
      "Iteration 1340, loss = 13781.00827679\n",
      "Iteration 1341, loss = 13731.44176335\n",
      "Iteration 1342, loss = 13681.99605135\n",
      "Iteration 1343, loss = 13633.36904640\n",
      "Iteration 1344, loss = 13584.86755933\n",
      "Iteration 1345, loss = 13536.52747065\n",
      "Iteration 1346, loss = 13488.30046088\n",
      "Iteration 1347, loss = 13440.15738736\n",
      "Iteration 1348, loss = 13392.25807382\n",
      "Iteration 1349, loss = 13344.45772661\n",
      "Iteration 1350, loss = 13296.70685403\n",
      "Iteration 1351, loss = 13248.87823594\n",
      "Iteration 1352, loss = 13201.20643396\n",
      "Iteration 1353, loss = 13154.04677733\n",
      "Iteration 1354, loss = 13107.49086418\n",
      "Iteration 1355, loss = 13061.11470102\n",
      "Iteration 1356, loss = 13014.90252822\n",
      "Iteration 1357, loss = 12968.81626205\n",
      "Iteration 1358, loss = 12922.80697110\n",
      "Iteration 1359, loss = 12876.94925163\n",
      "Iteration 1360, loss = 12831.27985201\n",
      "Iteration 1361, loss = 12785.72789385\n",
      "Iteration 1362, loss = 12740.29690129\n",
      "Iteration 1363, loss = 12695.15195137\n",
      "Iteration 1364, loss = 12650.22814993\n",
      "Iteration 1365, loss = 12605.52023648\n",
      "Iteration 1366, loss = 12561.02000411\n",
      "Iteration 1367, loss = 12516.72188859\n",
      "Iteration 1368, loss = 12472.58327191\n",
      "Iteration 1369, loss = 12428.67996559\n",
      "Iteration 1370, loss = 12385.03057771\n",
      "Iteration 1371, loss = 12341.61266598\n",
      "Iteration 1372, loss = 12298.42591355\n",
      "Iteration 1373, loss = 12255.39039481\n",
      "Iteration 1374, loss = 12212.56289360\n",
      "Iteration 1375, loss = 12169.83723050\n",
      "Iteration 1376, loss = 12127.31538020\n",
      "Iteration 1377, loss = 12084.90124112\n",
      "Iteration 1378, loss = 12042.59113665\n",
      "Iteration 1379, loss = 12000.49925376\n",
      "Iteration 1380, loss = 11958.56433302\n",
      "Iteration 1381, loss = 11916.81650417\n",
      "Iteration 1382, loss = 11875.20359642\n",
      "Iteration 1383, loss = 11833.76177748\n",
      "Iteration 1384, loss = 11792.48712666\n",
      "Iteration 1385, loss = 11751.33803968\n",
      "Iteration 1386, loss = 11710.32588345\n",
      "Iteration 1387, loss = 11669.52079583\n",
      "Iteration 1388, loss = 11628.97317782\n",
      "Iteration 1389, loss = 11588.52595931\n",
      "Iteration 1390, loss = 11548.20131422\n",
      "Iteration 1391, loss = 11507.95478008\n",
      "Iteration 1392, loss = 11467.88392452\n",
      "Iteration 1393, loss = 11427.92469455\n",
      "Iteration 1394, loss = 11388.06559552\n",
      "Iteration 1395, loss = 11348.39287971\n",
      "Iteration 1396, loss = 11308.82793979\n",
      "Iteration 1397, loss = 11269.33074194\n",
      "Iteration 1398, loss = 11230.02018765\n",
      "Iteration 1399, loss = 11190.84303849\n",
      "Iteration 1400, loss = 11152.37855850\n",
      "Iteration 1401, loss = 11114.05418904\n",
      "Iteration 1402, loss = 11075.81207902\n",
      "Iteration 1403, loss = 11037.66621241\n",
      "Iteration 1404, loss = 10999.55210013\n",
      "Iteration 1405, loss = 10961.87461546\n",
      "Iteration 1406, loss = 10924.55510285\n",
      "Iteration 1407, loss = 10887.31194566\n",
      "Iteration 1408, loss = 10850.13406615\n",
      "Iteration 1409, loss = 10813.14669098\n",
      "Iteration 1410, loss = 10776.29326302\n",
      "Iteration 1411, loss = 10739.51212348\n",
      "Iteration 1412, loss = 10702.89129300\n",
      "Iteration 1413, loss = 10666.65699681\n",
      "Iteration 1414, loss = 10630.97679168\n",
      "Iteration 1415, loss = 10595.34482566\n",
      "Iteration 1416, loss = 10559.86718694\n",
      "Iteration 1417, loss = 10524.51304975\n",
      "Iteration 1418, loss = 10489.30252769\n",
      "Iteration 1419, loss = 10454.19707459\n",
      "Iteration 1420, loss = 10419.22154861\n",
      "Iteration 1421, loss = 10384.41176865\n",
      "Iteration 1422, loss = 10349.76424252\n",
      "Iteration 1423, loss = 10315.34181459\n",
      "Iteration 1424, loss = 10281.19068966\n",
      "Iteration 1425, loss = 10247.13677942\n",
      "Iteration 1426, loss = 10213.29346377\n",
      "Iteration 1427, loss = 10179.62437924\n",
      "Iteration 1428, loss = 10146.18498110\n",
      "Iteration 1429, loss = 10112.93653733\n",
      "Iteration 1430, loss = 10079.87402929\n",
      "Iteration 1431, loss = 10046.96754387\n",
      "Iteration 1432, loss = 10014.26400504\n",
      "Iteration 1433, loss = 9981.70164339\n",
      "Iteration 1434, loss = 9949.37787927\n",
      "Iteration 1435, loss = 9917.24276660\n",
      "Iteration 1436, loss = 9885.19229739\n",
      "Iteration 1437, loss = 9853.37602597\n",
      "Iteration 1438, loss = 9821.75401355\n",
      "Iteration 1439, loss = 9790.20396234\n",
      "Iteration 1440, loss = 9758.74355745\n",
      "Iteration 1441, loss = 9727.40984992\n",
      "Iteration 1442, loss = 9696.16249849\n",
      "Iteration 1443, loss = 9665.08789749\n",
      "Iteration 1444, loss = 9634.11797038\n",
      "Iteration 1445, loss = 9603.21759755\n",
      "Iteration 1446, loss = 9572.38982961\n",
      "Iteration 1447, loss = 9541.69599052\n",
      "Iteration 1448, loss = 9511.18904274\n",
      "Iteration 1449, loss = 9480.72426036\n",
      "Iteration 1450, loss = 9450.35719836\n",
      "Iteration 1451, loss = 9420.14884036\n",
      "Iteration 1452, loss = 9390.01915974\n",
      "Iteration 1453, loss = 9359.98091368\n",
      "Iteration 1454, loss = 9330.01787767\n",
      "Iteration 1455, loss = 9300.19652323\n",
      "Iteration 1456, loss = 9270.50496009\n",
      "Iteration 1457, loss = 9240.93700029\n",
      "Iteration 1458, loss = 9211.42536170\n",
      "Iteration 1459, loss = 9182.03369853\n",
      "Iteration 1460, loss = 9152.81673547\n",
      "Iteration 1461, loss = 9123.71212668\n",
      "Iteration 1462, loss = 9094.71462628\n",
      "Iteration 1463, loss = 9065.81187992\n",
      "Iteration 1464, loss = 9037.02505684\n",
      "Iteration 1465, loss = 9008.25440320\n",
      "Iteration 1466, loss = 8979.51161496\n",
      "Iteration 1467, loss = 8950.93186434\n",
      "Iteration 1468, loss = 8922.96011232\n",
      "Iteration 1469, loss = 8894.95239879\n",
      "Iteration 1470, loss = 8867.05671931\n",
      "Iteration 1471, loss = 8839.24118870\n",
      "Iteration 1472, loss = 8811.40767922\n",
      "Iteration 1473, loss = 8783.58407351\n",
      "Iteration 1474, loss = 8755.92585088\n",
      "Iteration 1475, loss = 8728.36139531\n",
      "Iteration 1476, loss = 8700.88155380\n",
      "Iteration 1477, loss = 8673.45833942\n",
      "Iteration 1478, loss = 8646.20013812\n",
      "Iteration 1479, loss = 8618.96389140\n",
      "Iteration 1480, loss = 8591.89359880\n",
      "Iteration 1481, loss = 8564.92538182\n",
      "Iteration 1482, loss = 8538.49003435\n",
      "Iteration 1483, loss = 8512.36747349\n",
      "Iteration 1484, loss = 8486.30093245\n",
      "Iteration 1485, loss = 8460.31227077\n",
      "Iteration 1486, loss = 8434.30803743\n",
      "Iteration 1487, loss = 8408.36633657\n",
      "Iteration 1488, loss = 8382.54984535\n",
      "Iteration 1489, loss = 8356.99210360\n",
      "Iteration 1490, loss = 8331.49075833\n",
      "Iteration 1491, loss = 8306.07883366\n",
      "Iteration 1492, loss = 8280.84367766\n",
      "Iteration 1493, loss = 8255.87802340\n",
      "Iteration 1494, loss = 8231.24251232\n",
      "Iteration 1495, loss = 8206.77588498\n",
      "Iteration 1496, loss = 8182.38287363\n",
      "Iteration 1497, loss = 8158.03698220\n",
      "Iteration 1498, loss = 8133.81873541\n",
      "Iteration 1499, loss = 8109.71921218\n",
      "Iteration 1500, loss = 8085.79299872\n",
      "Iteration 1501, loss = 8061.93180344\n",
      "Iteration 1502, loss = 8038.21158520\n",
      "Iteration 1503, loss = 8014.59847279\n",
      "Iteration 1504, loss = 7991.21384128\n",
      "Iteration 1505, loss = 7967.98796910\n",
      "Iteration 1506, loss = 7944.79263199\n",
      "Iteration 1507, loss = 7921.65194086\n",
      "Iteration 1508, loss = 7898.77398354\n",
      "Iteration 1509, loss = 7876.03671534\n",
      "Iteration 1510, loss = 7853.36696474\n",
      "Iteration 1511, loss = 7830.87170904\n",
      "Iteration 1512, loss = 7808.48872717\n",
      "Iteration 1513, loss = 7786.26201737\n",
      "Iteration 1514, loss = 7764.18583458\n",
      "Iteration 1515, loss = 7742.22680242\n",
      "Iteration 1516, loss = 7720.35239422\n",
      "Iteration 1517, loss = 7698.64463615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1518, loss = 7677.03087838\n",
      "Iteration 1519, loss = 7655.58379865\n",
      "Iteration 1520, loss = 7634.22842185\n",
      "Iteration 1521, loss = 7612.98756414\n",
      "Iteration 1522, loss = 7591.82330843\n",
      "Iteration 1523, loss = 7570.83015133\n",
      "Iteration 1524, loss = 7549.94488631\n",
      "Iteration 1525, loss = 7529.08610333\n",
      "Iteration 1526, loss = 7508.39081096\n",
      "Iteration 1527, loss = 7487.80402046\n",
      "Iteration 1528, loss = 7467.31774348\n",
      "Iteration 1529, loss = 7447.02261208\n",
      "Iteration 1530, loss = 7426.73633303\n",
      "Iteration 1531, loss = 7406.43280501\n",
      "Iteration 1532, loss = 7386.34902933\n",
      "Iteration 1533, loss = 7366.36898876\n",
      "Iteration 1534, loss = 7346.38132790\n",
      "Iteration 1535, loss = 7326.48314757\n",
      "Iteration 1536, loss = 7306.68053966\n",
      "Iteration 1537, loss = 7286.91172913\n",
      "Iteration 1538, loss = 7267.27530681\n",
      "Iteration 1539, loss = 7247.69067071\n",
      "Iteration 1540, loss = 7228.10410051\n",
      "Iteration 1541, loss = 7208.61086352\n",
      "Iteration 1542, loss = 7189.19351343\n",
      "Iteration 1543, loss = 7169.75659381\n",
      "Iteration 1544, loss = 7150.32326177\n",
      "Iteration 1545, loss = 7130.92909027\n",
      "Iteration 1546, loss = 7111.64096952\n",
      "Iteration 1547, loss = 7092.39361170\n",
      "Iteration 1548, loss = 7073.19581331\n",
      "Iteration 1549, loss = 7054.06704714\n",
      "Iteration 1550, loss = 7035.12732405\n",
      "Iteration 1551, loss = 7016.48842439\n",
      "Iteration 1552, loss = 6997.86249319\n",
      "Iteration 1553, loss = 6979.31741127\n",
      "Iteration 1554, loss = 6960.85610908\n",
      "Iteration 1555, loss = 6942.38230392\n",
      "Iteration 1556, loss = 6923.99036078\n",
      "Iteration 1557, loss = 6905.68612716\n",
      "Iteration 1558, loss = 6887.40820583\n",
      "Iteration 1559, loss = 6869.12438975\n",
      "Iteration 1560, loss = 6850.91649555\n",
      "Iteration 1561, loss = 6832.80742355\n",
      "Iteration 1562, loss = 6814.68911156\n",
      "Iteration 1563, loss = 6796.57554090\n",
      "Iteration 1564, loss = 6778.63363026\n",
      "Iteration 1565, loss = 6760.96779341\n",
      "Iteration 1566, loss = 6743.35527097\n",
      "Iteration 1567, loss = 6725.74859703\n",
      "Iteration 1568, loss = 6708.30431829\n",
      "Iteration 1569, loss = 6690.87796522\n",
      "Iteration 1570, loss = 6673.51795462\n",
      "Iteration 1571, loss = 6656.23905589\n",
      "Iteration 1572, loss = 6638.88357469\n",
      "Iteration 1573, loss = 6621.60418776\n",
      "Iteration 1574, loss = 6604.36579108\n",
      "Iteration 1575, loss = 6587.27868983\n",
      "Iteration 1576, loss = 6570.24014381\n",
      "Iteration 1577, loss = 6553.26196951\n",
      "Iteration 1578, loss = 6536.34330473\n",
      "Iteration 1579, loss = 6519.54263533\n",
      "Iteration 1580, loss = 6503.10983972\n",
      "Iteration 1581, loss = 6486.72549221\n",
      "Iteration 1582, loss = 6470.43586416\n",
      "Iteration 1583, loss = 6454.15239253\n",
      "Iteration 1584, loss = 6437.95098363\n",
      "Iteration 1585, loss = 6421.85310734\n",
      "Iteration 1586, loss = 6405.81590862\n",
      "Iteration 1587, loss = 6389.90543178\n",
      "Iteration 1588, loss = 6374.05345269\n",
      "Iteration 1589, loss = 6358.18543749\n",
      "Iteration 1590, loss = 6342.39702288\n",
      "Iteration 1591, loss = 6326.67222834\n",
      "Iteration 1592, loss = 6311.02131262\n",
      "Iteration 1593, loss = 6295.41289262\n",
      "Iteration 1594, loss = 6279.83728619\n",
      "Iteration 1595, loss = 6264.32386981\n",
      "Iteration 1596, loss = 6248.88241889\n",
      "Iteration 1597, loss = 6233.44920609\n",
      "Iteration 1598, loss = 6218.03730010\n",
      "Iteration 1599, loss = 6202.69804292\n",
      "Iteration 1600, loss = 6187.48529600\n",
      "Iteration 1601, loss = 6172.25124452\n",
      "Iteration 1602, loss = 6156.90926049\n",
      "Iteration 1603, loss = 6141.62653563\n",
      "Iteration 1604, loss = 6126.38447596\n",
      "Iteration 1605, loss = 6111.19459206\n",
      "Iteration 1606, loss = 6096.03419065\n",
      "Iteration 1607, loss = 6080.94332609\n",
      "Iteration 1608, loss = 6065.90920836\n",
      "Iteration 1609, loss = 6050.95838212\n",
      "Iteration 1610, loss = 6035.96858750\n",
      "Iteration 1611, loss = 6021.04438980\n",
      "Iteration 1612, loss = 6006.23069395\n",
      "Iteration 1613, loss = 5991.42485579\n",
      "Iteration 1614, loss = 5976.66753900\n",
      "Iteration 1615, loss = 5961.94973224\n",
      "Iteration 1616, loss = 5947.27706262\n",
      "Iteration 1617, loss = 5932.72415932\n",
      "Iteration 1618, loss = 5918.21963220\n",
      "Iteration 1619, loss = 5903.79101801\n",
      "Iteration 1620, loss = 5889.35423131\n",
      "Iteration 1621, loss = 5874.97784025\n",
      "Iteration 1622, loss = 5860.64202703\n",
      "Iteration 1623, loss = 5846.35212795\n",
      "Iteration 1624, loss = 5832.07091358\n",
      "Iteration 1625, loss = 5817.83667826\n",
      "Iteration 1626, loss = 5803.66706269\n",
      "Iteration 1627, loss = 5789.56152344\n",
      "Iteration 1628, loss = 5775.47545305\n",
      "Iteration 1629, loss = 5761.48179614\n",
      "Iteration 1630, loss = 5747.53896397\n",
      "Iteration 1631, loss = 5733.66674994\n",
      "Iteration 1632, loss = 5719.83388649\n",
      "Iteration 1633, loss = 5705.98816822\n",
      "Iteration 1634, loss = 5692.24035585\n",
      "Iteration 1635, loss = 5678.52424791\n",
      "Iteration 1636, loss = 5664.80537159\n",
      "Iteration 1637, loss = 5651.17726562\n",
      "Iteration 1638, loss = 5637.60525919\n",
      "Iteration 1639, loss = 5624.06880224\n",
      "Iteration 1640, loss = 5610.58043532\n",
      "Iteration 1641, loss = 5597.13976851\n",
      "Iteration 1642, loss = 5583.89867746\n",
      "Iteration 1643, loss = 5570.76242202\n",
      "Iteration 1644, loss = 5557.64752890\n",
      "Iteration 1645, loss = 5544.53685628\n",
      "Iteration 1646, loss = 5531.50028522\n",
      "Iteration 1647, loss = 5518.48481923\n",
      "Iteration 1648, loss = 5505.69281056\n",
      "Iteration 1649, loss = 5493.00278035\n",
      "Iteration 1650, loss = 5480.30848181\n",
      "Iteration 1651, loss = 5467.66029729\n",
      "Iteration 1652, loss = 5455.13529890\n",
      "Iteration 1653, loss = 5442.78751319\n",
      "Iteration 1654, loss = 5430.46213245\n",
      "Iteration 1655, loss = 5418.19049095\n",
      "Iteration 1656, loss = 5406.00261064\n",
      "Iteration 1657, loss = 5393.82799808\n",
      "Iteration 1658, loss = 5381.70787875\n",
      "Iteration 1659, loss = 5369.58545222\n",
      "Iteration 1660, loss = 5357.48739016\n",
      "Iteration 1661, loss = 5345.51464131\n",
      "Iteration 1662, loss = 5333.59063666\n",
      "Iteration 1663, loss = 5321.71444471\n",
      "Iteration 1664, loss = 5309.85343912\n",
      "Iteration 1665, loss = 5298.13560647\n",
      "Iteration 1666, loss = 5286.44957207\n",
      "Iteration 1667, loss = 5274.72565666\n",
      "Iteration 1668, loss = 5263.09371489\n",
      "Iteration 1669, loss = 5251.53402746\n",
      "Iteration 1670, loss = 5240.04679040\n",
      "Iteration 1671, loss = 5228.59110775\n",
      "Iteration 1672, loss = 5217.19051183\n",
      "Iteration 1673, loss = 5205.81166605\n",
      "Iteration 1674, loss = 5194.47605219\n",
      "Iteration 1675, loss = 5183.22975975\n",
      "Iteration 1676, loss = 5172.03720278\n",
      "Iteration 1677, loss = 5160.92824873\n",
      "Iteration 1678, loss = 5149.83395257\n",
      "Iteration 1679, loss = 5138.75241833\n",
      "Iteration 1680, loss = 5127.73467760\n",
      "Iteration 1681, loss = 5116.77795207\n",
      "Iteration 1682, loss = 5105.83311687\n",
      "Iteration 1683, loss = 5094.98276257\n",
      "Iteration 1684, loss = 5084.12807908\n",
      "Iteration 1685, loss = 5073.37557499\n",
      "Iteration 1686, loss = 5062.63277926\n",
      "Iteration 1687, loss = 5051.87821626\n",
      "Iteration 1688, loss = 5041.14290096\n",
      "Iteration 1689, loss = 5030.51923308\n",
      "Iteration 1690, loss = 5019.86046654\n",
      "Iteration 1691, loss = 5009.24614737\n",
      "Iteration 1692, loss = 4998.62275874\n",
      "Iteration 1693, loss = 4988.00613745\n",
      "Iteration 1694, loss = 4977.43488198\n",
      "Iteration 1695, loss = 4966.91576858\n",
      "Iteration 1696, loss = 4956.38967901\n",
      "Iteration 1697, loss = 4945.91102525\n",
      "Iteration 1698, loss = 4935.37747235\n",
      "Iteration 1699, loss = 4924.88809041\n",
      "Iteration 1700, loss = 4914.46391005\n",
      "Iteration 1701, loss = 4904.01311669\n",
      "Iteration 1702, loss = 4893.56202367\n",
      "Iteration 1703, loss = 4883.17681946\n",
      "Iteration 1704, loss = 4872.87274829\n",
      "Iteration 1705, loss = 4862.56974965\n",
      "Iteration 1706, loss = 4852.28915622\n",
      "Iteration 1707, loss = 4842.03431434\n",
      "Iteration 1708, loss = 4831.80694266\n",
      "Iteration 1709, loss = 4821.63467238\n",
      "Iteration 1710, loss = 4811.47332221\n",
      "Iteration 1711, loss = 4801.35797011\n",
      "Iteration 1712, loss = 4791.27189891\n",
      "Iteration 1713, loss = 4781.22033898\n",
      "Iteration 1714, loss = 4771.22280996\n",
      "Iteration 1715, loss = 4761.24328031\n",
      "Iteration 1716, loss = 4751.29664199\n",
      "Iteration 1717, loss = 4741.39896652\n",
      "Iteration 1718, loss = 4731.49814998\n",
      "Iteration 1719, loss = 4721.64245947\n",
      "Iteration 1720, loss = 4711.87565360\n",
      "Iteration 1721, loss = 4702.11137597\n",
      "Iteration 1722, loss = 4692.37465921\n",
      "Iteration 1723, loss = 4682.66287796\n",
      "Iteration 1724, loss = 4672.96163821\n",
      "Iteration 1725, loss = 4663.34752508\n",
      "Iteration 1726, loss = 4653.82587709\n",
      "Iteration 1727, loss = 4644.29506122\n",
      "Iteration 1728, loss = 4634.69699758\n",
      "Iteration 1729, loss = 4625.16457924\n",
      "Iteration 1730, loss = 4615.63475095\n",
      "Iteration 1731, loss = 4606.14128444\n",
      "Iteration 1732, loss = 4596.66900531\n",
      "Iteration 1733, loss = 4587.25912736\n",
      "Iteration 1734, loss = 4577.87870976\n",
      "Iteration 1735, loss = 4568.47248135\n",
      "Iteration 1736, loss = 4559.12716654\n",
      "Iteration 1737, loss = 4549.85066104\n",
      "Iteration 1738, loss = 4540.57827015\n",
      "Iteration 1739, loss = 4531.34077364\n",
      "Iteration 1740, loss = 4522.12325834\n",
      "Iteration 1741, loss = 4512.97023400\n",
      "Iteration 1742, loss = 4503.85404608\n",
      "Iteration 1743, loss = 4494.71828511\n",
      "Iteration 1744, loss = 4485.60762351\n",
      "Iteration 1745, loss = 4476.56646141\n",
      "Iteration 1746, loss = 4467.52402524\n",
      "Iteration 1747, loss = 4458.47616891\n",
      "Iteration 1748, loss = 4449.49494216\n",
      "Iteration 1749, loss = 4440.53273541\n",
      "Iteration 1750, loss = 4431.59828639\n",
      "Iteration 1751, loss = 4422.71392743\n",
      "Iteration 1752, loss = 4413.83002846\n",
      "Iteration 1753, loss = 4404.99140507\n",
      "Iteration 1754, loss = 4396.18812772\n",
      "Iteration 1755, loss = 4387.41304143\n",
      "Iteration 1756, loss = 4378.67940027\n",
      "Iteration 1757, loss = 4369.98422530\n",
      "Iteration 1758, loss = 4361.31134455\n",
      "Iteration 1759, loss = 4352.67170368\n",
      "Iteration 1760, loss = 4344.03977169\n",
      "Iteration 1761, loss = 4335.47707714\n",
      "Iteration 1762, loss = 4327.09551734\n",
      "Iteration 1763, loss = 4318.65094411\n",
      "Iteration 1764, loss = 4310.19308910\n",
      "Iteration 1765, loss = 4301.71858063\n",
      "Iteration 1766, loss = 4293.28113612\n",
      "Iteration 1767, loss = 4284.89456604\n",
      "Iteration 1768, loss = 4276.55036701\n",
      "Iteration 1769, loss = 4268.26864847\n",
      "Iteration 1770, loss = 4259.99539909\n",
      "Iteration 1771, loss = 4251.69871214\n",
      "Iteration 1772, loss = 4243.43760791\n",
      "Iteration 1773, loss = 4235.13968465\n",
      "Iteration 1774, loss = 4226.83265582\n",
      "Iteration 1775, loss = 4218.55914599\n",
      "Iteration 1776, loss = 4210.38059522\n",
      "Iteration 1777, loss = 4202.19353140\n",
      "Iteration 1778, loss = 4194.02145933\n",
      "Iteration 1779, loss = 4185.85237819\n",
      "Iteration 1780, loss = 4177.69320578\n",
      "Iteration 1781, loss = 4169.51044739\n",
      "Iteration 1782, loss = 4161.38635427\n",
      "Iteration 1783, loss = 4153.31784088\n",
      "Iteration 1784, loss = 4145.31294275\n",
      "Iteration 1785, loss = 4137.41734690\n",
      "Iteration 1786, loss = 4129.54699823\n",
      "Iteration 1787, loss = 4121.66136187\n",
      "Iteration 1788, loss = 4113.79839961\n",
      "Iteration 1789, loss = 4106.02763191\n",
      "Iteration 1790, loss = 4098.27360322\n",
      "Iteration 1791, loss = 4090.54557232\n",
      "Iteration 1792, loss = 4082.86670535\n",
      "Iteration 1793, loss = 4075.21511881\n",
      "Iteration 1794, loss = 4067.61678644\n",
      "Iteration 1795, loss = 4060.05850694\n",
      "Iteration 1796, loss = 4052.53059545\n",
      "Iteration 1797, loss = 4045.05012846\n",
      "Iteration 1798, loss = 4037.58413677\n",
      "Iteration 1799, loss = 4030.11244973\n",
      "Iteration 1800, loss = 4022.68256684\n",
      "Iteration 1801, loss = 4015.29537764\n",
      "Iteration 1802, loss = 4007.94110423\n",
      "Iteration 1803, loss = 4000.64441450\n",
      "Iteration 1804, loss = 3993.39436796\n",
      "Iteration 1805, loss = 3986.14864046\n",
      "Iteration 1806, loss = 3978.93077016\n",
      "Iteration 1807, loss = 3971.74975446\n",
      "Iteration 1808, loss = 3964.58566453\n",
      "Iteration 1809, loss = 3957.50048603\n",
      "Iteration 1810, loss = 3950.45085351\n",
      "Iteration 1811, loss = 3943.41773967\n",
      "Iteration 1812, loss = 3936.39463213\n",
      "Iteration 1813, loss = 3929.47005230\n",
      "Iteration 1814, loss = 3922.55220995\n",
      "Iteration 1815, loss = 3915.65034269\n",
      "Iteration 1816, loss = 3908.79187949\n",
      "Iteration 1817, loss = 3901.92995028\n",
      "Iteration 1818, loss = 3895.13145321\n",
      "Iteration 1819, loss = 3888.39204882\n",
      "Iteration 1820, loss = 3881.67264981\n",
      "Iteration 1821, loss = 3874.95507127\n",
      "Iteration 1822, loss = 3868.24787083\n",
      "Iteration 1823, loss = 3861.53084612\n",
      "Iteration 1824, loss = 3854.82684343\n",
      "Iteration 1825, loss = 3848.16332464\n",
      "Iteration 1826, loss = 3841.52186428\n",
      "Iteration 1827, loss = 3834.87044050\n",
      "Iteration 1828, loss = 3828.23612849\n",
      "Iteration 1829, loss = 3821.67161120\n",
      "Iteration 1830, loss = 3815.11282890\n",
      "Iteration 1831, loss = 3808.55163322\n",
      "Iteration 1832, loss = 3802.02381748\n",
      "Iteration 1833, loss = 3795.54151141\n",
      "Iteration 1834, loss = 3789.07367878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1835, loss = 3782.61656670\n",
      "Iteration 1836, loss = 3776.17398452\n",
      "Iteration 1837, loss = 3769.73817123\n",
      "Iteration 1838, loss = 3763.30510429\n",
      "Iteration 1839, loss = 3756.88853834\n",
      "Iteration 1840, loss = 3750.47968126\n",
      "Iteration 1841, loss = 3744.08197146\n",
      "Iteration 1842, loss = 3737.71112045\n",
      "Iteration 1843, loss = 3731.35090630\n",
      "Iteration 1844, loss = 3725.03320156\n",
      "Iteration 1845, loss = 3718.71588729\n",
      "Iteration 1846, loss = 3712.43757833\n",
      "Iteration 1847, loss = 3706.16975501\n",
      "Iteration 1848, loss = 3699.92317666\n",
      "Iteration 1849, loss = 3693.69460562\n",
      "Iteration 1850, loss = 3687.46265252\n",
      "Iteration 1851, loss = 3681.28146408\n",
      "Iteration 1852, loss = 3675.13056956\n",
      "Iteration 1853, loss = 3668.97726450\n",
      "Iteration 1854, loss = 3662.84285408\n",
      "Iteration 1855, loss = 3656.73807967\n",
      "Iteration 1856, loss = 3650.66560920\n",
      "Iteration 1857, loss = 3644.60608816\n",
      "Iteration 1858, loss = 3638.56483801\n",
      "Iteration 1859, loss = 3632.53141788\n",
      "Iteration 1860, loss = 3626.52825681\n",
      "Iteration 1861, loss = 3620.55969765\n",
      "Iteration 1862, loss = 3614.59112975\n",
      "Iteration 1863, loss = 3608.60506279\n",
      "Iteration 1864, loss = 3602.68110221\n",
      "Iteration 1865, loss = 3596.80192992\n",
      "Iteration 1866, loss = 3590.93010342\n",
      "Iteration 1867, loss = 3585.08432473\n",
      "Iteration 1868, loss = 3579.22444285\n",
      "Iteration 1869, loss = 3573.38747938\n",
      "Iteration 1870, loss = 3567.57303397\n",
      "Iteration 1871, loss = 3561.75952351\n",
      "Iteration 1872, loss = 3555.97737375\n",
      "Iteration 1873, loss = 3550.21757415\n",
      "Iteration 1874, loss = 3544.47194444\n",
      "Iteration 1875, loss = 3538.77206999\n",
      "Iteration 1876, loss = 3533.07104171\n",
      "Iteration 1877, loss = 3527.39078598\n",
      "Iteration 1878, loss = 3521.70216465\n",
      "Iteration 1879, loss = 3516.03256411\n",
      "Iteration 1880, loss = 3510.39677169\n",
      "Iteration 1881, loss = 3504.77035354\n",
      "Iteration 1882, loss = 3499.14417022\n",
      "Iteration 1883, loss = 3493.54667814\n",
      "Iteration 1884, loss = 3487.97313302\n",
      "Iteration 1885, loss = 3482.41875097\n",
      "Iteration 1886, loss = 3476.86449408\n",
      "Iteration 1887, loss = 3471.32570864\n",
      "Iteration 1888, loss = 3465.82374542\n",
      "Iteration 1889, loss = 3460.34301481\n",
      "Iteration 1890, loss = 3454.87375958\n",
      "Iteration 1891, loss = 3449.41794273\n",
      "Iteration 1892, loss = 3443.99812171\n",
      "Iteration 1893, loss = 3438.58773387\n",
      "Iteration 1894, loss = 3433.20063610\n",
      "Iteration 1895, loss = 3427.81492927\n",
      "Iteration 1896, loss = 3422.46405958\n",
      "Iteration 1897, loss = 3417.13015911\n",
      "Iteration 1898, loss = 3411.83303994\n",
      "Iteration 1899, loss = 3406.54137002\n",
      "Iteration 1900, loss = 3401.26683852\n",
      "Iteration 1901, loss = 3395.97985156\n",
      "Iteration 1902, loss = 3390.72751755\n",
      "Iteration 1903, loss = 3385.49408276\n",
      "Iteration 1904, loss = 3380.27707109\n",
      "Iteration 1905, loss = 3375.07380653\n",
      "Iteration 1906, loss = 3369.88010147\n",
      "Iteration 1907, loss = 3364.71525243\n",
      "Iteration 1908, loss = 3359.57586120\n",
      "Iteration 1909, loss = 3354.43412788\n",
      "Iteration 1910, loss = 3349.27856583\n",
      "Iteration 1911, loss = 3344.12397043\n",
      "Iteration 1912, loss = 3338.98909157\n",
      "Iteration 1913, loss = 3333.88631634\n",
      "Iteration 1914, loss = 3328.79728656\n",
      "Iteration 1915, loss = 3323.70476175\n",
      "Iteration 1916, loss = 3318.62555563\n",
      "Iteration 1917, loss = 3313.56706032\n",
      "Iteration 1918, loss = 3308.55407358\n",
      "Iteration 1919, loss = 3303.54519008\n",
      "Iteration 1920, loss = 3298.52593932\n",
      "Iteration 1921, loss = 3293.50996313\n",
      "Iteration 1922, loss = 3288.52244284\n",
      "Iteration 1923, loss = 3283.55785060\n",
      "Iteration 1924, loss = 3278.60734563\n",
      "Iteration 1925, loss = 3273.64852356\n",
      "Iteration 1926, loss = 3268.71607126\n",
      "Iteration 1927, loss = 3263.80948826\n",
      "Iteration 1928, loss = 3258.91253521\n",
      "Iteration 1929, loss = 3254.00033135\n",
      "Iteration 1930, loss = 3249.11377483\n",
      "Iteration 1931, loss = 3244.27027345\n",
      "Iteration 1932, loss = 3239.43889221\n",
      "Iteration 1933, loss = 3234.59721638\n",
      "Iteration 1934, loss = 3229.77715763\n",
      "Iteration 1935, loss = 3224.98589937\n",
      "Iteration 1936, loss = 3220.20148980\n",
      "Iteration 1937, loss = 3215.43688300\n",
      "Iteration 1938, loss = 3210.71446468\n",
      "Iteration 1939, loss = 3206.02421962\n",
      "Iteration 1940, loss = 3201.34253903\n",
      "Iteration 1941, loss = 3196.65221054\n",
      "Iteration 1942, loss = 3191.98877827\n",
      "Iteration 1943, loss = 3187.34507828\n",
      "Iteration 1944, loss = 3182.70723414\n",
      "Iteration 1945, loss = 3178.09642074\n",
      "Iteration 1946, loss = 3173.52090397\n",
      "Iteration 1947, loss = 3168.94310680\n",
      "Iteration 1948, loss = 3164.38018054\n",
      "Iteration 1949, loss = 3159.84452359\n",
      "Iteration 1950, loss = 3155.32312655\n",
      "Iteration 1951, loss = 3150.81596261\n",
      "Iteration 1952, loss = 3146.32500681\n",
      "Iteration 1953, loss = 3141.84972687\n",
      "Iteration 1954, loss = 3137.43025838\n",
      "Iteration 1955, loss = 3132.99636745\n",
      "Iteration 1956, loss = 3128.56472282\n",
      "Iteration 1957, loss = 3124.15179497\n",
      "Iteration 1958, loss = 3119.74872642\n",
      "Iteration 1959, loss = 3115.34375803\n",
      "Iteration 1960, loss = 3110.94663236\n",
      "Iteration 1961, loss = 3106.57384007\n",
      "Iteration 1962, loss = 3102.21567724\n",
      "Iteration 1963, loss = 3097.86560308\n",
      "Iteration 1964, loss = 3093.53902080\n",
      "Iteration 1965, loss = 3089.23913880\n",
      "Iteration 1966, loss = 3084.95687025\n",
      "Iteration 1967, loss = 3080.67031003\n",
      "Iteration 1968, loss = 3076.40283408\n",
      "Iteration 1969, loss = 3072.17078999\n",
      "Iteration 1970, loss = 3067.95007005\n",
      "Iteration 1971, loss = 3063.75429383\n",
      "Iteration 1972, loss = 3059.56034682\n",
      "Iteration 1973, loss = 3055.37683937\n",
      "Iteration 1974, loss = 3051.20614830\n",
      "Iteration 1975, loss = 3047.05447638\n",
      "Iteration 1976, loss = 3042.93985325\n",
      "Iteration 1977, loss = 3038.83475311\n",
      "Iteration 1978, loss = 3034.72738436\n",
      "Iteration 1979, loss = 3030.63839766\n",
      "Iteration 1980, loss = 3026.58169088\n",
      "Iteration 1981, loss = 3022.53413428\n",
      "Iteration 1982, loss = 3018.49543384\n",
      "Iteration 1983, loss = 3014.45830370\n",
      "Iteration 1984, loss = 3010.44079450\n",
      "Iteration 1985, loss = 3006.43970717\n",
      "Iteration 1986, loss = 3002.44911766\n",
      "Iteration 1987, loss = 2998.45313061\n",
      "Iteration 1988, loss = 2994.46579553\n",
      "Iteration 1989, loss = 2990.51081817\n",
      "Iteration 1990, loss = 2986.57322027\n",
      "Iteration 1991, loss = 2982.64295703\n",
      "Iteration 1992, loss = 2978.75049190\n",
      "Iteration 1993, loss = 2974.85498318\n",
      "Iteration 1994, loss = 2970.95722062\n",
      "Iteration 1995, loss = 2967.05048790\n",
      "Iteration 1996, loss = 2963.17044057\n",
      "Iteration 1997, loss = 2959.31611037\n",
      "Iteration 1998, loss = 2955.45403431\n",
      "Iteration 1999, loss = 2951.57900227\n",
      "Iteration 2000, loss = 2947.72936767\n",
      "Iteration 2001, loss = 2943.88522142\n",
      "Iteration 2002, loss = 2940.06704839\n",
      "Iteration 2003, loss = 2936.27749489\n",
      "Iteration 2004, loss = 2932.47884296\n",
      "Iteration 2005, loss = 2928.68125505\n",
      "Iteration 2006, loss = 2924.92710102\n",
      "Iteration 2007, loss = 2921.19628110\n",
      "Iteration 2008, loss = 2917.46856445\n",
      "Iteration 2009, loss = 2913.73201383\n",
      "Iteration 2010, loss = 2910.02141077\n",
      "Iteration 2011, loss = 2906.33618267\n",
      "Iteration 2012, loss = 2902.67580081\n",
      "Iteration 2013, loss = 2899.01852874\n",
      "Iteration 2014, loss = 2895.34696092\n",
      "Iteration 2015, loss = 2891.69427834\n",
      "Iteration 2016, loss = 2888.07931799\n",
      "Iteration 2017, loss = 2884.49164353\n",
      "Iteration 2018, loss = 2880.90022103\n",
      "Iteration 2019, loss = 2877.30355795\n",
      "Iteration 2020, loss = 2873.73408672\n",
      "Iteration 2021, loss = 2870.17209379\n",
      "Iteration 2022, loss = 2866.62304848\n",
      "Iteration 2023, loss = 2863.10601817\n",
      "Iteration 2024, loss = 2859.58623595\n",
      "Iteration 2025, loss = 2856.08082364\n",
      "Iteration 2026, loss = 2852.60443189\n",
      "Iteration 2027, loss = 2849.16158720\n",
      "Iteration 2028, loss = 2845.73785802\n",
      "Iteration 2029, loss = 2842.33003998\n",
      "Iteration 2030, loss = 2838.93597400\n",
      "Iteration 2031, loss = 2835.56530896\n",
      "Iteration 2032, loss = 2832.20489742\n",
      "Iteration 2033, loss = 2828.80283739\n",
      "Iteration 2034, loss = 2825.39891758\n",
      "Iteration 2035, loss = 2822.00720167\n",
      "Iteration 2036, loss = 2818.61843646\n",
      "Iteration 2037, loss = 2815.22525272\n",
      "Iteration 2038, loss = 2811.81621610\n",
      "Iteration 2039, loss = 2808.37688554\n",
      "Iteration 2040, loss = 2804.95663118\n",
      "Iteration 2041, loss = 2801.51460499\n",
      "Iteration 2042, loss = 2798.07485025\n",
      "Iteration 2043, loss = 2794.63908685\n",
      "Iteration 2044, loss = 2791.21897731\n",
      "Iteration 2045, loss = 2787.76474132\n",
      "Iteration 2046, loss = 2784.27766583\n",
      "Iteration 2047, loss = 2780.77944351\n",
      "Iteration 2048, loss = 2777.25693047\n",
      "Iteration 2049, loss = 2773.73522604\n",
      "Iteration 2050, loss = 2770.21959116\n",
      "Iteration 2051, loss = 2766.66505297\n",
      "Iteration 2052, loss = 2763.10459192\n",
      "Iteration 2053, loss = 2759.52113810\n",
      "Iteration 2054, loss = 2755.92019111\n",
      "Iteration 2055, loss = 2752.28128724\n",
      "Iteration 2056, loss = 2748.64621683\n",
      "Iteration 2057, loss = 2745.01068366\n",
      "Iteration 2058, loss = 2741.41430422\n",
      "Iteration 2059, loss = 2737.79314603\n",
      "Iteration 2060, loss = 2734.14130789\n",
      "Iteration 2061, loss = 2730.47588683\n",
      "Iteration 2062, loss = 2726.79546115\n",
      "Iteration 2063, loss = 2723.10697922\n",
      "Iteration 2064, loss = 2719.40797648\n",
      "Iteration 2065, loss = 2715.70119613\n",
      "Iteration 2066, loss = 2711.97487034\n",
      "Iteration 2067, loss = 2708.24818808\n",
      "Iteration 2068, loss = 2704.51455745\n",
      "Iteration 2069, loss = 2700.79039204\n",
      "Iteration 2070, loss = 2697.04972353\n",
      "Iteration 2071, loss = 2693.29959816\n",
      "Iteration 2072, loss = 2689.55446836\n",
      "Iteration 2073, loss = 2685.83079341\n",
      "Iteration 2074, loss = 2682.10864070\n",
      "Iteration 2075, loss = 2678.36753160\n",
      "Iteration 2076, loss = 2674.62165158\n",
      "Iteration 2077, loss = 2670.87558222\n",
      "Iteration 2078, loss = 2667.13612603\n",
      "Iteration 2079, loss = 2663.39851158\n",
      "Iteration 2080, loss = 2659.66351201\n",
      "Iteration 2081, loss = 2655.92619742\n",
      "Iteration 2082, loss = 2652.19159889\n",
      "Iteration 2083, loss = 2648.46272289\n",
      "Iteration 2084, loss = 2644.72501176\n",
      "Iteration 2085, loss = 2640.97995652\n",
      "Iteration 2086, loss = 2637.24154648\n",
      "Iteration 2087, loss = 2633.51188027\n",
      "Iteration 2088, loss = 2629.78647445\n",
      "Iteration 2089, loss = 2626.07362698\n",
      "Iteration 2090, loss = 2622.35812528\n",
      "Iteration 2091, loss = 2618.63354822\n",
      "Iteration 2092, loss = 2614.91835974\n",
      "Iteration 2093, loss = 2611.21392323\n",
      "Iteration 2094, loss = 2607.50420331\n",
      "Iteration 2095, loss = 2603.79806950\n",
      "Iteration 2096, loss = 2600.11093184\n",
      "Iteration 2097, loss = 2596.40413416\n",
      "Iteration 2098, loss = 2592.69538893\n",
      "Iteration 2099, loss = 2588.99055541\n",
      "Iteration 2100, loss = 2585.28244401\n",
      "Iteration 2101, loss = 2581.59161218\n",
      "Iteration 2102, loss = 2577.89945440\n",
      "Iteration 2103, loss = 2574.20227276\n",
      "Iteration 2104, loss = 2570.52561836\n",
      "Iteration 2105, loss = 2566.84647103\n",
      "Iteration 2106, loss = 2563.16007619\n",
      "Iteration 2107, loss = 2559.48702616\n",
      "Iteration 2108, loss = 2555.84509187\n",
      "Iteration 2109, loss = 2552.19633381\n",
      "Iteration 2110, loss = 2548.54062529\n",
      "Iteration 2111, loss = 2544.89651643\n",
      "Iteration 2112, loss = 2541.27118129\n",
      "Iteration 2113, loss = 2537.65619003\n",
      "Iteration 2114, loss = 2534.03994200\n",
      "Iteration 2115, loss = 2530.42660840\n",
      "Iteration 2116, loss = 2526.80658135\n",
      "Iteration 2117, loss = 2523.22333888\n",
      "Iteration 2118, loss = 2519.64382442\n",
      "Iteration 2119, loss = 2516.06332433\n",
      "Iteration 2120, loss = 2512.49086290\n",
      "Iteration 2121, loss = 2508.93094127\n",
      "Iteration 2122, loss = 2505.38620802\n",
      "Iteration 2123, loss = 2501.84501780\n",
      "Iteration 2124, loss = 2498.29026749\n",
      "Iteration 2125, loss = 2494.73360783\n",
      "Iteration 2126, loss = 2491.19031563\n",
      "Iteration 2127, loss = 2487.64879478\n",
      "Iteration 2128, loss = 2484.11266235\n",
      "Iteration 2129, loss = 2480.58121161\n",
      "Iteration 2130, loss = 2477.05705533\n",
      "Iteration 2131, loss = 2473.53613454\n",
      "Iteration 2132, loss = 2470.02684545\n",
      "Iteration 2133, loss = 2466.52318319\n",
      "Iteration 2134, loss = 2463.02999118\n",
      "Iteration 2135, loss = 2459.54308689\n",
      "Iteration 2136, loss = 2456.06688126\n",
      "Iteration 2137, loss = 2452.60937544\n",
      "Iteration 2138, loss = 2449.14541800\n",
      "Iteration 2139, loss = 2445.68818035\n",
      "Iteration 2140, loss = 2442.23805815\n",
      "Iteration 2141, loss = 2438.81188575\n",
      "Iteration 2142, loss = 2435.39343373\n",
      "Iteration 2143, loss = 2431.95811740\n",
      "Iteration 2144, loss = 2428.51842948\n",
      "Iteration 2145, loss = 2425.09264474\n",
      "Iteration 2146, loss = 2421.67702661\n",
      "Iteration 2147, loss = 2418.23709951\n",
      "Iteration 2148, loss = 2414.81514874\n",
      "Iteration 2149, loss = 2411.38639953\n",
      "Iteration 2150, loss = 2407.96359817\n",
      "Iteration 2151, loss = 2404.53620301\n",
      "Iteration 2152, loss = 2401.11427215\n",
      "Iteration 2153, loss = 2397.71383414\n",
      "Iteration 2154, loss = 2394.32295928\n",
      "Iteration 2155, loss = 2390.93078584\n",
      "Iteration 2156, loss = 2387.54660899\n",
      "Iteration 2157, loss = 2384.16788553\n",
      "Iteration 2158, loss = 2380.78947785\n",
      "Iteration 2159, loss = 2377.42813568\n",
      "Iteration 2160, loss = 2374.06890100\n",
      "Iteration 2161, loss = 2370.71278896\n",
      "Iteration 2162, loss = 2367.36102242\n",
      "Iteration 2163, loss = 2364.01986003\n",
      "Iteration 2164, loss = 2360.67361688\n",
      "Iteration 2165, loss = 2357.34959441\n",
      "Iteration 2166, loss = 2354.03089345\n",
      "Iteration 2167, loss = 2350.71448338\n",
      "Iteration 2168, loss = 2347.40682253\n",
      "Iteration 2169, loss = 2344.11329909\n",
      "Iteration 2170, loss = 2340.79924757\n",
      "Iteration 2171, loss = 2337.46885334\n",
      "Iteration 2172, loss = 2334.13837690\n",
      "Iteration 2173, loss = 2330.80671179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2174, loss = 2327.47393425\n",
      "Iteration 2175, loss = 2324.14831948\n",
      "Iteration 2176, loss = 2320.82982889\n",
      "Iteration 2177, loss = 2317.51326154\n",
      "Iteration 2178, loss = 2314.20544762\n",
      "Iteration 2179, loss = 2310.88722496\n",
      "Iteration 2180, loss = 2307.57765301\n",
      "Iteration 2181, loss = 2304.28412122\n",
      "Iteration 2182, loss = 2300.98416925\n",
      "Iteration 2183, loss = 2297.72164893\n",
      "Iteration 2184, loss = 2294.50328854\n",
      "Iteration 2185, loss = 2291.28666095\n",
      "Iteration 2186, loss = 2288.05470537\n",
      "Iteration 2187, loss = 2284.82761245\n",
      "Iteration 2188, loss = 2281.60966551\n",
      "Iteration 2189, loss = 2278.37894817\n",
      "Iteration 2190, loss = 2275.16446440\n",
      "Iteration 2191, loss = 2271.95897718\n",
      "Iteration 2192, loss = 2268.74214963\n",
      "Iteration 2193, loss = 2265.52795951\n",
      "Iteration 2194, loss = 2262.35368267\n",
      "Iteration 2195, loss = 2259.20355661\n",
      "Iteration 2196, loss = 2256.05078526\n",
      "Iteration 2197, loss = 2252.89797252\n",
      "Iteration 2198, loss = 2249.73949099\n",
      "Iteration 2199, loss = 2246.58334390\n",
      "Iteration 2200, loss = 2243.45939644\n",
      "Iteration 2201, loss = 2240.34367300\n",
      "Iteration 2202, loss = 2237.21591341\n",
      "Iteration 2203, loss = 2234.09443643\n",
      "Iteration 2204, loss = 2230.97470454\n",
      "Iteration 2205, loss = 2227.86174192\n",
      "Iteration 2206, loss = 2224.76506515\n",
      "Iteration 2207, loss = 2221.68269510\n",
      "Iteration 2208, loss = 2218.60663150\n",
      "Iteration 2209, loss = 2215.52443200\n",
      "Iteration 2210, loss = 2212.45894870\n",
      "Iteration 2211, loss = 2209.40634193\n",
      "Iteration 2212, loss = 2206.34506399\n",
      "Iteration 2213, loss = 2203.30041398\n",
      "Iteration 2214, loss = 2200.27335256\n",
      "Iteration 2215, loss = 2197.24867082\n",
      "Iteration 2216, loss = 2194.23188014\n",
      "Iteration 2217, loss = 2191.22116647\n",
      "Iteration 2218, loss = 2188.23008636\n",
      "Iteration 2219, loss = 2185.25030256\n",
      "Iteration 2220, loss = 2182.26947524\n",
      "Iteration 2221, loss = 2179.29580709\n",
      "Iteration 2222, loss = 2176.33406041\n",
      "Iteration 2223, loss = 2173.38144960\n",
      "Iteration 2224, loss = 2170.44024289\n",
      "Iteration 2225, loss = 2167.50976822\n",
      "Iteration 2226, loss = 2164.57761287\n",
      "Iteration 2227, loss = 2161.65495461\n",
      "Iteration 2228, loss = 2158.74554644\n",
      "Iteration 2229, loss = 2155.84125125\n",
      "Iteration 2230, loss = 2152.94761648\n",
      "Iteration 2231, loss = 2150.05629974\n",
      "Iteration 2232, loss = 2147.17821408\n",
      "Iteration 2233, loss = 2144.31461839\n",
      "Iteration 2234, loss = 2141.45532479\n",
      "Iteration 2235, loss = 2138.58312425\n",
      "Iteration 2236, loss = 2135.74049469\n",
      "Iteration 2237, loss = 2132.90989501\n",
      "Iteration 2238, loss = 2130.08134095\n",
      "Iteration 2239, loss = 2127.25440989\n",
      "Iteration 2240, loss = 2124.43434277\n",
      "Iteration 2241, loss = 2121.62591568\n",
      "Iteration 2242, loss = 2118.82065237\n",
      "Iteration 2243, loss = 2116.03373824\n",
      "Iteration 2244, loss = 2113.24372514\n",
      "Iteration 2245, loss = 2110.46181459\n",
      "Iteration 2246, loss = 2107.68273036\n",
      "Iteration 2247, loss = 2104.91977823\n",
      "Iteration 2248, loss = 2102.16315010\n",
      "Iteration 2249, loss = 2099.40728299\n",
      "Iteration 2250, loss = 2096.64826962\n",
      "Iteration 2251, loss = 2093.90823157\n",
      "Iteration 2252, loss = 2091.17226122\n",
      "Iteration 2253, loss = 2088.44287533\n",
      "Iteration 2254, loss = 2085.71323788\n",
      "Iteration 2255, loss = 2082.99262355\n",
      "Iteration 2256, loss = 2080.28508331\n",
      "Iteration 2257, loss = 2077.57638329\n",
      "Iteration 2258, loss = 2074.87276727\n",
      "Iteration 2259, loss = 2072.17210373\n",
      "Iteration 2260, loss = 2069.53300630\n",
      "Iteration 2261, loss = 2066.88591813\n",
      "Iteration 2262, loss = 2064.21561636\n",
      "Iteration 2263, loss = 2061.54203728\n",
      "Iteration 2264, loss = 2058.86388316\n",
      "Iteration 2265, loss = 2056.17523929\n",
      "Iteration 2266, loss = 2053.49291664\n",
      "Iteration 2267, loss = 2050.81232217\n",
      "Iteration 2268, loss = 2048.14684691\n",
      "Iteration 2269, loss = 2045.48131441\n",
      "Iteration 2270, loss = 2042.86005921\n",
      "Iteration 2271, loss = 2040.24075154\n",
      "Iteration 2272, loss = 2037.61020000\n",
      "Iteration 2273, loss = 2034.97426878\n",
      "Iteration 2274, loss = 2032.35132303\n",
      "Iteration 2275, loss = 2029.72332145\n",
      "Iteration 2276, loss = 2027.09643820\n",
      "Iteration 2277, loss = 2024.50820164\n",
      "Iteration 2278, loss = 2021.92402104\n",
      "Iteration 2279, loss = 2019.33539384\n",
      "Iteration 2280, loss = 2016.74851706\n",
      "Iteration 2281, loss = 2014.16239078\n",
      "Iteration 2282, loss = 2011.58679483\n",
      "Iteration 2283, loss = 2009.01539956\n",
      "Iteration 2284, loss = 2006.45822355\n",
      "Iteration 2285, loss = 2003.89986635\n",
      "Iteration 2286, loss = 2001.34211143\n",
      "Iteration 2287, loss = 1998.80080394\n",
      "Iteration 2288, loss = 1996.26310229\n",
      "Iteration 2289, loss = 1993.74045464\n",
      "Iteration 2290, loss = 1991.22054732\n",
      "Iteration 2291, loss = 1988.71237704\n",
      "Iteration 2292, loss = 1986.21109966\n",
      "Iteration 2293, loss = 1983.70880583\n",
      "Iteration 2294, loss = 1981.22298677\n",
      "Iteration 2295, loss = 1978.73976813\n",
      "Iteration 2296, loss = 1976.25948511\n",
      "Iteration 2297, loss = 1973.79652546\n",
      "Iteration 2298, loss = 1971.34635575\n",
      "Iteration 2299, loss = 1968.89620886\n",
      "Iteration 2300, loss = 1966.45032320\n",
      "Iteration 2301, loss = 1964.01029945\n",
      "Iteration 2302, loss = 1961.57299240\n",
      "Iteration 2303, loss = 1959.14777554\n",
      "Iteration 2304, loss = 1956.73809126\n",
      "Iteration 2305, loss = 1954.33133066\n",
      "Iteration 2306, loss = 1951.92372193\n",
      "Iteration 2307, loss = 1949.52834332\n",
      "Iteration 2308, loss = 1947.13210841\n",
      "Iteration 2309, loss = 1944.75156217\n",
      "Iteration 2310, loss = 1942.37835529\n",
      "Iteration 2311, loss = 1940.00789256\n",
      "Iteration 2312, loss = 1937.64534680\n",
      "Iteration 2313, loss = 1935.28605664\n",
      "Iteration 2314, loss = 1932.93227076\n",
      "Iteration 2315, loss = 1930.58098974\n",
      "Iteration 2316, loss = 1928.24206823\n",
      "Iteration 2317, loss = 1925.91380655\n",
      "Iteration 2318, loss = 1923.58576029\n",
      "Iteration 2319, loss = 1921.25311043\n",
      "Iteration 2320, loss = 1918.93050324\n",
      "Iteration 2321, loss = 1916.62258421\n",
      "Iteration 2322, loss = 1914.31396170\n",
      "Iteration 2323, loss = 1912.01376113\n",
      "Iteration 2324, loss = 1909.71315121\n",
      "Iteration 2325, loss = 1907.42008510\n",
      "Iteration 2326, loss = 1905.13221445\n",
      "Iteration 2327, loss = 1902.84207808\n",
      "Iteration 2328, loss = 1900.56545324\n",
      "Iteration 2329, loss = 1898.28933443\n",
      "Iteration 2330, loss = 1896.00269024\n",
      "Iteration 2331, loss = 1893.71981928\n",
      "Iteration 2332, loss = 1891.43710542\n",
      "Iteration 2333, loss = 1889.15739787\n",
      "Iteration 2334, loss = 1886.88051109\n",
      "Iteration 2335, loss = 1884.60948606\n",
      "Iteration 2336, loss = 1882.34017069\n",
      "Iteration 2337, loss = 1880.07513682\n",
      "Iteration 2338, loss = 1877.81057881\n",
      "Iteration 2339, loss = 1875.54775933\n",
      "Iteration 2340, loss = 1873.29322952\n",
      "Iteration 2341, loss = 1871.03749783\n",
      "Iteration 2342, loss = 1868.79045836\n",
      "Iteration 2343, loss = 1866.54678279\n",
      "Iteration 2344, loss = 1864.30665684\n",
      "Iteration 2345, loss = 1862.06107363\n",
      "Iteration 2346, loss = 1859.82754089\n",
      "Iteration 2347, loss = 1857.59823036\n",
      "Iteration 2348, loss = 1855.36371623\n",
      "Iteration 2349, loss = 1853.13700198\n",
      "Iteration 2350, loss = 1850.98040915\n",
      "Iteration 2351, loss = 1848.82481228\n",
      "Iteration 2352, loss = 1846.64971324\n",
      "Iteration 2353, loss = 1844.47172014\n",
      "Iteration 2354, loss = 1842.28142426\n",
      "Iteration 2355, loss = 1840.08023060\n",
      "Iteration 2356, loss = 1837.89355029\n",
      "Iteration 2357, loss = 1835.70989582\n",
      "Iteration 2358, loss = 1833.51868178\n",
      "Iteration 2359, loss = 1831.33455728\n",
      "Iteration 2360, loss = 1829.15148069\n",
      "Iteration 2361, loss = 1826.99366971\n",
      "Iteration 2362, loss = 1824.85050133\n",
      "Iteration 2363, loss = 1822.70055704\n",
      "Iteration 2364, loss = 1820.54337335\n",
      "Iteration 2365, loss = 1818.38431119\n",
      "Iteration 2366, loss = 1816.21189192\n",
      "Iteration 2367, loss = 1814.04337722\n",
      "Iteration 2368, loss = 1811.89385269\n",
      "Iteration 2369, loss = 1809.77181989\n",
      "Iteration 2370, loss = 1807.64590155\n",
      "Iteration 2371, loss = 1805.51494694\n",
      "Iteration 2372, loss = 1803.38979365\n",
      "Iteration 2373, loss = 1801.26451080\n",
      "Iteration 2374, loss = 1799.12745330\n",
      "Iteration 2375, loss = 1796.98728362\n",
      "Iteration 2376, loss = 1794.84967131\n",
      "Iteration 2377, loss = 1792.71646914\n",
      "Iteration 2378, loss = 1790.57786078\n",
      "Iteration 2379, loss = 1788.44500117\n",
      "Iteration 2380, loss = 1786.32564757\n",
      "Iteration 2381, loss = 1784.22401672\n",
      "Iteration 2382, loss = 1782.11317506\n",
      "Iteration 2383, loss = 1779.99202903\n",
      "Iteration 2384, loss = 1777.87279111\n",
      "Iteration 2385, loss = 1775.76356942\n",
      "Iteration 2386, loss = 1773.65444581\n",
      "Iteration 2387, loss = 1771.54738949\n",
      "Iteration 2388, loss = 1769.44370196\n",
      "Iteration 2389, loss = 1767.34392810\n",
      "Iteration 2390, loss = 1765.24704767\n",
      "Iteration 2391, loss = 1763.15576983\n",
      "Iteration 2392, loss = 1761.06030587\n",
      "Iteration 2393, loss = 1758.97350860\n",
      "Iteration 2394, loss = 1756.89388034\n",
      "Iteration 2395, loss = 1754.81356082\n",
      "Iteration 2396, loss = 1752.73971145\n",
      "Iteration 2397, loss = 1750.66960212\n",
      "Iteration 2398, loss = 1748.60214862\n",
      "Iteration 2399, loss = 1746.54507949\n",
      "Iteration 2400, loss = 1744.49356907\n",
      "Iteration 2401, loss = 1742.44416642\n",
      "Iteration 2402, loss = 1740.39961155\n",
      "Iteration 2403, loss = 1738.36840124\n",
      "Iteration 2404, loss = 1736.33249614\n",
      "Iteration 2405, loss = 1734.30067528\n",
      "Iteration 2406, loss = 1732.27463760\n",
      "Iteration 2407, loss = 1730.25409651\n",
      "Iteration 2408, loss = 1728.23598056\n",
      "Iteration 2409, loss = 1726.22169941\n",
      "Iteration 2410, loss = 1724.21347504\n",
      "Iteration 2411, loss = 1722.21258510\n",
      "Iteration 2412, loss = 1720.21463980\n",
      "Iteration 2413, loss = 1718.20566397\n",
      "Iteration 2414, loss = 1716.19726260\n",
      "Iteration 2415, loss = 1714.19024463\n",
      "Iteration 2416, loss = 1712.18572210\n",
      "Iteration 2417, loss = 1710.18386571\n",
      "Iteration 2418, loss = 1708.19003765\n",
      "Iteration 2419, loss = 1706.19353036\n",
      "Iteration 2420, loss = 1704.19969647\n",
      "Iteration 2421, loss = 1702.20600884\n",
      "Iteration 2422, loss = 1700.21545833\n",
      "Iteration 2423, loss = 1698.23662863\n",
      "Iteration 2424, loss = 1696.24981358\n",
      "Iteration 2425, loss = 1694.25626976\n",
      "Iteration 2426, loss = 1692.26968869\n",
      "Iteration 2427, loss = 1690.28775581\n",
      "Iteration 2428, loss = 1688.31550436\n",
      "Iteration 2429, loss = 1686.33954226\n",
      "Iteration 2430, loss = 1684.36036577\n",
      "Iteration 2431, loss = 1682.38932818\n",
      "Iteration 2432, loss = 1680.42287616\n",
      "Iteration 2433, loss = 1678.45092432\n",
      "Iteration 2434, loss = 1676.47482161\n",
      "Iteration 2435, loss = 1674.49952491\n",
      "Iteration 2436, loss = 1672.52820082\n",
      "Iteration 2437, loss = 1670.55853549\n",
      "Iteration 2438, loss = 1668.59075536\n",
      "Iteration 2439, loss = 1666.61992155\n",
      "Iteration 2440, loss = 1664.65459272\n",
      "Iteration 2441, loss = 1662.69206641\n",
      "Iteration 2442, loss = 1660.73298517\n",
      "Iteration 2443, loss = 1658.77533004\n",
      "Iteration 2444, loss = 1656.81514821\n",
      "Iteration 2445, loss = 1654.86009185\n",
      "Iteration 2446, loss = 1652.91252595\n",
      "Iteration 2447, loss = 1650.96317283\n",
      "Iteration 2448, loss = 1649.01513018\n",
      "Iteration 2449, loss = 1647.07821880\n",
      "Iteration 2450, loss = 1645.14049681\n",
      "Iteration 2451, loss = 1643.20347611\n",
      "Iteration 2452, loss = 1641.26945965\n",
      "Iteration 2453, loss = 1639.33364123\n",
      "Iteration 2454, loss = 1637.41706776\n",
      "Iteration 2455, loss = 1635.53797185\n",
      "Iteration 2456, loss = 1633.65583106\n",
      "Iteration 2457, loss = 1631.76707825\n",
      "Iteration 2458, loss = 1629.87244978\n",
      "Iteration 2459, loss = 1627.97804790\n",
      "Iteration 2460, loss = 1626.08191101\n",
      "Iteration 2461, loss = 1624.18576950\n",
      "Iteration 2462, loss = 1622.29388079\n",
      "Iteration 2463, loss = 1620.41359301\n",
      "Iteration 2464, loss = 1618.56230108\n",
      "Iteration 2465, loss = 1616.70789111\n",
      "Iteration 2466, loss = 1614.85196479\n",
      "Iteration 2467, loss = 1612.99290024\n",
      "Iteration 2468, loss = 1611.13364743\n",
      "Iteration 2469, loss = 1609.27778855\n",
      "Iteration 2470, loss = 1607.45025966\n",
      "Iteration 2471, loss = 1605.62170074\n",
      "Iteration 2472, loss = 1603.79552462\n",
      "Iteration 2473, loss = 1601.97243616\n",
      "Iteration 2474, loss = 1600.14972315\n",
      "Iteration 2475, loss = 1598.32805560\n",
      "Iteration 2476, loss = 1596.50967494\n",
      "Iteration 2477, loss = 1594.69405191\n",
      "Iteration 2478, loss = 1592.87054146\n",
      "Iteration 2479, loss = 1591.05434317\n",
      "Iteration 2480, loss = 1589.23603594\n",
      "Iteration 2481, loss = 1587.40844501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2482, loss = 1585.57359097\n",
      "Iteration 2483, loss = 1583.75012916\n",
      "Iteration 2484, loss = 1581.93884967\n",
      "Iteration 2485, loss = 1580.12864197\n",
      "Iteration 2486, loss = 1578.30138259\n",
      "Iteration 2487, loss = 1576.47398746\n",
      "Iteration 2488, loss = 1574.64704593\n",
      "Iteration 2489, loss = 1572.82071200\n",
      "Iteration 2490, loss = 1570.99847457\n",
      "Iteration 2491, loss = 1569.17949989\n",
      "Iteration 2492, loss = 1567.36104997\n",
      "Iteration 2493, loss = 1565.54622550\n",
      "Iteration 2494, loss = 1563.73416196\n",
      "Iteration 2495, loss = 1561.92533802\n",
      "Iteration 2496, loss = 1560.11906160\n",
      "Iteration 2497, loss = 1558.33181423\n",
      "Iteration 2498, loss = 1556.52939541\n",
      "Iteration 2499, loss = 1554.73121981\n",
      "Iteration 2500, loss = 1552.94335581\n",
      "Iteration 2501, loss = 1551.15709063\n",
      "Iteration 2502, loss = 1549.37219479\n",
      "Iteration 2503, loss = 1547.59258780\n",
      "Iteration 2504, loss = 1545.81799191\n",
      "Iteration 2505, loss = 1544.04422241\n",
      "Iteration 2506, loss = 1542.27418123\n",
      "Iteration 2507, loss = 1540.50594754\n",
      "Iteration 2508, loss = 1538.74481426\n",
      "Iteration 2509, loss = 1536.98481567\n",
      "Iteration 2510, loss = 1535.22943674\n",
      "Iteration 2511, loss = 1533.47828667\n",
      "Iteration 2512, loss = 1531.73281737\n",
      "Iteration 2513, loss = 1529.98851557\n",
      "Iteration 2514, loss = 1528.24775057\n",
      "Iteration 2515, loss = 1526.51448424\n",
      "Iteration 2516, loss = 1524.78204409\n",
      "Iteration 2517, loss = 1523.05536435\n",
      "Iteration 2518, loss = 1521.32902039\n",
      "Iteration 2519, loss = 1519.60726731\n",
      "Iteration 2520, loss = 1517.88503039\n",
      "Iteration 2521, loss = 1516.17075083\n",
      "Iteration 2522, loss = 1514.45856313\n",
      "Iteration 2523, loss = 1512.74984650\n",
      "Iteration 2524, loss = 1511.04346934\n",
      "Iteration 2525, loss = 1509.34156316\n",
      "Iteration 2526, loss = 1507.63964535\n",
      "Iteration 2527, loss = 1505.92007220\n",
      "Iteration 2528, loss = 1504.19156909\n",
      "Iteration 2529, loss = 1502.46611243\n",
      "Iteration 2530, loss = 1500.73957063\n",
      "Iteration 2531, loss = 1499.01217227\n",
      "Iteration 2532, loss = 1497.28482092\n",
      "Iteration 2533, loss = 1495.56039021\n",
      "Iteration 2534, loss = 1493.83707464\n",
      "Iteration 2535, loss = 1492.11312271\n",
      "Iteration 2536, loss = 1490.39241059\n",
      "Iteration 2537, loss = 1488.67262830\n",
      "Iteration 2538, loss = 1486.94375410\n",
      "Iteration 2539, loss = 1485.21724690\n",
      "Iteration 2540, loss = 1483.49497190\n",
      "Iteration 2541, loss = 1481.77309108\n",
      "Iteration 2542, loss = 1480.04727490\n",
      "Iteration 2543, loss = 1478.32685014\n",
      "Iteration 2544, loss = 1476.60902411\n",
      "Iteration 2545, loss = 1474.89144150\n",
      "Iteration 2546, loss = 1473.17555741\n",
      "Iteration 2547, loss = 1471.46400182\n",
      "Iteration 2548, loss = 1469.75098896\n",
      "Iteration 2549, loss = 1468.04202914\n",
      "Iteration 2550, loss = 1466.33610649\n",
      "Iteration 2551, loss = 1464.62902563\n",
      "Iteration 2552, loss = 1462.92562284\n",
      "Iteration 2553, loss = 1461.22388991\n",
      "Iteration 2554, loss = 1459.52379649\n",
      "Iteration 2555, loss = 1457.82643468\n",
      "Iteration 2556, loss = 1456.12976790\n",
      "Iteration 2557, loss = 1454.42836146\n",
      "Iteration 2558, loss = 1452.72096595\n",
      "Iteration 2559, loss = 1451.00908656\n",
      "Iteration 2560, loss = 1449.30150240\n",
      "Iteration 2561, loss = 1447.59024147\n",
      "Iteration 2562, loss = 1445.88364559\n",
      "Iteration 2563, loss = 1444.18019013\n",
      "Iteration 2564, loss = 1442.47974899\n",
      "Iteration 2565, loss = 1440.77894130\n",
      "Iteration 2566, loss = 1439.07953142\n",
      "Iteration 2567, loss = 1437.38365430\n",
      "Iteration 2568, loss = 1435.68566615\n",
      "Iteration 2569, loss = 1433.98559775\n",
      "Iteration 2570, loss = 1432.29264328\n",
      "Iteration 2571, loss = 1430.60036696\n",
      "Iteration 2572, loss = 1428.90866256\n",
      "Iteration 2573, loss = 1427.21894781\n",
      "Iteration 2574, loss = 1425.53319078\n",
      "Iteration 2575, loss = 1423.85261413\n",
      "Iteration 2576, loss = 1422.17288114\n",
      "Iteration 2577, loss = 1420.49488899\n",
      "Iteration 2578, loss = 1418.81865674\n",
      "Iteration 2579, loss = 1417.14364172\n",
      "Iteration 2580, loss = 1415.47086344\n",
      "Iteration 2581, loss = 1413.80110969\n",
      "Iteration 2582, loss = 1412.13097746\n",
      "Iteration 2583, loss = 1410.47952391\n",
      "Iteration 2584, loss = 1408.87316504\n",
      "Iteration 2585, loss = 1407.24705408\n",
      "Iteration 2586, loss = 1405.60688515\n",
      "Iteration 2587, loss = 1403.95690245\n",
      "Iteration 2588, loss = 1402.29752813\n",
      "Iteration 2589, loss = 1400.68873874\n",
      "Iteration 2590, loss = 1399.08252323\n",
      "Iteration 2591, loss = 1397.47479845\n",
      "Iteration 2592, loss = 1395.86812848\n",
      "Iteration 2593, loss = 1394.26148839\n",
      "Iteration 2594, loss = 1392.65357485\n",
      "Iteration 2595, loss = 1391.04464805\n",
      "Iteration 2596, loss = 1389.43632441\n",
      "Iteration 2597, loss = 1387.82636866\n",
      "Iteration 2598, loss = 1386.21829619\n",
      "Iteration 2599, loss = 1384.65057256\n",
      "Iteration 2600, loss = 1383.08199241\n",
      "Iteration 2601, loss = 1381.50561126\n",
      "Iteration 2602, loss = 1379.92264790\n",
      "Iteration 2603, loss = 1378.33476376\n",
      "Iteration 2604, loss = 1376.74436421\n",
      "Iteration 2605, loss = 1375.18654943\n",
      "Iteration 2606, loss = 1373.63918494\n",
      "Iteration 2607, loss = 1372.08574398\n",
      "Iteration 2608, loss = 1370.52893305\n",
      "Iteration 2609, loss = 1368.97023954\n",
      "Iteration 2610, loss = 1367.40778472\n",
      "Iteration 2611, loss = 1365.85165767\n",
      "Iteration 2612, loss = 1364.32106352\n",
      "Iteration 2613, loss = 1362.78618766\n",
      "Iteration 2614, loss = 1361.24754143\n",
      "Iteration 2615, loss = 1359.70772878\n",
      "Iteration 2616, loss = 1358.18276563\n",
      "Iteration 2617, loss = 1356.66520598\n",
      "Iteration 2618, loss = 1355.14082932\n",
      "Iteration 2619, loss = 1353.61473588\n",
      "Iteration 2620, loss = 1352.10522284\n",
      "Iteration 2621, loss = 1350.59282749\n",
      "Iteration 2622, loss = 1349.08687481\n",
      "Iteration 2623, loss = 1347.57974793\n",
      "Iteration 2624, loss = 1346.08463146\n",
      "Iteration 2625, loss = 1344.59095942\n",
      "Iteration 2626, loss = 1343.09518285\n",
      "Iteration 2627, loss = 1341.59968715\n",
      "Iteration 2628, loss = 1340.11556227\n",
      "Iteration 2629, loss = 1338.63220605\n",
      "Iteration 2630, loss = 1337.15101746\n",
      "Iteration 2631, loss = 1335.67480633\n",
      "Iteration 2632, loss = 1334.20052385\n",
      "Iteration 2633, loss = 1332.72785682\n",
      "Iteration 2634, loss = 1331.26846717\n",
      "Iteration 2635, loss = 1329.80081479\n",
      "Iteration 2636, loss = 1328.33879122\n",
      "Iteration 2637, loss = 1326.88515230\n",
      "Iteration 2638, loss = 1325.43399568\n",
      "Iteration 2639, loss = 1323.98115078\n",
      "Iteration 2640, loss = 1322.52392447\n",
      "Iteration 2641, loss = 1321.06817845\n",
      "Iteration 2642, loss = 1319.62936218\n",
      "Iteration 2643, loss = 1318.18139626\n",
      "Iteration 2644, loss = 1316.73126653\n",
      "Iteration 2645, loss = 1315.29182869\n",
      "Iteration 2646, loss = 1313.85544258\n",
      "Iteration 2647, loss = 1312.41952923\n",
      "Iteration 2648, loss = 1310.98430113\n",
      "Iteration 2649, loss = 1309.55195391\n",
      "Iteration 2650, loss = 1308.12052672\n",
      "Iteration 2651, loss = 1306.69246743\n",
      "Iteration 2652, loss = 1305.28083764\n",
      "Iteration 2653, loss = 1303.85338360\n",
      "Iteration 2654, loss = 1302.42483077\n",
      "Iteration 2655, loss = 1301.00392128\n",
      "Iteration 2656, loss = 1299.58396993\n",
      "Iteration 2657, loss = 1298.16549364\n",
      "Iteration 2658, loss = 1296.74771860\n",
      "Iteration 2659, loss = 1295.33135071\n",
      "Iteration 2660, loss = 1293.91818983\n",
      "Iteration 2661, loss = 1292.50706629\n",
      "Iteration 2662, loss = 1291.09926301\n",
      "Iteration 2663, loss = 1289.69410214\n",
      "Iteration 2664, loss = 1288.29030905\n",
      "Iteration 2665, loss = 1286.88974438\n",
      "Iteration 2666, loss = 1285.49229282\n",
      "Iteration 2667, loss = 1284.09759373\n",
      "Iteration 2668, loss = 1282.70646061\n",
      "Iteration 2669, loss = 1281.31887591\n",
      "Iteration 2670, loss = 1279.93385972\n",
      "Iteration 2671, loss = 1278.55120939\n",
      "Iteration 2672, loss = 1277.17146054\n",
      "Iteration 2673, loss = 1275.79482501\n",
      "Iteration 2674, loss = 1274.41967485\n",
      "Iteration 2675, loss = 1273.04660951\n",
      "Iteration 2676, loss = 1271.67527323\n",
      "Iteration 2677, loss = 1270.30544215\n",
      "Iteration 2678, loss = 1268.93806656\n",
      "Iteration 2679, loss = 1267.57271708\n",
      "Iteration 2680, loss = 1266.21214142\n",
      "Iteration 2681, loss = 1264.85677119\n",
      "Iteration 2682, loss = 1263.50406854\n",
      "Iteration 2683, loss = 1262.15324828\n",
      "Iteration 2684, loss = 1260.80464522\n",
      "Iteration 2685, loss = 1259.45775803\n",
      "Iteration 2686, loss = 1258.11219248\n",
      "Iteration 2687, loss = 1256.76934391\n",
      "Iteration 2688, loss = 1255.42952007\n",
      "Iteration 2689, loss = 1254.09253878\n",
      "Iteration 2690, loss = 1252.75686881\n",
      "Iteration 2691, loss = 1251.41912021\n",
      "Iteration 2692, loss = 1250.07806706\n",
      "Iteration 2693, loss = 1248.73807806\n",
      "Iteration 2694, loss = 1247.39805565\n",
      "Iteration 2695, loss = 1246.05817546\n",
      "Iteration 2696, loss = 1244.72093956\n",
      "Iteration 2697, loss = 1243.38720224\n",
      "Iteration 2698, loss = 1242.05291962\n",
      "Iteration 2699, loss = 1240.71879821\n",
      "Iteration 2700, loss = 1239.38715605\n",
      "Iteration 2701, loss = 1238.05836528\n",
      "Iteration 2702, loss = 1236.73051372\n",
      "Iteration 2703, loss = 1235.40300879\n",
      "Iteration 2704, loss = 1234.07814043\n",
      "Iteration 2705, loss = 1232.75582611\n",
      "Iteration 2706, loss = 1231.43396293\n",
      "Iteration 2707, loss = 1230.11334702\n",
      "Iteration 2708, loss = 1228.79544376\n",
      "Iteration 2709, loss = 1227.47897859\n",
      "Iteration 2710, loss = 1226.16526131\n",
      "Iteration 2711, loss = 1224.85050220\n",
      "Iteration 2712, loss = 1223.54004340\n",
      "Iteration 2713, loss = 1222.23150670\n",
      "Iteration 2714, loss = 1220.92456996\n",
      "Iteration 2715, loss = 1219.61917856\n",
      "Iteration 2716, loss = 1218.31503591\n",
      "Iteration 2717, loss = 1217.01180554\n",
      "Iteration 2718, loss = 1215.71200196\n",
      "Iteration 2719, loss = 1214.41443708\n",
      "Iteration 2720, loss = 1213.11889316\n",
      "Iteration 2721, loss = 1211.82611468\n",
      "Iteration 2722, loss = 1210.53068934\n",
      "Iteration 2723, loss = 1209.24107057\n",
      "Iteration 2724, loss = 1207.95278945\n",
      "Iteration 2725, loss = 1206.66580357\n",
      "Iteration 2726, loss = 1205.38035362\n",
      "Iteration 2727, loss = 1204.09650514\n",
      "Iteration 2728, loss = 1202.81565350\n",
      "Iteration 2729, loss = 1201.53742331\n",
      "Iteration 2730, loss = 1200.25767939\n",
      "Iteration 2731, loss = 1198.98290130\n",
      "Iteration 2732, loss = 1197.70762206\n",
      "Iteration 2733, loss = 1196.43804480\n",
      "Iteration 2734, loss = 1195.16781228\n",
      "Iteration 2735, loss = 1193.89954850\n",
      "Iteration 2736, loss = 1192.63327790\n",
      "Iteration 2737, loss = 1191.36890517\n",
      "Iteration 2738, loss = 1190.10621496\n",
      "Iteration 2739, loss = 1188.84616312\n",
      "Iteration 2740, loss = 1187.58730442\n",
      "Iteration 2741, loss = 1186.32812887\n",
      "Iteration 2742, loss = 1185.07321577\n",
      "Iteration 2743, loss = 1183.82101450\n",
      "Iteration 2744, loss = 1182.57002889\n",
      "Iteration 2745, loss = 1181.31914092\n",
      "Iteration 2746, loss = 1180.07259327\n",
      "Iteration 2747, loss = 1178.82729440\n",
      "Iteration 2748, loss = 1177.58331402\n",
      "Iteration 2749, loss = 1176.34057715\n",
      "Iteration 2750, loss = 1175.10253291\n",
      "Iteration 2751, loss = 1173.86279188\n",
      "Iteration 2752, loss = 1172.62631639\n",
      "Iteration 2753, loss = 1171.39156185\n",
      "Iteration 2754, loss = 1170.15934198\n",
      "Iteration 2755, loss = 1168.92861159\n",
      "Iteration 2756, loss = 1167.69969474\n",
      "Iteration 2757, loss = 1166.47220019\n",
      "Iteration 2758, loss = 1165.24682195\n",
      "Iteration 2759, loss = 1164.02464593\n",
      "Iteration 2760, loss = 1162.80379624\n",
      "Iteration 2761, loss = 1161.58332433\n",
      "Iteration 2762, loss = 1160.36581418\n",
      "Iteration 2763, loss = 1159.15001425\n",
      "Iteration 2764, loss = 1157.93521837\n",
      "Iteration 2765, loss = 1156.72182311\n",
      "Iteration 2766, loss = 1155.51179736\n",
      "Iteration 2767, loss = 1154.30335435\n",
      "Iteration 2768, loss = 1153.09106664\n",
      "Iteration 2769, loss = 1151.88059023\n",
      "Iteration 2770, loss = 1150.66537418\n",
      "Iteration 2771, loss = 1149.45497537\n",
      "Iteration 2772, loss = 1148.24558931\n",
      "Iteration 2773, loss = 1147.03739701\n",
      "Iteration 2774, loss = 1145.83006455\n",
      "Iteration 2775, loss = 1144.62454118\n",
      "Iteration 2776, loss = 1143.41953743\n",
      "Iteration 2777, loss = 1142.21761378\n",
      "Iteration 2778, loss = 1141.01222600\n",
      "Iteration 2779, loss = 1139.80843759\n",
      "Iteration 2780, loss = 1138.60500936\n",
      "Iteration 2781, loss = 1137.40234601\n",
      "Iteration 2782, loss = 1136.20251328\n",
      "Iteration 2783, loss = 1135.00362430\n",
      "Iteration 2784, loss = 1133.80407667\n",
      "Iteration 2785, loss = 1132.60868973\n",
      "Iteration 2786, loss = 1131.41011935\n",
      "Iteration 2787, loss = 1130.20708573\n",
      "Iteration 2788, loss = 1129.00841285\n",
      "Iteration 2789, loss = 1127.80625721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2790, loss = 1126.60756841\n",
      "Iteration 2791, loss = 1125.40947015\n",
      "Iteration 2792, loss = 1124.24980768\n",
      "Iteration 2793, loss = 1123.08179526\n",
      "Iteration 2794, loss = 1121.89636231\n",
      "Iteration 2795, loss = 1120.69425588\n",
      "Iteration 2796, loss = 1119.49064151\n",
      "Iteration 2797, loss = 1118.32037303\n",
      "Iteration 2798, loss = 1117.15020056\n",
      "Iteration 2799, loss = 1115.98068893\n",
      "Iteration 2800, loss = 1114.81152685\n",
      "Iteration 2801, loss = 1113.64336376\n",
      "Iteration 2802, loss = 1112.47633806\n",
      "Iteration 2803, loss = 1111.30752483\n",
      "Iteration 2804, loss = 1110.13918829\n",
      "Iteration 2805, loss = 1108.97045391\n",
      "Iteration 2806, loss = 1107.82301111\n",
      "Iteration 2807, loss = 1106.67179115\n",
      "Iteration 2808, loss = 1105.50631222\n",
      "Iteration 2809, loss = 1104.34329307\n",
      "Iteration 2810, loss = 1103.19671550\n",
      "Iteration 2811, loss = 1102.04882803\n",
      "Iteration 2812, loss = 1100.90114527\n",
      "Iteration 2813, loss = 1099.75526497\n",
      "Iteration 2814, loss = 1098.60974767\n",
      "Iteration 2815, loss = 1097.48381215\n",
      "Iteration 2816, loss = 1096.35029666\n",
      "Iteration 2817, loss = 1095.20670065\n",
      "Iteration 2818, loss = 1094.06674257\n",
      "Iteration 2819, loss = 1092.93927162\n",
      "Iteration 2820, loss = 1091.80788241\n",
      "Iteration 2821, loss = 1090.67568303\n",
      "Iteration 2822, loss = 1089.54337165\n",
      "Iteration 2823, loss = 1088.42750625\n",
      "Iteration 2824, loss = 1087.30720124\n",
      "Iteration 2825, loss = 1086.17969506\n",
      "Iteration 2826, loss = 1085.05947661\n",
      "Iteration 2827, loss = 1083.94760128\n",
      "Iteration 2828, loss = 1082.83167413\n",
      "Iteration 2829, loss = 1081.70983183\n",
      "Iteration 2830, loss = 1080.59148800\n",
      "Iteration 2831, loss = 1079.47621808\n",
      "Iteration 2832, loss = 1078.35445357\n",
      "Iteration 2833, loss = 1077.24514629\n",
      "Iteration 2834, loss = 1076.13493001\n",
      "Iteration 2835, loss = 1075.01951885\n",
      "Iteration 2836, loss = 1073.90312966\n",
      "Iteration 2837, loss = 1072.79925325\n",
      "Iteration 2838, loss = 1071.69618732\n",
      "Iteration 2839, loss = 1070.58718345\n",
      "Iteration 2840, loss = 1069.47479714\n",
      "Iteration 2841, loss = 1068.38101605\n",
      "Iteration 2842, loss = 1067.28746174\n",
      "Iteration 2843, loss = 1066.19410236\n",
      "Iteration 2844, loss = 1065.09592859\n",
      "Iteration 2845, loss = 1064.00205898\n",
      "Iteration 2846, loss = 1062.91905682\n",
      "Iteration 2847, loss = 1061.82945955\n",
      "Iteration 2848, loss = 1060.73897135\n",
      "Iteration 2849, loss = 1059.66742462\n",
      "Iteration 2850, loss = 1058.59082712\n",
      "Iteration 2851, loss = 1057.50667498\n",
      "Iteration 2852, loss = 1056.41789007\n",
      "Iteration 2853, loss = 1055.35680322\n",
      "Iteration 2854, loss = 1054.28970364\n",
      "Iteration 2855, loss = 1053.22051349\n",
      "Iteration 2856, loss = 1052.14820023\n",
      "Iteration 2857, loss = 1051.07410997\n",
      "Iteration 2858, loss = 1050.00017669\n",
      "Iteration 2859, loss = 1048.94220242\n",
      "Iteration 2860, loss = 1047.88100530\n",
      "Iteration 2861, loss = 1046.80861952\n",
      "Iteration 2862, loss = 1045.73382874\n",
      "Iteration 2863, loss = 1044.67642278\n",
      "Iteration 2864, loss = 1043.62020850\n",
      "Iteration 2865, loss = 1042.56009255\n",
      "Iteration 2866, loss = 1041.49887382\n",
      "Iteration 2867, loss = 1040.42991132\n",
      "Iteration 2868, loss = 1039.35792921\n",
      "Iteration 2869, loss = 1038.28539086\n",
      "Iteration 2870, loss = 1037.22393575\n",
      "Iteration 2871, loss = 1036.16017653\n",
      "Iteration 2872, loss = 1035.10177653\n",
      "Iteration 2873, loss = 1034.03814103\n",
      "Iteration 2874, loss = 1032.98495566\n",
      "Iteration 2875, loss = 1031.92391019\n",
      "Iteration 2876, loss = 1030.86401818\n",
      "Iteration 2877, loss = 1029.80939589\n",
      "Iteration 2878, loss = 1028.75423065\n",
      "Iteration 2879, loss = 1027.69936946\n",
      "Iteration 2880, loss = 1026.64362206\n",
      "Iteration 2881, loss = 1025.58988320\n",
      "Iteration 2882, loss = 1024.53813234\n",
      "Iteration 2883, loss = 1023.49246159\n",
      "Iteration 2884, loss = 1022.44781030\n",
      "Iteration 2885, loss = 1021.40158109\n",
      "Iteration 2886, loss = 1020.35831932\n",
      "Iteration 2887, loss = 1019.30595391\n",
      "Iteration 2888, loss = 1018.25273474\n",
      "Iteration 2889, loss = 1017.20166627\n",
      "Iteration 2890, loss = 1016.15212609\n",
      "Iteration 2891, loss = 1015.10220848\n",
      "Iteration 2892, loss = 1014.05193709\n",
      "Iteration 2893, loss = 1012.99565305\n",
      "Iteration 2894, loss = 1011.94099813\n",
      "Iteration 2895, loss = 1010.88593259\n",
      "Iteration 2896, loss = 1009.83253824\n",
      "Iteration 2897, loss = 1008.77772968\n",
      "Iteration 2898, loss = 1007.72527034\n",
      "Iteration 2899, loss = 1006.67424432\n",
      "Iteration 2900, loss = 1005.62641344\n",
      "Iteration 2901, loss = 1004.57468886\n",
      "Iteration 2902, loss = 1003.51904547\n",
      "Iteration 2903, loss = 1002.46913056\n",
      "Iteration 2904, loss = 1001.45340748\n",
      "Iteration 2905, loss = 1000.42994095\n",
      "Iteration 2906, loss = 999.39298184\n",
      "Iteration 2907, loss = 998.33810295\n",
      "Iteration 2908, loss = 997.27356553\n",
      "Iteration 2909, loss = 996.20554619\n",
      "Iteration 2910, loss = 995.17642419\n",
      "Iteration 2911, loss = 994.13674832\n",
      "Iteration 2912, loss = 993.10305766\n",
      "Iteration 2913, loss = 992.06672074\n",
      "Iteration 2914, loss = 991.03026478\n",
      "Iteration 2915, loss = 989.99449891\n",
      "Iteration 2916, loss = 988.95772421\n",
      "Iteration 2917, loss = 987.92099667\n",
      "Iteration 2918, loss = 986.88572366\n",
      "Iteration 2919, loss = 985.85925756\n",
      "Iteration 2920, loss = 984.83841604\n",
      "Iteration 2921, loss = 983.81165678\n",
      "Iteration 2922, loss = 982.78321228\n",
      "Iteration 2923, loss = 981.76629034\n",
      "Iteration 2924, loss = 980.74951331\n",
      "Iteration 2925, loss = 979.73133159\n",
      "Iteration 2926, loss = 978.71220911\n",
      "Iteration 2927, loss = 977.70756133\n",
      "Iteration 2928, loss = 976.69561325\n",
      "Iteration 2929, loss = 975.67654956\n",
      "Iteration 2930, loss = 974.67241402\n",
      "Iteration 2931, loss = 973.67115458\n",
      "Iteration 2932, loss = 972.66911145\n",
      "Iteration 2933, loss = 971.66197800\n",
      "Iteration 2934, loss = 970.65409699\n",
      "Iteration 2935, loss = 969.63866304\n",
      "Iteration 2936, loss = 968.63028571\n",
      "Iteration 2937, loss = 967.62284020\n",
      "Iteration 2938, loss = 966.61018098\n",
      "Iteration 2939, loss = 965.61918397\n",
      "Iteration 2940, loss = 964.63649253\n",
      "Iteration 2941, loss = 963.65011203\n",
      "Iteration 2942, loss = 962.66397119\n",
      "Iteration 2943, loss = 961.67696925\n",
      "Iteration 2944, loss = 960.70386816\n",
      "Iteration 2945, loss = 959.72802743\n",
      "Iteration 2946, loss = 958.74429416\n",
      "Iteration 2947, loss = 957.76258587\n",
      "Iteration 2948, loss = 956.78882280\n",
      "Iteration 2949, loss = 955.81406710\n",
      "Iteration 2950, loss = 954.83864010\n",
      "Iteration 2951, loss = 953.86113321\n",
      "Iteration 2952, loss = 952.89926347\n",
      "Iteration 2953, loss = 951.93323303\n",
      "Iteration 2954, loss = 950.95948431\n",
      "Iteration 2955, loss = 949.98856912\n",
      "Iteration 2956, loss = 949.02799205\n",
      "Iteration 2957, loss = 948.06290180\n",
      "Iteration 2958, loss = 947.09667754\n",
      "Iteration 2959, loss = 946.13476544\n",
      "Iteration 2960, loss = 945.17458608\n",
      "Iteration 2961, loss = 944.21299876\n",
      "Iteration 2962, loss = 943.25710472\n",
      "Iteration 2963, loss = 942.29404276\n",
      "Iteration 2964, loss = 941.33802903\n",
      "Iteration 2965, loss = 940.37793110\n",
      "Iteration 2966, loss = 939.41617955\n",
      "Iteration 2967, loss = 938.45893885\n",
      "Iteration 2968, loss = 937.50071313\n",
      "Iteration 2969, loss = 936.54793910\n",
      "Iteration 2970, loss = 935.59235820\n",
      "Iteration 2971, loss = 934.63979516\n",
      "Iteration 2972, loss = 933.68925664\n",
      "Iteration 2973, loss = 932.73712355\n",
      "Iteration 2974, loss = 931.78453524\n",
      "Iteration 2975, loss = 930.83688752\n",
      "Iteration 2976, loss = 929.89176674\n",
      "Iteration 2977, loss = 928.94632595\n",
      "Iteration 2978, loss = 928.00237175\n",
      "Iteration 2979, loss = 927.06385529\n",
      "Iteration 2980, loss = 926.11858105\n",
      "Iteration 2981, loss = 925.17714068\n",
      "Iteration 2982, loss = 924.23503520\n",
      "Iteration 2983, loss = 923.29136797\n",
      "Iteration 2984, loss = 922.34705967\n",
      "Iteration 2985, loss = 921.41019796\n",
      "Iteration 2986, loss = 920.47138582\n",
      "Iteration 2987, loss = 919.52725491\n",
      "Iteration 2988, loss = 918.59568143\n",
      "Iteration 2989, loss = 917.66419572\n",
      "Iteration 2990, loss = 916.73094763\n",
      "Iteration 2991, loss = 915.79739031\n",
      "Iteration 2992, loss = 914.86083223\n",
      "Iteration 2993, loss = 913.93106966\n",
      "Iteration 2994, loss = 913.00575803\n",
      "Iteration 2995, loss = 912.07360395\n",
      "Iteration 2996, loss = 911.15235071\n",
      "Iteration 2997, loss = 910.23293802\n",
      "Iteration 2998, loss = 909.31104993\n",
      "Iteration 2999, loss = 908.38791009\n",
      "Iteration 3000, loss = 907.46377715\n",
      "Iteration 3001, loss = 906.55711836\n",
      "Iteration 3002, loss = 905.64580607\n",
      "Iteration 3003, loss = 904.72797963\n",
      "Iteration 3004, loss = 903.80581527\n",
      "Iteration 3005, loss = 902.90672180\n",
      "Iteration 3006, loss = 902.00491913\n",
      "Iteration 3007, loss = 901.10106939\n",
      "Iteration 3008, loss = 900.19534457\n",
      "Iteration 3009, loss = 899.28938124\n",
      "Iteration 3010, loss = 898.38210636\n",
      "Iteration 3011, loss = 897.47602234\n",
      "Iteration 3012, loss = 896.58985276\n",
      "Iteration 3013, loss = 895.69990434\n",
      "Iteration 3014, loss = 894.80514493\n",
      "Iteration 3015, loss = 893.90556743\n",
      "Iteration 3016, loss = 893.00286677\n",
      "Iteration 3017, loss = 892.12589562\n",
      "Iteration 3018, loss = 891.24458139\n",
      "Iteration 3019, loss = 890.36319293\n",
      "Iteration 3020, loss = 889.48045803\n",
      "Iteration 3021, loss = 888.59662218\n",
      "Iteration 3022, loss = 887.71159493\n",
      "Iteration 3023, loss = 886.82458100\n",
      "Iteration 3024, loss = 885.93990225\n",
      "Iteration 3025, loss = 885.07078817\n",
      "Iteration 3026, loss = 884.19604502\n",
      "Iteration 3027, loss = 883.32046211\n",
      "Iteration 3028, loss = 882.45301080\n",
      "Iteration 3029, loss = 881.58257967\n",
      "Iteration 3030, loss = 880.71940107\n",
      "Iteration 3031, loss = 879.85579332\n",
      "Iteration 3032, loss = 878.99098744\n",
      "Iteration 3033, loss = 878.13084802\n",
      "Iteration 3034, loss = 877.27039498\n",
      "Iteration 3035, loss = 876.41447254\n",
      "Iteration 3036, loss = 875.55910245\n",
      "Iteration 3037, loss = 874.70640638\n",
      "Iteration 3038, loss = 873.85601577\n",
      "Iteration 3039, loss = 873.00492189\n",
      "Iteration 3040, loss = 872.15713068\n",
      "Iteration 3041, loss = 871.31014715\n",
      "Iteration 3042, loss = 870.46435565\n",
      "Iteration 3043, loss = 869.61897587\n",
      "Iteration 3044, loss = 868.77301305\n",
      "Iteration 3045, loss = 867.93073234\n",
      "Iteration 3046, loss = 867.08954066\n",
      "Iteration 3047, loss = 866.24799970\n",
      "Iteration 3048, loss = 865.41176570\n",
      "Iteration 3049, loss = 864.57330502\n",
      "Iteration 3050, loss = 863.74144503\n",
      "Iteration 3051, loss = 862.90820825\n",
      "Iteration 3052, loss = 862.07131206\n",
      "Iteration 3053, loss = 861.23917442\n",
      "Iteration 3054, loss = 860.40738463\n",
      "Iteration 3055, loss = 859.58030514\n",
      "Iteration 3056, loss = 858.75291486\n",
      "Iteration 3057, loss = 857.92977386\n",
      "Iteration 3058, loss = 857.10214375\n",
      "Iteration 3059, loss = 856.27954717\n",
      "Iteration 3060, loss = 855.47385924\n",
      "Iteration 3061, loss = 854.67099242\n",
      "Iteration 3062, loss = 853.86701935\n",
      "Iteration 3063, loss = 853.05826354\n",
      "Iteration 3064, loss = 852.24717559\n",
      "Iteration 3065, loss = 851.43506056\n",
      "Iteration 3066, loss = 850.61919349\n",
      "Iteration 3067, loss = 849.80710935\n",
      "Iteration 3068, loss = 849.00690785\n",
      "Iteration 3069, loss = 848.20841092\n",
      "Iteration 3070, loss = 847.41777026\n",
      "Iteration 3071, loss = 846.62533094\n",
      "Iteration 3072, loss = 845.82778994\n",
      "Iteration 3073, loss = 845.02828554\n",
      "Iteration 3074, loss = 844.24503628\n",
      "Iteration 3075, loss = 843.45504201\n",
      "Iteration 3076, loss = 842.66065220\n",
      "Iteration 3077, loss = 841.86443101\n",
      "Iteration 3078, loss = 841.07856671\n",
      "Iteration 3079, loss = 840.30900389\n",
      "Iteration 3080, loss = 839.53575671\n",
      "Iteration 3081, loss = 838.75615475\n",
      "Iteration 3082, loss = 837.97125241\n",
      "Iteration 3083, loss = 837.18179246\n",
      "Iteration 3084, loss = 836.40215418\n",
      "Iteration 3085, loss = 835.63776636\n",
      "Iteration 3086, loss = 834.86942015\n",
      "Iteration 3087, loss = 834.09652234\n",
      "Iteration 3088, loss = 833.31697788\n",
      "Iteration 3089, loss = 832.54623085\n",
      "Iteration 3090, loss = 831.78583882\n",
      "Iteration 3091, loss = 831.02639643\n",
      "Iteration 3092, loss = 830.26365009\n",
      "Iteration 3093, loss = 829.51155569\n",
      "Iteration 3094, loss = 828.75712395\n",
      "Iteration 3095, loss = 828.00462352\n",
      "Iteration 3096, loss = 827.25209973\n",
      "Iteration 3097, loss = 826.49602610\n",
      "Iteration 3098, loss = 825.74501868\n",
      "Iteration 3099, loss = 824.99635337\n",
      "Iteration 3100, loss = 824.25232581\n",
      "Iteration 3101, loss = 823.50372677\n",
      "Iteration 3102, loss = 822.76694803\n",
      "Iteration 3103, loss = 822.02739912\n",
      "Iteration 3104, loss = 821.28446907\n",
      "Iteration 3105, loss = 820.54028033\n",
      "Iteration 3106, loss = 819.80112188\n",
      "Iteration 3107, loss = 819.05617313\n",
      "Iteration 3108, loss = 818.32759161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3109, loss = 817.60205783\n",
      "Iteration 3110, loss = 816.87192881\n",
      "Iteration 3111, loss = 816.13056158\n",
      "Iteration 3112, loss = 815.38472901\n",
      "Iteration 3113, loss = 814.65166759\n",
      "Iteration 3114, loss = 813.92784189\n",
      "Iteration 3115, loss = 813.19729208\n",
      "Iteration 3116, loss = 812.46360045\n",
      "Iteration 3117, loss = 811.74351291\n",
      "Iteration 3118, loss = 811.01690162\n",
      "Iteration 3119, loss = 810.28968186\n",
      "Iteration 3120, loss = 809.55878247\n",
      "Iteration 3121, loss = 808.83604322\n",
      "Iteration 3122, loss = 808.11094657\n",
      "Iteration 3123, loss = 807.38505540\n",
      "Iteration 3124, loss = 806.66109645\n",
      "Iteration 3125, loss = 805.94447700\n",
      "Iteration 3126, loss = 805.23006733\n",
      "Iteration 3127, loss = 804.51375146\n",
      "Iteration 3128, loss = 803.79633302\n",
      "Iteration 3129, loss = 803.07565120\n",
      "Iteration 3130, loss = 802.36929395\n",
      "Iteration 3131, loss = 801.66418937\n",
      "Iteration 3132, loss = 800.95304515\n",
      "Iteration 3133, loss = 800.24001284\n",
      "Iteration 3134, loss = 799.53332335\n",
      "Iteration 3135, loss = 798.82711760\n",
      "Iteration 3136, loss = 798.11952211\n",
      "Iteration 3137, loss = 797.42398501\n",
      "Iteration 3138, loss = 796.72689093\n",
      "Iteration 3139, loss = 796.02462662\n",
      "Iteration 3140, loss = 795.31910968\n",
      "Iteration 3141, loss = 794.61743476\n",
      "Iteration 3142, loss = 793.91571777\n",
      "Iteration 3143, loss = 793.21859472\n",
      "Iteration 3144, loss = 792.52000471\n",
      "Iteration 3145, loss = 791.82841292\n",
      "Iteration 3146, loss = 791.13567065\n",
      "Iteration 3147, loss = 790.44441857\n",
      "Iteration 3148, loss = 789.75234905\n",
      "Iteration 3149, loss = 789.05939164\n",
      "Iteration 3150, loss = 788.37347161\n",
      "Iteration 3151, loss = 787.68919951\n",
      "Iteration 3152, loss = 786.99892604\n",
      "Iteration 3153, loss = 786.31465905\n",
      "Iteration 3154, loss = 785.63567009\n",
      "Iteration 3155, loss = 784.95503942\n",
      "Iteration 3156, loss = 784.27326852\n",
      "Iteration 3157, loss = 783.59408351\n",
      "Iteration 3158, loss = 782.91760136\n",
      "Iteration 3159, loss = 782.24382165\n",
      "Iteration 3160, loss = 781.56497582\n",
      "Iteration 3161, loss = 780.90079645\n",
      "Iteration 3162, loss = 780.23068283\n",
      "Iteration 3163, loss = 779.56176936\n",
      "Iteration 3164, loss = 778.89301817\n",
      "Iteration 3165, loss = 778.22588812\n",
      "Iteration 3166, loss = 777.55729374\n",
      "Iteration 3167, loss = 776.89999604\n",
      "Iteration 3168, loss = 776.23905055\n",
      "Iteration 3169, loss = 775.57663485\n",
      "Iteration 3170, loss = 774.90861734\n",
      "Iteration 3171, loss = 774.25722699\n",
      "Iteration 3172, loss = 773.60548102\n",
      "Iteration 3173, loss = 772.95221614\n",
      "Iteration 3174, loss = 772.29282009\n",
      "Iteration 3175, loss = 771.62988989\n",
      "Iteration 3176, loss = 770.96853091\n",
      "Iteration 3177, loss = 770.30597792\n",
      "Iteration 3178, loss = 769.64214243\n",
      "Iteration 3179, loss = 768.99878877\n",
      "Iteration 3180, loss = 768.35183898\n",
      "Iteration 3181, loss = 767.69423144\n",
      "Iteration 3182, loss = 767.03314013\n",
      "Iteration 3183, loss = 766.37851173\n",
      "Iteration 3184, loss = 765.73367771\n",
      "Iteration 3185, loss = 765.08636119\n",
      "Iteration 3186, loss = 764.43498792\n",
      "Iteration 3187, loss = 763.78182061\n",
      "Iteration 3188, loss = 763.12858392\n",
      "Iteration 3189, loss = 762.47334479\n",
      "Iteration 3190, loss = 761.83543664\n",
      "Iteration 3191, loss = 761.19239417\n",
      "Iteration 3192, loss = 760.54163238\n",
      "Iteration 3193, loss = 759.88833352\n",
      "Iteration 3194, loss = 759.24789533\n",
      "Iteration 3195, loss = 758.60908161\n",
      "Iteration 3196, loss = 757.97032847\n",
      "Iteration 3197, loss = 757.33228919\n",
      "Iteration 3198, loss = 756.69327356\n",
      "Iteration 3199, loss = 756.05119255\n",
      "Iteration 3200, loss = 755.41413308\n",
      "Iteration 3201, loss = 754.77556820\n",
      "Iteration 3202, loss = 754.14212176\n",
      "Iteration 3203, loss = 753.51387892\n",
      "Iteration 3204, loss = 752.87841167\n",
      "Iteration 3205, loss = 752.24215755\n",
      "Iteration 3206, loss = 751.61638206\n",
      "Iteration 3207, loss = 750.98783060\n",
      "Iteration 3208, loss = 750.35966404\n",
      "Iteration 3209, loss = 749.73003290\n",
      "Iteration 3210, loss = 749.10920232\n",
      "Iteration 3211, loss = 748.48532552\n",
      "Iteration 3212, loss = 747.85654076\n",
      "Iteration 3213, loss = 747.24201343\n",
      "Iteration 3214, loss = 746.62274369\n",
      "Iteration 3215, loss = 746.00761066\n",
      "Iteration 3216, loss = 745.39012661\n",
      "Iteration 3217, loss = 744.76893084\n",
      "Iteration 3218, loss = 744.15214388\n",
      "Iteration 3219, loss = 743.53343982\n",
      "Iteration 3220, loss = 742.92038279\n",
      "Iteration 3221, loss = 742.31128282\n",
      "Iteration 3222, loss = 741.69947389\n",
      "Iteration 3223, loss = 741.09086016\n",
      "Iteration 3224, loss = 740.48403051\n",
      "Iteration 3225, loss = 739.88126164\n",
      "Iteration 3226, loss = 739.27153022\n",
      "Iteration 3227, loss = 738.67285141\n",
      "Iteration 3228, loss = 738.07551175\n",
      "Iteration 3229, loss = 737.47302262\n",
      "Iteration 3230, loss = 736.87404808\n",
      "Iteration 3231, loss = 736.27500773\n",
      "Iteration 3232, loss = 735.67840940\n",
      "Iteration 3233, loss = 735.09043224\n",
      "Iteration 3234, loss = 734.49890073\n",
      "Iteration 3235, loss = 733.90234512\n",
      "Iteration 3236, loss = 733.31590396\n",
      "Iteration 3237, loss = 732.73324411\n",
      "Iteration 3238, loss = 732.15108976\n",
      "Iteration 3239, loss = 731.56610598\n",
      "Iteration 3240, loss = 730.97955349\n",
      "Iteration 3241, loss = 730.39459229\n",
      "Iteration 3242, loss = 729.81232787\n",
      "Iteration 3243, loss = 729.23033746\n",
      "Iteration 3244, loss = 728.65691212\n",
      "Iteration 3245, loss = 728.07923621\n",
      "Iteration 3246, loss = 727.49853072\n",
      "Iteration 3247, loss = 726.91447574\n",
      "Iteration 3248, loss = 726.33978258\n",
      "Iteration 3249, loss = 725.76653626\n",
      "Iteration 3250, loss = 725.19301412\n",
      "Iteration 3251, loss = 724.61996395\n",
      "Iteration 3252, loss = 724.05089200\n",
      "Iteration 3253, loss = 723.48457268\n",
      "Iteration 3254, loss = 722.91660901\n",
      "Iteration 3255, loss = 722.35046668\n",
      "Iteration 3256, loss = 721.78534856\n",
      "Iteration 3257, loss = 721.22366158\n",
      "Iteration 3258, loss = 720.66243369\n",
      "Iteration 3259, loss = 720.09860245\n",
      "Iteration 3260, loss = 719.54402517\n",
      "Iteration 3261, loss = 718.98683874\n",
      "Iteration 3262, loss = 718.43071571\n",
      "Iteration 3263, loss = 717.87758339\n",
      "Iteration 3264, loss = 717.32537830\n",
      "Iteration 3265, loss = 716.77316108\n",
      "Iteration 3266, loss = 716.21982548\n",
      "Iteration 3267, loss = 715.66849615\n",
      "Iteration 3268, loss = 715.12299693\n",
      "Iteration 3269, loss = 714.57438597\n",
      "Iteration 3270, loss = 714.02854118\n",
      "Iteration 3271, loss = 713.48489325\n",
      "Iteration 3272, loss = 712.94414645\n",
      "Iteration 3273, loss = 712.40301914\n",
      "Iteration 3274, loss = 711.86357909\n",
      "Iteration 3275, loss = 711.32394551\n",
      "Iteration 3276, loss = 710.78375921\n",
      "Iteration 3277, loss = 710.24589310\n",
      "Iteration 3278, loss = 709.71391546\n",
      "Iteration 3279, loss = 709.18015326\n",
      "Iteration 3280, loss = 708.64523316\n",
      "Iteration 3281, loss = 708.11516333\n",
      "Iteration 3282, loss = 707.58429816\n",
      "Iteration 3283, loss = 707.05541079\n",
      "Iteration 3284, loss = 706.52889774\n",
      "Iteration 3285, loss = 706.00254179\n",
      "Iteration 3286, loss = 705.47844539\n",
      "Iteration 3287, loss = 704.95640117\n",
      "Iteration 3288, loss = 704.43396912\n",
      "Iteration 3289, loss = 703.91162957\n",
      "Iteration 3290, loss = 703.39070156\n",
      "Iteration 3291, loss = 702.86911361\n",
      "Iteration 3292, loss = 702.35799778\n",
      "Iteration 3293, loss = 701.83968787\n",
      "Iteration 3294, loss = 701.31135789\n",
      "Iteration 3295, loss = 700.79665317\n",
      "Iteration 3296, loss = 700.27912187\n",
      "Iteration 3297, loss = 699.76238610\n",
      "Iteration 3298, loss = 699.24641311\n",
      "Iteration 3299, loss = 698.73078531\n",
      "Iteration 3300, loss = 698.20966567\n",
      "Iteration 3301, loss = 697.68284476\n",
      "Iteration 3302, loss = 697.15657427\n",
      "Iteration 3303, loss = 696.62938924\n",
      "Iteration 3304, loss = 696.10175310\n",
      "Iteration 3305, loss = 695.58345448\n",
      "Iteration 3306, loss = 695.06366019\n",
      "Iteration 3307, loss = 694.53646575\n",
      "Iteration 3308, loss = 694.01228988\n",
      "Iteration 3309, loss = 693.49359138\n",
      "Iteration 3310, loss = 692.97364595\n",
      "Iteration 3311, loss = 692.45342273\n",
      "Iteration 3312, loss = 691.93513419\n",
      "Iteration 3313, loss = 691.41783581\n",
      "Iteration 3314, loss = 690.89706056\n",
      "Iteration 3315, loss = 690.37849270\n",
      "Iteration 3316, loss = 689.86147064\n",
      "Iteration 3317, loss = 689.35019942\n",
      "Iteration 3318, loss = 688.83809617\n",
      "Iteration 3319, loss = 688.32062511\n",
      "Iteration 3320, loss = 687.80880384\n",
      "Iteration 3321, loss = 687.29770699\n",
      "Iteration 3322, loss = 686.78824209\n",
      "Iteration 3323, loss = 686.27978028\n",
      "Iteration 3324, loss = 685.77211643\n",
      "Iteration 3325, loss = 685.26638044\n",
      "Iteration 3326, loss = 684.76132496\n",
      "Iteration 3327, loss = 684.25638696\n",
      "Iteration 3328, loss = 683.75427861\n",
      "Iteration 3329, loss = 683.25246163\n",
      "Iteration 3330, loss = 682.75228772\n",
      "Iteration 3331, loss = 682.25213703\n",
      "Iteration 3332, loss = 681.75400767\n",
      "Iteration 3333, loss = 681.25790250\n",
      "Iteration 3334, loss = 680.76709171\n",
      "Iteration 3335, loss = 680.26840926\n",
      "Iteration 3336, loss = 679.77464628\n",
      "Iteration 3337, loss = 679.28420434\n",
      "Iteration 3338, loss = 678.79381313\n",
      "Iteration 3339, loss = 678.30538589\n",
      "Iteration 3340, loss = 677.81413538\n",
      "Iteration 3341, loss = 677.32680036\n",
      "Iteration 3342, loss = 676.83911926\n",
      "Iteration 3343, loss = 676.35159313\n",
      "Iteration 3344, loss = 675.86760083\n",
      "Iteration 3345, loss = 675.38766514\n",
      "Iteration 3346, loss = 674.90297302\n",
      "Iteration 3347, loss = 674.41943422\n",
      "Iteration 3348, loss = 673.93968315\n",
      "Iteration 3349, loss = 673.46463400\n",
      "Iteration 3350, loss = 672.98827143\n",
      "Iteration 3351, loss = 672.51071860\n",
      "Iteration 3352, loss = 672.03555748\n",
      "Iteration 3353, loss = 671.56003201\n",
      "Iteration 3354, loss = 671.08747580\n",
      "Iteration 3355, loss = 670.61626218\n",
      "Iteration 3356, loss = 670.14724736\n",
      "Iteration 3357, loss = 669.67668425\n",
      "Iteration 3358, loss = 669.21224539\n",
      "Iteration 3359, loss = 668.74350828\n",
      "Iteration 3360, loss = 668.27777464\n",
      "Iteration 3361, loss = 667.81362447\n",
      "Iteration 3362, loss = 667.34870230\n",
      "Iteration 3363, loss = 666.88501882\n",
      "Iteration 3364, loss = 666.42390427\n",
      "Iteration 3365, loss = 665.95833172\n",
      "Iteration 3366, loss = 665.49626265\n",
      "Iteration 3367, loss = 665.03718506\n",
      "Iteration 3368, loss = 664.57637029\n",
      "Iteration 3369, loss = 664.12210258\n",
      "Iteration 3370, loss = 663.66165779\n",
      "Iteration 3371, loss = 663.20846306\n",
      "Iteration 3372, loss = 662.75426822\n",
      "Iteration 3373, loss = 662.30039352\n",
      "Iteration 3374, loss = 661.85006346\n",
      "Iteration 3375, loss = 661.40620727\n",
      "Iteration 3376, loss = 660.95780092\n",
      "Iteration 3377, loss = 660.51063341\n",
      "Iteration 3378, loss = 660.06552520\n",
      "Iteration 3379, loss = 659.62065478\n",
      "Iteration 3380, loss = 659.18103110\n",
      "Iteration 3381, loss = 658.73950088\n",
      "Iteration 3382, loss = 658.30042752\n",
      "Iteration 3383, loss = 657.86333590\n",
      "Iteration 3384, loss = 657.42538999\n",
      "Iteration 3385, loss = 656.98869965\n",
      "Iteration 3386, loss = 656.55164061\n",
      "Iteration 3387, loss = 656.11638296\n",
      "Iteration 3388, loss = 655.69033030\n",
      "Iteration 3389, loss = 655.25516163\n",
      "Iteration 3390, loss = 654.82255788\n",
      "Iteration 3391, loss = 654.39396347\n",
      "Iteration 3392, loss = 653.96811132\n",
      "Iteration 3393, loss = 653.54155485\n",
      "Iteration 3394, loss = 653.11607450\n",
      "Iteration 3395, loss = 652.68811210\n",
      "Iteration 3396, loss = 652.26300848\n",
      "Iteration 3397, loss = 651.84016126\n",
      "Iteration 3398, loss = 651.41829454\n",
      "Iteration 3399, loss = 651.00140702\n",
      "Iteration 3400, loss = 650.58422641\n",
      "Iteration 3401, loss = 650.16540097\n",
      "Iteration 3402, loss = 649.74748289\n",
      "Iteration 3403, loss = 649.33069649\n",
      "Iteration 3404, loss = 648.91624834\n",
      "Iteration 3405, loss = 648.50117744\n",
      "Iteration 3406, loss = 648.07973085\n",
      "Iteration 3407, loss = 647.66093135\n",
      "Iteration 3408, loss = 647.23966986\n",
      "Iteration 3409, loss = 646.81543341\n",
      "Iteration 3410, loss = 646.39481252\n",
      "Iteration 3411, loss = 645.96840460\n",
      "Iteration 3412, loss = 645.54697867\n",
      "Iteration 3413, loss = 645.12502767\n",
      "Iteration 3414, loss = 644.70275666\n",
      "Iteration 3415, loss = 644.28244562\n",
      "Iteration 3416, loss = 643.86338207\n",
      "Iteration 3417, loss = 643.44290371\n",
      "Iteration 3418, loss = 643.02297936\n",
      "Iteration 3419, loss = 642.60667958\n",
      "Iteration 3420, loss = 642.18874421\n",
      "Iteration 3421, loss = 641.77015670\n",
      "Iteration 3422, loss = 641.35187187\n",
      "Iteration 3423, loss = 640.93799564\n",
      "Iteration 3424, loss = 640.52341890\n",
      "Iteration 3425, loss = 640.10859909\n",
      "Iteration 3426, loss = 639.69452946\n",
      "Iteration 3427, loss = 639.28241330\n",
      "Iteration 3428, loss = 638.87252122\n",
      "Iteration 3429, loss = 638.46114092\n",
      "Iteration 3430, loss = 638.05324121\n",
      "Iteration 3431, loss = 637.64501552\n",
      "Iteration 3432, loss = 637.23949236\n",
      "Iteration 3433, loss = 636.83021570\n",
      "Iteration 3434, loss = 636.42445301\n",
      "Iteration 3435, loss = 636.01939590\n",
      "Iteration 3436, loss = 635.61600575\n",
      "Iteration 3437, loss = 635.21296906\n",
      "Iteration 3438, loss = 634.80763457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3439, loss = 634.40610486\n",
      "Iteration 3440, loss = 634.00543681\n",
      "Iteration 3441, loss = 633.60538164\n",
      "Iteration 3442, loss = 633.20672476\n",
      "Iteration 3443, loss = 632.80861995\n",
      "Iteration 3444, loss = 632.41151869\n",
      "Iteration 3445, loss = 632.01601842\n",
      "Iteration 3446, loss = 631.62181601\n",
      "Iteration 3447, loss = 631.22647410\n",
      "Iteration 3448, loss = 630.83520290\n",
      "Iteration 3449, loss = 630.44389223\n",
      "Iteration 3450, loss = 630.05278842\n",
      "Iteration 3451, loss = 629.66181884\n",
      "Iteration 3452, loss = 629.27183883\n",
      "Iteration 3453, loss = 628.88359257\n",
      "Iteration 3454, loss = 628.49613040\n",
      "Iteration 3455, loss = 628.10925684\n",
      "Iteration 3456, loss = 627.72682597\n",
      "Iteration 3457, loss = 627.34198901\n",
      "Iteration 3458, loss = 626.95796973\n",
      "Iteration 3459, loss = 626.57686618\n",
      "Iteration 3460, loss = 626.19422381\n",
      "Iteration 3461, loss = 625.81281610\n",
      "Iteration 3462, loss = 625.43179381\n",
      "Iteration 3463, loss = 625.05555343\n",
      "Iteration 3464, loss = 624.67554687\n",
      "Iteration 3465, loss = 624.29813835\n",
      "Iteration 3466, loss = 623.92297214\n",
      "Iteration 3467, loss = 623.54592531\n",
      "Iteration 3468, loss = 623.17030686\n",
      "Iteration 3469, loss = 622.79818782\n",
      "Iteration 3470, loss = 622.42649326\n",
      "Iteration 3471, loss = 622.05177034\n",
      "Iteration 3472, loss = 621.68144914\n",
      "Iteration 3473, loss = 621.31159571\n",
      "Iteration 3474, loss = 620.94206708\n",
      "Iteration 3475, loss = 620.57348141\n",
      "Iteration 3476, loss = 620.20566826\n",
      "Iteration 3477, loss = 619.83999150\n",
      "Iteration 3478, loss = 619.47211122\n",
      "Iteration 3479, loss = 619.10852465\n",
      "Iteration 3480, loss = 618.74460826\n",
      "Iteration 3481, loss = 618.38134360\n",
      "Iteration 3482, loss = 618.01905264\n",
      "Iteration 3483, loss = 617.65835162\n",
      "Iteration 3484, loss = 617.29982588\n",
      "Iteration 3485, loss = 616.93824816\n",
      "Iteration 3486, loss = 616.58129428\n",
      "Iteration 3487, loss = 616.22194489\n",
      "Iteration 3488, loss = 615.86207198\n",
      "Iteration 3489, loss = 615.50670324\n",
      "Iteration 3490, loss = 615.15278278\n",
      "Iteration 3491, loss = 614.79735760\n",
      "Iteration 3492, loss = 614.44205320\n",
      "Iteration 3493, loss = 614.08630051\n",
      "Iteration 3494, loss = 613.73255768\n",
      "Iteration 3495, loss = 613.37984474\n",
      "Iteration 3496, loss = 613.02535001\n",
      "Iteration 3497, loss = 612.67566615\n",
      "Iteration 3498, loss = 612.32270661\n",
      "Iteration 3499, loss = 611.97428950\n",
      "Iteration 3500, loss = 611.62482682\n",
      "Iteration 3501, loss = 611.27657611\n",
      "Iteration 3502, loss = 610.92820399\n",
      "Iteration 3503, loss = 610.58019726\n",
      "Iteration 3504, loss = 610.23300462\n",
      "Iteration 3505, loss = 609.88611087\n",
      "Iteration 3506, loss = 609.53974601\n",
      "Iteration 3507, loss = 609.19536437\n",
      "Iteration 3508, loss = 608.84946691\n",
      "Iteration 3509, loss = 608.50557079\n",
      "Iteration 3510, loss = 608.15965189\n",
      "Iteration 3511, loss = 607.81597031\n",
      "Iteration 3512, loss = 607.46924325\n",
      "Iteration 3513, loss = 607.12219426\n",
      "Iteration 3514, loss = 606.78029456\n",
      "Iteration 3515, loss = 606.43739643\n",
      "Iteration 3516, loss = 606.09438783\n",
      "Iteration 3517, loss = 605.75126590\n",
      "Iteration 3518, loss = 605.41012778\n",
      "Iteration 3519, loss = 605.06910710\n",
      "Iteration 3520, loss = 604.72674405\n",
      "Iteration 3521, loss = 604.38347014\n",
      "Iteration 3522, loss = 604.04517297\n",
      "Iteration 3523, loss = 603.70189171\n",
      "Iteration 3524, loss = 603.35899862\n",
      "Iteration 3525, loss = 603.02235037\n",
      "Iteration 3526, loss = 602.68571296\n",
      "Iteration 3527, loss = 602.34898941\n",
      "Iteration 3528, loss = 602.01093092\n",
      "Iteration 3529, loss = 601.67427127\n",
      "Iteration 3530, loss = 601.33858799\n",
      "Iteration 3531, loss = 601.00167821\n",
      "Iteration 3532, loss = 600.66588569\n",
      "Iteration 3533, loss = 600.32913472\n",
      "Iteration 3534, loss = 599.99370415\n",
      "Iteration 3535, loss = 599.65942100\n",
      "Iteration 3536, loss = 599.32709974\n",
      "Iteration 3537, loss = 598.99416879\n",
      "Iteration 3538, loss = 598.66188741\n",
      "Iteration 3539, loss = 598.33111560\n",
      "Iteration 3540, loss = 597.99858612\n",
      "Iteration 3541, loss = 597.66821337\n",
      "Iteration 3542, loss = 597.33982584\n",
      "Iteration 3543, loss = 597.00864580\n",
      "Iteration 3544, loss = 596.67964379\n",
      "Iteration 3545, loss = 596.34960527\n",
      "Iteration 3546, loss = 596.02196282\n",
      "Iteration 3547, loss = 595.69315115\n",
      "Iteration 3548, loss = 595.36668439\n",
      "Iteration 3549, loss = 595.04062701\n",
      "Iteration 3550, loss = 594.71441742\n",
      "Iteration 3551, loss = 594.38851648\n",
      "Iteration 3552, loss = 594.06399945\n",
      "Iteration 3553, loss = 593.73924387\n",
      "Iteration 3554, loss = 593.41599650\n",
      "Iteration 3555, loss = 593.09299304\n",
      "Iteration 3556, loss = 592.77082406\n",
      "Iteration 3557, loss = 592.45118170\n",
      "Iteration 3558, loss = 592.12996185\n",
      "Iteration 3559, loss = 591.81072711\n",
      "Iteration 3560, loss = 591.49184021\n",
      "Iteration 3561, loss = 591.17303224\n",
      "Iteration 3562, loss = 590.85696439\n",
      "Iteration 3563, loss = 590.53755287\n",
      "Iteration 3564, loss = 590.22127420\n",
      "Iteration 3565, loss = 589.90810389\n",
      "Iteration 3566, loss = 589.59389439\n",
      "Iteration 3567, loss = 589.28073273\n",
      "Iteration 3568, loss = 588.96689581\n",
      "Iteration 3569, loss = 588.65511236\n",
      "Iteration 3570, loss = 588.34385301\n",
      "Iteration 3571, loss = 588.03194506\n",
      "Iteration 3572, loss = 587.72087323\n",
      "Iteration 3573, loss = 587.40971984\n",
      "Iteration 3574, loss = 587.10175421\n",
      "Iteration 3575, loss = 586.79356222\n",
      "Iteration 3576, loss = 586.48686543\n",
      "Iteration 3577, loss = 586.18056089\n",
      "Iteration 3578, loss = 585.87304081\n",
      "Iteration 3579, loss = 585.56682016\n",
      "Iteration 3580, loss = 585.26279511\n",
      "Iteration 3581, loss = 584.95948439\n",
      "Iteration 3582, loss = 584.65640743\n",
      "Iteration 3583, loss = 584.35458515\n",
      "Iteration 3584, loss = 584.05238984\n",
      "Iteration 3585, loss = 583.75038544\n",
      "Iteration 3586, loss = 583.45158219\n",
      "Iteration 3587, loss = 583.15118513\n",
      "Iteration 3588, loss = 582.85157675\n",
      "Iteration 3589, loss = 582.55459311\n",
      "Iteration 3590, loss = 582.25762149\n",
      "Iteration 3591, loss = 581.96028500\n",
      "Iteration 3592, loss = 581.66343885\n",
      "Iteration 3593, loss = 581.36925314\n",
      "Iteration 3594, loss = 581.07586768\n",
      "Iteration 3595, loss = 580.78248320\n",
      "Iteration 3596, loss = 580.48953260\n",
      "Iteration 3597, loss = 580.19611769\n",
      "Iteration 3598, loss = 579.90414590\n",
      "Iteration 3599, loss = 579.61347877\n",
      "Iteration 3600, loss = 579.32142082\n",
      "Iteration 3601, loss = 579.03080060\n",
      "Iteration 3602, loss = 578.74269012\n",
      "Iteration 3603, loss = 578.45531611\n",
      "Iteration 3604, loss = 578.16528651\n",
      "Iteration 3605, loss = 577.87834406\n",
      "Iteration 3606, loss = 577.59249921\n",
      "Iteration 3607, loss = 577.30519553\n",
      "Iteration 3608, loss = 577.02168437\n",
      "Iteration 3609, loss = 576.73525397\n",
      "Iteration 3610, loss = 576.45098318\n",
      "Iteration 3611, loss = 576.16638801\n",
      "Iteration 3612, loss = 575.88353091\n",
      "Iteration 3613, loss = 575.60187645\n",
      "Iteration 3614, loss = 575.32018642\n",
      "Iteration 3615, loss = 575.03719950\n",
      "Iteration 3616, loss = 574.75585684\n",
      "Iteration 3617, loss = 574.47515460\n",
      "Iteration 3618, loss = 574.19558443\n",
      "Iteration 3619, loss = 573.91785924\n",
      "Iteration 3620, loss = 573.63932147\n",
      "Iteration 3621, loss = 573.36250896\n",
      "Iteration 3622, loss = 573.08551352\n",
      "Iteration 3623, loss = 572.81137554\n",
      "Iteration 3624, loss = 572.53789647\n",
      "Iteration 3625, loss = 572.26608004\n",
      "Iteration 3626, loss = 571.99308072\n",
      "Iteration 3627, loss = 571.72087030\n",
      "Iteration 3628, loss = 571.44805423\n",
      "Iteration 3629, loss = 571.17574276\n",
      "Iteration 3630, loss = 570.90333919\n",
      "Iteration 3631, loss = 570.63055742\n",
      "Iteration 3632, loss = 570.35785397\n",
      "Iteration 3633, loss = 570.08615800\n",
      "Iteration 3634, loss = 569.81618344\n",
      "Iteration 3635, loss = 569.54519673\n",
      "Iteration 3636, loss = 569.27456799\n",
      "Iteration 3637, loss = 569.00662356\n",
      "Iteration 3638, loss = 568.74311964\n",
      "Iteration 3639, loss = 568.48164442\n",
      "Iteration 3640, loss = 568.21601300\n",
      "Iteration 3641, loss = 567.94761704\n",
      "Iteration 3642, loss = 567.68295362\n",
      "Iteration 3643, loss = 567.42140206\n",
      "Iteration 3644, loss = 567.15808023\n",
      "Iteration 3645, loss = 566.89478798\n",
      "Iteration 3646, loss = 566.63326226\n",
      "Iteration 3647, loss = 566.37593776\n",
      "Iteration 3648, loss = 566.11537147\n",
      "Iteration 3649, loss = 565.85386075\n",
      "Iteration 3650, loss = 565.59636422\n",
      "Iteration 3651, loss = 565.33978306\n",
      "Iteration 3652, loss = 565.08157359\n",
      "Iteration 3653, loss = 564.82045685\n",
      "Iteration 3654, loss = 564.56100321\n",
      "Iteration 3655, loss = 564.30711069\n",
      "Iteration 3656, loss = 564.04972741\n",
      "Iteration 3657, loss = 563.79091976\n",
      "Iteration 3658, loss = 563.53443148\n",
      "Iteration 3659, loss = 563.27756372\n",
      "Iteration 3660, loss = 563.02367005\n",
      "Iteration 3661, loss = 562.76800570\n",
      "Iteration 3662, loss = 562.51275075\n",
      "Iteration 3663, loss = 562.25940243\n",
      "Iteration 3664, loss = 562.00440691\n",
      "Iteration 3665, loss = 561.75351286\n",
      "Iteration 3666, loss = 561.50158547\n",
      "Iteration 3667, loss = 561.25187545\n",
      "Iteration 3668, loss = 561.00120187\n",
      "Iteration 3669, loss = 560.75030907\n",
      "Iteration 3670, loss = 560.50432155\n",
      "Iteration 3671, loss = 560.25338407\n",
      "Iteration 3672, loss = 560.00460351\n",
      "Iteration 3673, loss = 559.75914280\n",
      "Iteration 3674, loss = 559.51238188\n",
      "Iteration 3675, loss = 559.26600358\n",
      "Iteration 3676, loss = 559.02131581\n",
      "Iteration 3677, loss = 558.76968119\n",
      "Iteration 3678, loss = 558.51924409\n",
      "Iteration 3679, loss = 558.26980655\n",
      "Iteration 3680, loss = 558.01854088\n",
      "Iteration 3681, loss = 557.77112829\n",
      "Iteration 3682, loss = 557.52009877\n",
      "Iteration 3683, loss = 557.26998786\n",
      "Iteration 3684, loss = 557.02010828\n",
      "Iteration 3685, loss = 556.77451338\n",
      "Iteration 3686, loss = 556.52760111\n",
      "Iteration 3687, loss = 556.27864243\n",
      "Iteration 3688, loss = 556.03227201\n",
      "Iteration 3689, loss = 555.78407250\n",
      "Iteration 3690, loss = 555.53705144\n",
      "Iteration 3691, loss = 555.29101257\n",
      "Iteration 3692, loss = 555.04327377\n",
      "Iteration 3693, loss = 554.80324785\n",
      "Iteration 3694, loss = 554.55832108\n",
      "Iteration 3695, loss = 554.31010377\n",
      "Iteration 3696, loss = 554.06821926\n",
      "Iteration 3697, loss = 553.82761244\n",
      "Iteration 3698, loss = 553.58552949\n",
      "Iteration 3699, loss = 553.34363203\n",
      "Iteration 3700, loss = 553.10097676\n",
      "Iteration 3701, loss = 552.85999491\n",
      "Iteration 3702, loss = 552.62033448\n",
      "Iteration 3703, loss = 552.37744610\n",
      "Iteration 3704, loss = 552.13752860\n",
      "Iteration 3705, loss = 551.90174797\n",
      "Iteration 3706, loss = 551.66168340\n",
      "Iteration 3707, loss = 551.42401591\n",
      "Iteration 3708, loss = 551.18604323\n",
      "Iteration 3709, loss = 550.95017657\n",
      "Iteration 3710, loss = 550.71426918\n",
      "Iteration 3711, loss = 550.47963315\n",
      "Iteration 3712, loss = 550.24556558\n",
      "Iteration 3713, loss = 550.01056641\n",
      "Iteration 3714, loss = 549.77759492\n",
      "Iteration 3715, loss = 549.54327949\n",
      "Iteration 3716, loss = 549.31062427\n",
      "Iteration 3717, loss = 549.08194736\n",
      "Iteration 3718, loss = 548.85226698\n",
      "Iteration 3719, loss = 548.62027507\n",
      "Iteration 3720, loss = 548.38998121\n",
      "Iteration 3721, loss = 548.15993452\n",
      "Iteration 3722, loss = 547.93238264\n",
      "Iteration 3723, loss = 547.70195506\n",
      "Iteration 3724, loss = 547.47369564\n",
      "Iteration 3725, loss = 547.24644566\n",
      "Iteration 3726, loss = 547.02007314\n",
      "Iteration 3727, loss = 546.79487371\n",
      "Iteration 3728, loss = 546.56984846\n",
      "Iteration 3729, loss = 546.34274340\n",
      "Iteration 3730, loss = 546.11764158\n",
      "Iteration 3731, loss = 545.89325111\n",
      "Iteration 3732, loss = 545.66823415\n",
      "Iteration 3733, loss = 545.44328654\n",
      "Iteration 3734, loss = 545.21790413\n",
      "Iteration 3735, loss = 544.99105461\n",
      "Iteration 3736, loss = 544.76288534\n",
      "Iteration 3737, loss = 544.53356089\n",
      "Iteration 3738, loss = 544.30814894\n",
      "Iteration 3739, loss = 544.07694110\n",
      "Iteration 3740, loss = 543.84281002\n",
      "Iteration 3741, loss = 543.61236911\n",
      "Iteration 3742, loss = 543.38237188\n",
      "Iteration 3743, loss = 543.15072462\n",
      "Iteration 3744, loss = 542.91760034\n",
      "Iteration 3745, loss = 542.68998066\n",
      "Iteration 3746, loss = 542.45583555\n",
      "Iteration 3747, loss = 542.22366796\n",
      "Iteration 3748, loss = 541.99335860\n",
      "Iteration 3749, loss = 541.76406418\n",
      "Iteration 3750, loss = 541.53247257\n",
      "Iteration 3751, loss = 541.29909682\n",
      "Iteration 3752, loss = 541.07269871\n",
      "Iteration 3753, loss = 540.84331864\n",
      "Iteration 3754, loss = 540.60987635\n",
      "Iteration 3755, loss = 540.38192707\n",
      "Iteration 3756, loss = 540.15390835\n",
      "Iteration 3757, loss = 539.93027433\n",
      "Iteration 3758, loss = 539.70413961\n",
      "Iteration 3759, loss = 539.47719126\n",
      "Iteration 3760, loss = 539.25241182\n",
      "Iteration 3761, loss = 539.02625399\n",
      "Iteration 3762, loss = 538.79602467\n",
      "Iteration 3763, loss = 538.56805271\n",
      "Iteration 3764, loss = 538.34005900\n",
      "Iteration 3765, loss = 538.10588216\n",
      "Iteration 3766, loss = 537.87777145\n",
      "Iteration 3767, loss = 537.65337514\n",
      "Iteration 3768, loss = 537.42877369\n",
      "Iteration 3769, loss = 537.20418197\n",
      "Iteration 3770, loss = 536.97992726\n",
      "Iteration 3771, loss = 536.75210306\n",
      "Iteration 3772, loss = 536.52385672\n",
      "Iteration 3773, loss = 536.29118809\n",
      "Iteration 3774, loss = 536.05233657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3775, loss = 535.80794822\n",
      "Iteration 3776, loss = 535.56236976\n",
      "Iteration 3777, loss = 535.31317264\n",
      "Iteration 3778, loss = 535.06031825\n",
      "Iteration 3779, loss = 534.80627262\n",
      "Iteration 3780, loss = 534.54623855\n",
      "Iteration 3781, loss = 534.28115448\n",
      "Iteration 3782, loss = 534.01820306\n",
      "Iteration 3783, loss = 533.74852984\n",
      "Iteration 3784, loss = 533.47716983\n",
      "Iteration 3785, loss = 533.20267951\n",
      "Iteration 3786, loss = 532.92458065\n",
      "Iteration 3787, loss = 532.63812827\n",
      "Iteration 3788, loss = 532.34569745\n",
      "Iteration 3789, loss = 532.04696164\n",
      "Iteration 3790, loss = 531.75340702\n",
      "Iteration 3791, loss = 531.45351956\n",
      "Iteration 3792, loss = 531.14806723\n",
      "Iteration 3793, loss = 530.84706975\n",
      "Iteration 3794, loss = 530.54191967\n",
      "Iteration 3795, loss = 530.23447563\n",
      "Iteration 3796, loss = 529.92540124\n",
      "Iteration 3797, loss = 529.61557560\n",
      "Iteration 3798, loss = 529.29586926\n",
      "Iteration 3799, loss = 528.97870969\n",
      "Iteration 3800, loss = 528.66150329\n",
      "Iteration 3801, loss = 528.34014685\n",
      "Iteration 3802, loss = 528.01903624\n",
      "Iteration 3803, loss = 527.69263177\n",
      "Iteration 3804, loss = 527.36453393\n",
      "Iteration 3805, loss = 527.03485503\n",
      "Iteration 3806, loss = 526.70236822\n",
      "Iteration 3807, loss = 526.37668024\n",
      "Iteration 3808, loss = 526.04869056\n",
      "Iteration 3809, loss = 525.71302790\n",
      "Iteration 3810, loss = 525.38256271\n",
      "Iteration 3811, loss = 525.04900171\n",
      "Iteration 3812, loss = 524.71599369\n",
      "Iteration 3813, loss = 524.39120916\n",
      "Iteration 3814, loss = 524.06813115\n",
      "Iteration 3815, loss = 523.74368241\n",
      "Iteration 3816, loss = 523.42095196\n",
      "Iteration 3817, loss = 523.09755523\n",
      "Iteration 3818, loss = 522.77527735\n",
      "Iteration 3819, loss = 522.45439829\n",
      "Iteration 3820, loss = 522.13493362\n",
      "Iteration 3821, loss = 521.82266363\n",
      "Iteration 3822, loss = 521.50841540\n",
      "Iteration 3823, loss = 521.18987034\n",
      "Iteration 3824, loss = 520.87866034\n",
      "Iteration 3825, loss = 520.56786100\n",
      "Iteration 3826, loss = 520.25781037\n",
      "Iteration 3827, loss = 519.94266379\n",
      "Iteration 3828, loss = 519.62607477\n",
      "Iteration 3829, loss = 519.30339581\n",
      "Iteration 3830, loss = 518.95210709\n",
      "Iteration 3831, loss = 518.59496406\n",
      "Iteration 3832, loss = 518.23538380\n",
      "Iteration 3833, loss = 517.87215595\n",
      "Iteration 3834, loss = 517.50763608\n",
      "Iteration 3835, loss = 517.14676341\n",
      "Iteration 3836, loss = 516.78026288\n",
      "Iteration 3837, loss = 516.40644366\n",
      "Iteration 3838, loss = 516.03839592\n",
      "Iteration 3839, loss = 515.67113444\n",
      "Iteration 3840, loss = 515.30458232\n",
      "Iteration 3841, loss = 514.94108187\n",
      "Iteration 3842, loss = 514.57553230\n",
      "Iteration 3843, loss = 514.21486223\n",
      "Iteration 3844, loss = 513.85258911\n",
      "Iteration 3845, loss = 513.49046263\n",
      "Iteration 3846, loss = 513.12833599\n",
      "Iteration 3847, loss = 512.76765951\n",
      "Iteration 3848, loss = 512.41526386\n",
      "Iteration 3849, loss = 512.06524364\n",
      "Iteration 3850, loss = 511.71061334\n",
      "Iteration 3851, loss = 511.36367554\n",
      "Iteration 3852, loss = 511.01708390\n",
      "Iteration 3853, loss = 510.67297058\n",
      "Iteration 3854, loss = 510.33044598\n",
      "Iteration 3855, loss = 509.98647747\n",
      "Iteration 3856, loss = 509.64381565\n",
      "Iteration 3857, loss = 509.30799575\n",
      "Iteration 3858, loss = 508.97017690\n",
      "Iteration 3859, loss = 508.63457927\n",
      "Iteration 3860, loss = 508.30214202\n",
      "Iteration 3861, loss = 507.97278473\n",
      "Iteration 3862, loss = 507.64575889\n",
      "Iteration 3863, loss = 507.31927366\n",
      "Iteration 3864, loss = 506.99185117\n",
      "Iteration 3865, loss = 506.69676296\n",
      "Iteration 3866, loss = 506.39947139\n",
      "Iteration 3867, loss = 506.09793765\n",
      "Iteration 3868, loss = 505.79852544\n",
      "Iteration 3869, loss = 505.49219494\n",
      "Iteration 3870, loss = 505.17975198\n",
      "Iteration 3871, loss = 504.87199456\n",
      "Iteration 3872, loss = 504.56539203\n",
      "Iteration 3873, loss = 504.27065627\n",
      "Iteration 3874, loss = 503.98644302\n",
      "Iteration 3875, loss = 503.69991274\n",
      "Iteration 3876, loss = 503.41061255\n",
      "Iteration 3877, loss = 503.11817565\n",
      "Iteration 3878, loss = 502.82932241\n",
      "Iteration 3879, loss = 502.54320394\n",
      "Iteration 3880, loss = 502.25259165\n",
      "Iteration 3881, loss = 501.97361964\n",
      "Iteration 3882, loss = 501.70271838\n",
      "Iteration 3883, loss = 501.42955660\n",
      "Iteration 3884, loss = 501.15238778\n",
      "Iteration 3885, loss = 500.87398155\n",
      "Iteration 3886, loss = 500.59775626\n",
      "Iteration 3887, loss = 500.32956861\n",
      "Iteration 3888, loss = 500.06246109\n",
      "Iteration 3889, loss = 499.79733784\n",
      "Iteration 3890, loss = 499.53593354\n",
      "Iteration 3891, loss = 499.27754837\n",
      "Iteration 3892, loss = 499.01663710\n",
      "Iteration 3893, loss = 498.75877775\n",
      "Iteration 3894, loss = 498.50031266\n",
      "Iteration 3895, loss = 498.25372217\n",
      "Iteration 3896, loss = 498.00453910\n",
      "Iteration 3897, loss = 497.75365865\n",
      "Iteration 3898, loss = 497.50504403\n",
      "Iteration 3899, loss = 497.25628878\n",
      "Iteration 3900, loss = 497.02193864\n",
      "Iteration 3901, loss = 496.78316286\n",
      "Iteration 3902, loss = 496.54524619\n",
      "Iteration 3903, loss = 496.30568201\n",
      "Iteration 3904, loss = 496.06647727\n",
      "Iteration 3905, loss = 495.83931472\n",
      "Iteration 3906, loss = 495.61149718\n",
      "Iteration 3907, loss = 495.38363000\n",
      "Iteration 3908, loss = 495.15527240\n",
      "Iteration 3909, loss = 494.92603429\n",
      "Iteration 3910, loss = 494.69588884\n",
      "Iteration 3911, loss = 494.47598063\n",
      "Iteration 3912, loss = 494.25965579\n",
      "Iteration 3913, loss = 494.04242572\n",
      "Iteration 3914, loss = 493.82090533\n",
      "Iteration 3915, loss = 493.60123300\n",
      "Iteration 3916, loss = 493.38399665\n",
      "Iteration 3917, loss = 493.17190947\n",
      "Iteration 3918, loss = 492.95881837\n",
      "Iteration 3919, loss = 492.74665382\n",
      "Iteration 3920, loss = 492.54303694\n",
      "Iteration 3921, loss = 492.34199794\n",
      "Iteration 3922, loss = 492.13708128\n",
      "Iteration 3923, loss = 491.93288976\n",
      "Iteration 3924, loss = 491.73329774\n",
      "Iteration 3925, loss = 491.53410775\n",
      "Iteration 3926, loss = 491.33557697\n",
      "Iteration 3927, loss = 491.13484267\n",
      "Iteration 3928, loss = 490.93494388\n",
      "Iteration 3929, loss = 490.73211056\n",
      "Iteration 3930, loss = 490.53900403\n",
      "Iteration 3931, loss = 490.35160278\n",
      "Iteration 3932, loss = 490.17024813\n",
      "Iteration 3933, loss = 489.98617459\n",
      "Iteration 3934, loss = 489.80131908\n",
      "Iteration 3935, loss = 489.61264272\n",
      "Iteration 3936, loss = 489.42354584\n",
      "Iteration 3937, loss = 489.23784031\n",
      "Iteration 3938, loss = 489.05498832\n",
      "Iteration 3939, loss = 488.87703990\n",
      "Iteration 3940, loss = 488.69198501\n",
      "Iteration 3941, loss = 488.50872369\n",
      "Iteration 3942, loss = 488.32825900\n",
      "Iteration 3943, loss = 488.15331059\n",
      "Iteration 3944, loss = 487.98094706\n",
      "Iteration 3945, loss = 487.80308557\n",
      "Iteration 3946, loss = 487.62557794\n",
      "Iteration 3947, loss = 487.45504707\n",
      "Iteration 3948, loss = 487.28160929\n",
      "Iteration 3949, loss = 487.10536249\n",
      "Iteration 3950, loss = 486.93152880\n",
      "Iteration 3951, loss = 486.76236035\n",
      "Iteration 3952, loss = 486.58995801\n",
      "Iteration 3953, loss = 486.42201278\n",
      "Iteration 3954, loss = 486.25500132\n",
      "Iteration 3955, loss = 486.08615542\n",
      "Iteration 3956, loss = 485.92079288\n",
      "Iteration 3957, loss = 485.75826190\n",
      "Iteration 3958, loss = 485.59529209\n",
      "Iteration 3959, loss = 485.43210136\n",
      "Iteration 3960, loss = 485.26680538\n",
      "Iteration 3961, loss = 485.12318114\n",
      "Iteration 3962, loss = 484.98649392\n",
      "Iteration 3963, loss = 484.84840527\n",
      "Iteration 3964, loss = 484.70762787\n",
      "Iteration 3965, loss = 484.57396522\n",
      "Iteration 3966, loss = 484.44785599\n",
      "Iteration 3967, loss = 484.31744585\n",
      "Iteration 3968, loss = 484.17891913\n",
      "Iteration 3969, loss = 484.04268458\n",
      "Iteration 3970, loss = 483.91786073\n",
      "Iteration 3971, loss = 483.79155981\n",
      "Iteration 3972, loss = 483.66298172\n",
      "Iteration 3973, loss = 483.52909172\n",
      "Iteration 3974, loss = 483.39673851\n",
      "Iteration 3975, loss = 483.27413041\n",
      "Iteration 3976, loss = 483.14739038\n",
      "Iteration 3977, loss = 483.02205970\n",
      "Iteration 3978, loss = 482.89643872\n",
      "Iteration 3979, loss = 482.76867886\n",
      "Iteration 3980, loss = 482.63737245\n",
      "Iteration 3981, loss = 482.51302312\n",
      "Iteration 3982, loss = 482.39129277\n",
      "Iteration 3983, loss = 482.26929727\n",
      "Iteration 3984, loss = 482.14462219\n",
      "Iteration 3985, loss = 482.02018156\n",
      "Iteration 3986, loss = 481.90204095\n",
      "Iteration 3987, loss = 481.78106862\n",
      "Iteration 3988, loss = 481.65879900\n",
      "Iteration 3989, loss = 481.54210703\n",
      "Iteration 3990, loss = 481.42240507\n",
      "Iteration 3991, loss = 481.30109935\n",
      "Iteration 3992, loss = 481.18207015\n",
      "Iteration 3993, loss = 481.06144280\n",
      "Iteration 3994, loss = 480.94359492\n",
      "Iteration 3995, loss = 480.82746501\n",
      "Iteration 3996, loss = 480.71043557\n",
      "Iteration 3997, loss = 480.59579982\n",
      "Iteration 3998, loss = 480.48098705\n",
      "Iteration 3999, loss = 480.36529342\n",
      "Iteration 4000, loss = 480.25477094\n",
      "Iteration 4001, loss = 480.13956829\n",
      "Iteration 4002, loss = 480.02741055\n",
      "Iteration 4003, loss = 479.91648639\n",
      "Iteration 4004, loss = 479.80734027\n",
      "Iteration 4005, loss = 479.69324520\n",
      "Iteration 4006, loss = 479.58033515\n",
      "Iteration 4007, loss = 479.46848451\n",
      "Iteration 4008, loss = 479.35690219\n",
      "Iteration 4009, loss = 479.24856287\n",
      "Iteration 4010, loss = 479.13864327\n",
      "Iteration 4011, loss = 479.02590367\n",
      "Iteration 4012, loss = 478.91378060\n",
      "Iteration 4013, loss = 478.80333424\n",
      "Iteration 4014, loss = 478.69606957\n",
      "Iteration 4015, loss = 478.58770758\n",
      "Iteration 4016, loss = 478.47681765\n",
      "Iteration 4017, loss = 478.36778147\n",
      "Iteration 4018, loss = 478.25849240\n",
      "Iteration 4019, loss = 478.15033490\n",
      "Iteration 4020, loss = 478.04853806\n",
      "Iteration 4021, loss = 477.94229999\n",
      "Iteration 4022, loss = 477.83394109\n",
      "Iteration 4023, loss = 477.72139343\n",
      "Iteration 4024, loss = 477.61753180\n",
      "Iteration 4025, loss = 477.51193162\n",
      "Iteration 4026, loss = 477.40685631\n",
      "Iteration 4027, loss = 477.30187898\n",
      "Iteration 4028, loss = 477.19565676\n",
      "Iteration 4029, loss = 477.09188956\n",
      "Iteration 4030, loss = 476.98729979\n",
      "Iteration 4031, loss = 476.88456738\n",
      "Iteration 4032, loss = 476.78168124\n",
      "Iteration 4033, loss = 476.67957361\n",
      "Iteration 4034, loss = 476.57724813\n",
      "Iteration 4035, loss = 476.47287476\n",
      "Iteration 4036, loss = 476.37237343\n",
      "Iteration 4037, loss = 476.27154567\n",
      "Iteration 4038, loss = 476.16963255\n",
      "Iteration 4039, loss = 476.06931828\n",
      "Iteration 4040, loss = 475.96809777\n",
      "Iteration 4041, loss = 475.86571530\n",
      "Iteration 4042, loss = 475.77111092\n",
      "Iteration 4043, loss = 475.67176810\n",
      "Iteration 4044, loss = 475.56791893\n",
      "Iteration 4045, loss = 475.47305401\n",
      "Iteration 4046, loss = 475.37516789\n",
      "Iteration 4047, loss = 475.27582642\n",
      "Iteration 4048, loss = 475.17993943\n",
      "Iteration 4049, loss = 475.08142466\n",
      "Iteration 4050, loss = 474.98157453\n",
      "Iteration 4051, loss = 474.88737789\n",
      "Iteration 4052, loss = 474.79152106\n",
      "Iteration 4053, loss = 474.69445525\n",
      "Iteration 4054, loss = 474.59763610\n",
      "Iteration 4055, loss = 474.50251971\n",
      "Iteration 4056, loss = 474.40816171\n",
      "Iteration 4057, loss = 474.31020865\n",
      "Iteration 4058, loss = 474.21915066\n",
      "Iteration 4059, loss = 474.12884435\n",
      "Iteration 4060, loss = 474.03643473\n",
      "Iteration 4061, loss = 473.94094201\n",
      "Iteration 4062, loss = 473.84587921\n",
      "Iteration 4063, loss = 473.74748190\n",
      "Iteration 4064, loss = 473.65088041\n",
      "Iteration 4065, loss = 473.55425289\n",
      "Iteration 4066, loss = 473.45848561\n",
      "Iteration 4067, loss = 473.36093298\n",
      "Iteration 4068, loss = 473.26627940\n",
      "Iteration 4069, loss = 473.16986851\n",
      "Iteration 4070, loss = 473.07774892\n",
      "Iteration 4071, loss = 472.98693311\n",
      "Iteration 4072, loss = 472.89468818\n",
      "Iteration 4073, loss = 472.80223461\n",
      "Iteration 4074, loss = 472.72253940\n",
      "Iteration 4075, loss = 472.65573083\n",
      "Iteration 4076, loss = 472.59618286\n",
      "Iteration 4077, loss = 472.50721224\n",
      "Iteration 4078, loss = 472.38214187\n",
      "Iteration 4079, loss = 472.27073792\n",
      "Iteration 4080, loss = 472.18748367\n",
      "Iteration 4081, loss = 472.10574100\n",
      "Iteration 4082, loss = 472.00395765\n",
      "Iteration 4083, loss = 471.90450362\n",
      "Iteration 4084, loss = 471.82761716\n",
      "Iteration 4085, loss = 471.73731713\n",
      "Iteration 4086, loss = 471.63032381\n",
      "Iteration 4087, loss = 471.54349644\n",
      "Iteration 4088, loss = 471.47218071\n",
      "Iteration 4089, loss = 471.37820612\n",
      "Iteration 4090, loss = 471.28396361\n",
      "Iteration 4091, loss = 471.20254267\n",
      "Iteration 4092, loss = 471.11899348\n",
      "Iteration 4093, loss = 471.02331656\n",
      "Iteration 4094, loss = 470.93360989\n",
      "Iteration 4095, loss = 470.85313921\n",
      "Iteration 4096, loss = 470.76349568\n",
      "Iteration 4097, loss = 470.68193801\n",
      "Iteration 4098, loss = 470.59252718\n",
      "Iteration 4099, loss = 470.51604364\n",
      "Iteration 4100, loss = 470.43365984\n",
      "Iteration 4101, loss = 470.34437884\n",
      "Iteration 4102, loss = 470.26021251\n",
      "Iteration 4103, loss = 470.17312953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4104, loss = 470.08639081\n",
      "Iteration 4105, loss = 469.99895435\n",
      "Iteration 4106, loss = 469.91765382\n",
      "Iteration 4107, loss = 469.83513893\n",
      "Iteration 4108, loss = 469.74935324\n",
      "Iteration 4109, loss = 469.66002973\n",
      "Iteration 4110, loss = 469.58065357\n",
      "Iteration 4111, loss = 469.49665627\n",
      "Iteration 4112, loss = 469.41061464\n",
      "Iteration 4113, loss = 469.32773553\n",
      "Iteration 4114, loss = 469.24568997\n",
      "Iteration 4115, loss = 469.15811354\n",
      "Iteration 4116, loss = 469.07545010\n",
      "Iteration 4117, loss = 468.99739075\n",
      "Iteration 4118, loss = 468.91200202\n",
      "Iteration 4119, loss = 468.82621934\n",
      "Iteration 4120, loss = 468.74568246\n",
      "Iteration 4121, loss = 468.65996570\n",
      "Iteration 4122, loss = 468.57579994\n",
      "Iteration 4123, loss = 468.49389623\n",
      "Iteration 4124, loss = 468.41397810\n",
      "Iteration 4125, loss = 468.33101698\n",
      "Iteration 4126, loss = 468.24683046\n",
      "Iteration 4127, loss = 468.16232100\n",
      "Iteration 4128, loss = 468.08254546\n",
      "Iteration 4129, loss = 468.00124121\n",
      "Iteration 4130, loss = 467.91910896\n",
      "Iteration 4131, loss = 467.83541296\n",
      "Iteration 4132, loss = 467.75741351\n",
      "Iteration 4133, loss = 467.67578869\n",
      "Iteration 4134, loss = 467.59137039\n",
      "Iteration 4135, loss = 467.51028189\n",
      "Iteration 4136, loss = 467.43105937\n",
      "Iteration 4137, loss = 467.34833486\n",
      "Iteration 4138, loss = 467.26559132\n",
      "Iteration 4139, loss = 467.18516237\n",
      "Iteration 4140, loss = 467.10442251\n",
      "Iteration 4141, loss = 467.02226171\n",
      "Iteration 4142, loss = 466.94089050\n",
      "Iteration 4143, loss = 466.86081976\n",
      "Iteration 4144, loss = 466.78043672\n",
      "Iteration 4145, loss = 466.70071996\n",
      "Iteration 4146, loss = 466.62220386\n",
      "Iteration 4147, loss = 466.54008363\n",
      "Iteration 4148, loss = 466.45804636\n",
      "Iteration 4149, loss = 466.38081540\n",
      "Iteration 4150, loss = 466.30215110\n",
      "Iteration 4151, loss = 466.22070052\n",
      "Iteration 4152, loss = 466.14391263\n",
      "Iteration 4153, loss = 466.06602925\n",
      "Iteration 4154, loss = 465.98613693\n",
      "Iteration 4155, loss = 465.90502089\n",
      "Iteration 4156, loss = 465.82774848\n",
      "Iteration 4157, loss = 465.74958764\n",
      "Iteration 4158, loss = 465.66771526\n",
      "Iteration 4159, loss = 465.58619841\n",
      "Iteration 4160, loss = 465.50968748\n",
      "Iteration 4161, loss = 465.43134057\n",
      "Iteration 4162, loss = 465.35305616\n",
      "Iteration 4163, loss = 465.27253308\n",
      "Iteration 4164, loss = 465.19488285\n",
      "Iteration 4165, loss = 465.11944521\n",
      "Iteration 4166, loss = 465.04023040\n",
      "Iteration 4167, loss = 464.96024158\n",
      "Iteration 4168, loss = 464.88445544\n",
      "Iteration 4169, loss = 464.80682188\n",
      "Iteration 4170, loss = 464.72887746\n",
      "Iteration 4171, loss = 464.64977524\n",
      "Iteration 4172, loss = 464.57204093\n",
      "Iteration 4173, loss = 464.49762804\n",
      "Iteration 4174, loss = 464.41924038\n",
      "Iteration 4175, loss = 464.34157467\n",
      "Iteration 4176, loss = 464.26816034\n",
      "Iteration 4177, loss = 464.19130222\n",
      "Iteration 4178, loss = 464.11391791\n",
      "Iteration 4179, loss = 464.03660119\n",
      "Iteration 4180, loss = 463.95785434\n",
      "Iteration 4181, loss = 463.88111123\n",
      "Iteration 4182, loss = 463.80594853\n",
      "Iteration 4183, loss = 463.73001316\n",
      "Iteration 4184, loss = 463.65449342\n",
      "Iteration 4185, loss = 463.57981447\n",
      "Iteration 4186, loss = 463.50460248\n",
      "Iteration 4187, loss = 463.42894546\n",
      "Iteration 4188, loss = 463.35213139\n",
      "Iteration 4189, loss = 463.27475481\n",
      "Iteration 4190, loss = 463.20214275\n",
      "Iteration 4191, loss = 463.12681640\n",
      "Iteration 4192, loss = 463.05009053\n",
      "Iteration 4193, loss = 462.97568346\n",
      "Iteration 4194, loss = 462.90331852\n",
      "Iteration 4195, loss = 462.82860204\n",
      "Iteration 4196, loss = 462.75178310\n",
      "Iteration 4197, loss = 462.67651787\n",
      "Iteration 4198, loss = 462.60150170\n",
      "Iteration 4199, loss = 462.52893995\n",
      "Iteration 4200, loss = 462.45469498\n",
      "Iteration 4201, loss = 462.37746055\n",
      "Iteration 4202, loss = 462.30662811\n",
      "Iteration 4203, loss = 462.23336166\n",
      "Iteration 4204, loss = 462.15728215\n",
      "Iteration 4205, loss = 462.08577028\n",
      "Iteration 4206, loss = 462.01220407\n",
      "Iteration 4207, loss = 461.93567677\n",
      "Iteration 4208, loss = 461.86180787\n",
      "Iteration 4209, loss = 461.78989300\n",
      "Iteration 4210, loss = 461.71658850\n",
      "Iteration 4211, loss = 461.64625117\n",
      "Iteration 4212, loss = 461.57313720\n",
      "Iteration 4213, loss = 461.49918813\n",
      "Iteration 4214, loss = 461.42501177\n",
      "Iteration 4215, loss = 461.35250411\n",
      "Iteration 4216, loss = 461.27668758\n",
      "Iteration 4217, loss = 461.20792347\n",
      "Iteration 4218, loss = 461.13988727\n",
      "Iteration 4219, loss = 461.06632374\n",
      "Iteration 4220, loss = 460.98959141\n",
      "Iteration 4221, loss = 460.91840856\n",
      "Iteration 4222, loss = 460.84858311\n",
      "Iteration 4223, loss = 460.77476533\n",
      "Iteration 4224, loss = 460.70070083\n",
      "Iteration 4225, loss = 460.62832596\n",
      "Iteration 4226, loss = 460.55616299\n",
      "Iteration 4227, loss = 460.48406854\n",
      "Iteration 4228, loss = 460.41500268\n",
      "Iteration 4229, loss = 460.34332802\n",
      "Iteration 4230, loss = 460.27010174\n",
      "Iteration 4231, loss = 460.19935318\n",
      "Iteration 4232, loss = 460.12827400\n",
      "Iteration 4233, loss = 460.05913110\n",
      "Iteration 4234, loss = 459.98780714\n",
      "Iteration 4235, loss = 459.91430515\n",
      "Iteration 4236, loss = 459.84318683\n",
      "Iteration 4237, loss = 459.77247585\n",
      "Iteration 4238, loss = 459.69984737\n",
      "Iteration 4239, loss = 459.62777773\n",
      "Iteration 4240, loss = 459.55857771\n",
      "Iteration 4241, loss = 459.48519123\n",
      "Iteration 4242, loss = 459.41639211\n",
      "Iteration 4243, loss = 459.34730818\n",
      "Iteration 4244, loss = 459.27543600\n",
      "Iteration 4245, loss = 459.20830666\n",
      "Iteration 4246, loss = 459.13879170\n",
      "Iteration 4247, loss = 459.06629317\n",
      "Iteration 4248, loss = 458.99526270\n",
      "Iteration 4249, loss = 458.92951903\n",
      "Iteration 4250, loss = 458.85627902\n",
      "Iteration 4251, loss = 458.78914339\n",
      "Iteration 4252, loss = 458.71942287\n",
      "Iteration 4253, loss = 458.65055217\n",
      "Iteration 4254, loss = 458.57926519\n",
      "Iteration 4255, loss = 458.51129640\n",
      "Iteration 4256, loss = 458.44224697\n",
      "Iteration 4257, loss = 458.37032834\n",
      "Iteration 4258, loss = 458.30117585\n",
      "Iteration 4259, loss = 458.23081817\n",
      "Iteration 4260, loss = 458.15764849\n",
      "Iteration 4261, loss = 458.08871379\n",
      "Iteration 4262, loss = 458.02124220\n",
      "Iteration 4263, loss = 457.95187782\n",
      "Iteration 4264, loss = 457.88264787\n",
      "Iteration 4265, loss = 457.81582117\n",
      "Iteration 4266, loss = 457.74749478\n",
      "Iteration 4267, loss = 457.68150490\n",
      "Iteration 4268, loss = 457.61772462\n",
      "Iteration 4269, loss = 457.55272828\n",
      "Iteration 4270, loss = 457.48427489\n",
      "Iteration 4271, loss = 457.42301797\n",
      "Iteration 4272, loss = 457.35894893\n",
      "Iteration 4273, loss = 457.29380941\n",
      "Iteration 4274, loss = 457.22818308\n",
      "Iteration 4275, loss = 457.16666106\n",
      "Iteration 4276, loss = 457.10109725\n",
      "Iteration 4277, loss = 457.04153096\n",
      "Iteration 4278, loss = 456.97321739\n",
      "Iteration 4279, loss = 456.90655778\n",
      "Iteration 4280, loss = 456.84675599\n",
      "Iteration 4281, loss = 456.78733709\n",
      "Iteration 4282, loss = 456.72232841\n",
      "Iteration 4283, loss = 456.65508440\n",
      "Iteration 4284, loss = 456.58657478\n",
      "Iteration 4285, loss = 456.52124334\n",
      "Iteration 4286, loss = 456.46022359\n",
      "Iteration 4287, loss = 456.39658410\n",
      "Iteration 4288, loss = 456.33098122\n",
      "Iteration 4289, loss = 456.26807649\n",
      "Iteration 4290, loss = 456.20607830\n",
      "Iteration 4291, loss = 456.14189841\n",
      "Iteration 4292, loss = 456.08208272\n",
      "Iteration 4293, loss = 456.02245302\n",
      "Iteration 4294, loss = 455.95806184\n",
      "Iteration 4295, loss = 455.89695803\n",
      "Iteration 4296, loss = 455.83730380\n",
      "Iteration 4297, loss = 455.77536002\n",
      "Iteration 4298, loss = 455.70974651\n",
      "Iteration 4299, loss = 455.64649722\n",
      "Iteration 4300, loss = 455.58081419\n",
      "Iteration 4301, loss = 455.51580290\n",
      "Iteration 4302, loss = 455.45390155\n",
      "Iteration 4303, loss = 455.39069060\n",
      "Iteration 4304, loss = 455.32893766\n",
      "Iteration 4305, loss = 455.26717323\n",
      "Iteration 4306, loss = 455.20428988\n",
      "Iteration 4307, loss = 455.14687026\n",
      "Iteration 4308, loss = 455.08595110\n",
      "Iteration 4309, loss = 455.02361381\n",
      "Iteration 4310, loss = 454.95913090\n",
      "Iteration 4311, loss = 454.89981410\n",
      "Iteration 4312, loss = 454.83926587\n",
      "Iteration 4313, loss = 454.77625019\n",
      "Iteration 4314, loss = 454.71142588\n",
      "Iteration 4315, loss = 454.64934505\n",
      "Iteration 4316, loss = 454.59113446\n",
      "Iteration 4317, loss = 454.53024184\n",
      "Iteration 4318, loss = 454.46317038\n",
      "Iteration 4319, loss = 454.40638108\n",
      "Iteration 4320, loss = 454.34755636\n",
      "Iteration 4321, loss = 454.28394361\n",
      "Iteration 4322, loss = 454.21872231\n",
      "Iteration 4323, loss = 454.16041704\n",
      "Iteration 4324, loss = 454.10117173\n",
      "Iteration 4325, loss = 454.04273204\n",
      "Iteration 4326, loss = 453.98003303\n",
      "Iteration 4327, loss = 453.91421053\n",
      "Iteration 4328, loss = 453.85971250\n",
      "Iteration 4329, loss = 453.80195957\n",
      "Iteration 4330, loss = 453.74232244\n",
      "Iteration 4331, loss = 453.67830545\n",
      "Iteration 4332, loss = 453.61374439\n",
      "Iteration 4333, loss = 453.55443342\n",
      "Iteration 4334, loss = 453.49802739\n",
      "Iteration 4335, loss = 453.43745202\n",
      "Iteration 4336, loss = 453.37595098\n",
      "Iteration 4337, loss = 453.31339493\n",
      "Iteration 4338, loss = 453.24849817\n",
      "Iteration 4339, loss = 453.18983354\n",
      "Iteration 4340, loss = 453.13112761\n",
      "Iteration 4341, loss = 453.06701623\n",
      "Iteration 4342, loss = 453.00851942\n",
      "Iteration 4343, loss = 452.94902667\n",
      "Iteration 4344, loss = 452.88817620\n",
      "Iteration 4345, loss = 452.82901340\n",
      "Iteration 4346, loss = 452.76801413\n",
      "Iteration 4347, loss = 452.71061306\n",
      "Iteration 4348, loss = 452.65192557\n",
      "Iteration 4349, loss = 452.59022780\n",
      "Iteration 4350, loss = 452.53319113\n",
      "Iteration 4351, loss = 452.47244962\n",
      "Iteration 4352, loss = 452.41076024\n",
      "Iteration 4353, loss = 452.35147427\n",
      "Iteration 4354, loss = 452.29227291\n",
      "Iteration 4355, loss = 452.23375600\n",
      "Iteration 4356, loss = 452.17389211\n",
      "Iteration 4357, loss = 452.11538852\n",
      "Iteration 4358, loss = 452.05739885\n",
      "Iteration 4359, loss = 451.99783498\n",
      "Iteration 4360, loss = 451.93890990\n",
      "Iteration 4361, loss = 451.87466726\n",
      "Iteration 4362, loss = 451.80763081\n",
      "Iteration 4363, loss = 451.74051904\n",
      "Iteration 4364, loss = 451.67559209\n",
      "Iteration 4365, loss = 451.60905087\n",
      "Iteration 4366, loss = 451.53990896\n",
      "Iteration 4367, loss = 451.47097049\n",
      "Iteration 4368, loss = 451.39825808\n",
      "Iteration 4369, loss = 451.32892504\n",
      "Iteration 4370, loss = 451.25852686\n",
      "Iteration 4371, loss = 451.18566031\n",
      "Iteration 4372, loss = 451.11736209\n",
      "Iteration 4373, loss = 451.04732909\n",
      "Iteration 4374, loss = 450.97153676\n",
      "Iteration 4375, loss = 450.89966162\n",
      "Iteration 4376, loss = 450.83046156\n",
      "Iteration 4377, loss = 450.75554853\n",
      "Iteration 4378, loss = 450.68019351\n",
      "Iteration 4379, loss = 450.61221435\n",
      "Iteration 4380, loss = 450.54333733\n",
      "Iteration 4381, loss = 450.46969586\n",
      "Iteration 4382, loss = 450.39236606\n",
      "Iteration 4383, loss = 450.32286264\n",
      "Iteration 4384, loss = 450.25139661\n",
      "Iteration 4385, loss = 450.17653672\n",
      "Iteration 4386, loss = 450.10407119\n",
      "Iteration 4387, loss = 450.02404830\n",
      "Iteration 4388, loss = 449.95432586\n",
      "Iteration 4389, loss = 449.88395668\n",
      "Iteration 4390, loss = 449.81150304\n",
      "Iteration 4391, loss = 449.73498284\n",
      "Iteration 4392, loss = 449.66040946\n",
      "Iteration 4393, loss = 449.59029875\n",
      "Iteration 4394, loss = 449.51773308\n",
      "Iteration 4395, loss = 449.44421515\n",
      "Iteration 4396, loss = 449.37260290\n",
      "Iteration 4397, loss = 449.30285110\n",
      "Iteration 4398, loss = 449.23098935\n",
      "Iteration 4399, loss = 449.15599828\n",
      "Iteration 4400, loss = 449.08766422\n",
      "Iteration 4401, loss = 449.01518615\n",
      "Iteration 4402, loss = 448.94304115\n",
      "Iteration 4403, loss = 448.87377933\n",
      "Iteration 4404, loss = 448.80228673\n",
      "Iteration 4405, loss = 448.73093586\n",
      "Iteration 4406, loss = 448.66188117\n",
      "Iteration 4407, loss = 448.59107397\n",
      "Iteration 4408, loss = 448.52406200\n",
      "Iteration 4409, loss = 448.45416776\n",
      "Iteration 4410, loss = 448.38198088\n",
      "Iteration 4411, loss = 448.31270156\n",
      "Iteration 4412, loss = 448.24203093\n",
      "Iteration 4413, loss = 448.17165231\n",
      "Iteration 4414, loss = 448.10603696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4415, loss = 448.03599235\n",
      "Iteration 4416, loss = 447.96603231\n",
      "Iteration 4417, loss = 447.89699031\n",
      "Iteration 4418, loss = 447.83147574\n",
      "Iteration 4419, loss = 447.76614071\n",
      "Iteration 4420, loss = 447.69744141\n",
      "Iteration 4421, loss = 447.62445039\n",
      "Iteration 4422, loss = 447.56140273\n",
      "Iteration 4423, loss = 447.49650443\n",
      "Iteration 4424, loss = 447.43354944\n",
      "Iteration 4425, loss = 447.36466180\n",
      "Iteration 4426, loss = 447.29395308\n",
      "Iteration 4427, loss = 447.22963955\n",
      "Iteration 4428, loss = 447.17204729\n",
      "Iteration 4429, loss = 447.10867710\n",
      "Iteration 4430, loss = 447.04004218\n",
      "Iteration 4431, loss = 446.98296055\n",
      "Iteration 4432, loss = 446.92992453\n",
      "Iteration 4433, loss = 446.87366107\n",
      "Iteration 4434, loss = 446.81160379\n",
      "Iteration 4435, loss = 446.74657145\n",
      "Iteration 4436, loss = 446.69122782\n",
      "Iteration 4437, loss = 446.63252419\n",
      "Iteration 4438, loss = 446.57336247\n",
      "Iteration 4439, loss = 446.51397585\n",
      "Iteration 4440, loss = 446.45612656\n",
      "Iteration 4441, loss = 446.40685764\n",
      "Iteration 4442, loss = 446.35166693\n",
      "Iteration 4443, loss = 446.29318813\n",
      "Iteration 4444, loss = 446.23662502\n",
      "Iteration 4445, loss = 446.18178083\n",
      "Iteration 4446, loss = 446.12194561\n",
      "Iteration 4447, loss = 446.06713284\n",
      "Iteration 4448, loss = 446.01098230\n",
      "Iteration 4449, loss = 445.95878218\n",
      "Iteration 4450, loss = 445.90266867\n",
      "Iteration 4451, loss = 445.85396242\n",
      "Iteration 4452, loss = 445.80162426\n",
      "Iteration 4453, loss = 445.74632744\n",
      "Iteration 4454, loss = 445.68963063\n",
      "Iteration 4455, loss = 445.63782137\n",
      "Iteration 4456, loss = 445.58619254\n",
      "Iteration 4457, loss = 445.53193272\n",
      "Iteration 4458, loss = 445.47484448\n",
      "Iteration 4459, loss = 445.41856443\n",
      "Iteration 4460, loss = 445.36044726\n",
      "Iteration 4461, loss = 445.31398952\n",
      "Iteration 4462, loss = 445.26077632\n",
      "Iteration 4463, loss = 445.20792669\n",
      "Iteration 4464, loss = 445.15736234\n",
      "Iteration 4465, loss = 445.10321519\n",
      "Iteration 4466, loss = 445.04788427\n",
      "Iteration 4467, loss = 444.99365362\n",
      "Iteration 4468, loss = 444.94033008\n",
      "Iteration 4469, loss = 444.88683516\n",
      "Iteration 4470, loss = 444.83334899\n",
      "Iteration 4471, loss = 444.78148224\n",
      "Iteration 4472, loss = 444.73153813\n",
      "Iteration 4473, loss = 444.67850711\n",
      "Iteration 4474, loss = 444.62667244\n",
      "Iteration 4475, loss = 444.57194561\n",
      "Iteration 4476, loss = 444.51820956\n",
      "Iteration 4477, loss = 444.47037544\n",
      "Iteration 4478, loss = 444.41453233\n",
      "Iteration 4479, loss = 444.36283258\n",
      "Iteration 4480, loss = 444.31007032\n",
      "Iteration 4481, loss = 444.25913714\n",
      "Iteration 4482, loss = 444.20896751\n",
      "Iteration 4483, loss = 444.15665459\n",
      "Iteration 4484, loss = 444.10614856\n",
      "Iteration 4485, loss = 444.05251903\n",
      "Iteration 4486, loss = 443.99646135\n",
      "Iteration 4487, loss = 443.94779228\n",
      "Iteration 4488, loss = 443.89711070\n",
      "Iteration 4489, loss = 443.84370966\n",
      "Iteration 4490, loss = 443.79165785\n",
      "Iteration 4491, loss = 443.74289531\n",
      "Iteration 4492, loss = 443.69298450\n",
      "Iteration 4493, loss = 443.64019600\n",
      "Iteration 4494, loss = 443.58832769\n",
      "Iteration 4495, loss = 443.53479854\n",
      "Iteration 4496, loss = 443.49087138\n",
      "Iteration 4497, loss = 443.43649713\n",
      "Iteration 4498, loss = 443.38615905\n",
      "Iteration 4499, loss = 443.33618514\n",
      "Iteration 4500, loss = 443.28260638\n",
      "Iteration 4501, loss = 443.23334716\n",
      "Iteration 4502, loss = 443.18346583\n",
      "Iteration 4503, loss = 443.13193213\n",
      "Iteration 4504, loss = 443.07981952\n",
      "Iteration 4505, loss = 443.03315634\n",
      "Iteration 4506, loss = 442.98438975\n",
      "Iteration 4507, loss = 442.93239839\n",
      "Iteration 4508, loss = 442.88442679\n",
      "Iteration 4509, loss = 442.83485799\n",
      "Iteration 4510, loss = 442.78211777\n",
      "Iteration 4511, loss = 442.73279133\n",
      "Iteration 4512, loss = 442.68409229\n",
      "Iteration 4513, loss = 442.63162699\n",
      "Iteration 4514, loss = 442.58260363\n",
      "Iteration 4515, loss = 442.53232145\n",
      "Iteration 4516, loss = 442.48176393\n",
      "Iteration 4517, loss = 442.43635988\n",
      "Iteration 4518, loss = 442.38524486\n",
      "Iteration 4519, loss = 442.33531810\n",
      "Iteration 4520, loss = 442.28637030\n",
      "Iteration 4521, loss = 442.23477131\n",
      "Iteration 4522, loss = 442.18612771\n",
      "Iteration 4523, loss = 442.13640869\n",
      "Iteration 4524, loss = 442.08979351\n",
      "Iteration 4525, loss = 442.04256021\n",
      "Iteration 4526, loss = 441.99377236\n",
      "Iteration 4527, loss = 441.94822595\n",
      "Iteration 4528, loss = 441.90056641\n",
      "Iteration 4529, loss = 441.85481484\n",
      "Iteration 4530, loss = 441.81135611\n",
      "Iteration 4531, loss = 441.76238553\n",
      "Iteration 4532, loss = 441.71898588\n",
      "Iteration 4533, loss = 441.67365738\n",
      "Iteration 4534, loss = 441.62762221\n",
      "Iteration 4535, loss = 441.57487119\n",
      "Iteration 4536, loss = 441.51742997\n",
      "Iteration 4537, loss = 441.46249187\n",
      "Iteration 4538, loss = 441.41003684\n",
      "Iteration 4539, loss = 441.35908323\n",
      "Iteration 4540, loss = 441.31110667\n",
      "Iteration 4541, loss = 441.27327981\n",
      "Iteration 4542, loss = 441.22880812\n",
      "Iteration 4543, loss = 441.18183279\n",
      "Iteration 4544, loss = 441.14194663\n",
      "Iteration 4545, loss = 441.09254612\n",
      "Iteration 4546, loss = 441.03771706\n",
      "Iteration 4547, loss = 440.98966653\n",
      "Iteration 4548, loss = 440.94295994\n",
      "Iteration 4549, loss = 440.89405669\n",
      "Iteration 4550, loss = 440.84637466\n",
      "Iteration 4551, loss = 440.79870135\n",
      "Iteration 4552, loss = 440.75510083\n",
      "Iteration 4553, loss = 440.70837370\n",
      "Iteration 4554, loss = 440.65960006\n",
      "Iteration 4555, loss = 440.61075872\n",
      "Iteration 4556, loss = 440.56391182\n",
      "Iteration 4557, loss = 440.51577752\n",
      "Iteration 4558, loss = 440.47171504\n",
      "Iteration 4559, loss = 440.43102728\n",
      "Iteration 4560, loss = 440.38631767\n",
      "Iteration 4561, loss = 440.33605601\n",
      "Iteration 4562, loss = 440.29063799\n",
      "Iteration 4563, loss = 440.24517956\n",
      "Iteration 4564, loss = 440.19731022\n",
      "Iteration 4565, loss = 440.15203433\n",
      "Iteration 4566, loss = 440.10623369\n",
      "Iteration 4567, loss = 440.06299356\n",
      "Iteration 4568, loss = 440.01992726\n",
      "Iteration 4569, loss = 439.97400916\n",
      "Iteration 4570, loss = 439.92590162\n",
      "Iteration 4571, loss = 439.88121741\n",
      "Iteration 4572, loss = 439.83613089\n",
      "Iteration 4573, loss = 439.78775257\n",
      "Iteration 4574, loss = 439.74321572\n",
      "Iteration 4575, loss = 439.69723691\n",
      "Iteration 4576, loss = 439.65345368\n",
      "Iteration 4577, loss = 439.61456212\n",
      "Iteration 4578, loss = 439.56625550\n",
      "Iteration 4579, loss = 439.52246450\n",
      "Iteration 4580, loss = 439.47784181\n",
      "Iteration 4581, loss = 439.42420495\n",
      "Iteration 4582, loss = 439.36690771\n",
      "Iteration 4583, loss = 439.31579308\n",
      "Iteration 4584, loss = 439.25754297\n",
      "Iteration 4585, loss = 439.20275842\n",
      "Iteration 4586, loss = 439.14625144\n",
      "Iteration 4587, loss = 439.08910664\n",
      "Iteration 4588, loss = 439.03023268\n",
      "Iteration 4589, loss = 438.96392601\n",
      "Iteration 4590, loss = 438.90572829\n",
      "Iteration 4591, loss = 438.84492501\n",
      "Iteration 4592, loss = 438.78191928\n",
      "Iteration 4593, loss = 438.71255350\n",
      "Iteration 4594, loss = 438.65215192\n",
      "Iteration 4595, loss = 438.59004694\n",
      "Iteration 4596, loss = 438.52581716\n",
      "Iteration 4597, loss = 438.46111394\n",
      "Iteration 4598, loss = 438.39537653\n",
      "Iteration 4599, loss = 438.33228299\n",
      "Iteration 4600, loss = 438.26713090\n",
      "Iteration 4601, loss = 438.20444056\n",
      "Iteration 4602, loss = 438.13914277\n",
      "Iteration 4603, loss = 438.07770804\n",
      "Iteration 4604, loss = 438.01757772\n",
      "Iteration 4605, loss = 437.95246782\n",
      "Iteration 4606, loss = 437.88752483\n",
      "Iteration 4607, loss = 437.82552053\n",
      "Iteration 4608, loss = 437.76194802\n",
      "Iteration 4609, loss = 437.69488778\n",
      "Iteration 4610, loss = 437.63623163\n",
      "Iteration 4611, loss = 437.57698941\n",
      "Iteration 4612, loss = 437.50893485\n",
      "Iteration 4613, loss = 437.44786099\n",
      "Iteration 4614, loss = 437.38839557\n",
      "Iteration 4615, loss = 437.34797870\n",
      "Iteration 4616, loss = 437.30528703\n",
      "Iteration 4617, loss = 437.26329017\n",
      "Iteration 4618, loss = 437.22195971\n",
      "Iteration 4619, loss = 437.17678493\n",
      "Iteration 4620, loss = 437.13504531\n",
      "Iteration 4621, loss = 437.09180195\n",
      "Iteration 4622, loss = 437.04622643\n",
      "Iteration 4623, loss = 437.00540546\n",
      "Iteration 4624, loss = 436.96434636\n",
      "Iteration 4625, loss = 436.91840586\n",
      "Iteration 4626, loss = 436.87442864\n",
      "Iteration 4627, loss = 436.83066905\n",
      "Iteration 4628, loss = 436.78967947\n",
      "Iteration 4629, loss = 436.74555437\n",
      "Iteration 4630, loss = 436.69958997\n",
      "Iteration 4631, loss = 436.65966486\n",
      "Iteration 4632, loss = 436.61448013\n",
      "Iteration 4633, loss = 436.56656765\n",
      "Iteration 4634, loss = 436.52571040\n",
      "Iteration 4635, loss = 436.48890250\n",
      "Iteration 4636, loss = 436.44528270\n",
      "Iteration 4637, loss = 436.39880856\n",
      "Iteration 4638, loss = 436.35329768\n",
      "Iteration 4639, loss = 436.31699760\n",
      "Iteration 4640, loss = 436.27955731\n",
      "Iteration 4641, loss = 436.23372504\n",
      "Iteration 4642, loss = 436.18537086\n",
      "Iteration 4643, loss = 436.14530375\n",
      "Iteration 4644, loss = 436.10494183\n",
      "Iteration 4645, loss = 436.06229561\n",
      "Iteration 4646, loss = 436.02573493\n",
      "Iteration 4647, loss = 435.98732542\n",
      "Iteration 4648, loss = 435.94496763\n",
      "Iteration 4649, loss = 435.91197589\n",
      "Iteration 4650, loss = 435.87431344\n",
      "Iteration 4651, loss = 435.83378285\n",
      "Iteration 4652, loss = 435.79276100\n",
      "Iteration 4653, loss = 435.74741684\n",
      "Iteration 4654, loss = 435.70060482\n",
      "Iteration 4655, loss = 435.66075686\n",
      "Iteration 4656, loss = 435.62003837\n",
      "Iteration 4657, loss = 435.58372007\n",
      "Iteration 4658, loss = 435.54636286\n",
      "Iteration 4659, loss = 435.50947940\n",
      "Iteration 4660, loss = 435.46963644\n",
      "Iteration 4661, loss = 435.43069318\n",
      "Iteration 4662, loss = 435.39275379\n",
      "Iteration 4663, loss = 435.35812922\n",
      "Iteration 4664, loss = 435.31599220\n",
      "Iteration 4665, loss = 435.28003182\n",
      "Iteration 4666, loss = 435.24751518\n",
      "Iteration 4667, loss = 435.21216075\n",
      "Iteration 4668, loss = 435.17255729\n",
      "Iteration 4669, loss = 435.12946756\n",
      "Iteration 4670, loss = 435.09243514\n",
      "Iteration 4671, loss = 435.05394007\n",
      "Iteration 4672, loss = 435.00943246\n",
      "Iteration 4673, loss = 434.96632588\n",
      "Iteration 4674, loss = 434.93111489\n",
      "Iteration 4675, loss = 434.89605676\n",
      "Iteration 4676, loss = 434.85629853\n",
      "Iteration 4677, loss = 434.81487785\n",
      "Iteration 4678, loss = 434.78017444\n",
      "Iteration 4679, loss = 434.74470546\n",
      "Iteration 4680, loss = 434.70472819\n",
      "Iteration 4681, loss = 434.66609698\n",
      "Iteration 4682, loss = 434.63108522\n",
      "Iteration 4683, loss = 434.59419398\n",
      "Iteration 4684, loss = 434.55587480\n",
      "Iteration 4685, loss = 434.51579828\n",
      "Iteration 4686, loss = 434.48094958\n",
      "Iteration 4687, loss = 434.44598575\n",
      "Iteration 4688, loss = 434.40656954\n",
      "Iteration 4689, loss = 434.37267843\n",
      "Iteration 4690, loss = 434.33547384\n",
      "Iteration 4691, loss = 434.29759783\n",
      "Iteration 4692, loss = 434.26456209\n",
      "Iteration 4693, loss = 434.22499764\n",
      "Iteration 4694, loss = 434.17973094\n",
      "Iteration 4695, loss = 434.15089404\n",
      "Iteration 4696, loss = 434.11945275\n",
      "Iteration 4697, loss = 434.08088760\n",
      "Iteration 4698, loss = 434.03725369\n",
      "Iteration 4699, loss = 434.00293127\n",
      "Iteration 4700, loss = 433.96582974\n",
      "Iteration 4701, loss = 433.92469798\n",
      "Iteration 4702, loss = 433.88885787\n",
      "Iteration 4703, loss = 433.85140884\n",
      "Iteration 4704, loss = 433.81694636\n",
      "Iteration 4705, loss = 433.77794224\n",
      "Iteration 4706, loss = 433.74062749\n",
      "Iteration 4707, loss = 433.70184561\n",
      "Iteration 4708, loss = 433.67059993\n",
      "Iteration 4709, loss = 433.63446248\n",
      "Iteration 4710, loss = 433.59522797\n",
      "Iteration 4711, loss = 433.55797583\n",
      "Iteration 4712, loss = 433.52182341\n",
      "Iteration 4713, loss = 433.48630994\n",
      "Iteration 4714, loss = 433.45093567\n",
      "Iteration 4715, loss = 433.41636426\n",
      "Iteration 4716, loss = 433.38241211\n",
      "Iteration 4717, loss = 433.34997511\n",
      "Iteration 4718, loss = 433.31251201\n",
      "Iteration 4719, loss = 433.27760672\n",
      "Iteration 4720, loss = 433.24098041\n",
      "Iteration 4721, loss = 433.20538972\n",
      "Iteration 4722, loss = 433.16629231\n",
      "Iteration 4723, loss = 433.13202260\n",
      "Iteration 4724, loss = 433.09219816\n",
      "Iteration 4725, loss = 433.05504948\n",
      "Iteration 4726, loss = 433.02111619\n",
      "Iteration 4727, loss = 432.98577855\n",
      "Iteration 4728, loss = 432.94645651\n",
      "Iteration 4729, loss = 432.90885386\n",
      "Iteration 4730, loss = 432.87335597\n",
      "Iteration 4731, loss = 432.83536175\n",
      "Iteration 4732, loss = 432.80045706\n",
      "Iteration 4733, loss = 432.76709587\n",
      "Iteration 4734, loss = 432.73366354\n",
      "Iteration 4735, loss = 432.69869886\n",
      "Iteration 4736, loss = 432.66078544\n",
      "Iteration 4737, loss = 432.62856363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4738, loss = 432.59721720\n",
      "Iteration 4739, loss = 432.55408738\n",
      "Iteration 4740, loss = 432.51963212\n",
      "Iteration 4741, loss = 432.48827272\n",
      "Iteration 4742, loss = 432.45458297\n",
      "Iteration 4743, loss = 432.41674670\n",
      "Iteration 4744, loss = 432.37918936\n",
      "Iteration 4745, loss = 432.34111500\n",
      "Iteration 4746, loss = 432.30309667\n",
      "Iteration 4747, loss = 432.27434550\n",
      "Iteration 4748, loss = 432.24263804\n",
      "Iteration 4749, loss = 432.20504209\n",
      "Iteration 4750, loss = 432.16568803\n",
      "Iteration 4751, loss = 432.13578176\n",
      "Iteration 4752, loss = 432.10339508\n",
      "Iteration 4753, loss = 432.06990903\n",
      "Iteration 4754, loss = 432.03619888\n",
      "Iteration 4755, loss = 432.00813723\n",
      "Iteration 4756, loss = 431.96632661\n",
      "Iteration 4757, loss = 431.93019652\n",
      "Iteration 4758, loss = 431.89221429\n",
      "Iteration 4759, loss = 431.86206309\n",
      "Iteration 4760, loss = 431.83231358\n",
      "Iteration 4761, loss = 431.79789817\n",
      "Iteration 4762, loss = 431.75684215\n",
      "Iteration 4763, loss = 431.72121764\n",
      "Iteration 4764, loss = 431.68720732\n",
      "Iteration 4765, loss = 431.65461221\n",
      "Iteration 4766, loss = 431.61852312\n",
      "Iteration 4767, loss = 431.58265123\n",
      "Iteration 4768, loss = 431.54631181\n",
      "Iteration 4769, loss = 431.50489628\n",
      "Iteration 4770, loss = 431.47170602\n",
      "Iteration 4771, loss = 431.44003856\n",
      "Iteration 4772, loss = 431.40455083\n",
      "Iteration 4773, loss = 431.37098390\n",
      "Iteration 4774, loss = 431.33846885\n",
      "Iteration 4775, loss = 431.30527308\n",
      "Iteration 4776, loss = 431.26991191\n",
      "Iteration 4777, loss = 431.23415201\n",
      "Iteration 4778, loss = 431.19969106\n",
      "Iteration 4779, loss = 431.16601877\n",
      "Iteration 4780, loss = 431.13243429\n",
      "Iteration 4781, loss = 431.09892408\n",
      "Iteration 4782, loss = 431.06560948\n",
      "Iteration 4783, loss = 431.02887046\n",
      "Iteration 4784, loss = 431.00124506\n",
      "Iteration 4785, loss = 430.96636673\n",
      "Iteration 4786, loss = 430.92789918\n",
      "Iteration 4787, loss = 430.89528732\n",
      "Iteration 4788, loss = 430.85970213\n",
      "Iteration 4789, loss = 430.82328861\n",
      "Iteration 4790, loss = 430.79858394\n",
      "Iteration 4791, loss = 430.76165727\n",
      "Iteration 4792, loss = 430.72372404\n",
      "Iteration 4793, loss = 430.69248263\n",
      "Iteration 4794, loss = 430.66387608\n",
      "Iteration 4795, loss = 430.63220178\n",
      "Iteration 4796, loss = 430.59754408\n",
      "Iteration 4797, loss = 430.56507123\n",
      "Iteration 4798, loss = 430.53112469\n",
      "Iteration 4799, loss = 430.49709828\n",
      "Iteration 4800, loss = 430.46638639\n",
      "Iteration 4801, loss = 430.43398432\n",
      "Iteration 4802, loss = 430.40050743\n",
      "Iteration 4803, loss = 430.36711820\n",
      "Iteration 4804, loss = 430.33048462\n",
      "Iteration 4805, loss = 430.30301657\n",
      "Iteration 4806, loss = 430.26516743\n",
      "Iteration 4807, loss = 430.22743962\n",
      "Iteration 4808, loss = 430.19399311\n",
      "Iteration 4809, loss = 430.15979037\n",
      "Iteration 4810, loss = 430.12590207\n",
      "Iteration 4811, loss = 430.08978938\n",
      "Iteration 4812, loss = 430.05983968\n",
      "Iteration 4813, loss = 430.02857265\n",
      "Iteration 4814, loss = 429.99972960\n",
      "Iteration 4815, loss = 429.97188078\n",
      "Iteration 4816, loss = 429.93950587\n",
      "Iteration 4817, loss = 429.91113105\n",
      "Iteration 4818, loss = 429.87689992\n",
      "Iteration 4819, loss = 429.84236758\n",
      "Iteration 4820, loss = 429.81008334\n",
      "Iteration 4821, loss = 429.77811203\n",
      "Iteration 4822, loss = 429.73416273\n",
      "Iteration 4823, loss = 429.69904760\n",
      "Iteration 4824, loss = 429.66862426\n",
      "Iteration 4825, loss = 429.63588830\n",
      "Iteration 4826, loss = 429.60176950\n",
      "Iteration 4827, loss = 429.56979934\n",
      "Iteration 4828, loss = 429.53731008\n",
      "Iteration 4829, loss = 429.50215459\n",
      "Iteration 4830, loss = 429.47736543\n",
      "Iteration 4831, loss = 429.44274694\n",
      "Iteration 4832, loss = 429.40322193\n",
      "Iteration 4833, loss = 429.37361072\n",
      "Iteration 4834, loss = 429.34224768\n",
      "Iteration 4835, loss = 429.31173043\n",
      "Iteration 4836, loss = 429.27856658\n",
      "Iteration 4837, loss = 429.24265418\n",
      "Iteration 4838, loss = 429.21010436\n",
      "Iteration 4839, loss = 429.18178953\n",
      "Iteration 4840, loss = 429.15622007\n",
      "Iteration 4841, loss = 429.12057839\n",
      "Iteration 4842, loss = 429.08220088\n",
      "Iteration 4843, loss = 429.04808289\n",
      "Iteration 4844, loss = 429.02049966\n",
      "Iteration 4845, loss = 428.98983986\n",
      "Iteration 4846, loss = 428.95599167\n",
      "Iteration 4847, loss = 428.91949754\n",
      "Iteration 4848, loss = 428.88251159\n",
      "Iteration 4849, loss = 428.85802488\n",
      "Iteration 4850, loss = 428.82705888\n",
      "Iteration 4851, loss = 428.78771188\n",
      "Iteration 4852, loss = 428.75826622\n",
      "Iteration 4853, loss = 428.73060863\n",
      "Iteration 4854, loss = 428.70074703\n",
      "Iteration 4855, loss = 428.67114418\n",
      "Iteration 4856, loss = 428.63596580\n",
      "Iteration 4857, loss = 428.59977417\n",
      "Iteration 4858, loss = 428.56579371\n",
      "Iteration 4859, loss = 428.53665916\n",
      "Iteration 4860, loss = 428.50673314\n",
      "Iteration 4861, loss = 428.47134421\n",
      "Iteration 4862, loss = 428.43380843\n",
      "Iteration 4863, loss = 428.40517076\n",
      "Iteration 4864, loss = 428.37648909\n",
      "Iteration 4865, loss = 428.34547829\n",
      "Iteration 4866, loss = 428.31267578\n",
      "Iteration 4867, loss = 428.27799221\n",
      "Iteration 4868, loss = 428.25841228\n",
      "Iteration 4869, loss = 428.22863489\n",
      "Iteration 4870, loss = 428.18738501\n",
      "Iteration 4871, loss = 428.15779050\n",
      "Iteration 4872, loss = 428.12806098\n",
      "Iteration 4873, loss = 428.09605768\n",
      "Iteration 4874, loss = 428.06514290\n",
      "Iteration 4875, loss = 428.03211058\n",
      "Iteration 4876, loss = 427.99507699\n",
      "Iteration 4877, loss = 427.96953701\n",
      "Iteration 4878, loss = 427.93719680\n",
      "Iteration 4879, loss = 427.90484975\n",
      "Iteration 4880, loss = 427.87509220\n",
      "Iteration 4881, loss = 427.84377675\n",
      "Iteration 4882, loss = 427.81148891\n",
      "Iteration 4883, loss = 427.78479977\n",
      "Iteration 4884, loss = 427.75044344\n",
      "Iteration 4885, loss = 427.71463822\n",
      "Iteration 4886, loss = 427.68500697\n",
      "Iteration 4887, loss = 427.65388987\n",
      "Iteration 4888, loss = 427.61945044\n",
      "Iteration 4889, loss = 427.58825383\n",
      "Iteration 4890, loss = 427.56100988\n",
      "Iteration 4891, loss = 427.52717968\n",
      "Iteration 4892, loss = 427.49479304\n",
      "Iteration 4893, loss = 427.46471303\n",
      "Iteration 4894, loss = 427.43444435\n",
      "Iteration 4895, loss = 427.40093643\n",
      "Iteration 4896, loss = 427.38056936\n",
      "Iteration 4897, loss = 427.34920085\n",
      "Iteration 4898, loss = 427.31177526\n",
      "Iteration 4899, loss = 427.28802933\n",
      "Iteration 4900, loss = 427.25977304\n",
      "Iteration 4901, loss = 427.22893075\n",
      "Iteration 4902, loss = 427.19607821\n",
      "Iteration 4903, loss = 427.17118538\n",
      "Iteration 4904, loss = 427.13544062\n",
      "Iteration 4905, loss = 427.09519870\n",
      "Iteration 4906, loss = 427.06097398\n",
      "Iteration 4907, loss = 427.03452710\n",
      "Iteration 4908, loss = 427.00136059\n",
      "Iteration 4909, loss = 426.97061523\n",
      "Iteration 4910, loss = 426.93663847\n",
      "Iteration 4911, loss = 426.90626730\n",
      "Iteration 4912, loss = 426.87414806\n",
      "Iteration 4913, loss = 426.84606866\n",
      "Iteration 4914, loss = 426.81470609\n",
      "Iteration 4915, loss = 426.78780410\n",
      "Iteration 4916, loss = 426.75530223\n",
      "Iteration 4917, loss = 426.71794885\n",
      "Iteration 4918, loss = 426.68939276\n",
      "Iteration 4919, loss = 426.65807423\n",
      "Iteration 4920, loss = 426.62458173\n",
      "Iteration 4921, loss = 426.59816370\n",
      "Iteration 4922, loss = 426.57100727\n",
      "Iteration 4923, loss = 426.54177809\n",
      "Iteration 4924, loss = 426.50925118\n",
      "Iteration 4925, loss = 426.47901708\n",
      "Iteration 4926, loss = 426.44936506\n",
      "Iteration 4927, loss = 426.41732569\n",
      "Iteration 4928, loss = 426.38895140\n",
      "Iteration 4929, loss = 426.35791117\n",
      "Iteration 4930, loss = 426.32228305\n",
      "Iteration 4931, loss = 426.29000386\n",
      "Iteration 4932, loss = 426.26340427\n",
      "Iteration 4933, loss = 426.23352445\n",
      "Iteration 4934, loss = 426.20548710\n",
      "Iteration 4935, loss = 426.16588488\n",
      "Iteration 4936, loss = 426.13491429\n",
      "Iteration 4937, loss = 426.10908674\n",
      "Iteration 4938, loss = 426.07710750\n",
      "Iteration 4939, loss = 426.04408949\n",
      "Iteration 4940, loss = 426.01297824\n",
      "Iteration 4941, loss = 425.98810156\n",
      "Iteration 4942, loss = 425.95857058\n",
      "Iteration 4943, loss = 425.92884986\n",
      "Iteration 4944, loss = 425.90031893\n",
      "Iteration 4945, loss = 425.86861008\n",
      "Iteration 4946, loss = 425.83878214\n",
      "Iteration 4947, loss = 425.81103756\n",
      "Iteration 4948, loss = 425.77714922\n",
      "Iteration 4949, loss = 425.74707643\n",
      "Iteration 4950, loss = 425.71730211\n",
      "Iteration 4951, loss = 425.68493345\n",
      "Iteration 4952, loss = 425.65285374\n",
      "Iteration 4953, loss = 425.62627555\n",
      "Iteration 4954, loss = 425.59702703\n",
      "Iteration 4955, loss = 425.56357551\n",
      "Iteration 4956, loss = 425.53224206\n",
      "Iteration 4957, loss = 425.50620130\n",
      "Iteration 4958, loss = 425.47900870\n",
      "Iteration 4959, loss = 425.44697131\n",
      "Iteration 4960, loss = 425.41432860\n",
      "Iteration 4961, loss = 425.38141407\n",
      "Iteration 4962, loss = 425.35253322\n",
      "Iteration 4963, loss = 425.32322721\n",
      "Iteration 4964, loss = 425.29244250\n",
      "Iteration 4965, loss = 425.26375699\n",
      "Iteration 4966, loss = 425.23246968\n",
      "Iteration 4967, loss = 425.20092021\n",
      "Iteration 4968, loss = 425.17297200\n",
      "Iteration 4969, loss = 425.14622758\n",
      "Iteration 4970, loss = 425.11844913\n",
      "Iteration 4971, loss = 425.08640992\n",
      "Iteration 4972, loss = 425.05926354\n",
      "Iteration 4973, loss = 425.02926778\n",
      "Iteration 4974, loss = 425.00318867\n",
      "Iteration 4975, loss = 424.97334948\n",
      "Iteration 4976, loss = 424.93861724\n",
      "Iteration 4977, loss = 424.90815197\n",
      "Iteration 4978, loss = 424.87728948\n",
      "Iteration 4979, loss = 424.85050630\n",
      "Iteration 4980, loss = 424.82431471\n",
      "Iteration 4981, loss = 424.79663987\n",
      "Iteration 4982, loss = 424.76520108\n",
      "Iteration 4983, loss = 424.74132116\n",
      "Iteration 4984, loss = 424.71281770\n",
      "Iteration 4985, loss = 424.68271272\n",
      "Iteration 4986, loss = 424.65429079\n",
      "Iteration 4987, loss = 424.62129716\n",
      "Iteration 4988, loss = 424.58887088\n",
      "Iteration 4989, loss = 424.56129870\n",
      "Iteration 4990, loss = 424.52702196\n",
      "Iteration 4991, loss = 424.50030783\n",
      "Iteration 4992, loss = 424.47385671\n",
      "Iteration 4993, loss = 424.44001228\n",
      "Iteration 4994, loss = 424.40841092\n",
      "Iteration 4995, loss = 424.38444767\n",
      "Iteration 4996, loss = 424.35702211\n",
      "Iteration 4997, loss = 424.32515034\n",
      "Iteration 4998, loss = 424.29514652\n",
      "Iteration 4999, loss = 424.26268315\n",
      "Iteration 5000, loss = 424.22778661\n",
      "Iteration 5001, loss = 424.20524312\n",
      "Iteration 5002, loss = 424.17608421\n",
      "Iteration 5003, loss = 424.14048673\n",
      "Iteration 5004, loss = 424.11645992\n",
      "Iteration 5005, loss = 424.09093815\n",
      "Iteration 5006, loss = 424.06342846\n",
      "Iteration 5007, loss = 424.03660441\n",
      "Iteration 5008, loss = 424.00854382\n",
      "Iteration 5009, loss = 423.97459133\n",
      "Iteration 5010, loss = 423.94187129\n",
      "Iteration 5011, loss = 423.91066187\n",
      "Iteration 5012, loss = 423.88155468\n",
      "Iteration 5013, loss = 423.85856736\n",
      "Iteration 5014, loss = 423.82597105\n",
      "Iteration 5015, loss = 423.79556297\n",
      "Iteration 5016, loss = 423.77092646\n",
      "Iteration 5017, loss = 423.73886366\n",
      "Iteration 5018, loss = 423.71503069\n",
      "Iteration 5019, loss = 423.69013550\n",
      "Iteration 5020, loss = 423.66238222\n",
      "Iteration 5021, loss = 423.63257094\n",
      "Iteration 5022, loss = 423.60038873\n",
      "Iteration 5023, loss = 423.56836155\n",
      "Iteration 5024, loss = 423.54150976\n",
      "Iteration 5025, loss = 423.50854879\n",
      "Iteration 5026, loss = 423.47818367\n",
      "Iteration 5027, loss = 423.45159595\n",
      "Iteration 5028, loss = 423.42423889\n",
      "Iteration 5029, loss = 423.39498432\n",
      "Iteration 5030, loss = 423.36792985\n",
      "Iteration 5031, loss = 423.34181068\n",
      "Iteration 5032, loss = 423.31447137\n",
      "Iteration 5033, loss = 423.28358455\n",
      "Iteration 5034, loss = 423.26139210\n",
      "Iteration 5035, loss = 423.23451310\n",
      "Iteration 5036, loss = 423.20808892\n",
      "Iteration 5037, loss = 423.17852948\n",
      "Iteration 5038, loss = 423.15003156\n",
      "Iteration 5039, loss = 423.12345413\n",
      "Iteration 5040, loss = 423.09070566\n",
      "Iteration 5041, loss = 423.06729755\n",
      "Iteration 5042, loss = 423.03835247\n",
      "Iteration 5043, loss = 423.00223668\n",
      "Iteration 5044, loss = 422.97152029\n",
      "Iteration 5045, loss = 422.94499977\n",
      "Iteration 5046, loss = 422.91372009\n",
      "Iteration 5047, loss = 422.89075771\n",
      "Iteration 5048, loss = 422.85983259\n",
      "Iteration 5049, loss = 422.83359037\n",
      "Iteration 5050, loss = 422.81016608\n",
      "Iteration 5051, loss = 422.77923156\n",
      "Iteration 5052, loss = 422.75302981\n",
      "Iteration 5053, loss = 422.72756760\n",
      "Iteration 5054, loss = 422.69693989\n",
      "Iteration 5055, loss = 422.67027029\n",
      "Iteration 5056, loss = 422.63885762\n",
      "Iteration 5057, loss = 422.60976080\n",
      "Iteration 5058, loss = 422.58396305\n",
      "Iteration 5059, loss = 422.55403324\n",
      "Iteration 5060, loss = 422.52060066\n",
      "Iteration 5061, loss = 422.49299283\n",
      "Iteration 5062, loss = 422.46526480\n",
      "Iteration 5063, loss = 422.44224397\n",
      "Iteration 5064, loss = 422.41120898\n",
      "Iteration 5065, loss = 422.38562257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5066, loss = 422.35749360\n",
      "Iteration 5067, loss = 422.32557337\n",
      "Iteration 5068, loss = 422.29676322\n",
      "Iteration 5069, loss = 422.27054084\n",
      "Iteration 5070, loss = 422.24189861\n",
      "Iteration 5071, loss = 422.21787047\n",
      "Iteration 5072, loss = 422.19032883\n",
      "Iteration 5073, loss = 422.16032340\n",
      "Iteration 5074, loss = 422.13360037\n",
      "Iteration 5075, loss = 422.10508148\n",
      "Iteration 5076, loss = 422.07629902\n",
      "Iteration 5077, loss = 422.05415667\n",
      "Iteration 5078, loss = 422.02443549\n",
      "Iteration 5079, loss = 421.99696247\n",
      "Iteration 5080, loss = 421.97325122\n",
      "Iteration 5081, loss = 421.94574742\n",
      "Iteration 5082, loss = 421.91641412\n",
      "Iteration 5083, loss = 421.88764169\n",
      "Iteration 5084, loss = 421.85689514\n",
      "Iteration 5085, loss = 421.82836080\n",
      "Iteration 5086, loss = 421.80257551\n",
      "Iteration 5087, loss = 421.77603100\n",
      "Iteration 5088, loss = 421.74960289\n",
      "Iteration 5089, loss = 421.72003233\n",
      "Iteration 5090, loss = 421.69168517\n",
      "Iteration 5091, loss = 421.67068468\n",
      "Iteration 5092, loss = 421.64235143\n",
      "Iteration 5093, loss = 421.61331643\n",
      "Iteration 5094, loss = 421.58573995\n",
      "Iteration 5095, loss = 421.55525371\n",
      "Iteration 5096, loss = 421.52956407\n",
      "Iteration 5097, loss = 421.50413890\n",
      "Iteration 5098, loss = 421.47941013\n",
      "Iteration 5099, loss = 421.44773716\n",
      "Iteration 5100, loss = 421.42338012\n",
      "Iteration 5101, loss = 421.39793698\n",
      "Iteration 5102, loss = 421.37365018\n",
      "Iteration 5103, loss = 421.34911831\n",
      "Iteration 5104, loss = 421.31408970\n",
      "Iteration 5105, loss = 421.28592363\n",
      "Iteration 5106, loss = 421.26398696\n",
      "Iteration 5107, loss = 421.23395676\n",
      "Iteration 5108, loss = 421.20625301\n",
      "Iteration 5109, loss = 421.18007292\n",
      "Iteration 5110, loss = 421.15488882\n",
      "Iteration 5111, loss = 421.12704905\n",
      "Iteration 5112, loss = 421.09973728\n",
      "Iteration 5113, loss = 421.06813464\n",
      "Iteration 5114, loss = 421.04726906\n",
      "Iteration 5115, loss = 421.02378161\n",
      "Iteration 5116, loss = 420.99512322\n",
      "Iteration 5117, loss = 420.96853751\n",
      "Iteration 5118, loss = 420.94369359\n",
      "Iteration 5119, loss = 420.92465929\n",
      "Iteration 5120, loss = 420.89650357\n",
      "Iteration 5121, loss = 420.86365631\n",
      "Iteration 5122, loss = 420.83954672\n",
      "Iteration 5123, loss = 420.82023998\n",
      "Iteration 5124, loss = 420.79695129\n",
      "Iteration 5125, loss = 420.76414901\n",
      "Iteration 5126, loss = 420.73313601\n",
      "Iteration 5127, loss = 420.70682261\n",
      "Iteration 5128, loss = 420.68150654\n",
      "Iteration 5129, loss = 420.64960745\n",
      "Iteration 5130, loss = 420.61972355\n",
      "Iteration 5131, loss = 420.58965738\n",
      "Iteration 5132, loss = 420.56718174\n",
      "Iteration 5133, loss = 420.53763741\n",
      "Iteration 5134, loss = 420.51098091\n",
      "Iteration 5135, loss = 420.48055211\n",
      "Iteration 5136, loss = 420.46194831\n",
      "Iteration 5137, loss = 420.43310599\n",
      "Iteration 5138, loss = 420.40288580\n",
      "Iteration 5139, loss = 420.38147091\n",
      "Iteration 5140, loss = 420.35749233\n",
      "Iteration 5141, loss = 420.33181877\n",
      "Iteration 5142, loss = 420.30407955\n",
      "Iteration 5143, loss = 420.28022564\n",
      "Iteration 5144, loss = 420.25234557\n",
      "Iteration 5145, loss = 420.22538567\n",
      "Iteration 5146, loss = 420.20111696\n",
      "Iteration 5147, loss = 420.17217447\n",
      "Iteration 5148, loss = 420.14668642\n",
      "Iteration 5149, loss = 420.12570632\n",
      "Iteration 5150, loss = 420.09478495\n",
      "Iteration 5151, loss = 420.06468199\n",
      "Iteration 5152, loss = 420.04520376\n",
      "Iteration 5153, loss = 420.02273645\n",
      "Iteration 5154, loss = 419.99496645\n",
      "Iteration 5155, loss = 419.96727532\n",
      "Iteration 5156, loss = 419.94204426\n",
      "Iteration 5157, loss = 419.92037759\n",
      "Iteration 5158, loss = 419.89473061\n",
      "Iteration 5159, loss = 419.87062995\n",
      "Iteration 5160, loss = 419.84520494\n",
      "Iteration 5161, loss = 419.81844355\n",
      "Iteration 5162, loss = 419.79235054\n",
      "Iteration 5163, loss = 419.76602703\n",
      "Iteration 5164, loss = 419.74133866\n",
      "Iteration 5165, loss = 419.71679474\n",
      "Iteration 5166, loss = 419.68703259\n",
      "Iteration 5167, loss = 419.66385748\n",
      "Iteration 5168, loss = 419.64021131\n",
      "Iteration 5169, loss = 419.61433947\n",
      "Iteration 5170, loss = 419.58475021\n",
      "Iteration 5171, loss = 419.56656563\n",
      "Iteration 5172, loss = 419.54155296\n",
      "Iteration 5173, loss = 419.51747066\n",
      "Iteration 5174, loss = 419.49661131\n",
      "Iteration 5175, loss = 419.47114097\n",
      "Iteration 5176, loss = 419.45188060\n",
      "Iteration 5177, loss = 419.42470908\n",
      "Iteration 5178, loss = 419.40858744\n",
      "Iteration 5179, loss = 419.38533269\n",
      "Iteration 5180, loss = 419.36233637\n",
      "Iteration 5181, loss = 419.34333555\n",
      "Iteration 5182, loss = 419.32068881\n",
      "Iteration 5183, loss = 419.29920701\n",
      "Iteration 5184, loss = 419.27610503\n",
      "Iteration 5185, loss = 419.25598509\n",
      "Iteration 5186, loss = 419.22667294\n",
      "Iteration 5187, loss = 419.20207034\n",
      "Iteration 5188, loss = 419.17881144\n",
      "Iteration 5189, loss = 419.16290204\n",
      "Iteration 5190, loss = 419.14388486\n",
      "Iteration 5191, loss = 419.12470562\n",
      "Iteration 5192, loss = 419.10701635\n",
      "Iteration 5193, loss = 419.09224724\n",
      "Iteration 5194, loss = 419.06323561\n",
      "Iteration 5195, loss = 419.04306317\n",
      "Iteration 5196, loss = 419.01613338\n",
      "Iteration 5197, loss = 418.98911435\n",
      "Iteration 5198, loss = 418.95944150\n",
      "Iteration 5199, loss = 418.94452327\n",
      "Iteration 5200, loss = 418.92210672\n",
      "Iteration 5201, loss = 418.90056232\n",
      "Iteration 5202, loss = 418.87885163\n",
      "Iteration 5203, loss = 418.85302621\n",
      "Iteration 5204, loss = 418.82975475\n",
      "Iteration 5205, loss = 418.81340673\n",
      "Iteration 5206, loss = 418.78706010\n",
      "Iteration 5207, loss = 418.77026456\n",
      "Iteration 5208, loss = 418.75364890\n",
      "Iteration 5209, loss = 418.73759501\n",
      "Iteration 5210, loss = 418.71511151\n",
      "Iteration 5211, loss = 418.68712755\n",
      "Iteration 5212, loss = 418.65944817\n",
      "Iteration 5213, loss = 418.63123088\n",
      "Iteration 5214, loss = 418.61646835\n",
      "Iteration 5215, loss = 418.60612768\n",
      "Iteration 5216, loss = 418.59740126\n",
      "Iteration 5217, loss = 418.56816776\n",
      "Iteration 5218, loss = 418.54183263\n",
      "Iteration 5219, loss = 418.51355021\n",
      "Iteration 5220, loss = 418.48387369\n",
      "Iteration 5221, loss = 418.46329392\n",
      "Iteration 5222, loss = 418.44944584\n",
      "Iteration 5223, loss = 418.42933622\n",
      "Iteration 5224, loss = 418.40637773\n",
      "Iteration 5225, loss = 418.37959287\n",
      "Iteration 5226, loss = 418.35469028\n",
      "Iteration 5227, loss = 418.34073618\n",
      "Iteration 5228, loss = 418.32464143\n",
      "Iteration 5229, loss = 418.29875081\n",
      "Iteration 5230, loss = 418.27776671\n",
      "Iteration 5231, loss = 418.25713796\n",
      "Iteration 5232, loss = 418.24010133\n",
      "Iteration 5233, loss = 418.21634245\n",
      "Iteration 5234, loss = 418.19153243\n",
      "Iteration 5235, loss = 418.17031184\n",
      "Iteration 5236, loss = 418.14852588\n",
      "Iteration 5237, loss = 418.12543183\n",
      "Iteration 5238, loss = 418.11116647\n",
      "Iteration 5239, loss = 418.09430285\n",
      "Iteration 5240, loss = 418.06646719\n",
      "Iteration 5241, loss = 418.04144385\n",
      "Iteration 5242, loss = 418.02131476\n",
      "Iteration 5243, loss = 418.00342149\n",
      "Iteration 5244, loss = 417.98594041\n",
      "Iteration 5245, loss = 417.96270966\n",
      "Iteration 5246, loss = 417.94952750\n",
      "Iteration 5247, loss = 417.92001921\n",
      "Iteration 5248, loss = 417.89895105\n",
      "Iteration 5249, loss = 417.87983365\n",
      "Iteration 5250, loss = 417.85703507\n",
      "Iteration 5251, loss = 417.84003289\n",
      "Iteration 5252, loss = 417.82181695\n",
      "Iteration 5253, loss = 417.80074243\n",
      "Iteration 5254, loss = 417.78706144\n",
      "Iteration 5255, loss = 417.75908044\n",
      "Iteration 5256, loss = 417.73537056\n",
      "Iteration 5257, loss = 417.71096895\n",
      "Iteration 5258, loss = 417.68664675\n",
      "Iteration 5259, loss = 417.67502388\n",
      "Iteration 5260, loss = 417.66420997\n",
      "Iteration 5261, loss = 417.63153216\n",
      "Iteration 5262, loss = 417.59689864\n",
      "Iteration 5263, loss = 417.58426609\n",
      "Iteration 5264, loss = 417.56669129\n",
      "Iteration 5265, loss = 417.54606706\n",
      "Iteration 5266, loss = 417.52739354\n",
      "Iteration 5267, loss = 417.50262576\n",
      "Iteration 5268, loss = 417.47908952\n",
      "Iteration 5269, loss = 417.46536374\n",
      "Iteration 5270, loss = 417.44442939\n",
      "Iteration 5271, loss = 417.41813730\n",
      "Iteration 5272, loss = 417.40834284\n",
      "Iteration 5273, loss = 417.39150249\n",
      "Iteration 5274, loss = 417.36067100\n",
      "Iteration 5275, loss = 417.34797636\n",
      "Iteration 5276, loss = 417.33216278\n",
      "Iteration 5277, loss = 417.30972230\n",
      "Iteration 5278, loss = 417.28129426\n",
      "Iteration 5279, loss = 417.25212852\n",
      "Iteration 5280, loss = 417.24175677\n",
      "Iteration 5281, loss = 417.21966344\n",
      "Iteration 5282, loss = 417.19192775\n",
      "Iteration 5283, loss = 417.16564733\n",
      "Iteration 5284, loss = 417.15096582\n",
      "Iteration 5285, loss = 417.13233844\n",
      "Iteration 5286, loss = 417.10802332\n",
      "Iteration 5287, loss = 417.09146742\n",
      "Iteration 5288, loss = 417.07292818\n",
      "Iteration 5289, loss = 417.04629745\n",
      "Iteration 5290, loss = 417.03239368\n",
      "Iteration 5291, loss = 417.01283666\n",
      "Iteration 5292, loss = 416.98547071\n",
      "Iteration 5293, loss = 416.96720410\n",
      "Iteration 5294, loss = 416.94850145\n",
      "Iteration 5295, loss = 416.92654705\n",
      "Iteration 5296, loss = 416.90532459\n",
      "Iteration 5297, loss = 416.88080012\n",
      "Iteration 5298, loss = 416.86579185\n",
      "Iteration 5299, loss = 416.84273423\n",
      "Iteration 5300, loss = 416.81877879\n",
      "Iteration 5301, loss = 416.80746182\n",
      "Iteration 5302, loss = 416.79533063\n",
      "Iteration 5303, loss = 416.77075632\n",
      "Iteration 5304, loss = 416.73956228\n",
      "Iteration 5305, loss = 416.71940296\n",
      "Iteration 5306, loss = 416.69654262\n",
      "Iteration 5307, loss = 416.67864844\n",
      "Iteration 5308, loss = 416.66109287\n",
      "Iteration 5309, loss = 416.63292379\n",
      "Iteration 5310, loss = 416.61926050\n",
      "Iteration 5311, loss = 416.60095631\n",
      "Iteration 5312, loss = 416.57534804\n",
      "Iteration 5313, loss = 416.55339348\n",
      "Iteration 5314, loss = 416.53493183\n",
      "Iteration 5315, loss = 416.51558468\n",
      "Iteration 5316, loss = 416.49475899\n",
      "Iteration 5317, loss = 416.48109100\n",
      "Iteration 5318, loss = 416.46117747\n",
      "Iteration 5319, loss = 416.43742033\n",
      "Iteration 5320, loss = 416.41157752\n",
      "Iteration 5321, loss = 416.39008437\n",
      "Iteration 5322, loss = 416.37127953\n",
      "Iteration 5323, loss = 416.35645195\n",
      "Iteration 5324, loss = 416.33329826\n",
      "Iteration 5325, loss = 416.31248117\n",
      "Iteration 5326, loss = 416.28940557\n",
      "Iteration 5327, loss = 416.27959336\n",
      "Iteration 5328, loss = 416.26297765\n",
      "Iteration 5329, loss = 416.23856102\n",
      "Iteration 5330, loss = 416.21392169\n",
      "Iteration 5331, loss = 416.18430347\n",
      "Iteration 5332, loss = 416.16919789\n",
      "Iteration 5333, loss = 416.15311574\n",
      "Iteration 5334, loss = 416.13598241\n",
      "Iteration 5335, loss = 416.11120136\n",
      "Iteration 5336, loss = 416.08263710\n",
      "Iteration 5337, loss = 416.06565576\n",
      "Iteration 5338, loss = 416.05222635\n",
      "Iteration 5339, loss = 416.02879220\n",
      "Iteration 5340, loss = 416.00938529\n",
      "Iteration 5341, loss = 415.98984023\n",
      "Iteration 5342, loss = 415.97219412\n",
      "Iteration 5343, loss = 415.94886627\n",
      "Iteration 5344, loss = 415.92365494\n",
      "Iteration 5345, loss = 415.90292713\n",
      "Iteration 5346, loss = 415.88566636\n",
      "Iteration 5347, loss = 415.86622391\n",
      "Iteration 5348, loss = 415.84336035\n",
      "Iteration 5349, loss = 415.82915905\n",
      "Iteration 5350, loss = 415.80888119\n",
      "Iteration 5351, loss = 415.79243521\n",
      "Iteration 5352, loss = 415.77551917\n",
      "Iteration 5353, loss = 415.75694191\n",
      "Iteration 5354, loss = 415.73801968\n",
      "Iteration 5355, loss = 415.72146029\n",
      "Iteration 5356, loss = 415.70205164\n",
      "Iteration 5357, loss = 415.68312478\n",
      "Iteration 5358, loss = 415.66672355\n",
      "Iteration 5359, loss = 415.65619235\n",
      "Iteration 5360, loss = 415.63335633\n",
      "Iteration 5361, loss = 415.61825648\n",
      "Iteration 5362, loss = 415.60466476\n",
      "Iteration 5363, loss = 415.59102095\n",
      "Iteration 5364, loss = 415.57778722\n",
      "Iteration 5365, loss = 415.56201402\n",
      "Iteration 5366, loss = 415.55026642\n",
      "Iteration 5367, loss = 415.53290530\n",
      "Iteration 5368, loss = 415.52300140\n",
      "Iteration 5369, loss = 415.50017961\n",
      "Iteration 5370, loss = 415.48898202\n",
      "Iteration 5371, loss = 415.47158458\n",
      "Iteration 5372, loss = 415.45247178\n",
      "Iteration 5373, loss = 415.43233636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5374, loss = 415.41357696\n",
      "Iteration 5375, loss = 415.40120987\n",
      "Iteration 5376, loss = 415.37827621\n",
      "Iteration 5377, loss = 415.36585735\n",
      "Iteration 5378, loss = 415.35557805\n",
      "Iteration 5379, loss = 415.33783529\n",
      "Iteration 5380, loss = 415.30931290\n",
      "Iteration 5381, loss = 415.29873997\n",
      "Iteration 5382, loss = 415.28290063\n",
      "Iteration 5383, loss = 415.26322314\n",
      "Iteration 5384, loss = 415.25219373\n",
      "Iteration 5385, loss = 415.23986122\n",
      "Iteration 5386, loss = 415.22407643\n",
      "Iteration 5387, loss = 415.20610094\n",
      "Iteration 5388, loss = 415.18853920\n",
      "Iteration 5389, loss = 415.17190592\n",
      "Iteration 5390, loss = 415.15034462\n",
      "Iteration 5391, loss = 415.12790421\n",
      "Iteration 5392, loss = 415.11691195\n",
      "Iteration 5393, loss = 415.10537495\n",
      "Iteration 5394, loss = 415.08899825\n",
      "Iteration 5395, loss = 415.07043348\n",
      "Iteration 5396, loss = 415.04901248\n",
      "Iteration 5397, loss = 415.03932300\n",
      "Iteration 5398, loss = 415.02864485\n",
      "Iteration 5399, loss = 415.01694248\n",
      "Iteration 5400, loss = 415.00263087\n",
      "Iteration 5401, loss = 414.98533137\n",
      "Iteration 5402, loss = 414.97415653\n",
      "Iteration 5403, loss = 414.96182910\n",
      "Iteration 5404, loss = 414.94654967\n",
      "Iteration 5405, loss = 414.92601993\n",
      "Iteration 5406, loss = 414.90600376\n",
      "Iteration 5407, loss = 414.88783156\n",
      "Iteration 5408, loss = 414.87018272\n",
      "Iteration 5409, loss = 414.84749556\n",
      "Iteration 5410, loss = 414.83542765\n",
      "Iteration 5411, loss = 414.81992350\n",
      "Iteration 5412, loss = 414.80162971\n",
      "Iteration 5413, loss = 414.78960014\n",
      "Iteration 5414, loss = 414.77321750\n",
      "Iteration 5415, loss = 414.75508939\n",
      "Iteration 5416, loss = 414.74230425\n",
      "Iteration 5417, loss = 414.71985613\n",
      "Iteration 5418, loss = 414.70462323\n",
      "Iteration 5419, loss = 414.69340461\n",
      "Iteration 5420, loss = 414.68194971\n",
      "Iteration 5421, loss = 414.66912088\n",
      "Iteration 5422, loss = 414.64848479\n",
      "Iteration 5423, loss = 414.63395712\n",
      "Iteration 5424, loss = 414.62208996\n",
      "Iteration 5425, loss = 414.60677287\n",
      "Iteration 5426, loss = 414.58575411\n",
      "Iteration 5427, loss = 414.56997144\n",
      "Iteration 5428, loss = 414.55408669\n",
      "Iteration 5429, loss = 414.54101180\n",
      "Iteration 5430, loss = 414.51986485\n",
      "Iteration 5431, loss = 414.50432314\n",
      "Iteration 5432, loss = 414.49290562\n",
      "Iteration 5433, loss = 414.47808777\n",
      "Iteration 5434, loss = 414.46161714\n",
      "Iteration 5435, loss = 414.45190242\n",
      "Iteration 5436, loss = 414.43517958\n",
      "Iteration 5437, loss = 414.41710048\n",
      "Iteration 5438, loss = 414.40267778\n",
      "Iteration 5439, loss = 414.38977147\n",
      "Iteration 5440, loss = 414.36952060\n",
      "Iteration 5441, loss = 414.35267636\n",
      "Iteration 5442, loss = 414.34591876\n",
      "Iteration 5443, loss = 414.32490949\n",
      "Iteration 5444, loss = 414.30995859\n",
      "Iteration 5445, loss = 414.29839115\n",
      "Iteration 5446, loss = 414.28533278\n",
      "Iteration 5447, loss = 414.26483608\n",
      "Iteration 5448, loss = 414.25154881\n",
      "Iteration 5449, loss = 414.23691550\n",
      "Iteration 5450, loss = 414.22848292\n",
      "Iteration 5451, loss = 414.20594632\n",
      "Iteration 5452, loss = 414.18943498\n",
      "Iteration 5453, loss = 414.17214227\n",
      "Iteration 5454, loss = 414.16171614\n",
      "Iteration 5455, loss = 414.14837874\n",
      "Iteration 5456, loss = 414.12408047\n",
      "Iteration 5457, loss = 414.11143295\n",
      "Iteration 5458, loss = 414.10314508\n",
      "Iteration 5459, loss = 414.09073224\n",
      "Iteration 5460, loss = 414.07693438\n",
      "Iteration 5461, loss = 414.05779790\n",
      "Iteration 5462, loss = 414.04394932\n",
      "Iteration 5463, loss = 414.02513193\n",
      "Iteration 5464, loss = 414.00217151\n",
      "Iteration 5465, loss = 413.98132015\n",
      "Iteration 5466, loss = 413.97531404\n",
      "Iteration 5467, loss = 413.97019383\n",
      "Iteration 5468, loss = 413.94946511\n",
      "Iteration 5469, loss = 413.92468469\n",
      "Iteration 5470, loss = 413.91778466\n",
      "Iteration 5471, loss = 413.90603184\n",
      "Iteration 5472, loss = 413.88685918\n",
      "Iteration 5473, loss = 413.87089773\n",
      "Iteration 5474, loss = 413.85454411\n",
      "Iteration 5475, loss = 413.83536398\n",
      "Iteration 5476, loss = 413.82448430\n",
      "Iteration 5477, loss = 413.80901284\n",
      "Iteration 5478, loss = 413.79407944\n",
      "Iteration 5479, loss = 413.78471871\n",
      "Iteration 5480, loss = 413.77221297\n",
      "Iteration 5481, loss = 413.75604938\n",
      "Iteration 5482, loss = 413.74175504\n",
      "Iteration 5483, loss = 413.72826294\n",
      "Iteration 5484, loss = 413.71662506\n",
      "Iteration 5485, loss = 413.69339155\n",
      "Iteration 5486, loss = 413.67180664\n",
      "Iteration 5487, loss = 413.65563776\n",
      "Iteration 5488, loss = 413.64793025\n",
      "Iteration 5489, loss = 413.62913119\n",
      "Iteration 5490, loss = 413.61656757\n",
      "Iteration 5491, loss = 413.60356592\n",
      "Iteration 5492, loss = 413.59302735\n",
      "Iteration 5493, loss = 413.57611077\n",
      "Iteration 5494, loss = 413.56699609\n",
      "Iteration 5495, loss = 413.54891342\n",
      "Iteration 5496, loss = 413.53307291\n",
      "Iteration 5497, loss = 413.51417802\n",
      "Iteration 5498, loss = 413.49748335\n",
      "Iteration 5499, loss = 413.48095785\n",
      "Iteration 5500, loss = 413.45990897\n",
      "Iteration 5501, loss = 413.45406442\n",
      "Iteration 5502, loss = 413.44259716\n",
      "Iteration 5503, loss = 413.43222131\n",
      "Iteration 5504, loss = 413.42339859\n",
      "Iteration 5505, loss = 413.40621090\n",
      "Iteration 5506, loss = 413.38329094\n",
      "Iteration 5507, loss = 413.35845853\n",
      "Iteration 5508, loss = 413.34464606\n",
      "Iteration 5509, loss = 413.33292274\n",
      "Iteration 5510, loss = 413.32294829\n",
      "Iteration 5511, loss = 413.31446626\n",
      "Iteration 5512, loss = 413.30857635\n",
      "Iteration 5513, loss = 413.28625639\n",
      "Iteration 5514, loss = 413.26228113\n",
      "Iteration 5515, loss = 413.23765032\n",
      "Iteration 5516, loss = 413.22796048\n",
      "Iteration 5517, loss = 413.22320077\n",
      "Iteration 5518, loss = 413.22238865\n",
      "Iteration 5519, loss = 413.20367344\n",
      "Iteration 5520, loss = 413.18194811\n",
      "Iteration 5521, loss = 413.16411566\n",
      "Iteration 5522, loss = 413.14508143\n",
      "Iteration 5523, loss = 413.12708028\n",
      "Iteration 5524, loss = 413.11412839\n",
      "Iteration 5525, loss = 413.10932258\n",
      "Iteration 5526, loss = 413.10421142\n",
      "Iteration 5527, loss = 413.08324224\n",
      "Iteration 5528, loss = 413.05416883\n",
      "Iteration 5529, loss = 413.03824576\n",
      "Iteration 5530, loss = 413.02964054\n",
      "Iteration 5531, loss = 413.01581544\n",
      "Iteration 5532, loss = 413.00388276\n",
      "Iteration 5533, loss = 412.98752762\n",
      "Iteration 5534, loss = 412.96602650\n",
      "Iteration 5535, loss = 412.94829905\n",
      "Iteration 5536, loss = 412.94147182\n",
      "Iteration 5537, loss = 412.92049057\n",
      "Iteration 5538, loss = 412.91879170\n",
      "Iteration 5539, loss = 412.90715900\n",
      "Iteration 5540, loss = 412.87746533\n",
      "Iteration 5541, loss = 412.86462568\n",
      "Iteration 5542, loss = 412.85337590\n",
      "Iteration 5543, loss = 412.84294076\n",
      "Iteration 5544, loss = 412.83205748\n",
      "Iteration 5545, loss = 412.81312688\n",
      "Iteration 5546, loss = 412.79254947\n",
      "Iteration 5547, loss = 412.77284079\n",
      "Iteration 5548, loss = 412.76450208\n",
      "Iteration 5549, loss = 412.75285275\n",
      "Iteration 5550, loss = 412.74006670\n",
      "Iteration 5551, loss = 412.72236186\n",
      "Iteration 5552, loss = 412.70741399\n",
      "Iteration 5553, loss = 412.69360139\n",
      "Iteration 5554, loss = 412.68130276\n",
      "Iteration 5555, loss = 412.67385082\n",
      "Iteration 5556, loss = 412.65222795\n",
      "Iteration 5557, loss = 412.63963498\n",
      "Iteration 5558, loss = 412.62450994\n",
      "Iteration 5559, loss = 412.60751365\n",
      "Iteration 5560, loss = 412.59259357\n",
      "Iteration 5561, loss = 412.57686913\n",
      "Iteration 5562, loss = 412.55771491\n",
      "Iteration 5563, loss = 412.53713929\n",
      "Iteration 5564, loss = 412.53495377\n",
      "Iteration 5565, loss = 412.51713922\n",
      "Iteration 5566, loss = 412.49504454\n",
      "Iteration 5567, loss = 412.48150062\n",
      "Iteration 5568, loss = 412.47354346\n",
      "Iteration 5569, loss = 412.46108129\n",
      "Iteration 5570, loss = 412.44731449\n",
      "Iteration 5571, loss = 412.43255126\n",
      "Iteration 5572, loss = 412.41925990\n",
      "Iteration 5573, loss = 412.39643759\n",
      "Iteration 5574, loss = 412.37700603\n",
      "Iteration 5575, loss = 412.36214931\n",
      "Iteration 5576, loss = 412.35352156\n",
      "Iteration 5577, loss = 412.34206441\n",
      "Iteration 5578, loss = 412.32402530\n",
      "Iteration 5579, loss = 412.30942116\n",
      "Iteration 5580, loss = 412.29155035\n",
      "Iteration 5581, loss = 412.28303455\n",
      "Iteration 5582, loss = 412.26318565\n",
      "Iteration 5583, loss = 412.24671783\n",
      "Iteration 5584, loss = 412.24346135\n",
      "Iteration 5585, loss = 412.22366935\n",
      "Iteration 5586, loss = 412.21123561\n",
      "Iteration 5587, loss = 412.19682941\n",
      "Iteration 5588, loss = 412.17753840\n",
      "Iteration 5589, loss = 412.16190146\n",
      "Iteration 5590, loss = 412.14621854\n",
      "Iteration 5591, loss = 412.14121839\n",
      "Iteration 5592, loss = 412.13560395\n",
      "Iteration 5593, loss = 412.12068108\n",
      "Iteration 5594, loss = 412.10212613\n",
      "Iteration 5595, loss = 412.08194687\n",
      "Iteration 5596, loss = 412.06716860\n",
      "Iteration 5597, loss = 412.05439748\n",
      "Iteration 5598, loss = 412.04817393\n",
      "Iteration 5599, loss = 412.03929288\n",
      "Iteration 5600, loss = 412.02384588\n",
      "Iteration 5601, loss = 412.00897318\n",
      "Iteration 5602, loss = 412.00043869\n",
      "Iteration 5603, loss = 411.98015301\n",
      "Iteration 5604, loss = 411.97092947\n",
      "Iteration 5605, loss = 411.95861340\n",
      "Iteration 5606, loss = 411.93149720\n",
      "Iteration 5607, loss = 411.90975249\n",
      "Iteration 5608, loss = 411.89587857\n",
      "Iteration 5609, loss = 411.87758739\n",
      "Iteration 5610, loss = 411.86080125\n",
      "Iteration 5611, loss = 411.85314334\n",
      "Iteration 5612, loss = 411.83916397\n",
      "Iteration 5613, loss = 411.82383165\n",
      "Iteration 5614, loss = 411.81496760\n",
      "Iteration 5615, loss = 411.79361108\n",
      "Iteration 5616, loss = 411.78216952\n",
      "Iteration 5617, loss = 411.77393103\n",
      "Iteration 5618, loss = 411.75624168\n",
      "Iteration 5619, loss = 411.74419583\n",
      "Iteration 5620, loss = 411.73092789\n",
      "Iteration 5621, loss = 411.71151580\n",
      "Iteration 5622, loss = 411.69447682\n",
      "Iteration 5623, loss = 411.67962567\n",
      "Iteration 5624, loss = 411.66831180\n",
      "Iteration 5625, loss = 411.65470901\n",
      "Iteration 5626, loss = 411.64350476\n",
      "Iteration 5627, loss = 411.62836014\n",
      "Iteration 5628, loss = 411.61013673\n",
      "Iteration 5629, loss = 411.59876487\n",
      "Iteration 5630, loss = 411.58549448\n",
      "Iteration 5631, loss = 411.57017882\n",
      "Iteration 5632, loss = 411.55503735\n",
      "Iteration 5633, loss = 411.54941404\n",
      "Iteration 5634, loss = 411.53444641\n",
      "Iteration 5635, loss = 411.51329209\n",
      "Iteration 5636, loss = 411.49905134\n",
      "Iteration 5637, loss = 411.49453307\n",
      "Iteration 5638, loss = 411.48433015\n",
      "Iteration 5639, loss = 411.47219759\n",
      "Iteration 5640, loss = 411.45365310\n",
      "Iteration 5641, loss = 411.43455289\n",
      "Iteration 5642, loss = 411.42559521\n",
      "Iteration 5643, loss = 411.41003833\n",
      "Iteration 5644, loss = 411.39157223\n",
      "Iteration 5645, loss = 411.37304250\n",
      "Iteration 5646, loss = 411.35935717\n",
      "Iteration 5647, loss = 411.36011573\n",
      "Iteration 5648, loss = 411.33520157\n",
      "Iteration 5649, loss = 411.31525305\n",
      "Iteration 5650, loss = 411.30944096\n",
      "Iteration 5651, loss = 411.29701881\n",
      "Iteration 5652, loss = 411.28627714\n",
      "Iteration 5653, loss = 411.27368526\n",
      "Iteration 5654, loss = 411.25590729\n",
      "Iteration 5655, loss = 411.23478975\n",
      "Iteration 5656, loss = 411.22447996\n",
      "Iteration 5657, loss = 411.20950772\n",
      "Iteration 5658, loss = 411.19178343\n",
      "Iteration 5659, loss = 411.18340766\n",
      "Iteration 5660, loss = 411.17108015\n",
      "Iteration 5661, loss = 411.16433374\n",
      "Iteration 5662, loss = 411.15252655\n",
      "Iteration 5663, loss = 411.13888409\n",
      "Iteration 5664, loss = 411.12475212\n",
      "Iteration 5665, loss = 411.10652815\n",
      "Iteration 5666, loss = 411.08438256\n",
      "Iteration 5667, loss = 411.07032710\n",
      "Iteration 5668, loss = 411.05939332\n",
      "Iteration 5669, loss = 411.04179666\n",
      "Iteration 5670, loss = 411.02568576\n",
      "Iteration 5671, loss = 411.01141116\n",
      "Iteration 5672, loss = 410.99709193\n",
      "Iteration 5673, loss = 410.98624760\n",
      "Iteration 5674, loss = 410.96801865\n",
      "Iteration 5675, loss = 410.94849559\n",
      "Iteration 5676, loss = 410.94308184\n",
      "Iteration 5677, loss = 410.92981521\n",
      "Iteration 5678, loss = 410.91680753\n",
      "Iteration 5679, loss = 410.90161603\n",
      "Iteration 5680, loss = 410.88650044\n",
      "Iteration 5681, loss = 410.87018621\n",
      "Iteration 5682, loss = 410.86514105\n",
      "Iteration 5683, loss = 410.84776026\n",
      "Iteration 5684, loss = 410.83924240\n",
      "Iteration 5685, loss = 410.81716119\n",
      "Iteration 5686, loss = 410.81073708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5687, loss = 410.79938111\n",
      "Iteration 5688, loss = 410.78521175\n",
      "Iteration 5689, loss = 410.77227646\n",
      "Iteration 5690, loss = 410.75591898\n",
      "Iteration 5691, loss = 410.73622107\n",
      "Iteration 5692, loss = 410.72512587\n",
      "Iteration 5693, loss = 410.71287015\n",
      "Iteration 5694, loss = 410.69940513\n",
      "Iteration 5695, loss = 410.68245553\n",
      "Iteration 5696, loss = 410.66990709\n",
      "Iteration 5697, loss = 410.65969819\n",
      "Iteration 5698, loss = 410.64944112\n",
      "Iteration 5699, loss = 410.63508174\n",
      "Iteration 5700, loss = 410.62454702\n",
      "Iteration 5701, loss = 410.60994286\n",
      "Iteration 5702, loss = 410.59106099\n",
      "Iteration 5703, loss = 410.57466037\n",
      "Iteration 5704, loss = 410.55734658\n",
      "Iteration 5705, loss = 410.54449807\n",
      "Iteration 5706, loss = 410.52702143\n",
      "Iteration 5707, loss = 410.52097040\n",
      "Iteration 5708, loss = 410.50505226\n",
      "Iteration 5709, loss = 410.48681438\n",
      "Iteration 5710, loss = 410.47568001\n",
      "Iteration 5711, loss = 410.46360955\n",
      "Iteration 5712, loss = 410.44950144\n",
      "Iteration 5713, loss = 410.43752700\n",
      "Iteration 5714, loss = 410.42592254\n",
      "Iteration 5715, loss = 410.41475440\n",
      "Iteration 5716, loss = 410.39597657\n",
      "Iteration 5717, loss = 410.38524857\n",
      "Iteration 5718, loss = 410.37221661\n",
      "Iteration 5719, loss = 410.35082910\n",
      "Iteration 5720, loss = 410.33774478\n",
      "Iteration 5721, loss = 410.32956893\n",
      "Iteration 5722, loss = 410.31954665\n",
      "Iteration 5723, loss = 410.30709612\n",
      "Iteration 5724, loss = 410.29499673\n",
      "Iteration 5725, loss = 410.28318164\n",
      "Iteration 5726, loss = 410.26871122\n",
      "Iteration 5727, loss = 410.24884364\n",
      "Iteration 5728, loss = 410.23981779\n",
      "Iteration 5729, loss = 410.22552428\n",
      "Iteration 5730, loss = 410.21722890\n",
      "Iteration 5731, loss = 410.20442963\n",
      "Iteration 5732, loss = 410.18914309\n",
      "Iteration 5733, loss = 410.17815509\n",
      "Iteration 5734, loss = 410.16204823\n",
      "Iteration 5735, loss = 410.15524218\n",
      "Iteration 5736, loss = 410.13750253\n",
      "Iteration 5737, loss = 410.11997013\n",
      "Iteration 5738, loss = 410.10840861\n",
      "Iteration 5739, loss = 410.08778785\n",
      "Iteration 5740, loss = 410.06574812\n",
      "Iteration 5741, loss = 410.05232004\n",
      "Iteration 5742, loss = 410.04481203\n",
      "Iteration 5743, loss = 410.02830547\n",
      "Iteration 5744, loss = 410.00690253\n",
      "Iteration 5745, loss = 409.99987864\n",
      "Iteration 5746, loss = 409.98800235\n",
      "Iteration 5747, loss = 409.97954591\n",
      "Iteration 5748, loss = 409.95926441\n",
      "Iteration 5749, loss = 409.94819134\n",
      "Iteration 5750, loss = 409.94399875\n",
      "Iteration 5751, loss = 409.92821560\n",
      "Iteration 5752, loss = 409.90442739\n",
      "Iteration 5753, loss = 409.89620868\n",
      "Iteration 5754, loss = 409.87814309\n",
      "Iteration 5755, loss = 409.86012511\n",
      "Iteration 5756, loss = 409.85829297\n",
      "Iteration 5757, loss = 409.84485336\n",
      "Iteration 5758, loss = 409.82452334\n",
      "Iteration 5759, loss = 409.81393369\n",
      "Iteration 5760, loss = 409.80162052\n",
      "Iteration 5761, loss = 409.78965788\n",
      "Iteration 5762, loss = 409.77288372\n",
      "Iteration 5763, loss = 409.75503563\n",
      "Iteration 5764, loss = 409.74061239\n",
      "Iteration 5765, loss = 409.72660170\n",
      "Iteration 5766, loss = 409.70989965\n",
      "Iteration 5767, loss = 409.69607272\n",
      "Iteration 5768, loss = 409.68560922\n",
      "Iteration 5769, loss = 409.66975893\n",
      "Iteration 5770, loss = 409.65992531\n",
      "Iteration 5771, loss = 409.64396987\n",
      "Iteration 5772, loss = 409.62820248\n",
      "Iteration 5773, loss = 409.61408647\n",
      "Iteration 5774, loss = 409.60386857\n",
      "Iteration 5775, loss = 409.58793443\n",
      "Iteration 5776, loss = 409.57731855\n",
      "Iteration 5777, loss = 409.56517449\n",
      "Iteration 5778, loss = 409.55171240\n",
      "Iteration 5779, loss = 409.54027717\n",
      "Iteration 5780, loss = 409.52874541\n",
      "Iteration 5781, loss = 409.52604207\n",
      "Iteration 5782, loss = 409.51191368\n",
      "Iteration 5783, loss = 409.49129507\n",
      "Iteration 5784, loss = 409.47442411\n",
      "Iteration 5785, loss = 409.45569452\n",
      "Iteration 5786, loss = 409.44455056\n",
      "Iteration 5787, loss = 409.43444562\n",
      "Iteration 5788, loss = 409.43166535\n",
      "Iteration 5789, loss = 409.41428646\n",
      "Iteration 5790, loss = 409.39335097\n",
      "Iteration 5791, loss = 409.37782580\n",
      "Iteration 5792, loss = 409.36428648\n",
      "Iteration 5793, loss = 409.34662963\n",
      "Iteration 5794, loss = 409.33206516\n",
      "Iteration 5795, loss = 409.31527642\n",
      "Iteration 5796, loss = 409.30497092\n",
      "Iteration 5797, loss = 409.28777316\n",
      "Iteration 5798, loss = 409.27676390\n",
      "Iteration 5799, loss = 409.27782102\n",
      "Iteration 5800, loss = 409.25737668\n",
      "Iteration 5801, loss = 409.23293109\n",
      "Iteration 5802, loss = 409.22957736\n",
      "Iteration 5803, loss = 409.21821746\n",
      "Iteration 5804, loss = 409.20531500\n",
      "Iteration 5805, loss = 409.18620492\n",
      "Iteration 5806, loss = 409.17229613\n",
      "Iteration 5807, loss = 409.15581585\n",
      "Iteration 5808, loss = 409.13675142\n",
      "Iteration 5809, loss = 409.11907040\n",
      "Iteration 5810, loss = 409.11983728\n",
      "Iteration 5811, loss = 409.10876753\n",
      "Iteration 5812, loss = 409.08855898\n",
      "Iteration 5813, loss = 409.07666948\n",
      "Iteration 5814, loss = 409.06907989\n",
      "Iteration 5815, loss = 409.05701651\n",
      "Iteration 5816, loss = 409.04195965\n",
      "Iteration 5817, loss = 409.02396478\n",
      "Iteration 5818, loss = 409.00724084\n",
      "Iteration 5819, loss = 408.98887420\n",
      "Iteration 5820, loss = 408.97811609\n",
      "Iteration 5821, loss = 408.97392440\n",
      "Iteration 5822, loss = 408.95645859\n",
      "Iteration 5823, loss = 408.93984365\n",
      "Iteration 5824, loss = 408.92368007\n",
      "Iteration 5825, loss = 408.90816424\n",
      "Iteration 5826, loss = 408.91393161\n",
      "Iteration 5827, loss = 408.89404836\n",
      "Iteration 5828, loss = 408.86867354\n",
      "Iteration 5829, loss = 408.86169986\n",
      "Iteration 5830, loss = 408.84789328\n",
      "Iteration 5831, loss = 408.82954404\n",
      "Iteration 5832, loss = 408.81244782\n",
      "Iteration 5833, loss = 408.81447250\n",
      "Iteration 5834, loss = 408.79738711\n",
      "Iteration 5835, loss = 408.76913052\n",
      "Iteration 5836, loss = 408.76037326\n",
      "Iteration 5837, loss = 408.75131364\n",
      "Iteration 5838, loss = 408.73292137\n",
      "Iteration 5839, loss = 408.71381374\n",
      "Iteration 5840, loss = 408.71020496\n",
      "Iteration 5841, loss = 408.69512263\n",
      "Iteration 5842, loss = 408.67824776\n",
      "Iteration 5843, loss = 408.67607261\n",
      "Iteration 5844, loss = 408.66636641\n",
      "Iteration 5845, loss = 408.65180795\n",
      "Iteration 5846, loss = 408.64578546\n",
      "Iteration 5847, loss = 408.64399762\n",
      "Iteration 5848, loss = 408.64823885\n",
      "Iteration 5849, loss = 408.63511163\n",
      "Iteration 5850, loss = 408.60251627\n",
      "Iteration 5851, loss = 408.58690652\n",
      "Iteration 5852, loss = 408.56599935\n",
      "Iteration 5853, loss = 408.54779829\n",
      "Iteration 5854, loss = 408.53729991\n",
      "Iteration 5855, loss = 408.52895107\n",
      "Iteration 5856, loss = 408.51534410\n",
      "Iteration 5857, loss = 408.49230287\n",
      "Iteration 5858, loss = 408.47435305\n",
      "Iteration 5859, loss = 408.45625920\n",
      "Iteration 5860, loss = 408.44063715\n",
      "Iteration 5861, loss = 408.43170653\n",
      "Iteration 5862, loss = 408.41980218\n",
      "Iteration 5863, loss = 408.40883145\n",
      "Iteration 5864, loss = 408.39703115\n",
      "Iteration 5865, loss = 408.38338939\n",
      "Iteration 5866, loss = 408.37290442\n",
      "Iteration 5867, loss = 408.36033120\n",
      "Iteration 5868, loss = 408.33587343\n",
      "Iteration 5869, loss = 408.33282594\n",
      "Iteration 5870, loss = 408.31329806\n",
      "Iteration 5871, loss = 408.31153547\n",
      "Iteration 5872, loss = 408.30163795\n",
      "Iteration 5873, loss = 408.28660071\n",
      "Iteration 5874, loss = 408.26873174\n",
      "Iteration 5875, loss = 408.25214754\n",
      "Iteration 5876, loss = 408.23406060\n",
      "Iteration 5877, loss = 408.21652737\n",
      "Iteration 5878, loss = 408.20598062\n",
      "Iteration 5879, loss = 408.19700900\n",
      "Iteration 5880, loss = 408.18841577\n",
      "Iteration 5881, loss = 408.17012435\n",
      "Iteration 5882, loss = 408.15644137\n",
      "Iteration 5883, loss = 408.14238601\n",
      "Iteration 5884, loss = 408.12653802\n",
      "Iteration 5885, loss = 408.11017622\n",
      "Iteration 5886, loss = 408.09879741\n",
      "Iteration 5887, loss = 408.08861700\n",
      "Iteration 5888, loss = 408.07702722\n",
      "Iteration 5889, loss = 408.05961222\n",
      "Iteration 5890, loss = 408.05462490\n",
      "Iteration 5891, loss = 408.04209052\n",
      "Iteration 5892, loss = 408.03053424\n",
      "Iteration 5893, loss = 408.01619454\n",
      "Iteration 5894, loss = 408.00091474\n",
      "Iteration 5895, loss = 407.98688618\n",
      "Iteration 5896, loss = 407.97801746\n",
      "Iteration 5897, loss = 407.96356633\n",
      "Iteration 5898, loss = 407.94964417\n",
      "Iteration 5899, loss = 407.93764341\n",
      "Iteration 5900, loss = 407.93241377\n",
      "Iteration 5901, loss = 407.91941367\n",
      "Iteration 5902, loss = 407.90068642\n",
      "Iteration 5903, loss = 407.89135238\n",
      "Iteration 5904, loss = 407.87652878\n",
      "Iteration 5905, loss = 407.86192696\n",
      "Iteration 5906, loss = 407.85590481\n",
      "Iteration 5907, loss = 407.84169785\n",
      "Iteration 5908, loss = 407.83783473\n",
      "Iteration 5909, loss = 407.82804415\n",
      "Iteration 5910, loss = 407.81244624\n",
      "Iteration 5911, loss = 407.79498938\n",
      "Iteration 5912, loss = 407.77759166\n",
      "Iteration 5913, loss = 407.76162413\n",
      "Iteration 5914, loss = 407.75480602\n",
      "Iteration 5915, loss = 407.74690227\n",
      "Iteration 5916, loss = 407.73969107\n",
      "Iteration 5917, loss = 407.72237984\n",
      "Iteration 5918, loss = 407.70929197\n",
      "Iteration 5919, loss = 407.70205643\n",
      "Iteration 5920, loss = 407.69317137\n",
      "Iteration 5921, loss = 407.68291752\n",
      "Iteration 5922, loss = 407.67105172\n",
      "Iteration 5923, loss = 407.65521964\n",
      "Iteration 5924, loss = 407.64200501\n",
      "Iteration 5925, loss = 407.63016403\n",
      "Iteration 5926, loss = 407.61197291\n",
      "Iteration 5927, loss = 407.59910550\n",
      "Iteration 5928, loss = 407.57636295\n",
      "Iteration 5929, loss = 407.56007293\n",
      "Iteration 5930, loss = 407.54879848\n",
      "Iteration 5931, loss = 407.53117414\n",
      "Iteration 5932, loss = 407.52375864\n",
      "Iteration 5933, loss = 407.51215316\n",
      "Iteration 5934, loss = 407.50619903\n",
      "Iteration 5935, loss = 407.49805369\n",
      "Iteration 5936, loss = 407.48936339\n",
      "Iteration 5937, loss = 407.47651044\n",
      "Iteration 5938, loss = 407.46426499\n",
      "Iteration 5939, loss = 407.44883793\n",
      "Iteration 5940, loss = 407.43113977\n",
      "Iteration 5941, loss = 407.41593458\n",
      "Iteration 5942, loss = 407.40141343\n",
      "Iteration 5943, loss = 407.38182612\n",
      "Iteration 5944, loss = 407.39074712\n",
      "Iteration 5945, loss = 407.37839853\n",
      "Iteration 5946, loss = 407.35549591\n",
      "Iteration 5947, loss = 407.34602799\n",
      "Iteration 5948, loss = 407.32951356\n",
      "Iteration 5949, loss = 407.31468119\n",
      "Iteration 5950, loss = 407.30563113\n",
      "Iteration 5951, loss = 407.29724905\n",
      "Iteration 5952, loss = 407.28408069\n",
      "Iteration 5953, loss = 407.26758827\n",
      "Iteration 5954, loss = 407.25229765\n",
      "Iteration 5955, loss = 407.23902484\n",
      "Iteration 5956, loss = 407.22801277\n",
      "Iteration 5957, loss = 407.21342211\n",
      "Iteration 5958, loss = 407.20667352\n",
      "Iteration 5959, loss = 407.19737796\n",
      "Iteration 5960, loss = 407.17861409\n",
      "Iteration 5961, loss = 407.16885449\n",
      "Iteration 5962, loss = 407.16259107\n",
      "Iteration 5963, loss = 407.14485950\n",
      "Iteration 5964, loss = 407.13704144\n",
      "Iteration 5965, loss = 407.13531305\n",
      "Iteration 5966, loss = 407.11912620\n",
      "Iteration 5967, loss = 407.10830360\n",
      "Iteration 5968, loss = 407.09999458\n",
      "Iteration 5969, loss = 407.08359217\n",
      "Iteration 5970, loss = 407.06489545\n",
      "Iteration 5971, loss = 407.05522711\n",
      "Iteration 5972, loss = 407.03720222\n",
      "Iteration 5973, loss = 407.03139364\n",
      "Iteration 5974, loss = 407.01613009\n",
      "Iteration 5975, loss = 407.00234594\n",
      "Iteration 5976, loss = 406.99815227\n",
      "Iteration 5977, loss = 406.98256979\n",
      "Iteration 5978, loss = 406.96855597\n",
      "Iteration 5979, loss = 406.95706499\n",
      "Iteration 5980, loss = 406.94907178\n",
      "Iteration 5981, loss = 406.93679997\n",
      "Iteration 5982, loss = 406.92478398\n",
      "Iteration 5983, loss = 406.91117326\n",
      "Iteration 5984, loss = 406.89543229\n",
      "Iteration 5985, loss = 406.88889012\n",
      "Iteration 5986, loss = 406.87577649\n",
      "Iteration 5987, loss = 406.84752867\n",
      "Iteration 5988, loss = 406.85650771\n",
      "Iteration 5989, loss = 406.83743793\n",
      "Iteration 5990, loss = 406.81530638\n",
      "Iteration 5991, loss = 406.80820821\n",
      "Iteration 5992, loss = 406.80489692\n",
      "Iteration 5993, loss = 406.79436953\n",
      "Iteration 5994, loss = 406.77769425\n",
      "Iteration 5995, loss = 406.77155786\n",
      "Iteration 5996, loss = 406.75800447\n",
      "Iteration 5997, loss = 406.73999163\n",
      "Iteration 5998, loss = 406.73376311\n",
      "Iteration 5999, loss = 406.71523997\n",
      "Iteration 6000, loss = 406.69736063\n",
      "Iteration 6001, loss = 406.68321824\n",
      "Iteration 6002, loss = 406.68289341\n",
      "Iteration 6003, loss = 406.67382823\n",
      "Iteration 6004, loss = 406.66190055\n",
      "Iteration 6005, loss = 406.65097418\n",
      "Iteration 6006, loss = 406.63674256\n",
      "Iteration 6007, loss = 406.62230514\n",
      "Iteration 6008, loss = 406.60703988\n",
      "Iteration 6009, loss = 406.60395941\n",
      "Iteration 6010, loss = 406.59182584\n",
      "Iteration 6011, loss = 406.57627984\n",
      "Iteration 6012, loss = 406.55945644\n",
      "Iteration 6013, loss = 406.55468270\n",
      "Iteration 6014, loss = 406.54099553\n",
      "Iteration 6015, loss = 406.53049067\n",
      "Iteration 6016, loss = 406.51938834\n",
      "Iteration 6017, loss = 406.50936071\n",
      "Iteration 6018, loss = 406.48994771\n",
      "Iteration 6019, loss = 406.48030814\n",
      "Iteration 6020, loss = 406.47539637\n",
      "Iteration 6021, loss = 406.46838261\n",
      "Iteration 6022, loss = 406.45214201\n",
      "Iteration 6023, loss = 406.44123031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6024, loss = 406.42909308\n",
      "Iteration 6025, loss = 406.41243615\n",
      "Iteration 6026, loss = 406.40197373\n",
      "Iteration 6027, loss = 406.39314504\n",
      "Iteration 6028, loss = 406.37938877\n",
      "Iteration 6029, loss = 406.36975635\n",
      "Iteration 6030, loss = 406.34897835\n",
      "Iteration 6031, loss = 406.33103277\n",
      "Iteration 6032, loss = 406.32194222\n",
      "Iteration 6033, loss = 406.30762744\n",
      "Iteration 6034, loss = 406.30300254\n",
      "Iteration 6035, loss = 406.29250927\n",
      "Iteration 6036, loss = 406.28323019\n",
      "Iteration 6037, loss = 406.27579393\n",
      "Iteration 6038, loss = 406.26016181\n",
      "Iteration 6039, loss = 406.24344900\n",
      "Iteration 6040, loss = 406.24436737\n",
      "Iteration 6041, loss = 406.23581573\n",
      "Iteration 6042, loss = 406.21675996\n",
      "Iteration 6043, loss = 406.20382712\n",
      "Iteration 6044, loss = 406.19552104\n",
      "Iteration 6045, loss = 406.17767736\n",
      "Iteration 6046, loss = 406.17633878\n",
      "Iteration 6047, loss = 406.15643727\n",
      "Iteration 6048, loss = 406.14708692\n",
      "Iteration 6049, loss = 406.13468449\n",
      "Iteration 6050, loss = 406.13124570\n",
      "Iteration 6051, loss = 406.11223441\n",
      "Iteration 6052, loss = 406.10062063\n",
      "Iteration 6053, loss = 406.08323373\n",
      "Iteration 6054, loss = 406.07926815\n",
      "Iteration 6055, loss = 406.06417022\n",
      "Iteration 6056, loss = 406.04143567\n",
      "Iteration 6057, loss = 406.03117129\n",
      "Iteration 6058, loss = 406.02880840\n",
      "Iteration 6059, loss = 406.01760660\n",
      "Iteration 6060, loss = 405.99980965\n",
      "Iteration 6061, loss = 405.99288759\n",
      "Iteration 6062, loss = 405.98735169\n",
      "Iteration 6063, loss = 405.96304897\n",
      "Iteration 6064, loss = 405.95918672\n",
      "Iteration 6065, loss = 405.95584930\n",
      "Iteration 6066, loss = 405.93943916\n",
      "Iteration 6067, loss = 405.93422101\n",
      "Iteration 6068, loss = 405.92252173\n",
      "Iteration 6069, loss = 405.90574283\n",
      "Iteration 6070, loss = 405.89173171\n",
      "Iteration 6071, loss = 405.88930919\n",
      "Iteration 6072, loss = 405.87557180\n",
      "Iteration 6073, loss = 405.85655343\n",
      "Iteration 6074, loss = 405.84623440\n",
      "Iteration 6075, loss = 405.83079914\n",
      "Iteration 6076, loss = 405.81733982\n",
      "Iteration 6077, loss = 405.81006892\n",
      "Iteration 6078, loss = 405.80500619\n",
      "Iteration 6079, loss = 405.79146272\n",
      "Iteration 6080, loss = 405.77802351\n",
      "Iteration 6081, loss = 405.76222683\n",
      "Iteration 6082, loss = 405.75913857\n",
      "Iteration 6083, loss = 405.73987307\n",
      "Iteration 6084, loss = 405.73703225\n",
      "Iteration 6085, loss = 405.72680946\n",
      "Iteration 6086, loss = 405.71658541\n",
      "Iteration 6087, loss = 405.70596474\n",
      "Iteration 6088, loss = 405.69251288\n",
      "Iteration 6089, loss = 405.68364230\n",
      "Iteration 6090, loss = 405.67331193\n",
      "Iteration 6091, loss = 405.65615909\n",
      "Iteration 6092, loss = 405.64640402\n",
      "Iteration 6093, loss = 405.64225754\n",
      "Iteration 6094, loss = 405.61690769\n",
      "Iteration 6095, loss = 405.60468992\n",
      "Iteration 6096, loss = 405.59085813\n",
      "Iteration 6097, loss = 405.58224301\n",
      "Iteration 6098, loss = 405.57247115\n",
      "Iteration 6099, loss = 405.56693157\n",
      "Iteration 6100, loss = 405.55312185\n",
      "Iteration 6101, loss = 405.54648393\n",
      "Iteration 6102, loss = 405.53761273\n",
      "Iteration 6103, loss = 405.52934567\n",
      "Iteration 6104, loss = 405.51379373\n",
      "Iteration 6105, loss = 405.50316592\n",
      "Iteration 6106, loss = 405.49384400\n",
      "Iteration 6107, loss = 405.47329934\n",
      "Iteration 6108, loss = 405.46624631\n",
      "Iteration 6109, loss = 405.46289021\n",
      "Iteration 6110, loss = 405.45993967\n",
      "Iteration 6111, loss = 405.44240496\n",
      "Iteration 6112, loss = 405.43751485\n",
      "Iteration 6113, loss = 405.42447598\n",
      "Iteration 6114, loss = 405.39837242\n",
      "Iteration 6115, loss = 405.38184169\n",
      "Iteration 6116, loss = 405.38241088\n",
      "Iteration 6117, loss = 405.37072262\n",
      "Iteration 6118, loss = 405.36621825\n",
      "Iteration 6119, loss = 405.36199082\n",
      "Iteration 6120, loss = 405.35398811\n",
      "Iteration 6121, loss = 405.34158844\n",
      "Iteration 6122, loss = 405.31914135\n",
      "Iteration 6123, loss = 405.30901128\n",
      "Iteration 6124, loss = 405.30345676\n",
      "Iteration 6125, loss = 405.29622293\n",
      "Iteration 6126, loss = 405.29290268\n",
      "Iteration 6127, loss = 405.27616391\n",
      "Iteration 6128, loss = 405.25966817\n",
      "Iteration 6129, loss = 405.25025614\n",
      "Iteration 6130, loss = 405.23487141\n",
      "Iteration 6131, loss = 405.21284428\n",
      "Iteration 6132, loss = 405.20159272\n",
      "Iteration 6133, loss = 405.19095124\n",
      "Iteration 6134, loss = 405.18625214\n",
      "Iteration 6135, loss = 405.17554605\n",
      "Iteration 6136, loss = 405.15223052\n",
      "Iteration 6137, loss = 405.14821851\n",
      "Iteration 6138, loss = 405.14420825\n",
      "Iteration 6139, loss = 405.12578536\n",
      "Iteration 6140, loss = 405.11860823\n",
      "Iteration 6141, loss = 405.10574816\n",
      "Iteration 6142, loss = 405.10417026\n",
      "Iteration 6143, loss = 405.09618670\n",
      "Iteration 6144, loss = 405.08682909\n",
      "Iteration 6145, loss = 405.06803965\n",
      "Iteration 6146, loss = 405.06033714\n",
      "Iteration 6147, loss = 405.06383373\n",
      "Iteration 6148, loss = 405.05295125\n",
      "Iteration 6149, loss = 405.03805258\n",
      "Iteration 6150, loss = 405.03468661\n",
      "Iteration 6151, loss = 405.02223628\n",
      "Iteration 6152, loss = 405.00369401\n",
      "Iteration 6153, loss = 404.99622984\n",
      "Iteration 6154, loss = 404.98334806\n",
      "Iteration 6155, loss = 404.97771891\n",
      "Iteration 6156, loss = 404.97237300\n",
      "Iteration 6157, loss = 404.96413860\n",
      "Iteration 6158, loss = 404.95309991\n",
      "Iteration 6159, loss = 404.93686702\n",
      "Iteration 6160, loss = 404.92864065\n",
      "Iteration 6161, loss = 404.92288918\n",
      "Iteration 6162, loss = 404.91073905\n",
      "Iteration 6163, loss = 404.90404651\n",
      "Iteration 6164, loss = 404.89212187\n",
      "Iteration 6165, loss = 404.87767852\n",
      "Iteration 6166, loss = 404.87474546\n",
      "Iteration 6167, loss = 404.87163848\n",
      "Iteration 6168, loss = 404.85688365\n",
      "Iteration 6169, loss = 404.84145529\n",
      "Iteration 6170, loss = 404.84887554\n",
      "Iteration 6171, loss = 404.83664073\n",
      "Iteration 6172, loss = 404.83036353\n",
      "Iteration 6173, loss = 404.81697688\n",
      "Iteration 6174, loss = 404.81591804\n",
      "Iteration 6175, loss = 404.80174638\n",
      "Iteration 6176, loss = 404.79392335\n",
      "Iteration 6177, loss = 404.77359091\n",
      "Iteration 6178, loss = 404.76956108\n",
      "Iteration 6179, loss = 404.76559917\n",
      "Iteration 6180, loss = 404.75857207\n",
      "Iteration 6181, loss = 404.75091493\n",
      "Iteration 6182, loss = 404.74407627\n",
      "Iteration 6183, loss = 404.73557258\n",
      "Iteration 6184, loss = 404.72268143\n",
      "Iteration 6185, loss = 404.72050993\n",
      "Iteration 6186, loss = 404.70918788\n",
      "Iteration 6187, loss = 404.69150982\n",
      "Iteration 6188, loss = 404.68409050\n",
      "Iteration 6189, loss = 404.66818867\n",
      "Iteration 6190, loss = 404.65870229\n",
      "Iteration 6191, loss = 404.65152157\n",
      "Iteration 6192, loss = 404.64080281\n",
      "Iteration 6193, loss = 404.63617783\n",
      "Iteration 6194, loss = 404.63058440\n",
      "Iteration 6195, loss = 404.61858453\n",
      "Iteration 6196, loss = 404.61136105\n",
      "Iteration 6197, loss = 404.60188157\n",
      "Iteration 6198, loss = 404.58982062\n",
      "Iteration 6199, loss = 404.58080656\n",
      "Iteration 6200, loss = 404.57336718\n",
      "Iteration 6201, loss = 404.56371438\n",
      "Iteration 6202, loss = 404.55468658\n",
      "Iteration 6203, loss = 404.55480762\n",
      "Iteration 6204, loss = 404.55273119\n",
      "Iteration 6205, loss = 404.53978593\n",
      "Iteration 6206, loss = 404.52840036\n",
      "Iteration 6207, loss = 404.50986433\n",
      "Iteration 6208, loss = 404.50614797\n",
      "Iteration 6209, loss = 404.50242916\n",
      "Iteration 6210, loss = 404.49069687\n",
      "Iteration 6211, loss = 404.47779960\n",
      "Iteration 6212, loss = 404.47601882\n",
      "Iteration 6213, loss = 404.47556798\n",
      "Iteration 6214, loss = 404.47131399\n",
      "Iteration 6215, loss = 404.46015857\n",
      "Iteration 6216, loss = 404.45057822\n",
      "Iteration 6217, loss = 404.43150714\n",
      "Iteration 6218, loss = 404.42233875\n",
      "Iteration 6219, loss = 404.41099143\n",
      "Iteration 6220, loss = 404.42082809\n",
      "Iteration 6221, loss = 404.41145925\n",
      "Iteration 6222, loss = 404.40145285\n",
      "Iteration 6223, loss = 404.38941867\n",
      "Iteration 6224, loss = 404.38816114\n",
      "Iteration 6225, loss = 404.37778135\n",
      "Iteration 6226, loss = 404.36067240\n",
      "Iteration 6227, loss = 404.34480727\n",
      "Iteration 6228, loss = 404.33132584\n",
      "Iteration 6229, loss = 404.32627621\n",
      "Iteration 6230, loss = 404.32175363\n",
      "Iteration 6231, loss = 404.32464796\n",
      "Iteration 6232, loss = 404.31120367\n",
      "Iteration 6233, loss = 404.29328370\n",
      "Iteration 6234, loss = 404.28339208\n",
      "Iteration 6235, loss = 404.27019587\n",
      "Iteration 6236, loss = 404.26838319\n",
      "Iteration 6237, loss = 404.25539244\n",
      "Iteration 6238, loss = 404.25117406\n",
      "Iteration 6239, loss = 404.23530531\n",
      "Iteration 6240, loss = 404.23210111\n",
      "Iteration 6241, loss = 404.22087399\n",
      "Iteration 6242, loss = 404.20594791\n",
      "Iteration 6243, loss = 404.20273539\n",
      "Iteration 6244, loss = 404.19349126\n",
      "Iteration 6245, loss = 404.18794132\n",
      "Iteration 6246, loss = 404.18133427\n",
      "Iteration 6247, loss = 404.17522164\n",
      "Iteration 6248, loss = 404.16554958\n",
      "Iteration 6249, loss = 404.16493539\n",
      "Iteration 6250, loss = 404.15265702\n",
      "Iteration 6251, loss = 404.13805941\n",
      "Iteration 6252, loss = 404.12717643\n",
      "Iteration 6253, loss = 404.12084551\n",
      "Iteration 6254, loss = 404.12338097\n",
      "Iteration 6255, loss = 404.10837221\n",
      "Iteration 6256, loss = 404.11949622\n",
      "Iteration 6257, loss = 404.11276237\n",
      "Iteration 6258, loss = 404.08923081\n",
      "Iteration 6259, loss = 404.06870236\n",
      "Iteration 6260, loss = 404.08106077\n",
      "Iteration 6261, loss = 404.07572898\n",
      "Iteration 6262, loss = 404.06295637\n",
      "Iteration 6263, loss = 404.05677981\n",
      "Iteration 6264, loss = 404.05027097\n",
      "Iteration 6265, loss = 404.02858736\n",
      "Iteration 6266, loss = 404.00909949\n",
      "Iteration 6267, loss = 404.00565138\n",
      "Iteration 6268, loss = 403.98782463\n",
      "Iteration 6269, loss = 403.97225442\n",
      "Iteration 6270, loss = 403.96454834\n",
      "Iteration 6271, loss = 403.96126848\n",
      "Iteration 6272, loss = 403.94880888\n",
      "Iteration 6273, loss = 403.94226654\n",
      "Iteration 6274, loss = 403.93418128\n",
      "Iteration 6275, loss = 403.92636514\n",
      "Iteration 6276, loss = 403.91740994\n",
      "Iteration 6277, loss = 403.91224918\n",
      "Iteration 6278, loss = 403.91217005\n",
      "Iteration 6279, loss = 403.89950222\n",
      "Iteration 6280, loss = 403.88307115\n",
      "Iteration 6281, loss = 403.87197801\n",
      "Iteration 6282, loss = 403.87156191\n",
      "Iteration 6283, loss = 403.86333124\n",
      "Iteration 6284, loss = 403.85008917\n",
      "Iteration 6285, loss = 403.84872589\n",
      "Iteration 6286, loss = 403.83355257\n",
      "Iteration 6287, loss = 403.82816961\n",
      "Iteration 6288, loss = 403.81816818\n",
      "Iteration 6289, loss = 403.81775804\n",
      "Iteration 6290, loss = 403.81375020\n",
      "Iteration 6291, loss = 403.80664312\n",
      "Iteration 6292, loss = 403.79392596\n",
      "Iteration 6293, loss = 403.77800994\n",
      "Iteration 6294, loss = 403.77356240\n",
      "Iteration 6295, loss = 403.77798265\n",
      "Iteration 6296, loss = 403.75898754\n",
      "Iteration 6297, loss = 403.75117792\n",
      "Iteration 6298, loss = 403.74929645\n",
      "Iteration 6299, loss = 403.74563911\n",
      "Iteration 6300, loss = 403.74620373\n",
      "Iteration 6301, loss = 403.72636425\n",
      "Iteration 6302, loss = 403.72318229\n",
      "Iteration 6303, loss = 403.71716555\n",
      "Iteration 6304, loss = 403.70244727\n",
      "Iteration 6305, loss = 403.69764828\n",
      "Iteration 6306, loss = 403.68505353\n",
      "Iteration 6307, loss = 403.67230100\n",
      "Iteration 6308, loss = 403.66457022\n",
      "Iteration 6309, loss = 403.65250808\n",
      "Iteration 6310, loss = 403.65441394\n",
      "Iteration 6311, loss = 403.65294038\n",
      "Iteration 6312, loss = 403.62348343\n",
      "Iteration 6313, loss = 403.62035425\n",
      "Iteration 6314, loss = 403.62782054\n",
      "Iteration 6315, loss = 403.62799895\n",
      "Iteration 6316, loss = 403.61369719\n",
      "Iteration 6317, loss = 403.60584499\n",
      "Iteration 6318, loss = 403.59062412\n",
      "Iteration 6319, loss = 403.58850229\n",
      "Iteration 6320, loss = 403.57916004\n",
      "Iteration 6321, loss = 403.55377572\n",
      "Iteration 6322, loss = 403.55850397\n",
      "Iteration 6323, loss = 403.55105054\n",
      "Iteration 6324, loss = 403.54713030\n",
      "Iteration 6325, loss = 403.55163175\n",
      "Iteration 6326, loss = 403.54379147\n",
      "Iteration 6327, loss = 403.53243305\n",
      "Iteration 6328, loss = 403.51647245\n",
      "Iteration 6329, loss = 403.49852580\n",
      "Iteration 6330, loss = 403.49226565\n",
      "Iteration 6331, loss = 403.47931267\n",
      "Iteration 6332, loss = 403.47069180\n",
      "Iteration 6333, loss = 403.45520053\n",
      "Iteration 6334, loss = 403.45051622\n",
      "Iteration 6335, loss = 403.44876537\n",
      "Iteration 6336, loss = 403.43241873\n",
      "Iteration 6337, loss = 403.43255096\n",
      "Iteration 6338, loss = 403.42372098\n",
      "Iteration 6339, loss = 403.41716892\n",
      "Iteration 6340, loss = 403.40877389\n",
      "Iteration 6341, loss = 403.40653862\n",
      "Iteration 6342, loss = 403.40040568\n",
      "Iteration 6343, loss = 403.38947753\n",
      "Iteration 6344, loss = 403.38451548\n",
      "Iteration 6345, loss = 403.37898922\n",
      "Iteration 6346, loss = 403.36441139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6347, loss = 403.34986598\n",
      "Iteration 6348, loss = 403.34844738\n",
      "Iteration 6349, loss = 403.33442784\n",
      "Iteration 6350, loss = 403.32125968\n",
      "Iteration 6351, loss = 403.31445257\n",
      "Iteration 6352, loss = 403.31246917\n",
      "Iteration 6353, loss = 403.29791172\n",
      "Iteration 6354, loss = 403.28424589\n",
      "Iteration 6355, loss = 403.29201359\n",
      "Iteration 6356, loss = 403.29091601\n",
      "Iteration 6357, loss = 403.27839419\n",
      "Iteration 6358, loss = 403.27157343\n",
      "Iteration 6359, loss = 403.27034975\n",
      "Iteration 6360, loss = 403.25443724\n",
      "Iteration 6361, loss = 403.25819894\n",
      "Iteration 6362, loss = 403.23456771\n",
      "Iteration 6363, loss = 403.22833727\n",
      "Iteration 6364, loss = 403.22351783\n",
      "Iteration 6365, loss = 403.20681184\n",
      "Iteration 6366, loss = 403.20129869\n",
      "Iteration 6367, loss = 403.19322489\n",
      "Iteration 6368, loss = 403.20064249\n",
      "Iteration 6369, loss = 403.19753506\n",
      "Iteration 6370, loss = 403.17364818\n",
      "Iteration 6371, loss = 403.16552752\n",
      "Iteration 6372, loss = 403.15916423\n",
      "Iteration 6373, loss = 403.14671352\n",
      "Iteration 6374, loss = 403.14090205\n",
      "Iteration 6375, loss = 403.14241124\n",
      "Iteration 6376, loss = 403.13136001\n",
      "Iteration 6377, loss = 403.11541043\n",
      "Iteration 6378, loss = 403.11243031\n",
      "Iteration 6379, loss = 403.12429548\n",
      "Iteration 6380, loss = 403.11197919\n",
      "Iteration 6381, loss = 403.09714699\n",
      "Iteration 6382, loss = 403.08011070\n",
      "Iteration 6383, loss = 403.07162405\n",
      "Iteration 6384, loss = 403.06792902\n",
      "Iteration 6385, loss = 403.06323799\n",
      "Iteration 6386, loss = 403.05258740\n",
      "Iteration 6387, loss = 403.04005536\n",
      "Iteration 6388, loss = 403.03728671\n",
      "Iteration 6389, loss = 403.02103524\n",
      "Iteration 6390, loss = 403.01098669\n",
      "Iteration 6391, loss = 403.00314454\n",
      "Iteration 6392, loss = 403.00401869\n",
      "Iteration 6393, loss = 402.99776923\n",
      "Iteration 6394, loss = 402.99178242\n",
      "Iteration 6395, loss = 402.98049335\n",
      "Iteration 6396, loss = 402.97978184\n",
      "Iteration 6397, loss = 402.96814474\n",
      "Iteration 6398, loss = 402.95675999\n",
      "Iteration 6399, loss = 402.94517084\n",
      "Iteration 6400, loss = 402.93633731\n",
      "Iteration 6401, loss = 402.94279570\n",
      "Iteration 6402, loss = 402.92648589\n",
      "Iteration 6403, loss = 402.90603208\n",
      "Iteration 6404, loss = 402.90444160\n",
      "Iteration 6405, loss = 402.89537836\n",
      "Iteration 6406, loss = 402.88459087\n",
      "Iteration 6407, loss = 402.89475737\n",
      "Iteration 6408, loss = 402.88751419\n",
      "Iteration 6409, loss = 402.87085406\n",
      "Iteration 6410, loss = 402.85251620\n",
      "Iteration 6411, loss = 402.84627072\n",
      "Iteration 6412, loss = 402.83611885\n",
      "Iteration 6413, loss = 402.84278906\n",
      "Iteration 6414, loss = 402.83964133\n",
      "Iteration 6415, loss = 402.82320479\n",
      "Iteration 6416, loss = 402.81330381\n",
      "Iteration 6417, loss = 402.80989299\n",
      "Iteration 6418, loss = 402.80896436\n",
      "Iteration 6419, loss = 402.80251703\n",
      "Iteration 6420, loss = 402.79723990\n",
      "Iteration 6421, loss = 402.79518187\n",
      "Iteration 6422, loss = 402.79195876\n",
      "Iteration 6423, loss = 402.77718625\n",
      "Iteration 6424, loss = 402.76578267\n",
      "Iteration 6425, loss = 402.75782620\n",
      "Iteration 6426, loss = 402.75273499\n",
      "Iteration 6427, loss = 402.74234534\n",
      "Iteration 6428, loss = 402.73038812\n",
      "Iteration 6429, loss = 402.72084274\n",
      "Iteration 6430, loss = 402.72447402\n",
      "Iteration 6431, loss = 402.71216447\n",
      "Iteration 6432, loss = 402.69259356\n",
      "Iteration 6433, loss = 402.69533848\n",
      "Iteration 6434, loss = 402.68766555\n",
      "Iteration 6435, loss = 402.66644068\n",
      "Iteration 6436, loss = 402.66488110\n",
      "Iteration 6437, loss = 402.66285757\n",
      "Iteration 6438, loss = 402.66221278\n",
      "Iteration 6439, loss = 402.64888982\n",
      "Iteration 6440, loss = 402.64586688\n",
      "Iteration 6441, loss = 402.62741592\n",
      "Iteration 6442, loss = 402.61599210\n",
      "Iteration 6443, loss = 402.62100621\n",
      "Iteration 6444, loss = 402.62971326\n",
      "Iteration 6445, loss = 402.61274920\n",
      "Iteration 6446, loss = 402.60689317\n",
      "Iteration 6447, loss = 402.59087284\n",
      "Iteration 6448, loss = 402.58914865\n",
      "Iteration 6449, loss = 402.58737510\n",
      "Iteration 6450, loss = 402.58245972\n",
      "Iteration 6451, loss = 402.57984677\n",
      "Iteration 6452, loss = 402.56274926\n",
      "Iteration 6453, loss = 402.56606084\n",
      "Iteration 6454, loss = 402.55552036\n",
      "Iteration 6455, loss = 402.52968567\n",
      "Iteration 6456, loss = 402.51713388\n",
      "Iteration 6457, loss = 402.52301427\n",
      "Iteration 6458, loss = 402.50468834\n",
      "Iteration 6459, loss = 402.50538543\n",
      "Iteration 6460, loss = 402.50230843\n",
      "Iteration 6461, loss = 402.50133777\n",
      "Iteration 6462, loss = 402.48765084\n",
      "Iteration 6463, loss = 402.46956839\n",
      "Iteration 6464, loss = 402.45895678\n",
      "Iteration 6465, loss = 402.44317242\n",
      "Iteration 6466, loss = 402.44649206\n",
      "Iteration 6467, loss = 402.45724865\n",
      "Iteration 6468, loss = 402.44116456\n",
      "Iteration 6469, loss = 402.42275071\n",
      "Iteration 6470, loss = 402.42906505\n",
      "Iteration 6471, loss = 402.41772557\n",
      "Iteration 6472, loss = 402.40682205\n",
      "Iteration 6473, loss = 402.39316937\n",
      "Iteration 6474, loss = 402.37495346\n",
      "Iteration 6475, loss = 402.37718190\n",
      "Iteration 6476, loss = 402.38457694\n",
      "Iteration 6477, loss = 402.36392624\n",
      "Iteration 6478, loss = 402.35412905\n",
      "Iteration 6479, loss = 402.35527062\n",
      "Iteration 6480, loss = 402.35403138\n",
      "Iteration 6481, loss = 402.34542579\n",
      "Iteration 6482, loss = 402.34079029\n",
      "Iteration 6483, loss = 402.32673295\n",
      "Iteration 6484, loss = 402.31766490\n",
      "Iteration 6485, loss = 402.32301707\n",
      "Iteration 6486, loss = 402.32375088\n",
      "Iteration 6487, loss = 402.30807587\n",
      "Iteration 6488, loss = 402.30639512\n",
      "Iteration 6489, loss = 402.30996418\n",
      "Iteration 6490, loss = 402.30404321\n",
      "Iteration 6491, loss = 402.29761495\n",
      "Iteration 6492, loss = 402.27727791\n",
      "Iteration 6493, loss = 402.25027583\n",
      "Iteration 6494, loss = 402.23336649\n",
      "Iteration 6495, loss = 402.22791940\n",
      "Iteration 6496, loss = 402.22681436\n",
      "Iteration 6497, loss = 402.22081138\n",
      "Iteration 6498, loss = 402.21448279\n",
      "Iteration 6499, loss = 402.20722960\n",
      "Iteration 6500, loss = 402.19732143\n",
      "Iteration 6501, loss = 402.18054701\n",
      "Iteration 6502, loss = 402.17032970\n",
      "Iteration 6503, loss = 402.17080656\n",
      "Iteration 6504, loss = 402.16461263\n",
      "Iteration 6505, loss = 402.15773884\n",
      "Iteration 6506, loss = 402.15624584\n",
      "Iteration 6507, loss = 402.15040086\n",
      "Iteration 6508, loss = 402.13928023\n",
      "Iteration 6509, loss = 402.13600966\n",
      "Iteration 6510, loss = 402.12577017\n",
      "Iteration 6511, loss = 402.11219362\n",
      "Iteration 6512, loss = 402.11021554\n",
      "Iteration 6513, loss = 402.10386881\n",
      "Iteration 6514, loss = 402.09324177\n",
      "Iteration 6515, loss = 402.09972847\n",
      "Iteration 6516, loss = 402.09766403\n",
      "Iteration 6517, loss = 402.09553952\n",
      "Iteration 6518, loss = 402.08868782\n",
      "Iteration 6519, loss = 402.08338207\n",
      "Iteration 6520, loss = 402.07052744\n",
      "Iteration 6521, loss = 402.05374993\n",
      "Iteration 6522, loss = 402.04406705\n",
      "Iteration 6523, loss = 402.04981524\n",
      "Iteration 6524, loss = 402.03585164\n",
      "Iteration 6525, loss = 402.01225847\n",
      "Iteration 6526, loss = 402.00960134\n",
      "Iteration 6527, loss = 402.01014943\n",
      "Iteration 6528, loss = 402.00130841\n",
      "Iteration 6529, loss = 401.99343498\n",
      "Iteration 6530, loss = 401.98445466\n",
      "Iteration 6531, loss = 401.97221938\n",
      "Iteration 6532, loss = 401.96669017\n",
      "Iteration 6533, loss = 401.96310508\n",
      "Iteration 6534, loss = 401.95581562\n",
      "Iteration 6535, loss = 401.95685904\n",
      "Iteration 6536, loss = 401.95280620\n",
      "Iteration 6537, loss = 401.94238162\n",
      "Iteration 6538, loss = 401.94551822\n",
      "Iteration 6539, loss = 401.93430660\n",
      "Iteration 6540, loss = 401.91923234\n",
      "Iteration 6541, loss = 401.93819325\n",
      "Iteration 6542, loss = 401.92201248\n",
      "Iteration 6543, loss = 401.90076440\n",
      "Iteration 6544, loss = 401.89085638\n",
      "Iteration 6545, loss = 401.89329466\n",
      "Iteration 6546, loss = 401.88598158\n",
      "Iteration 6547, loss = 401.86828279\n",
      "Iteration 6548, loss = 401.88640767\n",
      "Iteration 6549, loss = 401.87461572\n",
      "Iteration 6550, loss = 401.85503287\n",
      "Iteration 6551, loss = 401.84630765\n",
      "Iteration 6552, loss = 401.86253277\n",
      "Iteration 6553, loss = 401.84780988\n",
      "Iteration 6554, loss = 401.81816688\n",
      "Iteration 6555, loss = 401.81805724\n",
      "Iteration 6556, loss = 401.82743298\n",
      "Iteration 6557, loss = 401.81037871\n",
      "Iteration 6558, loss = 401.80179141\n",
      "Iteration 6559, loss = 401.79796467\n",
      "Iteration 6560, loss = 401.79258248\n",
      "Iteration 6561, loss = 401.79452127\n",
      "Iteration 6562, loss = 401.77657265\n",
      "Iteration 6563, loss = 401.75721652\n",
      "Iteration 6564, loss = 401.74875276\n",
      "Iteration 6565, loss = 401.73995532\n",
      "Iteration 6566, loss = 401.73047772\n",
      "Iteration 6567, loss = 401.72968704\n",
      "Iteration 6568, loss = 401.72125663\n",
      "Iteration 6569, loss = 401.71152862\n",
      "Iteration 6570, loss = 401.70453962\n",
      "Iteration 6571, loss = 401.69259739\n",
      "Iteration 6572, loss = 401.68378972\n",
      "Iteration 6573, loss = 401.67702417\n",
      "Iteration 6574, loss = 401.66898523\n",
      "Iteration 6575, loss = 401.65693171\n",
      "Iteration 6576, loss = 401.65058580\n",
      "Iteration 6577, loss = 401.64361773\n",
      "Iteration 6578, loss = 401.63459888\n",
      "Iteration 6579, loss = 401.62203968\n",
      "Iteration 6580, loss = 401.61142423\n",
      "Iteration 6581, loss = 401.61439909\n",
      "Iteration 6582, loss = 401.59660968\n",
      "Iteration 6583, loss = 401.59340286\n",
      "Iteration 6584, loss = 401.58690248\n",
      "Iteration 6585, loss = 401.58676359\n",
      "Iteration 6586, loss = 401.57563550\n",
      "Iteration 6587, loss = 401.55827592\n",
      "Iteration 6588, loss = 401.54660454\n",
      "Iteration 6589, loss = 401.53492254\n",
      "Iteration 6590, loss = 401.52673664\n",
      "Iteration 6591, loss = 401.52024153\n",
      "Iteration 6592, loss = 401.51992227\n",
      "Iteration 6593, loss = 401.50269086\n",
      "Iteration 6594, loss = 401.48358185\n",
      "Iteration 6595, loss = 401.48660061\n",
      "Iteration 6596, loss = 401.47925136\n",
      "Iteration 6597, loss = 401.46527510\n",
      "Iteration 6598, loss = 401.45166208\n",
      "Iteration 6599, loss = 401.45203168\n",
      "Iteration 6600, loss = 401.44772493\n",
      "Iteration 6601, loss = 401.42580225\n",
      "Iteration 6602, loss = 401.42030748\n",
      "Iteration 6603, loss = 401.41222912\n",
      "Iteration 6604, loss = 401.41072306\n",
      "Iteration 6605, loss = 401.39720107\n",
      "Iteration 6606, loss = 401.39277349\n",
      "Iteration 6607, loss = 401.39530440\n",
      "Iteration 6608, loss = 401.39477336\n",
      "Iteration 6609, loss = 401.38611507\n",
      "Iteration 6610, loss = 401.37711408\n",
      "Iteration 6611, loss = 401.35899162\n",
      "Iteration 6612, loss = 401.35064613\n",
      "Iteration 6613, loss = 401.33839389\n",
      "Iteration 6614, loss = 401.31491049\n",
      "Iteration 6615, loss = 401.29890336\n",
      "Iteration 6616, loss = 401.30792817\n",
      "Iteration 6617, loss = 401.30098168\n",
      "Iteration 6618, loss = 401.28980857\n",
      "Iteration 6619, loss = 401.27878356\n",
      "Iteration 6620, loss = 401.26494693\n",
      "Iteration 6621, loss = 401.25129931\n",
      "Iteration 6622, loss = 401.24182161\n",
      "Iteration 6623, loss = 401.23214273\n",
      "Iteration 6624, loss = 401.22727236\n",
      "Iteration 6625, loss = 401.21993144\n",
      "Iteration 6626, loss = 401.21543843\n",
      "Iteration 6627, loss = 401.21505601\n",
      "Iteration 6628, loss = 401.21598842\n",
      "Iteration 6629, loss = 401.20211412\n",
      "Iteration 6630, loss = 401.18365636\n",
      "Iteration 6631, loss = 401.17637597\n",
      "Iteration 6632, loss = 401.16849749\n",
      "Iteration 6633, loss = 401.15334013\n",
      "Iteration 6634, loss = 401.13145123\n",
      "Iteration 6635, loss = 401.13531381\n",
      "Iteration 6636, loss = 401.13496394\n",
      "Iteration 6637, loss = 401.11117556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6638, loss = 401.10406734\n",
      "Iteration 6639, loss = 401.10024385\n",
      "Iteration 6640, loss = 401.09235161\n",
      "Iteration 6641, loss = 401.08078665\n",
      "Iteration 6642, loss = 401.06573605\n",
      "Iteration 6643, loss = 401.06036238\n",
      "Iteration 6644, loss = 401.04534512\n",
      "Iteration 6645, loss = 401.03842566\n",
      "Iteration 6646, loss = 401.04259111\n",
      "Iteration 6647, loss = 401.03517161\n",
      "Iteration 6648, loss = 401.02073327\n",
      "Iteration 6649, loss = 401.01937502\n",
      "Iteration 6650, loss = 401.01198228\n",
      "Iteration 6651, loss = 400.99366115\n",
      "Iteration 6652, loss = 400.97371140\n",
      "Iteration 6653, loss = 400.98409517\n",
      "Iteration 6654, loss = 400.98420812\n",
      "Iteration 6655, loss = 400.95597921\n",
      "Iteration 6656, loss = 400.94193569\n",
      "Iteration 6657, loss = 400.94134667\n",
      "Iteration 6658, loss = 400.93304552\n",
      "Iteration 6659, loss = 400.92140927\n",
      "Iteration 6660, loss = 400.91734718\n",
      "Iteration 6661, loss = 400.90303862\n",
      "Iteration 6662, loss = 400.90037476\n",
      "Iteration 6663, loss = 400.88694949\n",
      "Iteration 6664, loss = 400.87492750\n",
      "Iteration 6665, loss = 400.86833095\n",
      "Iteration 6666, loss = 400.87803250\n",
      "Iteration 6667, loss = 400.86440534\n",
      "Iteration 6668, loss = 400.84729342\n",
      "Iteration 6669, loss = 400.84197380\n",
      "Iteration 6670, loss = 400.84206807\n",
      "Iteration 6671, loss = 400.83856792\n",
      "Iteration 6672, loss = 400.83245879\n",
      "Iteration 6673, loss = 400.81721989\n",
      "Iteration 6674, loss = 400.80681372\n",
      "Iteration 6675, loss = 400.79891178\n",
      "Iteration 6676, loss = 400.79953734\n",
      "Iteration 6677, loss = 400.79560462\n",
      "Iteration 6678, loss = 400.77741664\n",
      "Iteration 6679, loss = 400.76813711\n",
      "Iteration 6680, loss = 400.75418487\n",
      "Iteration 6681, loss = 400.75494093\n",
      "Iteration 6682, loss = 400.74454577\n",
      "Iteration 6683, loss = 400.72318907\n",
      "Iteration 6684, loss = 400.71464607\n",
      "Iteration 6685, loss = 400.71508110\n",
      "Iteration 6686, loss = 400.70415769\n",
      "Iteration 6687, loss = 400.68176572\n",
      "Iteration 6688, loss = 400.68115988\n",
      "Iteration 6689, loss = 400.67596332\n",
      "Iteration 6690, loss = 400.66756845\n",
      "Iteration 6691, loss = 400.65581108\n",
      "Iteration 6692, loss = 400.64575082\n",
      "Iteration 6693, loss = 400.63810767\n",
      "Iteration 6694, loss = 400.62670273\n",
      "Iteration 6695, loss = 400.61809082\n",
      "Iteration 6696, loss = 400.60692971\n",
      "Iteration 6697, loss = 400.59813375\n",
      "Iteration 6698, loss = 400.58978144\n",
      "Iteration 6699, loss = 400.59975867\n",
      "Iteration 6700, loss = 400.59635799\n",
      "Iteration 6701, loss = 400.59121513\n",
      "Iteration 6702, loss = 400.58002187\n",
      "Iteration 6703, loss = 400.56607793\n",
      "Iteration 6704, loss = 400.55293689\n",
      "Iteration 6705, loss = 400.54159631\n",
      "Iteration 6706, loss = 400.53192343\n",
      "Iteration 6707, loss = 400.52479171\n",
      "Iteration 6708, loss = 400.50750389\n",
      "Iteration 6709, loss = 400.49971251\n",
      "Iteration 6710, loss = 400.50070353\n",
      "Iteration 6711, loss = 400.48797984\n",
      "Iteration 6712, loss = 400.49069416\n",
      "Iteration 6713, loss = 400.49016006\n",
      "Iteration 6714, loss = 400.48349271\n",
      "Iteration 6715, loss = 400.47089512\n",
      "Iteration 6716, loss = 400.44979944\n",
      "Iteration 6717, loss = 400.43659582\n",
      "Iteration 6718, loss = 400.43033827\n",
      "Iteration 6719, loss = 400.42426175\n",
      "Iteration 6720, loss = 400.41836059\n",
      "Iteration 6721, loss = 400.39891595\n",
      "Iteration 6722, loss = 400.39529291\n",
      "Iteration 6723, loss = 400.39934939\n",
      "Iteration 6724, loss = 400.38784623\n",
      "Iteration 6725, loss = 400.37928846\n",
      "Iteration 6726, loss = 400.36785153\n",
      "Iteration 6727, loss = 400.35769391\n",
      "Iteration 6728, loss = 400.34050901\n",
      "Iteration 6729, loss = 400.33917253\n",
      "Iteration 6730, loss = 400.33727170\n",
      "Iteration 6731, loss = 400.33231397\n",
      "Iteration 6732, loss = 400.32557605\n",
      "Iteration 6733, loss = 400.31854566\n",
      "Iteration 6734, loss = 400.31517597\n",
      "Iteration 6735, loss = 400.29275816\n",
      "Iteration 6736, loss = 400.27869576\n",
      "Iteration 6737, loss = 400.27749565\n",
      "Iteration 6738, loss = 400.26982832\n",
      "Iteration 6739, loss = 400.25532848\n",
      "Iteration 6740, loss = 400.24383952\n",
      "Iteration 6741, loss = 400.25035010\n",
      "Iteration 6742, loss = 400.22797530\n",
      "Iteration 6743, loss = 400.21718994\n",
      "Iteration 6744, loss = 400.20634572\n",
      "Iteration 6745, loss = 400.20380255\n",
      "Iteration 6746, loss = 400.19395148\n",
      "Iteration 6747, loss = 400.19026858\n",
      "Iteration 6748, loss = 400.17517842\n",
      "Iteration 6749, loss = 400.18067692\n",
      "Iteration 6750, loss = 400.16243275\n",
      "Iteration 6751, loss = 400.16019633\n",
      "Iteration 6752, loss = 400.15143587\n",
      "Iteration 6753, loss = 400.14528454\n",
      "Iteration 6754, loss = 400.13202096\n",
      "Iteration 6755, loss = 400.12945443\n",
      "Iteration 6756, loss = 400.12366486\n",
      "Iteration 6757, loss = 400.11266851\n",
      "Iteration 6758, loss = 400.10575398\n",
      "Iteration 6759, loss = 400.10697085\n",
      "Iteration 6760, loss = 400.09574955\n",
      "Iteration 6761, loss = 400.08772776\n",
      "Iteration 6762, loss = 400.08221279\n",
      "Iteration 6763, loss = 400.08636108\n",
      "Iteration 6764, loss = 400.06394780\n",
      "Iteration 6765, loss = 400.05818377\n",
      "Iteration 6766, loss = 400.04193984\n",
      "Iteration 6767, loss = 400.02563845\n",
      "Iteration 6768, loss = 400.02343566\n",
      "Iteration 6769, loss = 400.02699844\n",
      "Iteration 6770, loss = 400.01940946\n",
      "Iteration 6771, loss = 400.00137813\n",
      "Iteration 6772, loss = 399.99255752\n",
      "Iteration 6773, loss = 399.98606427\n",
      "Iteration 6774, loss = 399.99818999\n",
      "Iteration 6775, loss = 399.98565928\n",
      "Iteration 6776, loss = 399.96285530\n",
      "Iteration 6777, loss = 399.96268462\n",
      "Iteration 6778, loss = 399.96086929\n",
      "Iteration 6779, loss = 399.95286487\n",
      "Iteration 6780, loss = 399.93264700\n",
      "Iteration 6781, loss = 399.93197409\n",
      "Iteration 6782, loss = 399.93505404\n",
      "Iteration 6783, loss = 399.92799197\n",
      "Iteration 6784, loss = 399.91334680\n",
      "Iteration 6785, loss = 399.90244938\n",
      "Iteration 6786, loss = 399.88727000\n",
      "Iteration 6787, loss = 399.88477910\n",
      "Iteration 6788, loss = 399.87440686\n",
      "Iteration 6789, loss = 399.85432479\n",
      "Iteration 6790, loss = 399.84540098\n",
      "Iteration 6791, loss = 399.85394254\n",
      "Iteration 6792, loss = 399.85104450\n",
      "Iteration 6793, loss = 399.83481993\n",
      "Iteration 6794, loss = 399.82791433\n",
      "Iteration 6795, loss = 399.84668682\n",
      "Iteration 6796, loss = 399.82936825\n",
      "Iteration 6797, loss = 399.81395253\n",
      "Iteration 6798, loss = 399.81637752\n",
      "Iteration 6799, loss = 399.80628811\n",
      "Iteration 6800, loss = 399.79748551\n",
      "Iteration 6801, loss = 399.77962606\n",
      "Iteration 6802, loss = 399.76645452\n",
      "Iteration 6803, loss = 399.75309802\n",
      "Iteration 6804, loss = 399.74689661\n",
      "Iteration 6805, loss = 399.75552056\n",
      "Iteration 6806, loss = 399.72901700\n",
      "Iteration 6807, loss = 399.71261161\n",
      "Iteration 6808, loss = 399.71381037\n",
      "Iteration 6809, loss = 399.70614432\n",
      "Iteration 6810, loss = 399.69594855\n",
      "Iteration 6811, loss = 399.69530020\n",
      "Iteration 6812, loss = 399.70025185\n",
      "Iteration 6813, loss = 399.68339930\n",
      "Iteration 6814, loss = 399.66694204\n",
      "Iteration 6815, loss = 399.66741308\n",
      "Iteration 6816, loss = 399.65659187\n",
      "Iteration 6817, loss = 399.65440246\n",
      "Iteration 6818, loss = 399.64700082\n",
      "Iteration 6819, loss = 399.64947834\n",
      "Iteration 6820, loss = 399.64434252\n",
      "Iteration 6821, loss = 399.62206740\n",
      "Iteration 6822, loss = 399.62002726\n",
      "Iteration 6823, loss = 399.61779260\n",
      "Iteration 6824, loss = 399.61085927\n",
      "Iteration 6825, loss = 399.60507285\n",
      "Iteration 6826, loss = 399.59973042\n",
      "Iteration 6827, loss = 399.57653754\n",
      "Iteration 6828, loss = 399.56614132\n",
      "Iteration 6829, loss = 399.54668951\n",
      "Iteration 6830, loss = 399.53625736\n",
      "Iteration 6831, loss = 399.53226555\n",
      "Iteration 6832, loss = 399.55073662\n",
      "Iteration 6833, loss = 399.55224325\n",
      "Iteration 6834, loss = 399.53690341\n",
      "Iteration 6835, loss = 399.54045162\n",
      "Iteration 6836, loss = 399.53201917\n",
      "Iteration 6837, loss = 399.50787163\n",
      "Iteration 6838, loss = 399.49449026\n",
      "Iteration 6839, loss = 399.47769623\n",
      "Iteration 6840, loss = 399.47490549\n",
      "Iteration 6841, loss = 399.46870562\n",
      "Iteration 6842, loss = 399.45788730\n",
      "Iteration 6843, loss = 399.45587750\n",
      "Iteration 6844, loss = 399.42828440\n",
      "Iteration 6845, loss = 399.42797792\n",
      "Iteration 6846, loss = 399.41730010\n",
      "Iteration 6847, loss = 399.40373765\n",
      "Iteration 6848, loss = 399.39509043\n",
      "Iteration 6849, loss = 399.38945093\n",
      "Iteration 6850, loss = 399.38117532\n",
      "Iteration 6851, loss = 399.36749771\n",
      "Iteration 6852, loss = 399.37887438\n",
      "Iteration 6853, loss = 399.36511462\n",
      "Iteration 6854, loss = 399.36670843\n",
      "Iteration 6855, loss = 399.35608727\n",
      "Iteration 6856, loss = 399.33745972\n",
      "Iteration 6857, loss = 399.33133947\n",
      "Iteration 6858, loss = 399.32629497\n",
      "Iteration 6859, loss = 399.32584788\n",
      "Iteration 6860, loss = 399.30649391\n",
      "Iteration 6861, loss = 399.29490086\n",
      "Iteration 6862, loss = 399.29014188\n",
      "Iteration 6863, loss = 399.29209152\n",
      "Iteration 6864, loss = 399.27702769\n",
      "Iteration 6865, loss = 399.25838221\n",
      "Iteration 6866, loss = 399.26143814\n",
      "Iteration 6867, loss = 399.25818188\n",
      "Iteration 6868, loss = 399.26466103\n",
      "Iteration 6869, loss = 399.24756086\n",
      "Iteration 6870, loss = 399.23819144\n",
      "Iteration 6871, loss = 399.21538768\n",
      "Iteration 6872, loss = 399.20786695\n",
      "Iteration 6873, loss = 399.22332792\n",
      "Iteration 6874, loss = 399.21440716\n",
      "Iteration 6875, loss = 399.20837450\n",
      "Iteration 6876, loss = 399.19935619\n",
      "Iteration 6877, loss = 399.18675608\n",
      "Iteration 6878, loss = 399.16860557\n",
      "Iteration 6879, loss = 399.16012424\n",
      "Iteration 6880, loss = 399.15276213\n",
      "Iteration 6881, loss = 399.14167163\n",
      "Iteration 6882, loss = 399.14195433\n",
      "Iteration 6883, loss = 399.14020940\n",
      "Iteration 6884, loss = 399.13095444\n",
      "Iteration 6885, loss = 399.11206300\n",
      "Iteration 6886, loss = 399.10797549\n",
      "Iteration 6887, loss = 399.11030445\n",
      "Iteration 6888, loss = 399.11411886\n",
      "Iteration 6889, loss = 399.11056275\n",
      "Iteration 6890, loss = 399.08250833\n",
      "Iteration 6891, loss = 399.06942195\n",
      "Iteration 6892, loss = 399.07544972\n",
      "Iteration 6893, loss = 399.07665763\n",
      "Iteration 6894, loss = 399.04448141\n",
      "Iteration 6895, loss = 399.04109431\n",
      "Iteration 6896, loss = 399.05502475\n",
      "Iteration 6897, loss = 399.04163551\n",
      "Iteration 6898, loss = 399.03047752\n",
      "Iteration 6899, loss = 399.02674865\n",
      "Iteration 6900, loss = 399.01905776\n",
      "Iteration 6901, loss = 398.99160916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6902, loss = 398.98322619\n",
      "Iteration 6903, loss = 398.98129111\n",
      "Iteration 6904, loss = 398.95557876\n",
      "Iteration 6905, loss = 398.95633071\n",
      "Iteration 6906, loss = 398.95306522\n",
      "Iteration 6907, loss = 398.95433835\n",
      "Iteration 6908, loss = 398.94437116\n",
      "Iteration 6909, loss = 398.93882800\n",
      "Iteration 6910, loss = 398.92454880\n",
      "Iteration 6911, loss = 398.91995685\n",
      "Iteration 6912, loss = 398.91570960\n",
      "Iteration 6913, loss = 398.90448602\n",
      "Iteration 6914, loss = 398.89968324\n",
      "Iteration 6915, loss = 398.88855773\n",
      "Iteration 6916, loss = 398.87674850\n",
      "Iteration 6917, loss = 398.86867215\n",
      "Iteration 6918, loss = 398.85877291\n",
      "Iteration 6919, loss = 398.84699915\n",
      "Iteration 6920, loss = 398.84720288\n",
      "Iteration 6921, loss = 398.84090631\n",
      "Iteration 6922, loss = 398.82610436\n",
      "Iteration 6923, loss = 398.81297127\n",
      "Iteration 6924, loss = 398.81310853\n",
      "Iteration 6925, loss = 398.81254776\n",
      "Iteration 6926, loss = 398.82544105\n",
      "Iteration 6927, loss = 398.81145812\n",
      "Iteration 6928, loss = 398.77761510\n",
      "Iteration 6929, loss = 398.76282288\n",
      "Iteration 6930, loss = 398.76003252\n",
      "Iteration 6931, loss = 398.75494601\n",
      "Iteration 6932, loss = 398.74981660\n",
      "Iteration 6933, loss = 398.73163355\n",
      "Iteration 6934, loss = 398.73072862\n",
      "Iteration 6935, loss = 398.72589502\n",
      "Iteration 6936, loss = 398.72136143\n",
      "Iteration 6937, loss = 398.72306896\n",
      "Iteration 6938, loss = 398.71171471\n",
      "Iteration 6939, loss = 398.70643456\n",
      "Iteration 6940, loss = 398.69768494\n",
      "Iteration 6941, loss = 398.68291627\n",
      "Iteration 6942, loss = 398.67176145\n",
      "Iteration 6943, loss = 398.66612577\n",
      "Iteration 6944, loss = 398.64771589\n",
      "Iteration 6945, loss = 398.66312912\n",
      "Iteration 6946, loss = 398.65636982\n",
      "Iteration 6947, loss = 398.64067677\n",
      "Iteration 6948, loss = 398.63032686\n",
      "Iteration 6949, loss = 398.61815122\n",
      "Iteration 6950, loss = 398.60809860\n",
      "Iteration 6951, loss = 398.61307984\n",
      "Iteration 6952, loss = 398.60659071\n",
      "Iteration 6953, loss = 398.60272363\n",
      "Iteration 6954, loss = 398.59404611\n",
      "Iteration 6955, loss = 398.59420379\n",
      "Iteration 6956, loss = 398.58189342\n",
      "Iteration 6957, loss = 398.57523321\n",
      "Iteration 6958, loss = 398.57246935\n",
      "Iteration 6959, loss = 398.56580338\n",
      "Iteration 6960, loss = 398.55513181\n",
      "Iteration 6961, loss = 398.54452621\n",
      "Iteration 6962, loss = 398.52784173\n",
      "Iteration 6963, loss = 398.52581497\n",
      "Iteration 6964, loss = 398.50962694\n",
      "Iteration 6965, loss = 398.51214475\n",
      "Iteration 6966, loss = 398.51477181\n",
      "Iteration 6967, loss = 398.50759472\n",
      "Iteration 6968, loss = 398.47912459\n",
      "Iteration 6969, loss = 398.46432780\n",
      "Iteration 6970, loss = 398.47787887\n",
      "Iteration 6971, loss = 398.48156238\n",
      "Iteration 6972, loss = 398.45611483\n",
      "Iteration 6973, loss = 398.44302336\n",
      "Iteration 6974, loss = 398.43951122\n",
      "Iteration 6975, loss = 398.43070571\n",
      "Iteration 6976, loss = 398.44144294\n",
      "Iteration 6977, loss = 398.43128384\n",
      "Iteration 6978, loss = 398.40926581\n",
      "Iteration 6979, loss = 398.40230893\n",
      "Iteration 6980, loss = 398.38804036\n",
      "Iteration 6981, loss = 398.39435250\n",
      "Iteration 6982, loss = 398.37515223\n",
      "Iteration 6983, loss = 398.37491710\n",
      "Iteration 6984, loss = 398.36963319\n",
      "Iteration 6985, loss = 398.36245045\n",
      "Iteration 6986, loss = 398.34971744\n",
      "Iteration 6987, loss = 398.34293718\n",
      "Iteration 6988, loss = 398.33184311\n",
      "Iteration 6989, loss = 398.32874148\n",
      "Iteration 6990, loss = 398.32743817\n",
      "Iteration 6991, loss = 398.32352791\n",
      "Iteration 6992, loss = 398.30394961\n",
      "Iteration 6993, loss = 398.29516245\n",
      "Iteration 6994, loss = 398.28460467\n",
      "Iteration 6995, loss = 398.28439935\n",
      "Iteration 6996, loss = 398.28702472\n",
      "Iteration 6997, loss = 398.27893661\n",
      "Iteration 6998, loss = 398.25913954\n",
      "Iteration 6999, loss = 398.25419806\n",
      "Iteration 7000, loss = 398.24886331\n",
      "Iteration 7001, loss = 398.23629891\n",
      "Iteration 7002, loss = 398.23231249\n",
      "Iteration 7003, loss = 398.22441473\n",
      "Iteration 7004, loss = 398.19873376\n",
      "Iteration 7005, loss = 398.20164699\n",
      "Iteration 7006, loss = 398.20257739\n",
      "Iteration 7007, loss = 398.18748568\n",
      "Iteration 7008, loss = 398.19109122\n",
      "Iteration 7009, loss = 398.18216756\n",
      "Iteration 7010, loss = 398.18237863\n",
      "Iteration 7011, loss = 398.18118430\n",
      "Iteration 7012, loss = 398.17182720\n",
      "Iteration 7013, loss = 398.15760117\n",
      "Iteration 7014, loss = 398.14126006\n",
      "Iteration 7015, loss = 398.15375361\n",
      "Iteration 7016, loss = 398.15571521\n",
      "Iteration 7017, loss = 398.14580987\n",
      "Iteration 7018, loss = 398.11819657\n",
      "Iteration 7019, loss = 398.09534442\n",
      "Iteration 7020, loss = 398.10495586\n",
      "Iteration 7021, loss = 398.09115798\n",
      "Iteration 7022, loss = 398.08111109\n",
      "Iteration 7023, loss = 398.09592608\n",
      "Iteration 7024, loss = 398.06475514\n",
      "Iteration 7025, loss = 398.05743918\n",
      "Iteration 7026, loss = 398.05248346\n",
      "Iteration 7027, loss = 398.04722764\n",
      "Iteration 7028, loss = 398.02140408\n",
      "Iteration 7029, loss = 398.01047937\n",
      "Iteration 7030, loss = 398.01510190\n",
      "Iteration 7031, loss = 398.02557081\n",
      "Iteration 7032, loss = 398.02762703\n",
      "Iteration 7033, loss = 398.00869494\n",
      "Iteration 7034, loss = 397.99264501\n",
      "Iteration 7035, loss = 398.00089192\n",
      "Iteration 7036, loss = 397.98051264\n",
      "Iteration 7037, loss = 397.98956368\n",
      "Iteration 7038, loss = 397.98791297\n",
      "Iteration 7039, loss = 397.96686342\n",
      "Iteration 7040, loss = 397.95534286\n",
      "Iteration 7041, loss = 397.95697471\n",
      "Iteration 7042, loss = 397.93762753\n",
      "Iteration 7043, loss = 397.93484808\n",
      "Iteration 7044, loss = 397.91581481\n",
      "Iteration 7045, loss = 397.91210362\n",
      "Iteration 7046, loss = 397.89794694\n",
      "Iteration 7047, loss = 397.89898050\n",
      "Iteration 7048, loss = 397.90120847\n",
      "Iteration 7049, loss = 397.88691393\n",
      "Iteration 7050, loss = 397.87633891\n",
      "Iteration 7051, loss = 397.87783860\n",
      "Iteration 7052, loss = 397.88089791\n",
      "Iteration 7053, loss = 397.85752888\n",
      "Iteration 7054, loss = 397.86358396\n",
      "Iteration 7055, loss = 397.85976310\n",
      "Iteration 7056, loss = 397.83160678\n",
      "Iteration 7057, loss = 397.84178942\n",
      "Iteration 7058, loss = 397.83194087\n",
      "Iteration 7059, loss = 397.81992080\n",
      "Iteration 7060, loss = 397.81021468\n",
      "Iteration 7061, loss = 397.80592388\n",
      "Iteration 7062, loss = 397.80628609\n",
      "Iteration 7063, loss = 397.78343356\n",
      "Iteration 7064, loss = 397.77219118\n",
      "Iteration 7065, loss = 397.76944753\n",
      "Iteration 7066, loss = 397.74352445\n",
      "Iteration 7067, loss = 397.75023797\n",
      "Iteration 7068, loss = 397.74716100\n",
      "Iteration 7069, loss = 397.74104667\n",
      "Iteration 7070, loss = 397.72799808\n",
      "Iteration 7071, loss = 397.72684142\n",
      "Iteration 7072, loss = 397.72219742\n",
      "Iteration 7073, loss = 397.71302726\n",
      "Iteration 7074, loss = 397.71171773\n",
      "Iteration 7075, loss = 397.70145202\n",
      "Iteration 7076, loss = 397.68273028\n",
      "Iteration 7077, loss = 397.66173162\n",
      "Iteration 7078, loss = 397.65427585\n",
      "Iteration 7079, loss = 397.66218223\n",
      "Iteration 7080, loss = 397.66197205\n",
      "Iteration 7081, loss = 397.62838546\n",
      "Iteration 7082, loss = 397.63915865\n",
      "Iteration 7083, loss = 397.63639411\n",
      "Iteration 7084, loss = 397.65228301\n",
      "Iteration 7085, loss = 397.64954286\n",
      "Iteration 7086, loss = 397.63367727\n",
      "Iteration 7087, loss = 397.61804511\n",
      "Iteration 7088, loss = 397.60817516\n",
      "Iteration 7089, loss = 397.59356121\n",
      "Iteration 7090, loss = 397.58735487\n",
      "Iteration 7091, loss = 397.56560005\n",
      "Iteration 7092, loss = 397.56835337\n",
      "Iteration 7093, loss = 397.55568510\n",
      "Iteration 7094, loss = 397.55514344\n",
      "Iteration 7095, loss = 397.53728601\n",
      "Iteration 7096, loss = 397.53002242\n",
      "Iteration 7097, loss = 397.51514214\n",
      "Iteration 7098, loss = 397.51257761\n",
      "Iteration 7099, loss = 397.52935981\n",
      "Iteration 7100, loss = 397.50437248\n",
      "Iteration 7101, loss = 397.49109907\n",
      "Iteration 7102, loss = 397.49040295\n",
      "Iteration 7103, loss = 397.48763564\n",
      "Iteration 7104, loss = 397.48464196\n",
      "Iteration 7105, loss = 397.47286242\n",
      "Iteration 7106, loss = 397.45856664\n",
      "Iteration 7107, loss = 397.45600572\n",
      "Iteration 7108, loss = 397.46070006\n",
      "Iteration 7109, loss = 397.45194949\n",
      "Iteration 7110, loss = 397.44429816\n",
      "Iteration 7111, loss = 397.45031416\n",
      "Iteration 7112, loss = 397.45089304\n",
      "Iteration 7113, loss = 397.43765933\n",
      "Iteration 7114, loss = 397.41841959\n",
      "Iteration 7115, loss = 397.39844886\n",
      "Iteration 7116, loss = 397.40487561\n",
      "Iteration 7117, loss = 397.39021264\n",
      "Iteration 7118, loss = 397.37570091\n",
      "Iteration 7119, loss = 397.37109961\n",
      "Iteration 7120, loss = 397.37950409\n",
      "Iteration 7121, loss = 397.37360985\n",
      "Iteration 7122, loss = 397.35365547\n",
      "Iteration 7123, loss = 397.35756658\n",
      "Iteration 7124, loss = 397.35663230\n",
      "Iteration 7125, loss = 397.32647096\n",
      "Iteration 7126, loss = 397.31142793\n",
      "Iteration 7127, loss = 397.31775086\n",
      "Iteration 7128, loss = 397.31428366\n",
      "Iteration 7129, loss = 397.30889315\n",
      "Iteration 7130, loss = 397.29733662\n",
      "Iteration 7131, loss = 397.29266615\n",
      "Iteration 7132, loss = 397.26976395\n",
      "Iteration 7133, loss = 397.26291299\n",
      "Iteration 7134, loss = 397.26456150\n",
      "Iteration 7135, loss = 397.23783011\n",
      "Iteration 7136, loss = 397.24943139\n",
      "Iteration 7137, loss = 397.23666993\n",
      "Iteration 7138, loss = 397.23634979\n",
      "Iteration 7139, loss = 397.23014687\n",
      "Iteration 7140, loss = 397.21553382\n",
      "Iteration 7141, loss = 397.20814977\n",
      "Iteration 7142, loss = 397.19460718\n",
      "Iteration 7143, loss = 397.19511404\n",
      "Iteration 7144, loss = 397.18724013\n",
      "Iteration 7145, loss = 397.17666602\n",
      "Iteration 7146, loss = 397.17029650\n",
      "Iteration 7147, loss = 397.14458271\n",
      "Iteration 7148, loss = 397.15344266\n",
      "Iteration 7149, loss = 397.15351581\n",
      "Iteration 7150, loss = 397.14528747\n",
      "Iteration 7151, loss = 397.13606352\n",
      "Iteration 7152, loss = 397.13090484\n",
      "Iteration 7153, loss = 397.10278686\n",
      "Iteration 7154, loss = 397.12010534\n",
      "Iteration 7155, loss = 397.11439386\n",
      "Iteration 7156, loss = 397.09425398\n",
      "Iteration 7157, loss = 397.08029728\n",
      "Iteration 7158, loss = 397.08859970\n",
      "Iteration 7159, loss = 397.07526682\n",
      "Iteration 7160, loss = 397.06837393\n",
      "Iteration 7161, loss = 397.05559435\n",
      "Iteration 7162, loss = 397.04684102\n",
      "Iteration 7163, loss = 397.03652867\n",
      "Iteration 7164, loss = 397.02564983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7165, loss = 397.00840202\n",
      "Iteration 7166, loss = 397.00409756\n",
      "Iteration 7167, loss = 396.99891272\n",
      "Iteration 7168, loss = 396.97669814\n",
      "Iteration 7169, loss = 396.96782128\n",
      "Iteration 7170, loss = 396.97194316\n",
      "Iteration 7171, loss = 396.97901249\n",
      "Iteration 7172, loss = 396.97300591\n",
      "Iteration 7173, loss = 396.96140963\n",
      "Iteration 7174, loss = 396.95107857\n",
      "Iteration 7175, loss = 396.95276908\n",
      "Iteration 7176, loss = 396.93990984\n",
      "Iteration 7177, loss = 396.93714802\n",
      "Iteration 7178, loss = 396.91263024\n",
      "Iteration 7179, loss = 396.93168382\n",
      "Iteration 7180, loss = 396.91306133\n",
      "Iteration 7181, loss = 396.90101698\n",
      "Iteration 7182, loss = 396.89134702\n",
      "Iteration 7183, loss = 396.88132097\n",
      "Iteration 7184, loss = 396.87174834\n",
      "Iteration 7185, loss = 396.86578812\n",
      "Iteration 7186, loss = 396.84382148\n",
      "Iteration 7187, loss = 396.83465658\n",
      "Iteration 7188, loss = 396.84323829\n",
      "Iteration 7189, loss = 396.83442662\n",
      "Iteration 7190, loss = 396.81052782\n",
      "Iteration 7191, loss = 396.80319503\n",
      "Iteration 7192, loss = 396.79140347\n",
      "Iteration 7193, loss = 396.78150101\n",
      "Iteration 7194, loss = 396.77416686\n",
      "Iteration 7195, loss = 396.76550789\n",
      "Iteration 7196, loss = 396.76252610\n",
      "Iteration 7197, loss = 396.75207237\n",
      "Iteration 7198, loss = 396.74527229\n",
      "Iteration 7199, loss = 396.74707378\n",
      "Iteration 7200, loss = 396.71780415\n",
      "Iteration 7201, loss = 396.71646282\n",
      "Iteration 7202, loss = 396.72477518\n",
      "Iteration 7203, loss = 396.69723250\n",
      "Iteration 7204, loss = 396.69697271\n",
      "Iteration 7205, loss = 396.69811111\n",
      "Iteration 7206, loss = 396.68313448\n",
      "Iteration 7207, loss = 396.68196128\n",
      "Iteration 7208, loss = 396.66010280\n",
      "Iteration 7209, loss = 396.65392688\n",
      "Iteration 7210, loss = 396.64518682\n",
      "Iteration 7211, loss = 396.64218393\n",
      "Iteration 7212, loss = 396.64003032\n",
      "Iteration 7213, loss = 396.62268536\n",
      "Iteration 7214, loss = 396.59898052\n",
      "Iteration 7215, loss = 396.59509366\n",
      "Iteration 7216, loss = 396.60180507\n",
      "Iteration 7217, loss = 396.59012086\n",
      "Iteration 7218, loss = 396.56855738\n",
      "Iteration 7219, loss = 396.56665144\n",
      "Iteration 7220, loss = 396.55963463\n",
      "Iteration 7221, loss = 396.54805329\n",
      "Iteration 7222, loss = 396.53286354\n",
      "Iteration 7223, loss = 396.51841234\n",
      "Iteration 7224, loss = 396.52657674\n",
      "Iteration 7225, loss = 396.52109158\n",
      "Iteration 7226, loss = 396.50583822\n",
      "Iteration 7227, loss = 396.50521605\n",
      "Iteration 7228, loss = 396.50638347\n",
      "Iteration 7229, loss = 396.49942495\n",
      "Iteration 7230, loss = 396.47581951\n",
      "Iteration 7231, loss = 396.46178439\n",
      "Iteration 7232, loss = 396.45754256\n",
      "Iteration 7233, loss = 396.45449230\n",
      "Iteration 7234, loss = 396.44660633\n",
      "Iteration 7235, loss = 396.44091155\n",
      "Iteration 7236, loss = 396.42200341\n",
      "Iteration 7237, loss = 396.41740565\n",
      "Iteration 7238, loss = 396.41734881\n",
      "Iteration 7239, loss = 396.39728103\n",
      "Iteration 7240, loss = 396.38986496\n",
      "Iteration 7241, loss = 396.40366020\n",
      "Iteration 7242, loss = 396.39093785\n",
      "Iteration 7243, loss = 396.40206872\n",
      "Iteration 7244, loss = 396.38760900\n",
      "Iteration 7245, loss = 396.35686775\n",
      "Iteration 7246, loss = 396.35024180\n",
      "Iteration 7247, loss = 396.33096048\n",
      "Iteration 7248, loss = 396.35802367\n",
      "Iteration 7249, loss = 396.34560174\n",
      "Iteration 7250, loss = 396.32107658\n",
      "Iteration 7251, loss = 396.29525120\n",
      "Iteration 7252, loss = 396.30132371\n",
      "Iteration 7253, loss = 396.28335747\n",
      "Iteration 7254, loss = 396.27236753\n",
      "Iteration 7255, loss = 396.26732893\n",
      "Iteration 7256, loss = 396.26720462\n",
      "Iteration 7257, loss = 396.25228369\n",
      "Iteration 7258, loss = 396.24193240\n",
      "Iteration 7259, loss = 396.23444671\n",
      "Iteration 7260, loss = 396.22456753\n",
      "Iteration 7261, loss = 396.20992279\n",
      "Iteration 7262, loss = 396.20762388\n",
      "Iteration 7263, loss = 396.20783096\n",
      "Iteration 7264, loss = 396.18691434\n",
      "Iteration 7265, loss = 396.17995230\n",
      "Iteration 7266, loss = 396.17252502\n",
      "Iteration 7267, loss = 396.16179686\n",
      "Iteration 7268, loss = 396.15851655\n",
      "Iteration 7269, loss = 396.15108133\n",
      "Iteration 7270, loss = 396.14179472\n",
      "Iteration 7271, loss = 396.13531282\n",
      "Iteration 7272, loss = 396.11778877\n",
      "Iteration 7273, loss = 396.11526083\n",
      "Iteration 7274, loss = 396.10566833\n",
      "Iteration 7275, loss = 396.10975179\n",
      "Iteration 7276, loss = 396.10905578\n",
      "Iteration 7277, loss = 396.08763386\n",
      "Iteration 7278, loss = 396.07589837\n",
      "Iteration 7279, loss = 396.07827472\n",
      "Iteration 7280, loss = 396.06284331\n",
      "Iteration 7281, loss = 396.05987477\n",
      "Iteration 7282, loss = 396.05774679\n",
      "Iteration 7283, loss = 396.04328428\n",
      "Iteration 7284, loss = 396.02681370\n",
      "Iteration 7285, loss = 396.01914741\n",
      "Iteration 7286, loss = 396.01339253\n",
      "Iteration 7287, loss = 395.99528264\n",
      "Iteration 7288, loss = 396.00305991\n",
      "Iteration 7289, loss = 395.99261986\n",
      "Iteration 7290, loss = 395.97245359\n",
      "Iteration 7291, loss = 395.97254176\n",
      "Iteration 7292, loss = 395.97221894\n",
      "Iteration 7293, loss = 395.95876934\n",
      "Iteration 7294, loss = 395.96014578\n",
      "Iteration 7295, loss = 395.94712567\n",
      "Iteration 7296, loss = 395.93430027\n",
      "Iteration 7297, loss = 395.92452438\n",
      "Iteration 7298, loss = 395.93229486\n",
      "Iteration 7299, loss = 395.92876771\n",
      "Iteration 7300, loss = 395.91088027\n",
      "Iteration 7301, loss = 395.90630219\n",
      "Iteration 7302, loss = 395.89349910\n",
      "Iteration 7303, loss = 395.89511360\n",
      "Iteration 7304, loss = 395.89523406\n",
      "Iteration 7305, loss = 395.88035584\n",
      "Iteration 7306, loss = 395.87379732\n",
      "Iteration 7307, loss = 395.85484690\n",
      "Iteration 7308, loss = 395.83214953\n",
      "Iteration 7309, loss = 395.82649885\n",
      "Iteration 7310, loss = 395.81642810\n",
      "Iteration 7311, loss = 395.81105376\n",
      "Iteration 7312, loss = 395.80918784\n",
      "Iteration 7313, loss = 395.78294256\n",
      "Iteration 7314, loss = 395.78949497\n",
      "Iteration 7315, loss = 395.79112426\n",
      "Iteration 7316, loss = 395.77490997\n",
      "Iteration 7317, loss = 395.76326573\n",
      "Iteration 7318, loss = 395.75660768\n",
      "Iteration 7319, loss = 395.73860952\n",
      "Iteration 7320, loss = 395.73310107\n",
      "Iteration 7321, loss = 395.71387189\n",
      "Iteration 7322, loss = 395.71504284\n",
      "Iteration 7323, loss = 395.72736806\n",
      "Iteration 7324, loss = 395.70030954\n",
      "Iteration 7325, loss = 395.68738425\n",
      "Iteration 7326, loss = 395.68077650\n",
      "Iteration 7327, loss = 395.68956890\n",
      "Iteration 7328, loss = 395.68924572\n",
      "Iteration 7329, loss = 395.66029981\n",
      "Iteration 7330, loss = 395.64666357\n",
      "Iteration 7331, loss = 395.64261967\n",
      "Iteration 7332, loss = 395.62501983\n",
      "Iteration 7333, loss = 395.62389327\n",
      "Iteration 7334, loss = 395.61967008\n",
      "Iteration 7335, loss = 395.60959146\n",
      "Iteration 7336, loss = 395.57559162\n",
      "Iteration 7337, loss = 395.58393764\n",
      "Iteration 7338, loss = 395.58012395\n",
      "Iteration 7339, loss = 395.56252204\n",
      "Iteration 7340, loss = 395.55518849\n",
      "Iteration 7341, loss = 395.54654134\n",
      "Iteration 7342, loss = 395.53532587\n",
      "Iteration 7343, loss = 395.52731527\n",
      "Iteration 7344, loss = 395.52253767\n",
      "Iteration 7345, loss = 395.51155009\n",
      "Iteration 7346, loss = 395.52577873\n",
      "Iteration 7347, loss = 395.50593073\n",
      "Iteration 7348, loss = 395.49309331\n",
      "Iteration 7349, loss = 395.49729200\n",
      "Iteration 7350, loss = 395.47194029\n",
      "Iteration 7351, loss = 395.47815549\n",
      "Iteration 7352, loss = 395.48321937\n",
      "Iteration 7353, loss = 395.46623574\n",
      "Iteration 7354, loss = 395.45873367\n",
      "Iteration 7355, loss = 395.45042161\n",
      "Iteration 7356, loss = 395.43996164\n",
      "Iteration 7357, loss = 395.43045952\n",
      "Iteration 7358, loss = 395.44354989\n",
      "Iteration 7359, loss = 395.43500699\n",
      "Iteration 7360, loss = 395.41939621\n",
      "Iteration 7361, loss = 395.40292369\n",
      "Iteration 7362, loss = 395.39004798\n",
      "Iteration 7363, loss = 395.38166192\n",
      "Iteration 7364, loss = 395.37014678\n",
      "Iteration 7365, loss = 395.36161549\n",
      "Iteration 7366, loss = 395.35048597\n",
      "Iteration 7367, loss = 395.33679916\n",
      "Iteration 7368, loss = 395.33897515\n",
      "Iteration 7369, loss = 395.33342177\n",
      "Iteration 7370, loss = 395.33201442\n",
      "Iteration 7371, loss = 395.33912442\n",
      "Iteration 7372, loss = 395.30520456\n",
      "Iteration 7373, loss = 395.30866396\n",
      "Iteration 7374, loss = 395.31051762\n",
      "Iteration 7375, loss = 395.28650073\n",
      "Iteration 7376, loss = 395.28518990\n",
      "Iteration 7377, loss = 395.27939169\n",
      "Iteration 7378, loss = 395.26002702\n",
      "Iteration 7379, loss = 395.25271970\n",
      "Iteration 7380, loss = 395.25704336\n",
      "Iteration 7381, loss = 395.23181467\n",
      "Iteration 7382, loss = 395.21318692\n",
      "Iteration 7383, loss = 395.20449608\n",
      "Iteration 7384, loss = 395.20625546\n",
      "Iteration 7385, loss = 395.20968717\n",
      "Iteration 7386, loss = 395.19697837\n",
      "Iteration 7387, loss = 395.19286216\n",
      "Iteration 7388, loss = 395.17229460\n",
      "Iteration 7389, loss = 395.16166200\n",
      "Iteration 7390, loss = 395.14843789\n",
      "Iteration 7391, loss = 395.13179534\n",
      "Iteration 7392, loss = 395.12807587\n",
      "Iteration 7393, loss = 395.12172527\n",
      "Iteration 7394, loss = 395.12556090\n",
      "Iteration 7395, loss = 395.10257064\n",
      "Iteration 7396, loss = 395.08326603\n",
      "Iteration 7397, loss = 395.08690980\n",
      "Iteration 7398, loss = 395.07968393\n",
      "Iteration 7399, loss = 395.07384883\n",
      "Iteration 7400, loss = 395.07591010\n",
      "Iteration 7401, loss = 395.07038183\n",
      "Iteration 7402, loss = 395.05138899\n",
      "Iteration 7403, loss = 395.03500386\n",
      "Iteration 7404, loss = 395.04259361\n",
      "Iteration 7405, loss = 395.02439657\n",
      "Iteration 7406, loss = 394.99944599\n",
      "Iteration 7407, loss = 395.00102389\n",
      "Iteration 7408, loss = 394.99213647\n",
      "Iteration 7409, loss = 394.99613579\n",
      "Iteration 7410, loss = 394.98584005\n",
      "Iteration 7411, loss = 394.99261143\n",
      "Iteration 7412, loss = 394.96127916\n",
      "Iteration 7413, loss = 394.94250061\n",
      "Iteration 7414, loss = 394.93712179\n",
      "Iteration 7415, loss = 394.91223273\n",
      "Iteration 7416, loss = 394.92397889\n",
      "Iteration 7417, loss = 394.91724930\n",
      "Iteration 7418, loss = 394.92048092\n",
      "Iteration 7419, loss = 394.90023701\n",
      "Iteration 7420, loss = 394.88838373\n",
      "Iteration 7421, loss = 394.89460316\n",
      "Iteration 7422, loss = 394.89661397\n",
      "Iteration 7423, loss = 394.86882361\n",
      "Iteration 7424, loss = 394.84848496\n",
      "Iteration 7425, loss = 394.84971325\n",
      "Iteration 7426, loss = 394.83146039\n",
      "Iteration 7427, loss = 394.84236810\n",
      "Iteration 7428, loss = 394.83730443\n",
      "Iteration 7429, loss = 394.82374118\n",
      "Iteration 7430, loss = 394.80203668\n",
      "Iteration 7431, loss = 394.80528851\n",
      "Iteration 7432, loss = 394.81857334\n",
      "Iteration 7433, loss = 394.78794632\n",
      "Iteration 7434, loss = 394.79214147\n",
      "Iteration 7435, loss = 394.78831114\n",
      "Iteration 7436, loss = 394.78170846\n",
      "Iteration 7437, loss = 394.75894849\n",
      "Iteration 7438, loss = 394.74188893\n",
      "Iteration 7439, loss = 394.72890917\n",
      "Iteration 7440, loss = 394.71532339\n",
      "Iteration 7441, loss = 394.71138241\n",
      "Iteration 7442, loss = 394.68897126\n",
      "Iteration 7443, loss = 394.68242725\n",
      "Iteration 7444, loss = 394.66849151\n",
      "Iteration 7445, loss = 394.68010224\n",
      "Iteration 7446, loss = 394.67644466\n",
      "Iteration 7447, loss = 394.65680243\n",
      "Iteration 7448, loss = 394.65656947\n",
      "Iteration 7449, loss = 394.64934834\n",
      "Iteration 7450, loss = 394.64351457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7451, loss = 394.63303045\n",
      "Iteration 7452, loss = 394.60463799\n",
      "Iteration 7453, loss = 394.61301130\n",
      "Iteration 7454, loss = 394.61010642\n",
      "Iteration 7455, loss = 394.59322903\n",
      "Iteration 7456, loss = 394.58821714\n",
      "Iteration 7457, loss = 394.58272462\n",
      "Iteration 7458, loss = 394.56410632\n",
      "Iteration 7459, loss = 394.55108630\n",
      "Iteration 7460, loss = 394.55257541\n",
      "Iteration 7461, loss = 394.53988851\n",
      "Iteration 7462, loss = 394.53509504\n",
      "Iteration 7463, loss = 394.52218974\n",
      "Iteration 7464, loss = 394.51461620\n",
      "Iteration 7465, loss = 394.49741392\n",
      "Iteration 7466, loss = 394.50809995\n",
      "Iteration 7467, loss = 394.50063164\n",
      "Iteration 7468, loss = 394.48270507\n",
      "Iteration 7469, loss = 394.48882933\n",
      "Iteration 7470, loss = 394.49091040\n",
      "Iteration 7471, loss = 394.47840666\n",
      "Iteration 7472, loss = 394.46185876\n",
      "Iteration 7473, loss = 394.46328163\n",
      "Iteration 7474, loss = 394.43615246\n",
      "Iteration 7475, loss = 394.42072217\n",
      "Iteration 7476, loss = 394.43234409\n",
      "Iteration 7477, loss = 394.44720097\n",
      "Iteration 7478, loss = 394.42453587\n",
      "Iteration 7479, loss = 394.40046194\n",
      "Iteration 7480, loss = 394.38719343\n",
      "Iteration 7481, loss = 394.38959101\n",
      "Iteration 7482, loss = 394.38360903\n",
      "Iteration 7483, loss = 394.36014171\n",
      "Iteration 7484, loss = 394.33704972\n",
      "Iteration 7485, loss = 394.34075660\n",
      "Iteration 7486, loss = 394.35822434\n",
      "Iteration 7487, loss = 394.34546333\n",
      "Iteration 7488, loss = 394.33212048\n",
      "Iteration 7489, loss = 394.32244355\n",
      "Iteration 7490, loss = 394.30041920\n",
      "Iteration 7491, loss = 394.28610971\n",
      "Iteration 7492, loss = 394.28446556\n",
      "Iteration 7493, loss = 394.27002570\n",
      "Iteration 7494, loss = 394.26109174\n",
      "Iteration 7495, loss = 394.26055845\n",
      "Iteration 7496, loss = 394.25088719\n",
      "Iteration 7497, loss = 394.25209979\n",
      "Iteration 7498, loss = 394.24466858\n",
      "Iteration 7499, loss = 394.22809335\n",
      "Iteration 7500, loss = 394.20853380\n",
      "Iteration 7501, loss = 394.19579288\n",
      "Iteration 7502, loss = 394.18819404\n",
      "Iteration 7503, loss = 394.17566298\n",
      "Iteration 7504, loss = 394.17132581\n",
      "Iteration 7505, loss = 394.17333643\n",
      "Iteration 7506, loss = 394.15098407\n",
      "Iteration 7507, loss = 394.14594432\n",
      "Iteration 7508, loss = 394.14840632\n",
      "Iteration 7509, loss = 394.14396543\n",
      "Iteration 7510, loss = 394.15196142\n",
      "Iteration 7511, loss = 394.13338221\n",
      "Iteration 7512, loss = 394.10721435\n",
      "Iteration 7513, loss = 394.08795714\n",
      "Iteration 7514, loss = 394.10371983\n",
      "Iteration 7515, loss = 394.09909558\n",
      "Iteration 7516, loss = 394.09539294\n",
      "Iteration 7517, loss = 394.09781353\n",
      "Iteration 7518, loss = 394.09029499\n",
      "Iteration 7519, loss = 394.07766416\n",
      "Iteration 7520, loss = 394.04905828\n",
      "Iteration 7521, loss = 394.04076956\n",
      "Iteration 7522, loss = 394.01711718\n",
      "Iteration 7523, loss = 394.02448202\n",
      "Iteration 7524, loss = 394.01437516\n",
      "Iteration 7525, loss = 394.00710221\n",
      "Iteration 7526, loss = 393.97176166\n",
      "Iteration 7527, loss = 393.97918820\n",
      "Iteration 7528, loss = 393.96914945\n",
      "Iteration 7529, loss = 393.98119861\n",
      "Iteration 7530, loss = 393.97490001\n",
      "Iteration 7531, loss = 393.95114841\n",
      "Iteration 7532, loss = 393.93646003\n",
      "Iteration 7533, loss = 393.91493161\n",
      "Iteration 7534, loss = 393.90904597\n",
      "Iteration 7535, loss = 393.91583502\n",
      "Iteration 7536, loss = 393.90918939\n",
      "Iteration 7537, loss = 393.89065487\n",
      "Iteration 7538, loss = 393.87619713\n",
      "Iteration 7539, loss = 393.88079030\n",
      "Iteration 7540, loss = 393.87904153\n",
      "Iteration 7541, loss = 393.88252212\n",
      "Iteration 7542, loss = 393.88177270\n",
      "Iteration 7543, loss = 393.86376028\n",
      "Iteration 7544, loss = 393.82627918\n",
      "Iteration 7545, loss = 393.83353802\n",
      "Iteration 7546, loss = 393.81198842\n",
      "Iteration 7547, loss = 393.81942128\n",
      "Iteration 7548, loss = 393.82964968\n",
      "Iteration 7549, loss = 393.81714162\n",
      "Iteration 7550, loss = 393.76963254\n",
      "Iteration 7551, loss = 393.77901866\n",
      "Iteration 7552, loss = 393.78461716\n",
      "Iteration 7553, loss = 393.78038000\n",
      "Iteration 7554, loss = 393.76653544\n",
      "Iteration 7555, loss = 393.74573362\n",
      "Iteration 7556, loss = 393.73002735\n",
      "Iteration 7557, loss = 393.71219391\n",
      "Iteration 7558, loss = 393.70509147\n",
      "Iteration 7559, loss = 393.71437823\n",
      "Iteration 7560, loss = 393.70914732\n",
      "Iteration 7561, loss = 393.70066511\n",
      "Iteration 7562, loss = 393.66893964\n",
      "Iteration 7563, loss = 393.67866852\n",
      "Iteration 7564, loss = 393.68342570\n",
      "Iteration 7565, loss = 393.69590444\n",
      "Iteration 7566, loss = 393.67127502\n",
      "Iteration 7567, loss = 393.65597360\n",
      "Iteration 7568, loss = 393.62626598\n",
      "Iteration 7569, loss = 393.60514022\n",
      "Iteration 7570, loss = 393.60498796\n",
      "Iteration 7571, loss = 393.58003594\n",
      "Iteration 7572, loss = 393.56341291\n",
      "Iteration 7573, loss = 393.56516542\n",
      "Iteration 7574, loss = 393.57118762\n",
      "Iteration 7575, loss = 393.56407786\n",
      "Iteration 7576, loss = 393.53304969\n",
      "Iteration 7577, loss = 393.51924440\n",
      "Iteration 7578, loss = 393.51345985\n",
      "Iteration 7579, loss = 393.52969730\n",
      "Iteration 7580, loss = 393.50470712\n",
      "Iteration 7581, loss = 393.48493114\n",
      "Iteration 7582, loss = 393.49678409\n",
      "Iteration 7583, loss = 393.49734648\n",
      "Iteration 7584, loss = 393.48370539\n",
      "Iteration 7585, loss = 393.47546898\n",
      "Iteration 7586, loss = 393.47199837\n",
      "Iteration 7587, loss = 393.45173520\n",
      "Iteration 7588, loss = 393.43524128\n",
      "Iteration 7589, loss = 393.41950078\n",
      "Iteration 7590, loss = 393.42729483\n",
      "Iteration 7591, loss = 393.42803858\n",
      "Iteration 7592, loss = 393.42029090\n",
      "Iteration 7593, loss = 393.38401990\n",
      "Iteration 7594, loss = 393.38866266\n",
      "Iteration 7595, loss = 393.40922716\n",
      "Iteration 7596, loss = 393.40127428\n",
      "Iteration 7597, loss = 393.38688911\n",
      "Iteration 7598, loss = 393.36637365\n",
      "Iteration 7599, loss = 393.34578318\n",
      "Iteration 7600, loss = 393.33466233\n",
      "Iteration 7601, loss = 393.33722414\n",
      "Iteration 7602, loss = 393.30861279\n",
      "Iteration 7603, loss = 393.30376097\n",
      "Iteration 7604, loss = 393.31421415\n",
      "Iteration 7605, loss = 393.30346387\n",
      "Iteration 7606, loss = 393.29354396\n",
      "Iteration 7607, loss = 393.29647278\n",
      "Iteration 7608, loss = 393.27898833\n",
      "Iteration 7609, loss = 393.25735056\n",
      "Iteration 7610, loss = 393.26303214\n",
      "Iteration 7611, loss = 393.25678250\n",
      "Iteration 7612, loss = 393.24605405\n",
      "Iteration 7613, loss = 393.21607181\n",
      "Iteration 7614, loss = 393.19457054\n",
      "Iteration 7615, loss = 393.20258340\n",
      "Iteration 7616, loss = 393.20273866\n",
      "Iteration 7617, loss = 393.22250970\n",
      "Iteration 7618, loss = 393.21248186\n",
      "Iteration 7619, loss = 393.18515588\n",
      "Iteration 7620, loss = 393.16587632\n",
      "Iteration 7621, loss = 393.12959695\n",
      "Iteration 7622, loss = 393.13290696\n",
      "Iteration 7623, loss = 393.13859030\n",
      "Iteration 7624, loss = 393.12674463\n",
      "Iteration 7625, loss = 393.07959983\n",
      "Iteration 7626, loss = 393.09323098\n",
      "Iteration 7627, loss = 393.10095740\n",
      "Iteration 7628, loss = 393.09326311\n",
      "Iteration 7629, loss = 393.11113053\n",
      "Iteration 7630, loss = 393.08530289\n",
      "Iteration 7631, loss = 393.08085376\n",
      "Iteration 7632, loss = 393.07063671\n",
      "Iteration 7633, loss = 393.05301415\n",
      "Iteration 7634, loss = 393.04945334\n",
      "Iteration 7635, loss = 393.04898355\n",
      "Iteration 7636, loss = 393.02377114\n",
      "Iteration 7637, loss = 392.99231591\n",
      "Iteration 7638, loss = 392.99239068\n",
      "Iteration 7639, loss = 392.99270548\n",
      "Iteration 7640, loss = 392.96763357\n",
      "Iteration 7641, loss = 392.95357487\n",
      "Iteration 7642, loss = 392.95868237\n",
      "Iteration 7643, loss = 392.95042099\n",
      "Iteration 7644, loss = 392.92866441\n",
      "Iteration 7645, loss = 392.94175378\n",
      "Iteration 7646, loss = 392.93119160\n",
      "Iteration 7647, loss = 392.91121132\n",
      "Iteration 7648, loss = 392.91870419\n",
      "Iteration 7649, loss = 392.89769582\n",
      "Iteration 7650, loss = 392.89942285\n",
      "Iteration 7651, loss = 392.90222087\n",
      "Iteration 7652, loss = 392.89287698\n",
      "Iteration 7653, loss = 392.88913345\n",
      "Iteration 7654, loss = 392.88698712\n",
      "Iteration 7655, loss = 392.88521660\n",
      "Iteration 7656, loss = 392.88553754\n",
      "Iteration 7657, loss = 392.86582375\n",
      "Iteration 7658, loss = 392.82493537\n",
      "Iteration 7659, loss = 392.81352358\n",
      "Iteration 7660, loss = 392.80427963\n",
      "Iteration 7661, loss = 392.80542631\n",
      "Iteration 7662, loss = 392.80007092\n",
      "Iteration 7663, loss = 392.78588317\n",
      "Iteration 7664, loss = 392.77149132\n",
      "Iteration 7665, loss = 392.74162019\n",
      "Iteration 7666, loss = 392.75043607\n",
      "Iteration 7667, loss = 392.74786824\n",
      "Iteration 7668, loss = 392.75786524\n",
      "Iteration 7669, loss = 392.73603416\n",
      "Iteration 7670, loss = 392.74099562\n",
      "Iteration 7671, loss = 392.74580714\n",
      "Iteration 7672, loss = 392.73228617\n",
      "Iteration 7673, loss = 392.74685669\n",
      "Iteration 7674, loss = 392.72279759\n",
      "Iteration 7675, loss = 392.70960363\n",
      "Iteration 7676, loss = 392.68458245\n",
      "Iteration 7677, loss = 392.66014091\n",
      "Iteration 7678, loss = 392.67631922\n",
      "Iteration 7679, loss = 392.68547069\n",
      "Iteration 7680, loss = 392.64893414\n",
      "Iteration 7681, loss = 392.63460321\n",
      "Iteration 7682, loss = 392.64149758\n",
      "Iteration 7683, loss = 392.63869937\n",
      "Iteration 7684, loss = 392.61953475\n",
      "Iteration 7685, loss = 392.60115668\n",
      "Iteration 7686, loss = 392.60594925\n",
      "Iteration 7687, loss = 392.60308691\n",
      "Iteration 7688, loss = 392.56551177\n",
      "Iteration 7689, loss = 392.55414182\n",
      "Iteration 7690, loss = 392.55911408\n",
      "Iteration 7691, loss = 392.55299859\n",
      "Iteration 7692, loss = 392.56014266\n",
      "Iteration 7693, loss = 392.52530093\n",
      "Iteration 7694, loss = 392.54523339\n",
      "Iteration 7695, loss = 392.53714951\n",
      "Iteration 7696, loss = 392.52949794\n",
      "Iteration 7697, loss = 392.50024047\n",
      "Iteration 7698, loss = 392.47944967\n",
      "Iteration 7699, loss = 392.47616570\n",
      "Iteration 7700, loss = 392.46771522\n",
      "Iteration 7701, loss = 392.46959804\n",
      "Iteration 7702, loss = 392.46438753\n",
      "Iteration 7703, loss = 392.46192361\n",
      "Iteration 7704, loss = 392.43117392\n",
      "Iteration 7705, loss = 392.44675931\n",
      "Iteration 7706, loss = 392.43206427\n",
      "Iteration 7707, loss = 392.42649452\n",
      "Iteration 7708, loss = 392.41509203\n",
      "Iteration 7709, loss = 392.42011963\n",
      "Iteration 7710, loss = 392.41025595\n",
      "Iteration 7711, loss = 392.40711581\n",
      "Iteration 7712, loss = 392.37370624\n",
      "Iteration 7713, loss = 392.35238342\n",
      "Iteration 7714, loss = 392.37515530\n",
      "Iteration 7715, loss = 392.36986945\n",
      "Iteration 7716, loss = 392.34187880\n",
      "Iteration 7717, loss = 392.32700409\n",
      "Iteration 7718, loss = 392.32329385\n",
      "Iteration 7719, loss = 392.30517811\n",
      "Iteration 7720, loss = 392.29127088\n",
      "Iteration 7721, loss = 392.27915649\n",
      "Iteration 7722, loss = 392.27634777\n",
      "Iteration 7723, loss = 392.26833540\n",
      "Iteration 7724, loss = 392.26474855\n",
      "Iteration 7725, loss = 392.26431627\n",
      "Iteration 7726, loss = 392.25778977\n",
      "Iteration 7727, loss = 392.24660076\n",
      "Iteration 7728, loss = 392.22439217\n",
      "Iteration 7729, loss = 392.22364365\n",
      "Iteration 7730, loss = 392.21489829\n",
      "Iteration 7731, loss = 392.18223968\n",
      "Iteration 7732, loss = 392.19397300\n",
      "Iteration 7733, loss = 392.18750698\n",
      "Iteration 7734, loss = 392.18826991\n",
      "Iteration 7735, loss = 392.17378429\n",
      "Iteration 7736, loss = 392.17992982\n",
      "Iteration 7737, loss = 392.13958600\n",
      "Iteration 7738, loss = 392.13706823\n",
      "Iteration 7739, loss = 392.13936294\n",
      "Iteration 7740, loss = 392.14616690\n",
      "Iteration 7741, loss = 392.12785132\n",
      "Iteration 7742, loss = 392.09768689\n",
      "Iteration 7743, loss = 392.11517532\n",
      "Iteration 7744, loss = 392.12438668\n",
      "Iteration 7745, loss = 392.09936767\n",
      "Iteration 7746, loss = 392.08587152\n",
      "Iteration 7747, loss = 392.09069837\n",
      "Iteration 7748, loss = 392.06422189\n",
      "Iteration 7749, loss = 392.06634487\n",
      "Iteration 7750, loss = 392.03851775\n",
      "Iteration 7751, loss = 392.02210333\n",
      "Iteration 7752, loss = 392.02613055\n",
      "Iteration 7753, loss = 392.00178781\n",
      "Iteration 7754, loss = 391.95996692\n",
      "Iteration 7755, loss = 391.96491072\n",
      "Iteration 7756, loss = 391.96641162\n",
      "Iteration 7757, loss = 391.94882296\n",
      "Iteration 7758, loss = 391.93868655\n",
      "Iteration 7759, loss = 391.93423001\n",
      "Iteration 7760, loss = 391.92482432\n",
      "Iteration 7761, loss = 391.89298617\n",
      "Iteration 7762, loss = 391.86752068\n",
      "Iteration 7763, loss = 391.89072098\n",
      "Iteration 7764, loss = 391.88425815\n",
      "Iteration 7765, loss = 391.88953229\n",
      "Iteration 7766, loss = 391.84924367\n",
      "Iteration 7767, loss = 391.82572088\n",
      "Iteration 7768, loss = 391.83439714\n",
      "Iteration 7769, loss = 391.82007669\n",
      "Iteration 7770, loss = 391.80502178\n",
      "Iteration 7771, loss = 391.78694722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7772, loss = 391.78119800\n",
      "Iteration 7773, loss = 391.76633153\n",
      "Iteration 7774, loss = 391.73771103\n",
      "Iteration 7775, loss = 391.73337157\n",
      "Iteration 7776, loss = 391.72076007\n",
      "Iteration 7777, loss = 391.71151590\n",
      "Iteration 7778, loss = 391.70920656\n",
      "Iteration 7779, loss = 391.69296462\n",
      "Iteration 7780, loss = 391.67475767\n",
      "Iteration 7781, loss = 391.65895098\n",
      "Iteration 7782, loss = 391.62294051\n",
      "Iteration 7783, loss = 391.61221439\n",
      "Iteration 7784, loss = 391.62942530\n",
      "Iteration 7785, loss = 391.59667309\n",
      "Iteration 7786, loss = 391.56763376\n",
      "Iteration 7787, loss = 391.57347980\n",
      "Iteration 7788, loss = 391.54088560\n",
      "Iteration 7789, loss = 391.54627151\n",
      "Iteration 7790, loss = 391.53598477\n",
      "Iteration 7791, loss = 391.50090780\n",
      "Iteration 7792, loss = 391.50674916\n",
      "Iteration 7793, loss = 391.49694691\n",
      "Iteration 7794, loss = 391.47400492\n",
      "Iteration 7795, loss = 391.46201506\n",
      "Iteration 7796, loss = 391.45783345\n",
      "Iteration 7797, loss = 391.42771237\n",
      "Iteration 7798, loss = 391.40898645\n",
      "Iteration 7799, loss = 391.40433233\n",
      "Iteration 7800, loss = 391.39400464\n",
      "Iteration 7801, loss = 391.37244657\n",
      "Iteration 7802, loss = 391.35616112\n",
      "Iteration 7803, loss = 391.33897079\n",
      "Iteration 7804, loss = 391.32564905\n",
      "Iteration 7805, loss = 391.30302089\n",
      "Iteration 7806, loss = 391.29999432\n",
      "Iteration 7807, loss = 391.28264329\n",
      "Iteration 7808, loss = 391.26100386\n",
      "Iteration 7809, loss = 391.25099440\n",
      "Iteration 7810, loss = 391.23828508\n",
      "Iteration 7811, loss = 391.23490781\n",
      "Iteration 7812, loss = 391.21917578\n",
      "Iteration 7813, loss = 391.20509156\n",
      "Iteration 7814, loss = 391.18443933\n",
      "Iteration 7815, loss = 391.17929572\n",
      "Iteration 7816, loss = 391.15613467\n",
      "Iteration 7817, loss = 391.13995920\n",
      "Iteration 7818, loss = 391.14688679\n",
      "Iteration 7819, loss = 391.12355943\n",
      "Iteration 7820, loss = 391.10007161\n",
      "Iteration 7821, loss = 391.09962912\n",
      "Iteration 7822, loss = 391.08017318\n",
      "Iteration 7823, loss = 391.06302274\n",
      "Iteration 7824, loss = 391.05181971\n",
      "Iteration 7825, loss = 391.04186133\n",
      "Iteration 7826, loss = 391.01344002\n",
      "Iteration 7827, loss = 390.98981474\n",
      "Iteration 7828, loss = 390.99441560\n",
      "Iteration 7829, loss = 390.99746185\n",
      "Iteration 7830, loss = 390.97423307\n",
      "Iteration 7831, loss = 390.95732903\n",
      "Iteration 7832, loss = 390.94481219\n",
      "Iteration 7833, loss = 390.91605460\n",
      "Iteration 7834, loss = 390.91039256\n",
      "Iteration 7835, loss = 390.90554669\n",
      "Iteration 7836, loss = 390.89129514\n",
      "Iteration 7837, loss = 390.86641731\n",
      "Iteration 7838, loss = 390.85489018\n",
      "Iteration 7839, loss = 390.84040807\n",
      "Iteration 7840, loss = 390.84861401\n",
      "Iteration 7841, loss = 390.83225174\n",
      "Iteration 7842, loss = 390.81281717\n",
      "Iteration 7843, loss = 390.80102038\n",
      "Iteration 7844, loss = 390.79533950\n",
      "Iteration 7845, loss = 390.78279822\n",
      "Iteration 7846, loss = 390.75603694\n",
      "Iteration 7847, loss = 390.75640381\n",
      "Iteration 7848, loss = 390.73221565\n",
      "Iteration 7849, loss = 390.71445015\n",
      "Iteration 7850, loss = 390.68788699\n",
      "Iteration 7851, loss = 390.69799861\n",
      "Iteration 7852, loss = 390.69383514\n",
      "Iteration 7853, loss = 390.66839456\n",
      "Iteration 7854, loss = 390.66603744\n",
      "Iteration 7855, loss = 390.64808461\n",
      "Iteration 7856, loss = 390.64937455\n",
      "Iteration 7857, loss = 390.63502717\n",
      "Iteration 7858, loss = 390.61044779\n",
      "Iteration 7859, loss = 390.59081847\n",
      "Iteration 7860, loss = 390.57311675\n",
      "Iteration 7861, loss = 390.55783953\n",
      "Iteration 7862, loss = 390.56024423\n",
      "Iteration 7863, loss = 390.53661321\n",
      "Iteration 7864, loss = 390.52288730\n",
      "Iteration 7865, loss = 390.51921550\n",
      "Iteration 7866, loss = 390.52413596\n",
      "Iteration 7867, loss = 390.51344331\n",
      "Iteration 7868, loss = 390.49696659\n",
      "Iteration 7869, loss = 390.46756615\n",
      "Iteration 7870, loss = 390.47574391\n",
      "Iteration 7871, loss = 390.44025455\n",
      "Iteration 7872, loss = 390.40070900\n",
      "Iteration 7873, loss = 390.41065246\n",
      "Iteration 7874, loss = 390.40061144\n",
      "Iteration 7875, loss = 390.38776559\n",
      "Iteration 7876, loss = 390.36686715\n",
      "Iteration 7877, loss = 390.33975721\n",
      "Iteration 7878, loss = 390.34300800\n",
      "Iteration 7879, loss = 390.35239346\n",
      "Iteration 7880, loss = 390.32608669\n",
      "Iteration 7881, loss = 390.29732099\n",
      "Iteration 7882, loss = 390.29493215\n",
      "Iteration 7883, loss = 390.29153826\n",
      "Iteration 7884, loss = 390.25581189\n",
      "Iteration 7885, loss = 390.24361286\n",
      "Iteration 7886, loss = 390.23648833\n",
      "Iteration 7887, loss = 390.21452461\n",
      "Iteration 7888, loss = 390.21370485\n",
      "Iteration 7889, loss = 390.19478159\n",
      "Iteration 7890, loss = 390.18719526\n",
      "Iteration 7891, loss = 390.16355781\n",
      "Iteration 7892, loss = 390.15513193\n",
      "Iteration 7893, loss = 390.13044906\n",
      "Iteration 7894, loss = 390.12435212\n",
      "Iteration 7895, loss = 390.11586266\n",
      "Iteration 7896, loss = 390.10204562\n",
      "Iteration 7897, loss = 390.09724685\n",
      "Iteration 7898, loss = 390.07738587\n",
      "Iteration 7899, loss = 390.08249214\n",
      "Iteration 7900, loss = 390.06671259\n",
      "Iteration 7901, loss = 390.03622234\n",
      "Iteration 7902, loss = 390.03873241\n",
      "Iteration 7903, loss = 390.04265235\n",
      "Iteration 7904, loss = 390.03271785\n",
      "Iteration 7905, loss = 390.01795158\n",
      "Iteration 7906, loss = 389.99794358\n",
      "Iteration 7907, loss = 389.98001043\n",
      "Iteration 7908, loss = 389.98533518\n",
      "Iteration 7909, loss = 389.97485811\n",
      "Iteration 7910, loss = 389.93408615\n",
      "Iteration 7911, loss = 389.92581238\n",
      "Iteration 7912, loss = 389.94766282\n",
      "Iteration 7913, loss = 389.93733217\n",
      "Iteration 7914, loss = 389.91549095\n",
      "Iteration 7915, loss = 389.90679272\n",
      "Iteration 7916, loss = 389.91203249\n",
      "Iteration 7917, loss = 389.89404171\n",
      "Iteration 7918, loss = 389.85758341\n",
      "Iteration 7919, loss = 389.83083119\n",
      "Iteration 7920, loss = 389.84304827\n",
      "Iteration 7921, loss = 389.84641440\n",
      "Iteration 7922, loss = 389.83325474\n",
      "Iteration 7923, loss = 389.81530628\n",
      "Iteration 7924, loss = 389.80756477\n",
      "Iteration 7925, loss = 389.78110136\n",
      "Iteration 7926, loss = 389.76370132\n",
      "Iteration 7927, loss = 389.75908983\n",
      "Iteration 7928, loss = 389.72973366\n",
      "Iteration 7929, loss = 389.71109762\n",
      "Iteration 7930, loss = 389.71339063\n",
      "Iteration 7931, loss = 389.70341724\n",
      "Iteration 7932, loss = 389.70834909\n",
      "Iteration 7933, loss = 389.69681879\n",
      "Iteration 7934, loss = 389.65972356\n",
      "Iteration 7935, loss = 389.65069313\n",
      "Iteration 7936, loss = 389.65969746\n",
      "Iteration 7937, loss = 389.63093513\n",
      "Iteration 7938, loss = 389.61338620\n",
      "Iteration 7939, loss = 389.60032000\n",
      "Iteration 7940, loss = 389.58862304\n",
      "Iteration 7941, loss = 389.57429974\n",
      "Iteration 7942, loss = 389.57925476\n",
      "Iteration 7943, loss = 389.55468936\n",
      "Iteration 7944, loss = 389.55103350\n",
      "Iteration 7945, loss = 389.52351253\n",
      "Iteration 7946, loss = 389.49396109\n",
      "Iteration 7947, loss = 389.51360499\n",
      "Iteration 7948, loss = 389.51416998\n",
      "Iteration 7949, loss = 389.49147883\n",
      "Iteration 7950, loss = 389.47313738\n",
      "Iteration 7951, loss = 389.45089009\n",
      "Iteration 7952, loss = 389.43756054\n",
      "Iteration 7953, loss = 389.44900944\n",
      "Iteration 7954, loss = 389.43096424\n",
      "Iteration 7955, loss = 389.42771843\n",
      "Iteration 7956, loss = 389.40993991\n",
      "Iteration 7957, loss = 389.40002606\n",
      "Iteration 7958, loss = 389.39005323\n",
      "Iteration 7959, loss = 389.39020579\n",
      "Iteration 7960, loss = 389.37025638\n",
      "Iteration 7961, loss = 389.33637449\n",
      "Iteration 7962, loss = 389.33711556\n",
      "Iteration 7963, loss = 389.31971765\n",
      "Iteration 7964, loss = 389.28861496\n",
      "Iteration 7965, loss = 389.28845893\n",
      "Iteration 7966, loss = 389.28050737\n",
      "Iteration 7967, loss = 389.25828649\n",
      "Iteration 7968, loss = 389.24871256\n",
      "Iteration 7969, loss = 389.23070518\n",
      "Iteration 7970, loss = 389.23554540\n",
      "Iteration 7971, loss = 389.22484774\n",
      "Iteration 7972, loss = 389.21294701\n",
      "Iteration 7973, loss = 389.20805877\n",
      "Iteration 7974, loss = 389.18361602\n",
      "Iteration 7975, loss = 389.15878339\n",
      "Iteration 7976, loss = 389.16714184\n",
      "Iteration 7977, loss = 389.17713353\n",
      "Iteration 7978, loss = 389.16287580\n",
      "Iteration 7979, loss = 389.15749924\n",
      "Iteration 7980, loss = 389.14268850\n",
      "Iteration 7981, loss = 389.13808497\n",
      "Iteration 7982, loss = 389.11593034\n",
      "Iteration 7983, loss = 389.11798767\n",
      "Iteration 7984, loss = 389.10280093\n",
      "Iteration 7985, loss = 389.08748303\n",
      "Iteration 7986, loss = 389.05268005\n",
      "Iteration 7987, loss = 389.07288079\n",
      "Iteration 7988, loss = 389.07269262\n",
      "Iteration 7989, loss = 389.04722592\n",
      "Iteration 7990, loss = 389.02871492\n",
      "Iteration 7991, loss = 389.02411237\n",
      "Iteration 7992, loss = 389.01953996\n",
      "Iteration 7993, loss = 388.99988645\n",
      "Iteration 7994, loss = 388.95856575\n",
      "Iteration 7995, loss = 388.94400521\n",
      "Iteration 7996, loss = 388.94350560\n",
      "Iteration 7997, loss = 388.95885713\n",
      "Iteration 7998, loss = 388.93972781\n",
      "Iteration 7999, loss = 388.91056879\n",
      "Iteration 8000, loss = 388.87122576\n",
      "Iteration 8001, loss = 388.88887466\n",
      "Iteration 8002, loss = 388.88736112\n",
      "Iteration 8003, loss = 388.87743371\n",
      "Iteration 8004, loss = 388.86566194\n",
      "Iteration 8005, loss = 388.83222820\n",
      "Iteration 8006, loss = 388.81679215\n",
      "Iteration 8007, loss = 388.82093280\n",
      "Iteration 8008, loss = 388.80059507\n",
      "Iteration 8009, loss = 388.80563688\n",
      "Iteration 8010, loss = 388.80284592\n",
      "Iteration 8011, loss = 388.79974081\n",
      "Iteration 8012, loss = 388.77403946\n",
      "Iteration 8013, loss = 388.75546229\n",
      "Iteration 8014, loss = 388.75165828\n",
      "Iteration 8015, loss = 388.74099566\n",
      "Iteration 8016, loss = 388.72855687\n",
      "Iteration 8017, loss = 388.74449897\n",
      "Iteration 8018, loss = 388.73985286\n",
      "Iteration 8019, loss = 388.69629298\n",
      "Iteration 8020, loss = 388.68857156\n",
      "Iteration 8021, loss = 388.69576384\n",
      "Iteration 8022, loss = 388.68444959\n",
      "Iteration 8023, loss = 388.65156737\n",
      "Iteration 8024, loss = 388.64221483\n",
      "Iteration 8025, loss = 388.61308711\n",
      "Iteration 8026, loss = 388.59146434\n",
      "Iteration 8027, loss = 388.58457753\n",
      "Iteration 8028, loss = 388.57534755\n",
      "Iteration 8029, loss = 388.54818303\n",
      "Iteration 8030, loss = 388.54076006\n",
      "Iteration 8031, loss = 388.55123959\n",
      "Iteration 8032, loss = 388.54461976\n",
      "Iteration 8033, loss = 388.52073005\n",
      "Iteration 8034, loss = 388.50951860\n",
      "Iteration 8035, loss = 388.50301747\n",
      "Iteration 8036, loss = 388.48277561\n",
      "Iteration 8037, loss = 388.46899818\n",
      "Iteration 8038, loss = 388.45837331\n",
      "Iteration 8039, loss = 388.42852595\n",
      "Iteration 8040, loss = 388.43425774\n",
      "Iteration 8041, loss = 388.45267618\n",
      "Iteration 8042, loss = 388.44473121\n",
      "Iteration 8043, loss = 388.42097184\n",
      "Iteration 8044, loss = 388.40455250\n",
      "Iteration 8045, loss = 388.37739821\n",
      "Iteration 8046, loss = 388.37490566\n",
      "Iteration 8047, loss = 388.36750563\n",
      "Iteration 8048, loss = 388.34920301\n",
      "Iteration 8049, loss = 388.31977299\n",
      "Iteration 8050, loss = 388.31255885\n",
      "Iteration 8051, loss = 388.30285081\n",
      "Iteration 8052, loss = 388.29099738\n",
      "Iteration 8053, loss = 388.30290353\n",
      "Iteration 8054, loss = 388.30841007\n",
      "Iteration 8055, loss = 388.30001664\n",
      "Iteration 8056, loss = 388.31873349\n",
      "Iteration 8057, loss = 388.30043199\n",
      "Iteration 8058, loss = 388.27881296\n",
      "Iteration 8059, loss = 388.25768324\n",
      "Iteration 8060, loss = 388.23110864\n",
      "Iteration 8061, loss = 388.22475531\n",
      "Iteration 8062, loss = 388.24190205\n",
      "Iteration 8063, loss = 388.20697822\n",
      "Iteration 8064, loss = 388.19615950\n",
      "Iteration 8065, loss = 388.20014029\n",
      "Iteration 8066, loss = 388.20271712\n",
      "Iteration 8067, loss = 388.18983260\n",
      "Iteration 8068, loss = 388.16778216\n",
      "Iteration 8069, loss = 388.15137514\n",
      "Iteration 8070, loss = 388.14258021\n",
      "Iteration 8071, loss = 388.12513974\n",
      "Iteration 8072, loss = 388.11060070\n",
      "Iteration 8073, loss = 388.11374621\n",
      "Iteration 8074, loss = 388.09895996\n",
      "Iteration 8075, loss = 388.09637782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8076, loss = 388.07705391\n",
      "Iteration 8077, loss = 388.05720667\n",
      "Iteration 8078, loss = 388.04349794\n",
      "Iteration 8079, loss = 388.01812321\n",
      "Iteration 8080, loss = 387.99896343\n",
      "Iteration 8081, loss = 388.01464780\n",
      "Iteration 8082, loss = 388.00340844\n",
      "Iteration 8083, loss = 387.99816614\n",
      "Iteration 8084, loss = 387.98854900\n",
      "Iteration 8085, loss = 387.98543353\n",
      "Iteration 8086, loss = 387.96501872\n",
      "Iteration 8087, loss = 387.94261809\n",
      "Iteration 8088, loss = 387.92864353\n",
      "Iteration 8089, loss = 387.91718620\n",
      "Iteration 8090, loss = 387.90095049\n",
      "Iteration 8091, loss = 387.88981713\n",
      "Iteration 8092, loss = 387.88819061\n",
      "Iteration 8093, loss = 387.87697915\n",
      "Iteration 8094, loss = 387.87272826\n",
      "Iteration 8095, loss = 387.86058197\n",
      "Iteration 8096, loss = 387.85725491\n",
      "Iteration 8097, loss = 387.84654308\n",
      "Iteration 8098, loss = 387.84041252\n",
      "Iteration 8099, loss = 387.84196984\n",
      "Iteration 8100, loss = 387.83293901\n",
      "Iteration 8101, loss = 387.81238437\n",
      "Iteration 8102, loss = 387.80666390\n",
      "Iteration 8103, loss = 387.81386945\n",
      "Iteration 8104, loss = 387.80448862\n",
      "Iteration 8105, loss = 387.78825334\n",
      "Iteration 8106, loss = 387.79082541\n",
      "Iteration 8107, loss = 387.78279622\n",
      "Iteration 8108, loss = 387.78567595\n",
      "Iteration 8109, loss = 387.78111435\n",
      "Iteration 8110, loss = 387.77587771\n",
      "Iteration 8111, loss = 387.77074401\n",
      "Iteration 8112, loss = 387.74864456\n",
      "Iteration 8113, loss = 387.73791023\n",
      "Iteration 8114, loss = 387.75232327\n",
      "Iteration 8115, loss = 387.75201689\n",
      "Iteration 8116, loss = 387.71586158\n",
      "Iteration 8117, loss = 387.71893131\n",
      "Iteration 8118, loss = 387.69575261\n",
      "Iteration 8119, loss = 387.68942199\n",
      "Iteration 8120, loss = 387.69422833\n",
      "Iteration 8121, loss = 387.69445857\n",
      "Iteration 8122, loss = 387.68331978\n",
      "Iteration 8123, loss = 387.66799790\n",
      "Iteration 8124, loss = 387.66607996\n",
      "Iteration 8125, loss = 387.65143131\n",
      "Iteration 8126, loss = 387.64967936\n",
      "Iteration 8127, loss = 387.64148686\n",
      "Iteration 8128, loss = 387.63904339\n",
      "Iteration 8129, loss = 387.64983856\n",
      "Iteration 8130, loss = 387.62552742\n",
      "Iteration 8131, loss = 387.61264730\n",
      "Iteration 8132, loss = 387.60960478\n",
      "Iteration 8133, loss = 387.59969607\n",
      "Iteration 8134, loss = 387.57567642\n",
      "Iteration 8135, loss = 387.58090303\n",
      "Iteration 8136, loss = 387.58363042\n",
      "Iteration 8137, loss = 387.56214085\n",
      "Iteration 8138, loss = 387.55369133\n",
      "Iteration 8139, loss = 387.55595347\n",
      "Iteration 8140, loss = 387.55884668\n",
      "Iteration 8141, loss = 387.54263084\n",
      "Iteration 8142, loss = 387.53584839\n",
      "Iteration 8143, loss = 387.50730885\n",
      "Iteration 8144, loss = 387.51033657\n",
      "Iteration 8145, loss = 387.52539923\n",
      "Iteration 8146, loss = 387.51622209\n",
      "Iteration 8147, loss = 387.49483336\n",
      "Iteration 8148, loss = 387.49169654\n",
      "Iteration 8149, loss = 387.50085075\n",
      "Iteration 8150, loss = 387.50105410\n",
      "Iteration 8151, loss = 387.46180628\n",
      "Iteration 8152, loss = 387.44277734\n",
      "Iteration 8153, loss = 387.46150019\n",
      "Iteration 8154, loss = 387.45760691\n",
      "Iteration 8155, loss = 387.42979115\n",
      "Iteration 8156, loss = 387.42575212\n",
      "Iteration 8157, loss = 387.44182801\n",
      "Iteration 8158, loss = 387.43528852\n",
      "Iteration 8159, loss = 387.42669016\n",
      "Iteration 8160, loss = 387.40596277\n",
      "Iteration 8161, loss = 387.41930503\n",
      "Iteration 8162, loss = 387.39906489\n",
      "Iteration 8163, loss = 387.37518730\n",
      "Iteration 8164, loss = 387.37335149\n",
      "Iteration 8165, loss = 387.38332636\n",
      "Iteration 8166, loss = 387.35931334\n",
      "Iteration 8167, loss = 387.36641800\n",
      "Iteration 8168, loss = 387.36090404\n",
      "Iteration 8169, loss = 387.34500422\n",
      "Iteration 8170, loss = 387.35531962\n",
      "Iteration 8171, loss = 387.33322441\n",
      "Iteration 8172, loss = 387.31185902\n",
      "Iteration 8173, loss = 387.30744620\n",
      "Iteration 8174, loss = 387.31459316\n",
      "Iteration 8175, loss = 387.29388411\n",
      "Iteration 8176, loss = 387.27732194\n",
      "Iteration 8177, loss = 387.28294908\n",
      "Iteration 8178, loss = 387.28401772\n",
      "Iteration 8179, loss = 387.27080011\n",
      "Iteration 8180, loss = 387.26708260\n",
      "Iteration 8181, loss = 387.24160313\n",
      "Iteration 8182, loss = 387.27004211\n",
      "Iteration 8183, loss = 387.26981108\n",
      "Iteration 8184, loss = 387.23901848\n",
      "Iteration 8185, loss = 387.25160230\n",
      "Iteration 8186, loss = 387.25672968\n",
      "Iteration 8187, loss = 387.25186143\n",
      "Iteration 8188, loss = 387.24785045\n",
      "Iteration 8189, loss = 387.24825985\n",
      "Iteration 8190, loss = 387.22345449\n",
      "Iteration 8191, loss = 387.22116166\n",
      "Iteration 8192, loss = 387.22874006\n",
      "Iteration 8193, loss = 387.21122225\n",
      "Iteration 8194, loss = 387.19971429\n",
      "Iteration 8195, loss = 387.20230124\n",
      "Iteration 8196, loss = 387.20766848\n",
      "Iteration 8197, loss = 387.20336588\n",
      "Iteration 8198, loss = 387.18545527\n",
      "Iteration 8199, loss = 387.16219696\n",
      "Iteration 8200, loss = 387.14809635\n",
      "Iteration 8201, loss = 387.12821763\n",
      "Iteration 8202, loss = 387.15759790\n",
      "Iteration 8203, loss = 387.16175935\n",
      "Iteration 8204, loss = 387.14679045\n",
      "Iteration 8205, loss = 387.13110053\n",
      "Iteration 8206, loss = 387.13656576\n",
      "Iteration 8207, loss = 387.14206956\n",
      "Iteration 8208, loss = 387.13729880\n",
      "Iteration 8209, loss = 387.12893285\n",
      "Iteration 8210, loss = 387.12538799\n",
      "Iteration 8211, loss = 387.07995570\n",
      "Iteration 8212, loss = 387.08101809\n",
      "Iteration 8213, loss = 387.06711042\n",
      "Iteration 8214, loss = 387.05961389\n",
      "Iteration 8215, loss = 387.05414097\n",
      "Iteration 8216, loss = 387.05941941\n",
      "Iteration 8217, loss = 387.03019311\n",
      "Iteration 8218, loss = 387.04210630\n",
      "Iteration 8219, loss = 387.05271634\n",
      "Iteration 8220, loss = 387.05326702\n",
      "Iteration 8221, loss = 387.06110581\n",
      "Iteration 8222, loss = 387.05067104\n",
      "Iteration 8223, loss = 387.02024908\n",
      "Iteration 8224, loss = 387.01795675\n",
      "Iteration 8225, loss = 387.01744026\n",
      "Iteration 8226, loss = 387.00140496\n",
      "Iteration 8227, loss = 387.00356179\n",
      "Iteration 8228, loss = 386.98416899\n",
      "Iteration 8229, loss = 386.95966127\n",
      "Iteration 8230, loss = 386.97639844\n",
      "Iteration 8231, loss = 386.98088553\n",
      "Iteration 8232, loss = 386.96297790\n",
      "Iteration 8233, loss = 386.96780717\n",
      "Iteration 8234, loss = 386.96673469\n",
      "Iteration 8235, loss = 386.96799779\n",
      "Iteration 8236, loss = 386.94671793\n",
      "Iteration 8237, loss = 386.94202941\n",
      "Iteration 8238, loss = 386.93120864\n",
      "Iteration 8239, loss = 386.92253531\n",
      "Iteration 8240, loss = 386.94214069\n",
      "Iteration 8241, loss = 386.92847532\n",
      "Iteration 8242, loss = 386.91730798\n",
      "Iteration 8243, loss = 386.90994947\n",
      "Iteration 8244, loss = 386.90155417\n",
      "Iteration 8245, loss = 386.90358127\n",
      "Iteration 8246, loss = 386.90111265\n",
      "Iteration 8247, loss = 386.86980371\n",
      "Iteration 8248, loss = 386.85799761\n",
      "Iteration 8249, loss = 386.85916182\n",
      "Iteration 8250, loss = 386.84682308\n",
      "Iteration 8251, loss = 386.83976844\n",
      "Iteration 8252, loss = 386.82836465\n",
      "Iteration 8253, loss = 386.83451592\n",
      "Iteration 8254, loss = 386.82806935\n",
      "Iteration 8255, loss = 386.81116525\n",
      "Iteration 8256, loss = 386.80015400\n",
      "Iteration 8257, loss = 386.81423611\n",
      "Iteration 8258, loss = 386.80991318\n",
      "Iteration 8259, loss = 386.79028769\n",
      "Iteration 8260, loss = 386.78740809\n",
      "Iteration 8261, loss = 386.79523965\n",
      "Iteration 8262, loss = 386.79647850\n",
      "Iteration 8263, loss = 386.79118935\n",
      "Iteration 8264, loss = 386.80031200\n",
      "Iteration 8265, loss = 386.79744851\n",
      "Iteration 8266, loss = 386.76922930\n",
      "Iteration 8267, loss = 386.74886506\n",
      "Iteration 8268, loss = 386.76519490\n",
      "Iteration 8269, loss = 386.77366300\n",
      "Iteration 8270, loss = 386.75282752\n",
      "Iteration 8271, loss = 386.71582486\n",
      "Iteration 8272, loss = 386.71465060\n",
      "Iteration 8273, loss = 386.71476722\n",
      "Iteration 8274, loss = 386.71651139\n",
      "Iteration 8275, loss = 386.70904800\n",
      "Iteration 8276, loss = 386.71921482\n",
      "Iteration 8277, loss = 386.70805766\n",
      "Iteration 8278, loss = 386.68440273\n",
      "Iteration 8279, loss = 386.69646152\n",
      "Iteration 8280, loss = 386.68461978\n",
      "Iteration 8281, loss = 386.67262935\n",
      "Iteration 8282, loss = 386.70016844\n",
      "Iteration 8283, loss = 386.69607978\n",
      "Iteration 8284, loss = 386.68206274\n",
      "Iteration 8285, loss = 386.66041488\n",
      "Iteration 8286, loss = 386.66311644\n",
      "Iteration 8287, loss = 386.66134513\n",
      "Iteration 8288, loss = 386.64620196\n",
      "Iteration 8289, loss = 386.64580400\n",
      "Iteration 8290, loss = 386.63936655\n",
      "Iteration 8291, loss = 386.62155873\n",
      "Iteration 8292, loss = 386.62766812\n",
      "Iteration 8293, loss = 386.63692265\n",
      "Iteration 8294, loss = 386.62669029\n",
      "Iteration 8295, loss = 386.62159761\n",
      "Iteration 8296, loss = 386.60640147\n",
      "Iteration 8297, loss = 386.58927043\n",
      "Iteration 8298, loss = 386.58614067\n",
      "Iteration 8299, loss = 386.58910280\n",
      "Iteration 8300, loss = 386.55974724\n",
      "Iteration 8301, loss = 386.55578895\n",
      "Iteration 8302, loss = 386.55436639\n",
      "Iteration 8303, loss = 386.55757753\n",
      "Iteration 8304, loss = 386.55335958\n",
      "Iteration 8305, loss = 386.54231360\n",
      "Iteration 8306, loss = 386.53653456\n",
      "Iteration 8307, loss = 386.53594753\n",
      "Iteration 8308, loss = 386.53671644\n",
      "Iteration 8309, loss = 386.51915607\n",
      "Iteration 8310, loss = 386.50509107\n",
      "Iteration 8311, loss = 386.53409404\n",
      "Iteration 8312, loss = 386.53882058\n",
      "Iteration 8313, loss = 386.48063904\n",
      "Iteration 8314, loss = 386.46986976\n",
      "Iteration 8315, loss = 386.49597412\n",
      "Iteration 8316, loss = 386.50487300\n",
      "Iteration 8317, loss = 386.49897237\n",
      "Iteration 8318, loss = 386.47166623\n",
      "Iteration 8319, loss = 386.46106606\n",
      "Iteration 8320, loss = 386.44836748\n",
      "Iteration 8321, loss = 386.45475096\n",
      "Iteration 8322, loss = 386.44948157\n",
      "Iteration 8323, loss = 386.42384585\n",
      "Iteration 8324, loss = 386.42283981\n",
      "Iteration 8325, loss = 386.41712818\n",
      "Iteration 8326, loss = 386.43186096\n",
      "Iteration 8327, loss = 386.43688988\n",
      "Iteration 8328, loss = 386.40710048\n",
      "Iteration 8329, loss = 386.39078049\n",
      "Iteration 8330, loss = 386.39024313\n",
      "Iteration 8331, loss = 386.42343430\n",
      "Iteration 8332, loss = 386.43420185\n",
      "Iteration 8333, loss = 386.40971178\n",
      "Iteration 8334, loss = 386.36987564\n",
      "Iteration 8335, loss = 386.38167832\n",
      "Iteration 8336, loss = 386.38272635\n",
      "Iteration 8337, loss = 386.39642676\n",
      "Iteration 8338, loss = 386.39994760\n",
      "Iteration 8339, loss = 386.38229878\n",
      "Iteration 8340, loss = 386.37772876\n",
      "Iteration 8341, loss = 386.36229126\n",
      "Iteration 8342, loss = 386.34020520\n",
      "Iteration 8343, loss = 386.35150524\n",
      "Iteration 8344, loss = 386.35948190\n",
      "Iteration 8345, loss = 386.33282662\n",
      "Iteration 8346, loss = 386.32585047\n",
      "Iteration 8347, loss = 386.30889174\n",
      "Iteration 8348, loss = 386.28218619\n",
      "Iteration 8349, loss = 386.30007935\n",
      "Iteration 8350, loss = 386.30973373\n",
      "Iteration 8351, loss = 386.31624335\n",
      "Iteration 8352, loss = 386.30592799\n",
      "Iteration 8353, loss = 386.27578040\n",
      "Iteration 8354, loss = 386.26828901\n",
      "Iteration 8355, loss = 386.26265139\n",
      "Iteration 8356, loss = 386.24208852\n",
      "Iteration 8357, loss = 386.23500872\n",
      "Iteration 8358, loss = 386.23540265\n",
      "Iteration 8359, loss = 386.23370204\n",
      "Iteration 8360, loss = 386.25070058\n",
      "Iteration 8361, loss = 386.22453910\n",
      "Iteration 8362, loss = 386.24241358\n",
      "Iteration 8363, loss = 386.23243142\n",
      "Iteration 8364, loss = 386.20797059\n",
      "Iteration 8365, loss = 386.19065459\n",
      "Iteration 8366, loss = 386.19428939\n",
      "Iteration 8367, loss = 386.18797736\n",
      "Iteration 8368, loss = 386.17224401\n",
      "Iteration 8369, loss = 386.17414549\n",
      "Iteration 8370, loss = 386.18440791\n",
      "Iteration 8371, loss = 386.17993957\n",
      "Iteration 8372, loss = 386.15512275\n",
      "Iteration 8373, loss = 386.15399051\n",
      "Iteration 8374, loss = 386.13478994\n",
      "Iteration 8375, loss = 386.13282507\n",
      "Iteration 8376, loss = 386.14822338\n",
      "Iteration 8377, loss = 386.14295673\n",
      "Iteration 8378, loss = 386.12797362\n",
      "Iteration 8379, loss = 386.11193234\n",
      "Iteration 8380, loss = 386.13424675\n",
      "Iteration 8381, loss = 386.13381601\n",
      "Iteration 8382, loss = 386.12226923\n",
      "Iteration 8383, loss = 386.12268731\n",
      "Iteration 8384, loss = 386.09278565\n",
      "Iteration 8385, loss = 386.09289722\n",
      "Iteration 8386, loss = 386.11827258\n",
      "Iteration 8387, loss = 386.09199723\n",
      "Iteration 8388, loss = 386.04745805\n",
      "Iteration 8389, loss = 386.06046286\n",
      "Iteration 8390, loss = 386.09253571\n",
      "Iteration 8391, loss = 386.08296247\n",
      "Iteration 8392, loss = 386.05180234\n",
      "Iteration 8393, loss = 386.06417978\n",
      "Iteration 8394, loss = 386.05540737\n",
      "Iteration 8395, loss = 386.03366452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8396, loss = 386.01231616\n",
      "Iteration 8397, loss = 386.02492604\n",
      "Iteration 8398, loss = 386.00828842\n",
      "Iteration 8399, loss = 385.98296856\n",
      "Iteration 8400, loss = 386.01453159\n",
      "Iteration 8401, loss = 386.00088526\n",
      "Iteration 8402, loss = 385.97501189\n",
      "Iteration 8403, loss = 385.97843149\n",
      "Iteration 8404, loss = 385.97949536\n",
      "Iteration 8405, loss = 385.97730971\n",
      "Iteration 8406, loss = 385.96845725\n",
      "Iteration 8407, loss = 385.96711704\n",
      "Iteration 8408, loss = 385.98241726\n",
      "Iteration 8409, loss = 385.95962648\n",
      "Iteration 8410, loss = 385.94984859\n",
      "Iteration 8411, loss = 385.94338812\n",
      "Iteration 8412, loss = 385.93312975\n",
      "Iteration 8413, loss = 385.92061491\n",
      "Iteration 8414, loss = 385.92057240\n",
      "Iteration 8415, loss = 385.91305947\n",
      "Iteration 8416, loss = 385.90021291\n",
      "Iteration 8417, loss = 385.89720664\n",
      "Iteration 8418, loss = 385.88652990\n",
      "Iteration 8419, loss = 385.87787075\n",
      "Iteration 8420, loss = 385.90226218\n",
      "Iteration 8421, loss = 385.89377609\n",
      "Iteration 8422, loss = 385.86894837\n",
      "Iteration 8423, loss = 385.86234506\n",
      "Iteration 8424, loss = 385.86930011\n",
      "Iteration 8425, loss = 385.86069203\n",
      "Iteration 8426, loss = 385.84330222\n",
      "Iteration 8427, loss = 385.82924203\n",
      "Iteration 8428, loss = 385.83906372\n",
      "Iteration 8429, loss = 385.84545601\n",
      "Iteration 8430, loss = 385.83410990\n",
      "Iteration 8431, loss = 385.83444469\n",
      "Iteration 8432, loss = 385.81968387\n",
      "Iteration 8433, loss = 385.79309071\n",
      "Iteration 8434, loss = 385.79556775\n",
      "Iteration 8435, loss = 385.80335543\n",
      "Iteration 8436, loss = 385.78664661\n",
      "Iteration 8437, loss = 385.79421933\n",
      "Iteration 8438, loss = 385.81917033\n",
      "Iteration 8439, loss = 385.79811223\n",
      "Iteration 8440, loss = 385.77842550\n",
      "Iteration 8441, loss = 385.78630674\n",
      "Iteration 8442, loss = 385.77491106\n",
      "Iteration 8443, loss = 385.75006811\n",
      "Iteration 8444, loss = 385.75026218\n",
      "Iteration 8445, loss = 385.74944376\n",
      "Iteration 8446, loss = 385.74405236\n",
      "Iteration 8447, loss = 385.74183081\n",
      "Iteration 8448, loss = 385.73313775\n",
      "Iteration 8449, loss = 385.72900140\n",
      "Iteration 8450, loss = 385.70050095\n",
      "Iteration 8451, loss = 385.71929899\n",
      "Iteration 8452, loss = 385.72060132\n",
      "Iteration 8453, loss = 385.70926802\n",
      "Iteration 8454, loss = 385.70206104\n",
      "Iteration 8455, loss = 385.70707667\n",
      "Iteration 8456, loss = 385.69290486\n",
      "Iteration 8457, loss = 385.68543624\n",
      "Iteration 8458, loss = 385.68672139\n",
      "Iteration 8459, loss = 385.69962408\n",
      "Iteration 8460, loss = 385.70009312\n",
      "Iteration 8461, loss = 385.68050939\n",
      "Iteration 8462, loss = 385.67644562\n",
      "Iteration 8463, loss = 385.66377304\n",
      "Iteration 8464, loss = 385.66691444\n",
      "Iteration 8465, loss = 385.65831501\n",
      "Iteration 8466, loss = 385.62790668\n",
      "Iteration 8467, loss = 385.62052450\n",
      "Iteration 8468, loss = 385.61131327\n",
      "Iteration 8469, loss = 385.62610062\n",
      "Iteration 8470, loss = 385.61129219\n",
      "Iteration 8471, loss = 385.59139920\n",
      "Iteration 8472, loss = 385.61454859\n",
      "Iteration 8473, loss = 385.59325477\n",
      "Iteration 8474, loss = 385.58537475\n",
      "Iteration 8475, loss = 385.59715011\n",
      "Iteration 8476, loss = 385.57968719\n",
      "Iteration 8477, loss = 385.57640373\n",
      "Iteration 8478, loss = 385.58074398\n",
      "Iteration 8479, loss = 385.59223758\n",
      "Iteration 8480, loss = 385.58155321\n",
      "Iteration 8481, loss = 385.55982954\n",
      "Iteration 8482, loss = 385.54624657\n",
      "Iteration 8483, loss = 385.54011271\n",
      "Iteration 8484, loss = 385.54412948\n",
      "Iteration 8485, loss = 385.51677146\n",
      "Iteration 8486, loss = 385.52411264\n",
      "Iteration 8487, loss = 385.55368580\n",
      "Iteration 8488, loss = 385.54574873\n",
      "Iteration 8489, loss = 385.52879709\n",
      "Iteration 8490, loss = 385.52243950\n",
      "Iteration 8491, loss = 385.52775412\n",
      "Iteration 8492, loss = 385.50625148\n",
      "Iteration 8493, loss = 385.47587692\n",
      "Iteration 8494, loss = 385.48080064\n",
      "Iteration 8495, loss = 385.47501700\n",
      "Iteration 8496, loss = 385.49152657\n",
      "Iteration 8497, loss = 385.47033919\n",
      "Iteration 8498, loss = 385.46391641\n",
      "Iteration 8499, loss = 385.45586053\n",
      "Iteration 8500, loss = 385.45704551\n",
      "Iteration 8501, loss = 385.45429654\n",
      "Iteration 8502, loss = 385.43615355\n",
      "Iteration 8503, loss = 385.43861807\n",
      "Iteration 8504, loss = 385.43485917\n",
      "Iteration 8505, loss = 385.43831566\n",
      "Iteration 8506, loss = 385.41454690\n",
      "Iteration 8507, loss = 385.41592218\n",
      "Iteration 8508, loss = 385.41881167\n",
      "Iteration 8509, loss = 385.43534069\n",
      "Iteration 8510, loss = 385.44741973\n",
      "Iteration 8511, loss = 385.44015173\n",
      "Iteration 8512, loss = 385.40907210\n",
      "Iteration 8513, loss = 385.38595691\n",
      "Iteration 8514, loss = 385.35901890\n",
      "Iteration 8515, loss = 385.38454624\n",
      "Iteration 8516, loss = 385.37736139\n",
      "Iteration 8517, loss = 385.36770593\n",
      "Iteration 8518, loss = 385.35326346\n",
      "Iteration 8519, loss = 385.35951938\n",
      "Iteration 8520, loss = 385.36559479\n",
      "Iteration 8521, loss = 385.36080884\n",
      "Iteration 8522, loss = 385.35930265\n",
      "Iteration 8523, loss = 385.33468455\n",
      "Iteration 8524, loss = 385.33715250\n",
      "Iteration 8525, loss = 385.33806243\n",
      "Iteration 8526, loss = 385.30208023\n",
      "Iteration 8527, loss = 385.27779772\n",
      "Iteration 8528, loss = 385.28142304\n",
      "Iteration 8529, loss = 385.28918436\n",
      "Iteration 8530, loss = 385.28129287\n",
      "Iteration 8531, loss = 385.28223242\n",
      "Iteration 8532, loss = 385.30307969\n",
      "Iteration 8533, loss = 385.28616456\n",
      "Iteration 8534, loss = 385.26814052\n",
      "Iteration 8535, loss = 385.25505593\n",
      "Iteration 8536, loss = 385.26305166\n",
      "Iteration 8537, loss = 385.26900732\n",
      "Iteration 8538, loss = 385.24233934\n",
      "Iteration 8539, loss = 385.22901063\n",
      "Iteration 8540, loss = 385.23400357\n",
      "Iteration 8541, loss = 385.21756062\n",
      "Iteration 8542, loss = 385.22535114\n",
      "Iteration 8543, loss = 385.22510836\n",
      "Iteration 8544, loss = 385.18677896\n",
      "Iteration 8545, loss = 385.19504262\n",
      "Iteration 8546, loss = 385.19700582\n",
      "Iteration 8547, loss = 385.20268428\n",
      "Iteration 8548, loss = 385.18892793\n",
      "Iteration 8549, loss = 385.18424709\n",
      "Iteration 8550, loss = 385.20087536\n",
      "Iteration 8551, loss = 385.19304092\n",
      "Iteration 8552, loss = 385.17682615\n",
      "Iteration 8553, loss = 385.14779957\n",
      "Iteration 8554, loss = 385.14463381\n",
      "Iteration 8555, loss = 385.18090459\n",
      "Iteration 8556, loss = 385.17526282\n",
      "Iteration 8557, loss = 385.14820121\n",
      "Iteration 8558, loss = 385.14494639\n",
      "Iteration 8559, loss = 385.13895661\n",
      "Iteration 8560, loss = 385.11793624\n",
      "Iteration 8561, loss = 385.12941899\n",
      "Iteration 8562, loss = 385.12632541\n",
      "Iteration 8563, loss = 385.13331609\n",
      "Iteration 8564, loss = 385.12229701\n",
      "Iteration 8565, loss = 385.11513810\n",
      "Iteration 8566, loss = 385.11448479\n",
      "Iteration 8567, loss = 385.10081360\n",
      "Iteration 8568, loss = 385.08661006\n",
      "Iteration 8569, loss = 385.06048599\n",
      "Iteration 8570, loss = 385.10076983\n",
      "Iteration 8571, loss = 385.10895729\n",
      "Iteration 8572, loss = 385.07575693\n",
      "Iteration 8573, loss = 385.03386023\n",
      "Iteration 8574, loss = 385.04590968\n",
      "Iteration 8575, loss = 385.06511620\n",
      "Iteration 8576, loss = 385.03892270\n",
      "Iteration 8577, loss = 385.02305918\n",
      "Iteration 8578, loss = 385.03813924\n",
      "Iteration 8579, loss = 385.03841606\n",
      "Iteration 8580, loss = 385.02595151\n",
      "Iteration 8581, loss = 385.02935603\n",
      "Iteration 8582, loss = 385.01297712\n",
      "Iteration 8583, loss = 385.00499598\n",
      "Iteration 8584, loss = 385.02144578\n",
      "Iteration 8585, loss = 385.01411964\n",
      "Iteration 8586, loss = 385.01153527\n",
      "Iteration 8587, loss = 384.97514623\n",
      "Iteration 8588, loss = 384.97337127\n",
      "Iteration 8589, loss = 384.97268562\n",
      "Iteration 8590, loss = 384.96218418\n",
      "Iteration 8591, loss = 384.97714760\n",
      "Iteration 8592, loss = 384.94703014\n",
      "Iteration 8593, loss = 384.93499275\n",
      "Iteration 8594, loss = 384.93179959\n",
      "Iteration 8595, loss = 384.94411853\n",
      "Iteration 8596, loss = 384.91145128\n",
      "Iteration 8597, loss = 384.90407288\n",
      "Iteration 8598, loss = 384.93273565\n",
      "Iteration 8599, loss = 384.92634845\n",
      "Iteration 8600, loss = 384.91087690\n",
      "Iteration 8601, loss = 384.91490093\n",
      "Iteration 8602, loss = 384.90301428\n",
      "Iteration 8603, loss = 384.89452445\n",
      "Iteration 8604, loss = 384.86355632\n",
      "Iteration 8605, loss = 384.86779534\n",
      "Iteration 8606, loss = 384.87400228\n",
      "Iteration 8607, loss = 384.89280346\n",
      "Iteration 8608, loss = 384.87073568\n",
      "Iteration 8609, loss = 384.83918247\n",
      "Iteration 8610, loss = 384.87267023\n",
      "Iteration 8611, loss = 384.86964515\n",
      "Iteration 8612, loss = 384.83907323\n",
      "Iteration 8613, loss = 384.82124968\n",
      "Iteration 8614, loss = 384.82381915\n",
      "Iteration 8615, loss = 384.83592556\n",
      "Iteration 8616, loss = 384.82493760\n",
      "Iteration 8617, loss = 384.80770287\n",
      "Iteration 8618, loss = 384.79884134\n",
      "Iteration 8619, loss = 384.79385371\n",
      "Iteration 8620, loss = 384.79540224\n",
      "Iteration 8621, loss = 384.79303684\n",
      "Iteration 8622, loss = 384.79099085\n",
      "Iteration 8623, loss = 384.78222896\n",
      "Iteration 8624, loss = 384.77002343\n",
      "Iteration 8625, loss = 384.76353930\n",
      "Iteration 8626, loss = 384.75084578\n",
      "Iteration 8627, loss = 384.74310903\n",
      "Iteration 8628, loss = 384.75729598\n",
      "Iteration 8629, loss = 384.76517693\n",
      "Iteration 8630, loss = 384.74086374\n",
      "Iteration 8631, loss = 384.74386566\n",
      "Iteration 8632, loss = 384.73720851\n",
      "Iteration 8633, loss = 384.75685222\n",
      "Iteration 8634, loss = 384.75602925\n",
      "Iteration 8635, loss = 384.74536616\n",
      "Iteration 8636, loss = 384.74243898\n",
      "Iteration 8637, loss = 384.73658467\n",
      "Iteration 8638, loss = 384.71132971\n",
      "Iteration 8639, loss = 384.70306862\n",
      "Iteration 8640, loss = 384.70037162\n",
      "Iteration 8641, loss = 384.67183480\n",
      "Iteration 8642, loss = 384.67504368\n",
      "Iteration 8643, loss = 384.68548452\n",
      "Iteration 8644, loss = 384.68262353\n",
      "Iteration 8645, loss = 384.67153504\n",
      "Iteration 8646, loss = 384.66423921\n",
      "Iteration 8647, loss = 384.65471247\n",
      "Iteration 8648, loss = 384.64073998\n",
      "Iteration 8649, loss = 384.63921148\n",
      "Iteration 8650, loss = 384.65395097\n",
      "Iteration 8651, loss = 384.64847106\n",
      "Iteration 8652, loss = 384.61946116\n",
      "Iteration 8653, loss = 384.63736457\n",
      "Iteration 8654, loss = 384.62075364\n",
      "Iteration 8655, loss = 384.60788582\n",
      "Iteration 8656, loss = 384.61630438\n",
      "Iteration 8657, loss = 384.59191757\n",
      "Iteration 8658, loss = 384.60543205\n",
      "Iteration 8659, loss = 384.58719289\n",
      "Iteration 8660, loss = 384.58250630\n",
      "Iteration 8661, loss = 384.57766556\n",
      "Iteration 8662, loss = 384.56098681\n",
      "Iteration 8663, loss = 384.56936057\n",
      "Iteration 8664, loss = 384.59024905\n",
      "Iteration 8665, loss = 384.58852300\n",
      "Iteration 8666, loss = 384.57632830\n",
      "Iteration 8667, loss = 384.55274453\n",
      "Iteration 8668, loss = 384.56285387\n",
      "Iteration 8669, loss = 384.55968433\n",
      "Iteration 8670, loss = 384.53697973\n",
      "Iteration 8671, loss = 384.53953413\n",
      "Iteration 8672, loss = 384.52479188\n",
      "Iteration 8673, loss = 384.52849804\n",
      "Iteration 8674, loss = 384.50238790\n",
      "Iteration 8675, loss = 384.51863420\n",
      "Iteration 8676, loss = 384.51559089\n",
      "Iteration 8677, loss = 384.49556021\n",
      "Iteration 8678, loss = 384.50039883\n",
      "Iteration 8679, loss = 384.51129263\n",
      "Iteration 8680, loss = 384.49806878\n",
      "Iteration 8681, loss = 384.47632052\n",
      "Iteration 8682, loss = 384.46935196\n",
      "Iteration 8683, loss = 384.46972295\n",
      "Iteration 8684, loss = 384.48358474\n",
      "Iteration 8685, loss = 384.44428266\n",
      "Iteration 8686, loss = 384.46806199\n",
      "Iteration 8687, loss = 384.45499858\n",
      "Iteration 8688, loss = 384.45758569\n",
      "Iteration 8689, loss = 384.44659691\n",
      "Iteration 8690, loss = 384.45147950\n",
      "Iteration 8691, loss = 384.46727797\n",
      "Iteration 8692, loss = 384.44266170\n",
      "Iteration 8693, loss = 384.41939838\n",
      "Iteration 8694, loss = 384.39637885\n",
      "Iteration 8695, loss = 384.42529324\n",
      "Iteration 8696, loss = 384.41850190\n",
      "Iteration 8697, loss = 384.39609099\n",
      "Iteration 8698, loss = 384.40104687\n",
      "Iteration 8699, loss = 384.40092697\n",
      "Iteration 8700, loss = 384.38737089\n",
      "Iteration 8701, loss = 384.35114977\n",
      "Iteration 8702, loss = 384.37140471\n",
      "Iteration 8703, loss = 384.38137291\n",
      "Iteration 8704, loss = 384.34333900\n",
      "Iteration 8705, loss = 384.35406841\n",
      "Iteration 8706, loss = 384.36966474\n",
      "Iteration 8707, loss = 384.35606786\n",
      "Iteration 8708, loss = 384.35203948\n",
      "Iteration 8709, loss = 384.33251361\n",
      "Iteration 8710, loss = 384.30665762\n",
      "Iteration 8711, loss = 384.33631516\n",
      "Iteration 8712, loss = 384.33991725\n",
      "Iteration 8713, loss = 384.31658912\n",
      "Iteration 8714, loss = 384.30038147\n",
      "Iteration 8715, loss = 384.32533989\n",
      "Iteration 8716, loss = 384.32105380\n",
      "Iteration 8717, loss = 384.29522728\n",
      "Iteration 8718, loss = 384.27829666\n",
      "Iteration 8719, loss = 384.28554316\n",
      "Iteration 8720, loss = 384.28776759\n",
      "Iteration 8721, loss = 384.27208131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8722, loss = 384.26697182\n",
      "Iteration 8723, loss = 384.27193348\n",
      "Iteration 8724, loss = 384.26500199\n",
      "Iteration 8725, loss = 384.27305478\n",
      "Iteration 8726, loss = 384.24907564\n",
      "Iteration 8727, loss = 384.24860310\n",
      "Iteration 8728, loss = 384.24811732\n",
      "Iteration 8729, loss = 384.24712497\n",
      "Iteration 8730, loss = 384.21418265\n",
      "Iteration 8731, loss = 384.19250342\n",
      "Iteration 8732, loss = 384.21269923\n",
      "Iteration 8733, loss = 384.20421751\n",
      "Iteration 8734, loss = 384.19888675\n",
      "Iteration 8735, loss = 384.18459457\n",
      "Iteration 8736, loss = 384.17359572\n",
      "Iteration 8737, loss = 384.17153279\n",
      "Iteration 8738, loss = 384.16960992\n",
      "Iteration 8739, loss = 384.18787635\n",
      "Iteration 8740, loss = 384.16787756\n",
      "Iteration 8741, loss = 384.16859807\n",
      "Iteration 8742, loss = 384.18005416\n",
      "Iteration 8743, loss = 384.17460881\n",
      "Iteration 8744, loss = 384.16285600\n",
      "Iteration 8745, loss = 384.15864286\n",
      "Iteration 8746, loss = 384.15794587\n",
      "Iteration 8747, loss = 384.13011370\n",
      "Iteration 8748, loss = 384.11352435\n",
      "Iteration 8749, loss = 384.13814013\n",
      "Iteration 8750, loss = 384.12573979\n",
      "Iteration 8751, loss = 384.11958863\n",
      "Iteration 8752, loss = 384.10760961\n",
      "Iteration 8753, loss = 384.08574475\n",
      "Iteration 8754, loss = 384.12034524\n",
      "Iteration 8755, loss = 384.10909894\n",
      "Iteration 8756, loss = 384.11226572\n",
      "Iteration 8757, loss = 384.07347907\n",
      "Iteration 8758, loss = 384.08677553\n",
      "Iteration 8759, loss = 384.10006272\n",
      "Iteration 8760, loss = 384.09698177\n",
      "Iteration 8761, loss = 384.09688261\n",
      "Iteration 8762, loss = 384.08773645\n",
      "Iteration 8763, loss = 384.08536093\n",
      "Iteration 8764, loss = 384.05180235\n",
      "Iteration 8765, loss = 384.04580910\n",
      "Iteration 8766, loss = 384.06877688\n",
      "Iteration 8767, loss = 384.07706827\n",
      "Iteration 8768, loss = 384.04626090\n",
      "Iteration 8769, loss = 384.02919870\n",
      "Iteration 8770, loss = 383.99660841\n",
      "Iteration 8771, loss = 384.02010122\n",
      "Iteration 8772, loss = 384.02474260\n",
      "Iteration 8773, loss = 384.01645985\n",
      "Iteration 8774, loss = 384.00214165\n",
      "Iteration 8775, loss = 383.99689422\n",
      "Iteration 8776, loss = 383.96786220\n",
      "Iteration 8777, loss = 383.97360315\n",
      "Iteration 8778, loss = 383.97139127\n",
      "Iteration 8779, loss = 383.94576126\n",
      "Iteration 8780, loss = 383.94636450\n",
      "Iteration 8781, loss = 383.95408230\n",
      "Iteration 8782, loss = 383.95578368\n",
      "Iteration 8783, loss = 383.94363114\n",
      "Iteration 8784, loss = 383.95104582\n",
      "Iteration 8785, loss = 383.94802620\n",
      "Iteration 8786, loss = 383.91855502\n",
      "Iteration 8787, loss = 383.95705402\n",
      "Iteration 8788, loss = 383.96001072\n",
      "Iteration 8789, loss = 383.95817778\n",
      "Iteration 8790, loss = 383.92425055\n",
      "Iteration 8791, loss = 383.89811692\n",
      "Iteration 8792, loss = 383.92725104\n",
      "Iteration 8793, loss = 383.91387941\n",
      "Iteration 8794, loss = 383.92815477\n",
      "Iteration 8795, loss = 383.87815664\n",
      "Iteration 8796, loss = 383.92123985\n",
      "Iteration 8797, loss = 383.90832361\n",
      "Iteration 8798, loss = 383.93660310\n",
      "Iteration 8799, loss = 383.94121245\n",
      "Iteration 8800, loss = 383.89497001\n",
      "Iteration 8801, loss = 383.87500173\n",
      "Iteration 8802, loss = 383.88566667\n",
      "Iteration 8803, loss = 383.89658916\n",
      "Iteration 8804, loss = 383.83616242\n",
      "Iteration 8805, loss = 383.83473855\n",
      "Iteration 8806, loss = 383.85141815\n",
      "Iteration 8807, loss = 383.83922509\n",
      "Iteration 8808, loss = 383.83272009\n",
      "Iteration 8809, loss = 383.81278857\n",
      "Iteration 8810, loss = 383.81770587\n",
      "Iteration 8811, loss = 383.81043067\n",
      "Iteration 8812, loss = 383.82349062\n",
      "Iteration 8813, loss = 383.80736534\n",
      "Iteration 8814, loss = 383.81519990\n",
      "Iteration 8815, loss = 383.82430881\n",
      "Iteration 8816, loss = 383.80493776\n",
      "Iteration 8817, loss = 383.78065672\n",
      "Iteration 8818, loss = 383.76985608\n",
      "Iteration 8819, loss = 383.79185064\n",
      "Iteration 8820, loss = 383.74841274\n",
      "Iteration 8821, loss = 383.74904129\n",
      "Iteration 8822, loss = 383.76356388\n",
      "Iteration 8823, loss = 383.74823818\n",
      "Iteration 8824, loss = 383.74085713\n",
      "Iteration 8825, loss = 383.71693665\n",
      "Iteration 8826, loss = 383.71060036\n",
      "Iteration 8827, loss = 383.71673284\n",
      "Iteration 8828, loss = 383.71109276\n",
      "Iteration 8829, loss = 383.69708014\n",
      "Iteration 8830, loss = 383.71938531\n",
      "Iteration 8831, loss = 383.72689341\n",
      "Iteration 8832, loss = 383.69953849\n",
      "Iteration 8833, loss = 383.70151008\n",
      "Iteration 8834, loss = 383.69232386\n",
      "Iteration 8835, loss = 383.70975799\n",
      "Iteration 8836, loss = 383.68150964\n",
      "Iteration 8837, loss = 383.67406411\n",
      "Iteration 8838, loss = 383.65678784\n",
      "Iteration 8839, loss = 383.64322582\n",
      "Iteration 8840, loss = 383.65643077\n",
      "Iteration 8841, loss = 383.64928005\n",
      "Iteration 8842, loss = 383.66729424\n",
      "Iteration 8843, loss = 383.67000276\n",
      "Iteration 8844, loss = 383.63949051\n",
      "Iteration 8845, loss = 383.62823309\n",
      "Iteration 8846, loss = 383.61661794\n",
      "Iteration 8847, loss = 383.61860737\n",
      "Iteration 8848, loss = 383.62766752\n",
      "Iteration 8849, loss = 383.60001436\n",
      "Iteration 8850, loss = 383.60156991\n",
      "Iteration 8851, loss = 383.57773147\n",
      "Iteration 8852, loss = 383.59463154\n",
      "Iteration 8853, loss = 383.58371117\n",
      "Iteration 8854, loss = 383.55295505\n",
      "Iteration 8855, loss = 383.58165058\n",
      "Iteration 8856, loss = 383.58245162\n",
      "Iteration 8857, loss = 383.56089950\n",
      "Iteration 8858, loss = 383.56457286\n",
      "Iteration 8859, loss = 383.54516185\n",
      "Iteration 8860, loss = 383.54851361\n",
      "Iteration 8861, loss = 383.55849307\n",
      "Iteration 8862, loss = 383.54259572\n",
      "Iteration 8863, loss = 383.52942547\n",
      "Iteration 8864, loss = 383.51354764\n",
      "Iteration 8865, loss = 383.52944784\n",
      "Iteration 8866, loss = 383.53318792\n",
      "Iteration 8867, loss = 383.52364124\n",
      "Iteration 8868, loss = 383.52100146\n",
      "Iteration 8869, loss = 383.53596332\n",
      "Iteration 8870, loss = 383.52560390\n",
      "Iteration 8871, loss = 383.49399355\n",
      "Iteration 8872, loss = 383.49379578\n",
      "Iteration 8873, loss = 383.50152104\n",
      "Iteration 8874, loss = 383.49717704\n",
      "Iteration 8875, loss = 383.49916158\n",
      "Iteration 8876, loss = 383.49501614\n",
      "Iteration 8877, loss = 383.44910907\n",
      "Iteration 8878, loss = 383.48375753\n",
      "Iteration 8879, loss = 383.50022558\n",
      "Iteration 8880, loss = 383.46300634\n",
      "Iteration 8881, loss = 383.48547551\n",
      "Iteration 8882, loss = 383.47668046\n",
      "Iteration 8883, loss = 383.46566595\n",
      "Iteration 8884, loss = 383.46153586\n",
      "Iteration 8885, loss = 383.45612258\n",
      "Iteration 8886, loss = 383.43505358\n",
      "Iteration 8887, loss = 383.43417963\n",
      "Iteration 8888, loss = 383.44418571\n",
      "Iteration 8889, loss = 383.44022807\n",
      "Iteration 8890, loss = 383.40770475\n",
      "Iteration 8891, loss = 383.40905310\n",
      "Iteration 8892, loss = 383.43502632\n",
      "Iteration 8893, loss = 383.42106117\n",
      "Iteration 8894, loss = 383.37520449\n",
      "Iteration 8895, loss = 383.36354482\n",
      "Iteration 8896, loss = 383.40799167\n",
      "Iteration 8897, loss = 383.41239001\n",
      "Iteration 8898, loss = 383.36895428\n",
      "Iteration 8899, loss = 383.37032860\n",
      "Iteration 8900, loss = 383.37362002\n",
      "Iteration 8901, loss = 383.39482701\n",
      "Iteration 8902, loss = 383.36963531\n",
      "Iteration 8903, loss = 383.33867816\n",
      "Iteration 8904, loss = 383.32729187\n",
      "Iteration 8905, loss = 383.33138048\n",
      "Iteration 8906, loss = 383.33733710\n",
      "Iteration 8907, loss = 383.33718408\n",
      "Iteration 8908, loss = 383.33543585\n",
      "Iteration 8909, loss = 383.32134980\n",
      "Iteration 8910, loss = 383.28473279\n",
      "Iteration 8911, loss = 383.28021039\n",
      "Iteration 8912, loss = 383.26047131\n",
      "Iteration 8913, loss = 383.27279176\n",
      "Iteration 8914, loss = 383.26599038\n",
      "Iteration 8915, loss = 383.27654143\n",
      "Iteration 8916, loss = 383.26417116\n",
      "Iteration 8917, loss = 383.27390331\n",
      "Iteration 8918, loss = 383.25517786\n",
      "Iteration 8919, loss = 383.23121580\n",
      "Iteration 8920, loss = 383.23266666\n",
      "Iteration 8921, loss = 383.23514743\n",
      "Iteration 8922, loss = 383.23240246\n",
      "Iteration 8923, loss = 383.21557521\n",
      "Iteration 8924, loss = 383.20072072\n",
      "Iteration 8925, loss = 383.21781876\n",
      "Iteration 8926, loss = 383.22342592\n",
      "Iteration 8927, loss = 383.19691861\n",
      "Iteration 8928, loss = 383.21684796\n",
      "Iteration 8929, loss = 383.23008888\n",
      "Iteration 8930, loss = 383.23609399\n",
      "Iteration 8931, loss = 383.20790987\n",
      "Iteration 8932, loss = 383.20010639\n",
      "Iteration 8933, loss = 383.18058377\n",
      "Iteration 8934, loss = 383.18007138\n",
      "Iteration 8935, loss = 383.18396067\n",
      "Iteration 8936, loss = 383.17827555\n",
      "Iteration 8937, loss = 383.17396016\n",
      "Iteration 8938, loss = 383.13799599\n",
      "Iteration 8939, loss = 383.13666943\n",
      "Iteration 8940, loss = 383.16157625\n",
      "Iteration 8941, loss = 383.15805461\n",
      "Iteration 8942, loss = 383.13390546\n",
      "Iteration 8943, loss = 383.12326706\n",
      "Iteration 8944, loss = 383.10714299\n",
      "Iteration 8945, loss = 383.09871567\n",
      "Iteration 8946, loss = 383.10645526\n",
      "Iteration 8947, loss = 383.10484708\n",
      "Iteration 8948, loss = 383.09887081\n",
      "Iteration 8949, loss = 383.10129165\n",
      "Iteration 8950, loss = 383.09931222\n",
      "Iteration 8951, loss = 383.07733754\n",
      "Iteration 8952, loss = 383.05450609\n",
      "Iteration 8953, loss = 383.06404235\n",
      "Iteration 8954, loss = 383.05601890\n",
      "Iteration 8955, loss = 383.04540046\n",
      "Iteration 8956, loss = 383.05229953\n",
      "Iteration 8957, loss = 383.04052283\n",
      "Iteration 8958, loss = 383.02926575\n",
      "Iteration 8959, loss = 383.02667520\n",
      "Iteration 8960, loss = 383.03556214\n",
      "Iteration 8961, loss = 383.03045231\n",
      "Iteration 8962, loss = 383.01694945\n",
      "Iteration 8963, loss = 383.01164708\n",
      "Iteration 8964, loss = 383.02617500\n",
      "Iteration 8965, loss = 383.02099413\n",
      "Iteration 8966, loss = 383.02771118\n",
      "Iteration 8967, loss = 383.01429769\n",
      "Iteration 8968, loss = 383.00807867\n",
      "Iteration 8969, loss = 382.97481994\n",
      "Iteration 8970, loss = 382.99040405\n",
      "Iteration 8971, loss = 382.97505187\n",
      "Iteration 8972, loss = 382.96693790\n",
      "Iteration 8973, loss = 382.97127404\n",
      "Iteration 8974, loss = 382.94185497\n",
      "Iteration 8975, loss = 382.95240146\n",
      "Iteration 8976, loss = 382.95042927\n",
      "Iteration 8977, loss = 382.94288462\n",
      "Iteration 8978, loss = 382.94930788\n",
      "Iteration 8979, loss = 382.92836421\n",
      "Iteration 8980, loss = 382.92853219\n",
      "Iteration 8981, loss = 382.91581899\n",
      "Iteration 8982, loss = 382.92496690\n",
      "Iteration 8983, loss = 382.93695719\n",
      "Iteration 8984, loss = 382.91985859\n",
      "Iteration 8985, loss = 382.92147332\n",
      "Iteration 8986, loss = 382.90776751\n",
      "Iteration 8987, loss = 382.91922530\n",
      "Iteration 8988, loss = 382.89989728\n",
      "Iteration 8989, loss = 382.87221613\n",
      "Iteration 8990, loss = 382.87186355\n",
      "Iteration 8991, loss = 382.87012485\n",
      "Iteration 8992, loss = 382.86777656\n",
      "Iteration 8993, loss = 382.86686095\n",
      "Iteration 8994, loss = 382.86723282\n",
      "Iteration 8995, loss = 382.85335862\n",
      "Iteration 8996, loss = 382.83673454\n",
      "Iteration 8997, loss = 382.82865565\n",
      "Iteration 8998, loss = 382.82315721\n",
      "Iteration 8999, loss = 382.82511255\n",
      "Iteration 9000, loss = 382.81520282\n",
      "Iteration 9001, loss = 382.81252205\n",
      "Iteration 9002, loss = 382.81940537\n",
      "Iteration 9003, loss = 382.81466210\n",
      "Iteration 9004, loss = 382.79785393\n",
      "Iteration 9005, loss = 382.81888590\n",
      "Iteration 9006, loss = 382.84452422\n",
      "Iteration 9007, loss = 382.81941973\n",
      "Iteration 9008, loss = 382.78533620\n",
      "Iteration 9009, loss = 382.78793477\n",
      "Iteration 9010, loss = 382.78673304\n",
      "Iteration 9011, loss = 382.79038882\n",
      "Iteration 9012, loss = 382.78000142\n",
      "Iteration 9013, loss = 382.76279916\n",
      "Iteration 9014, loss = 382.76427922\n",
      "Iteration 9015, loss = 382.75257776\n",
      "Iteration 9016, loss = 382.75422654\n",
      "Iteration 9017, loss = 382.75149827\n",
      "Iteration 9018, loss = 382.72596022\n",
      "Iteration 9019, loss = 382.72505941\n",
      "Iteration 9020, loss = 382.74417328\n",
      "Iteration 9021, loss = 382.72880743\n",
      "Iteration 9022, loss = 382.72208795\n",
      "Iteration 9023, loss = 382.71804487\n",
      "Iteration 9024, loss = 382.70288624\n",
      "Iteration 9025, loss = 382.69361718\n",
      "Iteration 9026, loss = 382.67945041\n",
      "Iteration 9027, loss = 382.67980000\n",
      "Iteration 9028, loss = 382.69323649\n",
      "Iteration 9029, loss = 382.70349893\n",
      "Iteration 9030, loss = 382.70192890\n",
      "Iteration 9031, loss = 382.67262402\n",
      "Iteration 9032, loss = 382.66500922\n",
      "Iteration 9033, loss = 382.68298781\n",
      "Iteration 9034, loss = 382.67319858\n",
      "Iteration 9035, loss = 382.66124473\n",
      "Iteration 9036, loss = 382.64719808\n",
      "Iteration 9037, loss = 382.64183207\n",
      "Iteration 9038, loss = 382.62819977\n",
      "Iteration 9039, loss = 382.64451482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9040, loss = 382.66260695\n",
      "Iteration 9041, loss = 382.63745278\n",
      "Iteration 9042, loss = 382.60532792\n",
      "Iteration 9043, loss = 382.58302001\n",
      "Iteration 9044, loss = 382.60451790\n",
      "Iteration 9045, loss = 382.63121975\n",
      "Iteration 9046, loss = 382.59856723\n",
      "Iteration 9047, loss = 382.57415696\n",
      "Iteration 9048, loss = 382.58541114\n",
      "Iteration 9049, loss = 382.57556779\n",
      "Iteration 9050, loss = 382.56094519\n",
      "Iteration 9051, loss = 382.56733530\n",
      "Iteration 9052, loss = 382.58131283\n",
      "Iteration 9053, loss = 382.55028197\n",
      "Iteration 9054, loss = 382.55340996\n",
      "Iteration 9055, loss = 382.54935880\n",
      "Iteration 9056, loss = 382.52325993\n",
      "Iteration 9057, loss = 382.53309770\n",
      "Iteration 9058, loss = 382.52354653\n",
      "Iteration 9059, loss = 382.49973016\n",
      "Iteration 9060, loss = 382.50837091\n",
      "Iteration 9061, loss = 382.49447487\n",
      "Iteration 9062, loss = 382.50781160\n",
      "Iteration 9063, loss = 382.49547159\n",
      "Iteration 9064, loss = 382.48293944\n",
      "Iteration 9065, loss = 382.51743738\n",
      "Iteration 9066, loss = 382.51383745\n",
      "Iteration 9067, loss = 382.49763445\n",
      "Iteration 9068, loss = 382.48230118\n",
      "Iteration 9069, loss = 382.49199282\n",
      "Iteration 9070, loss = 382.47710300\n",
      "Iteration 9071, loss = 382.45072046\n",
      "Iteration 9072, loss = 382.43890974\n",
      "Iteration 9073, loss = 382.44903895\n",
      "Iteration 9074, loss = 382.45177004\n",
      "Iteration 9075, loss = 382.44658556\n",
      "Iteration 9076, loss = 382.43626982\n",
      "Iteration 9077, loss = 382.42021742\n",
      "Iteration 9078, loss = 382.42200095\n",
      "Iteration 9079, loss = 382.42115072\n",
      "Iteration 9080, loss = 382.40836281\n",
      "Iteration 9081, loss = 382.43151531\n",
      "Iteration 9082, loss = 382.44759866\n",
      "Iteration 9083, loss = 382.41827063\n",
      "Iteration 9084, loss = 382.40008300\n",
      "Iteration 9085, loss = 382.41995840\n",
      "Iteration 9086, loss = 382.41638347\n",
      "Iteration 9087, loss = 382.39387305\n",
      "Iteration 9088, loss = 382.38423700\n",
      "Iteration 9089, loss = 382.36247742\n",
      "Iteration 9090, loss = 382.36611688\n",
      "Iteration 9091, loss = 382.36489241\n",
      "Iteration 9092, loss = 382.36153550\n",
      "Iteration 9093, loss = 382.36910524\n",
      "Iteration 9094, loss = 382.36758661\n",
      "Iteration 9095, loss = 382.34766803\n",
      "Iteration 9096, loss = 382.32183351\n",
      "Iteration 9097, loss = 382.31145199\n",
      "Iteration 9098, loss = 382.31087642\n",
      "Iteration 9099, loss = 382.30548878\n",
      "Iteration 9100, loss = 382.30102227\n",
      "Iteration 9101, loss = 382.29264617\n",
      "Iteration 9102, loss = 382.30225688\n",
      "Iteration 9103, loss = 382.30099621\n",
      "Iteration 9104, loss = 382.28898860\n",
      "Iteration 9105, loss = 382.28348540\n",
      "Iteration 9106, loss = 382.28721602\n",
      "Iteration 9107, loss = 382.28525165\n",
      "Iteration 9108, loss = 382.26348278\n",
      "Iteration 9109, loss = 382.24600488\n",
      "Iteration 9110, loss = 382.27923964\n",
      "Iteration 9111, loss = 382.28384210\n",
      "Iteration 9112, loss = 382.26408919\n",
      "Iteration 9113, loss = 382.24403953\n",
      "Iteration 9114, loss = 382.22737510\n",
      "Iteration 9115, loss = 382.22014682\n",
      "Iteration 9116, loss = 382.22595883\n",
      "Iteration 9117, loss = 382.21042499\n",
      "Iteration 9118, loss = 382.21844683\n",
      "Iteration 9119, loss = 382.22813548\n",
      "Iteration 9120, loss = 382.22057695\n",
      "Iteration 9121, loss = 382.20290494\n",
      "Iteration 9122, loss = 382.23448363\n",
      "Iteration 9123, loss = 382.24038977\n",
      "Iteration 9124, loss = 382.25067519\n",
      "Iteration 9125, loss = 382.24378370\n",
      "Iteration 9126, loss = 382.21530024\n",
      "Iteration 9127, loss = 382.16888238\n",
      "Iteration 9128, loss = 382.18966311\n",
      "Iteration 9129, loss = 382.20810572\n",
      "Iteration 9130, loss = 382.19234736\n",
      "Iteration 9131, loss = 382.18143953\n",
      "Iteration 9132, loss = 382.18510869\n",
      "Iteration 9133, loss = 382.18554835\n",
      "Iteration 9134, loss = 382.16388578\n",
      "Iteration 9135, loss = 382.15250602\n",
      "Iteration 9136, loss = 382.16550593\n",
      "Iteration 9137, loss = 382.13787276\n",
      "Iteration 9138, loss = 382.12162713\n",
      "Iteration 9139, loss = 382.11998156\n",
      "Iteration 9140, loss = 382.11948294\n",
      "Iteration 9141, loss = 382.11061379\n",
      "Iteration 9142, loss = 382.13131575\n",
      "Iteration 9143, loss = 382.13060219\n",
      "Iteration 9144, loss = 382.12048967\n",
      "Iteration 9145, loss = 382.10013943\n",
      "Iteration 9146, loss = 382.08528692\n",
      "Iteration 9147, loss = 382.10152225\n",
      "Iteration 9148, loss = 382.08588164\n",
      "Iteration 9149, loss = 382.07713999\n",
      "Iteration 9150, loss = 382.05123862\n",
      "Iteration 9151, loss = 382.03535528\n",
      "Iteration 9152, loss = 382.05214075\n",
      "Iteration 9153, loss = 382.07166499\n",
      "Iteration 9154, loss = 382.06199733\n",
      "Iteration 9155, loss = 382.06178869\n",
      "Iteration 9156, loss = 382.05184421\n",
      "Iteration 9157, loss = 382.06079372\n",
      "Iteration 9158, loss = 382.03041909\n",
      "Iteration 9159, loss = 382.01011971\n",
      "Iteration 9160, loss = 382.03077504\n",
      "Iteration 9161, loss = 382.04392365\n",
      "Iteration 9162, loss = 382.02897387\n",
      "Iteration 9163, loss = 381.99887572\n",
      "Iteration 9164, loss = 381.98503142\n",
      "Iteration 9165, loss = 381.98749264\n",
      "Iteration 9166, loss = 382.00114694\n",
      "Iteration 9167, loss = 381.97803272\n",
      "Iteration 9168, loss = 381.95444119\n",
      "Iteration 9169, loss = 381.97080271\n",
      "Iteration 9170, loss = 381.98268877\n",
      "Iteration 9171, loss = 381.98098687\n",
      "Iteration 9172, loss = 381.95669572\n",
      "Iteration 9173, loss = 381.97116263\n",
      "Iteration 9174, loss = 381.95174113\n",
      "Iteration 9175, loss = 381.92171685\n",
      "Iteration 9176, loss = 381.94420719\n",
      "Iteration 9177, loss = 381.93254608\n",
      "Iteration 9178, loss = 381.93865072\n",
      "Iteration 9179, loss = 381.93885135\n",
      "Iteration 9180, loss = 381.93050602\n",
      "Iteration 9181, loss = 381.93615253\n",
      "Iteration 9182, loss = 381.92198094\n",
      "Iteration 9183, loss = 381.92209490\n",
      "Iteration 9184, loss = 381.91388234\n",
      "Iteration 9185, loss = 381.86862217\n",
      "Iteration 9186, loss = 381.86691589\n",
      "Iteration 9187, loss = 381.89417755\n",
      "Iteration 9188, loss = 381.89494950\n",
      "Iteration 9189, loss = 381.87127483\n",
      "Iteration 9190, loss = 381.87373693\n",
      "Iteration 9191, loss = 381.87472291\n",
      "Iteration 9192, loss = 381.88296261\n",
      "Iteration 9193, loss = 381.88656319\n",
      "Iteration 9194, loss = 381.85697235\n",
      "Iteration 9195, loss = 381.85862580\n",
      "Iteration 9196, loss = 381.84399427\n",
      "Iteration 9197, loss = 381.84690736\n",
      "Iteration 9198, loss = 381.83804925\n",
      "Iteration 9199, loss = 381.81921599\n",
      "Iteration 9200, loss = 381.82193961\n",
      "Iteration 9201, loss = 381.83233491\n",
      "Iteration 9202, loss = 381.81662296\n",
      "Iteration 9203, loss = 381.80535817\n",
      "Iteration 9204, loss = 381.79523355\n",
      "Iteration 9205, loss = 381.78057667\n",
      "Iteration 9206, loss = 381.77893647\n",
      "Iteration 9207, loss = 381.76948592\n",
      "Iteration 9208, loss = 381.78292257\n",
      "Iteration 9209, loss = 381.77704444\n",
      "Iteration 9210, loss = 381.76138510\n",
      "Iteration 9211, loss = 381.77343787\n",
      "Iteration 9212, loss = 381.77715110\n",
      "Iteration 9213, loss = 381.76504263\n",
      "Iteration 9214, loss = 381.75296538\n",
      "Iteration 9215, loss = 381.73531811\n",
      "Iteration 9216, loss = 381.71878220\n",
      "Iteration 9217, loss = 381.72043459\n",
      "Iteration 9218, loss = 381.71401108\n",
      "Iteration 9219, loss = 381.69381736\n",
      "Iteration 9220, loss = 381.70742266\n",
      "Iteration 9221, loss = 381.71793313\n",
      "Iteration 9222, loss = 381.70383177\n",
      "Iteration 9223, loss = 381.68521117\n",
      "Iteration 9224, loss = 381.69687957\n",
      "Iteration 9225, loss = 381.69491481\n",
      "Iteration 9226, loss = 381.71863202\n",
      "Iteration 9227, loss = 381.69758650\n",
      "Iteration 9228, loss = 381.67334631\n",
      "Iteration 9229, loss = 381.66868992\n",
      "Iteration 9230, loss = 381.65779260\n",
      "Iteration 9231, loss = 381.67344165\n",
      "Iteration 9232, loss = 381.67636393\n",
      "Iteration 9233, loss = 381.67242437\n",
      "Iteration 9234, loss = 381.65274930\n",
      "Iteration 9235, loss = 381.65342394\n",
      "Iteration 9236, loss = 381.68140215\n",
      "Iteration 9237, loss = 381.67020319\n",
      "Iteration 9238, loss = 381.64669794\n",
      "Iteration 9239, loss = 381.63972263\n",
      "Iteration 9240, loss = 381.63331689\n",
      "Iteration 9241, loss = 381.63185856\n",
      "Iteration 9242, loss = 381.60754129\n",
      "Iteration 9243, loss = 381.60492576\n",
      "Iteration 9244, loss = 381.61043847\n",
      "Iteration 9245, loss = 381.61122689\n",
      "Iteration 9246, loss = 381.58649984\n",
      "Iteration 9247, loss = 381.57553732\n",
      "Iteration 9248, loss = 381.58232272\n",
      "Iteration 9249, loss = 381.58355645\n",
      "Iteration 9250, loss = 381.60505578\n",
      "Iteration 9251, loss = 381.57434163\n",
      "Iteration 9252, loss = 381.57576674\n",
      "Iteration 9253, loss = 381.55806725\n",
      "Iteration 9254, loss = 381.57840891\n",
      "Iteration 9255, loss = 381.59399234\n",
      "Iteration 9256, loss = 381.54394856\n",
      "Iteration 9257, loss = 381.54350439\n",
      "Iteration 9258, loss = 381.54536956\n",
      "Iteration 9259, loss = 381.55114636\n",
      "Iteration 9260, loss = 381.54462948\n",
      "Iteration 9261, loss = 381.53201134\n",
      "Iteration 9262, loss = 381.53144278\n",
      "Iteration 9263, loss = 381.53407879\n",
      "Iteration 9264, loss = 381.52823738\n",
      "Iteration 9265, loss = 381.55115491\n",
      "Iteration 9266, loss = 381.52601238\n",
      "Iteration 9267, loss = 381.48329474\n",
      "Iteration 9268, loss = 381.48325601\n",
      "Iteration 9269, loss = 381.47900049\n",
      "Iteration 9270, loss = 381.48136060\n",
      "Iteration 9271, loss = 381.46709003\n",
      "Iteration 9272, loss = 381.47990027\n",
      "Iteration 9273, loss = 381.47102551\n",
      "Iteration 9274, loss = 381.44562929\n",
      "Iteration 9275, loss = 381.43542118\n",
      "Iteration 9276, loss = 381.44334680\n",
      "Iteration 9277, loss = 381.44123384\n",
      "Iteration 9278, loss = 381.42544601\n",
      "Iteration 9279, loss = 381.40735691\n",
      "Iteration 9280, loss = 381.39920420\n",
      "Iteration 9281, loss = 381.41633073\n",
      "Iteration 9282, loss = 381.40259154\n",
      "Iteration 9283, loss = 381.38809095\n",
      "Iteration 9284, loss = 381.40589242\n",
      "Iteration 9285, loss = 381.37998578\n",
      "Iteration 9286, loss = 381.37632838\n",
      "Iteration 9287, loss = 381.37973148\n",
      "Iteration 9288, loss = 381.36558926\n",
      "Iteration 9289, loss = 381.39079398\n",
      "Iteration 9290, loss = 381.37085342\n",
      "Iteration 9291, loss = 381.35349196\n",
      "Iteration 9292, loss = 381.37490138\n",
      "Iteration 9293, loss = 381.36937631\n",
      "Iteration 9294, loss = 381.34000025\n",
      "Iteration 9295, loss = 381.35363607\n",
      "Iteration 9296, loss = 381.34816232\n",
      "Iteration 9297, loss = 381.33787623\n",
      "Iteration 9298, loss = 381.31767623\n",
      "Iteration 9299, loss = 381.35994335\n",
      "Iteration 9300, loss = 381.36421802\n",
      "Iteration 9301, loss = 381.34433374\n",
      "Iteration 9302, loss = 381.32752478\n",
      "Iteration 9303, loss = 381.30062972\n",
      "Iteration 9304, loss = 381.30993307\n",
      "Iteration 9305, loss = 381.29204196\n",
      "Iteration 9306, loss = 381.27374238\n",
      "Iteration 9307, loss = 381.30006175\n",
      "Iteration 9308, loss = 381.28208077\n",
      "Iteration 9309, loss = 381.27104567\n",
      "Iteration 9310, loss = 381.25970706\n",
      "Iteration 9311, loss = 381.24911117\n",
      "Iteration 9312, loss = 381.25915093\n",
      "Iteration 9313, loss = 381.23772089\n",
      "Iteration 9314, loss = 381.25507878\n",
      "Iteration 9315, loss = 381.24616093\n",
      "Iteration 9316, loss = 381.25690013\n",
      "Iteration 9317, loss = 381.25877758\n",
      "Iteration 9318, loss = 381.24129214\n",
      "Iteration 9319, loss = 381.23083777\n",
      "Iteration 9320, loss = 381.21571793\n",
      "Iteration 9321, loss = 381.20152005\n",
      "Iteration 9322, loss = 381.21832578\n",
      "Iteration 9323, loss = 381.20482083\n",
      "Iteration 9324, loss = 381.19853760\n",
      "Iteration 9325, loss = 381.19775493\n",
      "Iteration 9326, loss = 381.22237566\n",
      "Iteration 9327, loss = 381.22392669\n",
      "Iteration 9328, loss = 381.18959901\n",
      "Iteration 9329, loss = 381.18491406\n",
      "Iteration 9330, loss = 381.16053452\n",
      "Iteration 9331, loss = 381.18056143\n",
      "Iteration 9332, loss = 381.14522540\n",
      "Iteration 9333, loss = 381.16722695\n",
      "Iteration 9334, loss = 381.20052355\n",
      "Iteration 9335, loss = 381.18286343\n",
      "Iteration 9336, loss = 381.15390553\n",
      "Iteration 9337, loss = 381.14925566\n",
      "Iteration 9338, loss = 381.12830518\n",
      "Iteration 9339, loss = 381.13912703\n",
      "Iteration 9340, loss = 381.15220431\n",
      "Iteration 9341, loss = 381.11483113\n",
      "Iteration 9342, loss = 381.12257112\n",
      "Iteration 9343, loss = 381.13052065\n",
      "Iteration 9344, loss = 381.15527034\n",
      "Iteration 9345, loss = 381.12442676\n",
      "Iteration 9346, loss = 381.07170802\n",
      "Iteration 9347, loss = 381.09887192\n",
      "Iteration 9348, loss = 381.13928329\n",
      "Iteration 9349, loss = 381.11847463\n",
      "Iteration 9350, loss = 381.08393991\n",
      "Iteration 9351, loss = 381.07852266\n",
      "Iteration 9352, loss = 381.07610325\n",
      "Iteration 9353, loss = 381.06023348\n",
      "Iteration 9354, loss = 381.05758117\n",
      "Iteration 9355, loss = 381.07861123\n",
      "Iteration 9356, loss = 381.05052048\n",
      "Iteration 9357, loss = 381.02686228\n",
      "Iteration 9358, loss = 381.04397097\n",
      "Iteration 9359, loss = 381.06217589\n",
      "Iteration 9360, loss = 381.07190285\n",
      "Iteration 9361, loss = 381.01914148\n",
      "Iteration 9362, loss = 381.03854180\n",
      "Iteration 9363, loss = 381.04706617\n",
      "Iteration 9364, loss = 381.02491363\n",
      "Iteration 9365, loss = 381.02740484\n",
      "Iteration 9366, loss = 381.01606694\n",
      "Iteration 9367, loss = 380.99453843\n",
      "Iteration 9368, loss = 380.99484790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9369, loss = 380.98237354\n",
      "Iteration 9370, loss = 380.98915288\n",
      "Iteration 9371, loss = 380.98722425\n",
      "Iteration 9372, loss = 380.97704411\n",
      "Iteration 9373, loss = 380.97504403\n",
      "Iteration 9374, loss = 380.96025600\n",
      "Iteration 9375, loss = 380.96308722\n",
      "Iteration 9376, loss = 380.96449002\n",
      "Iteration 9377, loss = 380.95872645\n",
      "Iteration 9378, loss = 380.95339896\n",
      "Iteration 9379, loss = 380.92592809\n",
      "Iteration 9380, loss = 380.93687776\n",
      "Iteration 9381, loss = 380.95866071\n",
      "Iteration 9382, loss = 380.92622176\n",
      "Iteration 9383, loss = 380.92644751\n",
      "Iteration 9384, loss = 380.92478373\n",
      "Iteration 9385, loss = 380.90591222\n",
      "Iteration 9386, loss = 380.91066514\n",
      "Iteration 9387, loss = 380.90030653\n",
      "Iteration 9388, loss = 380.88029477\n",
      "Iteration 9389, loss = 380.89625089\n",
      "Iteration 9390, loss = 380.87962273\n",
      "Iteration 9391, loss = 380.89397566\n",
      "Iteration 9392, loss = 380.88667867\n",
      "Iteration 9393, loss = 380.86160540\n",
      "Iteration 9394, loss = 380.86866953\n",
      "Iteration 9395, loss = 380.85274343\n",
      "Iteration 9396, loss = 380.84127846\n",
      "Iteration 9397, loss = 380.85644756\n",
      "Iteration 9398, loss = 380.82770339\n",
      "Iteration 9399, loss = 380.84612183\n",
      "Iteration 9400, loss = 380.81720830\n",
      "Iteration 9401, loss = 380.81906823\n",
      "Iteration 9402, loss = 380.81329880\n",
      "Iteration 9403, loss = 380.80121858\n",
      "Iteration 9404, loss = 380.79995790\n",
      "Iteration 9405, loss = 380.79287135\n",
      "Iteration 9406, loss = 380.77818379\n",
      "Iteration 9407, loss = 380.76363728\n",
      "Iteration 9408, loss = 380.79009477\n",
      "Iteration 9409, loss = 380.76508545\n",
      "Iteration 9410, loss = 380.77472851\n",
      "Iteration 9411, loss = 380.76804323\n",
      "Iteration 9412, loss = 380.75279952\n",
      "Iteration 9413, loss = 380.75965397\n",
      "Iteration 9414, loss = 380.73710988\n",
      "Iteration 9415, loss = 380.74208401\n",
      "Iteration 9416, loss = 380.71671672\n",
      "Iteration 9417, loss = 380.71259096\n",
      "Iteration 9418, loss = 380.71648260\n",
      "Iteration 9419, loss = 380.70898428\n",
      "Iteration 9420, loss = 380.71036737\n",
      "Iteration 9421, loss = 380.71579141\n",
      "Iteration 9422, loss = 380.69755296\n",
      "Iteration 9423, loss = 380.71419469\n",
      "Iteration 9424, loss = 380.71746010\n",
      "Iteration 9425, loss = 380.68792454\n",
      "Iteration 9426, loss = 380.69286831\n",
      "Iteration 9427, loss = 380.69793231\n",
      "Iteration 9428, loss = 380.68286231\n",
      "Iteration 9429, loss = 380.66199044\n",
      "Iteration 9430, loss = 380.65539015\n",
      "Iteration 9431, loss = 380.65110964\n",
      "Iteration 9432, loss = 380.67263301\n",
      "Iteration 9433, loss = 380.67016210\n",
      "Iteration 9434, loss = 380.64989674\n",
      "Iteration 9435, loss = 380.65885956\n",
      "Iteration 9436, loss = 380.66339509\n",
      "Iteration 9437, loss = 380.65242981\n",
      "Iteration 9438, loss = 380.62753826\n",
      "Iteration 9439, loss = 380.62703331\n",
      "Iteration 9440, loss = 380.64804420\n",
      "Iteration 9441, loss = 380.65027722\n",
      "Iteration 9442, loss = 380.63086546\n",
      "Iteration 9443, loss = 380.63699207\n",
      "Iteration 9444, loss = 380.64979855\n",
      "Iteration 9445, loss = 380.65642828\n",
      "Iteration 9446, loss = 380.63451110\n",
      "Iteration 9447, loss = 380.60115178\n",
      "Iteration 9448, loss = 380.57805321\n",
      "Iteration 9449, loss = 380.56213766\n",
      "Iteration 9450, loss = 380.58171533\n",
      "Iteration 9451, loss = 380.59450389\n",
      "Iteration 9452, loss = 380.58018304\n",
      "Iteration 9453, loss = 380.57466954\n",
      "Iteration 9454, loss = 380.58756422\n",
      "Iteration 9455, loss = 380.59053676\n",
      "Iteration 9456, loss = 380.57505710\n",
      "Iteration 9457, loss = 380.53184865\n",
      "Iteration 9458, loss = 380.54555101\n",
      "Iteration 9459, loss = 380.53877329\n",
      "Iteration 9460, loss = 380.52733958\n",
      "Iteration 9461, loss = 380.52397153\n",
      "Iteration 9462, loss = 380.51847132\n",
      "Iteration 9463, loss = 380.51438859\n",
      "Iteration 9464, loss = 380.49697931\n",
      "Iteration 9465, loss = 380.49763326\n",
      "Iteration 9466, loss = 380.50119334\n",
      "Iteration 9467, loss = 380.48696751\n",
      "Iteration 9468, loss = 380.48239815\n",
      "Iteration 9469, loss = 380.49676563\n",
      "Iteration 9470, loss = 380.50112514\n",
      "Iteration 9471, loss = 380.49426141\n",
      "Iteration 9472, loss = 380.50198029\n",
      "Iteration 9473, loss = 380.47351378\n",
      "Iteration 9474, loss = 380.49385061\n",
      "Iteration 9475, loss = 380.48589537\n",
      "Iteration 9476, loss = 380.47767203\n",
      "Iteration 9477, loss = 380.43379558\n",
      "Iteration 9478, loss = 380.42218708\n",
      "Iteration 9479, loss = 380.43502095\n",
      "Iteration 9480, loss = 380.40732768\n",
      "Iteration 9481, loss = 380.40205020\n",
      "Iteration 9482, loss = 380.39988273\n",
      "Iteration 9483, loss = 380.38076641\n",
      "Iteration 9484, loss = 380.38093309\n",
      "Iteration 9485, loss = 380.37329445\n",
      "Iteration 9486, loss = 380.36613492\n",
      "Iteration 9487, loss = 380.36070637\n",
      "Iteration 9488, loss = 380.38141555\n",
      "Iteration 9489, loss = 380.41317109\n",
      "Iteration 9490, loss = 380.38930675\n",
      "Iteration 9491, loss = 380.36104349\n",
      "Iteration 9492, loss = 380.37493040\n",
      "Iteration 9493, loss = 380.36036656\n",
      "Iteration 9494, loss = 380.37604924\n",
      "Iteration 9495, loss = 380.35622678\n",
      "Iteration 9496, loss = 380.34196280\n",
      "Iteration 9497, loss = 380.35143538\n",
      "Iteration 9498, loss = 380.33960899\n",
      "Iteration 9499, loss = 380.30866259\n",
      "Iteration 9500, loss = 380.32240769\n",
      "Iteration 9501, loss = 380.33553941\n",
      "Iteration 9502, loss = 380.30878191\n",
      "Iteration 9503, loss = 380.30365521\n",
      "Iteration 9504, loss = 380.30675349\n",
      "Iteration 9505, loss = 380.28741205\n",
      "Iteration 9506, loss = 380.29502028\n",
      "Iteration 9507, loss = 380.27930145\n",
      "Iteration 9508, loss = 380.26635318\n",
      "Iteration 9509, loss = 380.26308461\n",
      "Iteration 9510, loss = 380.25715674\n",
      "Iteration 9511, loss = 380.23435767\n",
      "Iteration 9512, loss = 380.26435955\n",
      "Iteration 9513, loss = 380.28270314\n",
      "Iteration 9514, loss = 380.25838111\n",
      "Iteration 9515, loss = 380.25614825\n",
      "Iteration 9516, loss = 380.24342374\n",
      "Iteration 9517, loss = 380.22918241\n",
      "Iteration 9518, loss = 380.19937259\n",
      "Iteration 9519, loss = 380.22821481\n",
      "Iteration 9520, loss = 380.23520603\n",
      "Iteration 9521, loss = 380.20625453\n",
      "Iteration 9522, loss = 380.20338358\n",
      "Iteration 9523, loss = 380.21066759\n",
      "Iteration 9524, loss = 380.19467443\n",
      "Iteration 9525, loss = 380.17574330\n",
      "Iteration 9526, loss = 380.19908954\n",
      "Iteration 9527, loss = 380.16950221\n",
      "Iteration 9528, loss = 380.15688472\n",
      "Iteration 9529, loss = 380.18791876\n",
      "Iteration 9530, loss = 380.16785358\n",
      "Iteration 9531, loss = 380.15356017\n",
      "Iteration 9532, loss = 380.15812845\n",
      "Iteration 9533, loss = 380.14938974\n",
      "Iteration 9534, loss = 380.16962711\n",
      "Iteration 9535, loss = 380.16037548\n",
      "Iteration 9536, loss = 380.13486089\n",
      "Iteration 9537, loss = 380.13695393\n",
      "Iteration 9538, loss = 380.12338084\n",
      "Iteration 9539, loss = 380.11965160\n",
      "Iteration 9540, loss = 380.10053518\n",
      "Iteration 9541, loss = 380.10997860\n",
      "Iteration 9542, loss = 380.12139458\n",
      "Iteration 9543, loss = 380.08495719\n",
      "Iteration 9544, loss = 380.08047768\n",
      "Iteration 9545, loss = 380.09699782\n",
      "Iteration 9546, loss = 380.09716678\n",
      "Iteration 9547, loss = 380.08479862\n",
      "Iteration 9548, loss = 380.04763874\n",
      "Iteration 9549, loss = 380.06443401\n",
      "Iteration 9550, loss = 380.07379941\n",
      "Iteration 9551, loss = 380.08700019\n",
      "Iteration 9552, loss = 380.06002941\n",
      "Iteration 9553, loss = 380.03755474\n",
      "Iteration 9554, loss = 380.02354693\n",
      "Iteration 9555, loss = 380.02695336\n",
      "Iteration 9556, loss = 380.06192501\n",
      "Iteration 9557, loss = 380.04738093\n",
      "Iteration 9558, loss = 380.04609523\n",
      "Iteration 9559, loss = 380.03878329\n",
      "Iteration 9560, loss = 380.01179973\n",
      "Iteration 9561, loss = 380.01769485\n",
      "Iteration 9562, loss = 380.00538762\n",
      "Iteration 9563, loss = 379.99007264\n",
      "Iteration 9564, loss = 379.99163957\n",
      "Iteration 9565, loss = 379.98939601\n",
      "Iteration 9566, loss = 380.00279903\n",
      "Iteration 9567, loss = 380.01933264\n",
      "Iteration 9568, loss = 379.97928791\n",
      "Iteration 9569, loss = 379.94734215\n",
      "Iteration 9570, loss = 379.99887200\n",
      "Iteration 9571, loss = 379.98474408\n",
      "Iteration 9572, loss = 379.95081087\n",
      "Iteration 9573, loss = 379.96127241\n",
      "Iteration 9574, loss = 379.99178672\n",
      "Iteration 9575, loss = 379.97082481\n",
      "Iteration 9576, loss = 379.93363488\n",
      "Iteration 9577, loss = 379.93884345\n",
      "Iteration 9578, loss = 379.93931948\n",
      "Iteration 9579, loss = 379.92015070\n",
      "Iteration 9580, loss = 379.90863399\n",
      "Iteration 9581, loss = 379.90332466\n",
      "Iteration 9582, loss = 379.92467791\n",
      "Iteration 9583, loss = 379.91377441\n",
      "Iteration 9584, loss = 379.88786050\n",
      "Iteration 9585, loss = 379.90655725\n",
      "Iteration 9586, loss = 379.90730848\n",
      "Iteration 9587, loss = 379.87227216\n",
      "Iteration 9588, loss = 379.87265052\n",
      "Iteration 9589, loss = 379.87213583\n",
      "Iteration 9590, loss = 379.87769853\n",
      "Iteration 9591, loss = 379.85595896\n",
      "Iteration 9592, loss = 379.85653394\n",
      "Iteration 9593, loss = 379.90344208\n",
      "Iteration 9594, loss = 379.89156168\n",
      "Iteration 9595, loss = 379.84197385\n",
      "Iteration 9596, loss = 379.81329925\n",
      "Iteration 9597, loss = 379.84182154\n",
      "Iteration 9598, loss = 379.86045420\n",
      "Iteration 9599, loss = 379.82673972\n",
      "Iteration 9600, loss = 379.81603757\n",
      "Iteration 9601, loss = 379.81148346\n",
      "Iteration 9602, loss = 379.82086348\n",
      "Iteration 9603, loss = 379.79821705\n",
      "Iteration 9604, loss = 379.77689683\n",
      "Iteration 9605, loss = 379.77967012\n",
      "Iteration 9606, loss = 379.76847121\n",
      "Iteration 9607, loss = 379.75713709\n",
      "Iteration 9608, loss = 379.75245737\n",
      "Iteration 9609, loss = 379.77791217\n",
      "Iteration 9610, loss = 379.76603398\n",
      "Iteration 9611, loss = 379.75061876\n",
      "Iteration 9612, loss = 379.73202155\n",
      "Iteration 9613, loss = 379.73537496\n",
      "Iteration 9614, loss = 379.73005815\n",
      "Iteration 9615, loss = 379.72509316\n",
      "Iteration 9616, loss = 379.71875715\n",
      "Iteration 9617, loss = 379.71917181\n",
      "Iteration 9618, loss = 379.71445434\n",
      "Iteration 9619, loss = 379.70605346\n",
      "Iteration 9620, loss = 379.69987981\n",
      "Iteration 9621, loss = 379.69461122\n",
      "Iteration 9622, loss = 379.70915523\n",
      "Iteration 9623, loss = 379.71967982\n",
      "Iteration 9624, loss = 379.69172151\n",
      "Iteration 9625, loss = 379.66811782\n",
      "Iteration 9626, loss = 379.67245527\n",
      "Iteration 9627, loss = 379.67868579\n",
      "Iteration 9628, loss = 379.66136620\n",
      "Iteration 9629, loss = 379.64861871\n",
      "Iteration 9630, loss = 379.65912317\n",
      "Iteration 9631, loss = 379.65938742\n",
      "Iteration 9632, loss = 379.64998225\n",
      "Iteration 9633, loss = 379.64564805\n",
      "Iteration 9634, loss = 379.63744391\n",
      "Iteration 9635, loss = 379.62070647\n",
      "Iteration 9636, loss = 379.63860376\n",
      "Iteration 9637, loss = 379.61669806\n",
      "Iteration 9638, loss = 379.62855423\n",
      "Iteration 9639, loss = 379.63145650\n",
      "Iteration 9640, loss = 379.60859787\n",
      "Iteration 9641, loss = 379.60033526\n",
      "Iteration 9642, loss = 379.59341160\n",
      "Iteration 9643, loss = 379.59328634\n",
      "Iteration 9644, loss = 379.57248541\n",
      "Iteration 9645, loss = 379.59208862\n",
      "Iteration 9646, loss = 379.61413502\n",
      "Iteration 9647, loss = 379.59653467\n",
      "Iteration 9648, loss = 379.59452545\n",
      "Iteration 9649, loss = 379.61544628\n",
      "Iteration 9650, loss = 379.58607012\n",
      "Iteration 9651, loss = 379.55783103\n",
      "Iteration 9652, loss = 379.56173766\n",
      "Iteration 9653, loss = 379.55189202\n",
      "Iteration 9654, loss = 379.54656612\n",
      "Iteration 9655, loss = 379.54963972\n",
      "Iteration 9656, loss = 379.55924516\n",
      "Iteration 9657, loss = 379.56518088\n",
      "Iteration 9658, loss = 379.54303325\n",
      "Iteration 9659, loss = 379.52465754\n",
      "Iteration 9660, loss = 379.51320914\n",
      "Iteration 9661, loss = 379.52317570\n",
      "Iteration 9662, loss = 379.51696022\n",
      "Iteration 9663, loss = 379.48830564\n",
      "Iteration 9664, loss = 379.47572824\n",
      "Iteration 9665, loss = 379.44694658\n",
      "Iteration 9666, loss = 379.46354802\n",
      "Iteration 9667, loss = 379.47458202\n",
      "Iteration 9668, loss = 379.45338751\n",
      "Iteration 9669, loss = 379.46899079\n",
      "Iteration 9670, loss = 379.46494946\n",
      "Iteration 9671, loss = 379.47727074\n",
      "Iteration 9672, loss = 379.48398789\n",
      "Iteration 9673, loss = 379.45224538\n",
      "Iteration 9674, loss = 379.48557352\n",
      "Iteration 9675, loss = 379.49300228\n",
      "Iteration 9676, loss = 379.48858852\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Mean squared error: 596961.41\n"
     ]
    }
   ],
   "source": [
    "#Antrenam modeul folosind setul de train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Facem predictii\n",
    "y_pred = regr.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0]),\n",
       " array([7281,  364,  389,   20]),\n",
       " array([3, 0, 1, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([512,   5, 101,   2]),\n",
       " array([9, 0, 3, 0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([2315,   81,  253,   13]),\n",
       " array([6234,  305,  380,   22]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([2062,   67,  248,   11]),\n",
       " array([77,  0, 14,  0]),\n",
       " array([1562,   39,  233,    7]),\n",
       " array([-1,  0,  0,  0]),\n",
       " array([3524,  153,  330,   20]),\n",
       " array([4172,  189,  349,   21]),\n",
       " array([154,   0,  26,   0]),\n",
       " array([0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertim din float in int\n",
    "result_int = []\n",
    "for x in y_pred:\n",
    "    result_int.append(x.astype(int))\n",
    "\n",
    "result_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.50897365e+00, -1.51320548e+03,  1.65702373e-02, -2.16647283e+03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#MLP Regressor pentru NN Multy Layer\n",
    "regr = MLPRegressor(solver='adam', hidden_layer_sizes=(200,100), max_iter=10000,activation='relu')\n",
    "#regr = MLPRegressor(solver=’lbfgs’, hiddenlayersizes=(200,150), maxiter=20000,activation=’relu’, alpha = 0.0003)\n",
    "#regr = MLPRegressor(solver=’adam’, hiddenlayersizes=(200,100), maxiter=10000,activation=’relu’)\n",
    "\n",
    "#Cross validation score\n",
    "cross_val_score(regr, y_test, X_test, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6, 7671,   12,    4, 1206,    5, 3660, 3351, 8289,    4,  -39,\n",
       "          4,    4,  162,    4, -313,    4,    4,    4,    4,  644])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregatim coloana pentru cazuri de persoane infectate\n",
    "y = data.iloc[:, 2].values\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "X_final = data.iloc[:, 0:2].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.17)\n",
    "\n",
    "regr.fit(X_train, y_train.ravel())\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0],\n",
       "       [7707],\n",
       "       [   0],\n",
       "       [   3],\n",
       "       [1029],\n",
       "       [   0],\n",
       "       [3183],\n",
       "       [2738],\n",
       "       [8418],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [ 158],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   9],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   3],\n",
       "       [ 576]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6, 7671,   12,    4, 1206,    5, 3660, 3351, 8289,    4,    0,\n",
       "          4,    4,  162,    4,    0,    4,    4,    4,    4,  644])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daca avem numere negative, le facem 0 pentru a putea aplica metricile de evaluare\n",
    "num = 0\n",
    "while(num < len(y_pred)): \n",
    "      \n",
    "    if y_pred[num] < 0: \n",
    "        y_pred[num] = 0\n",
    "    num = num + 1\n",
    "    \n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952023958340268"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Am folosit diferite metrici pentru a putea estima acuritatea rezultatelor obtinute\n",
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613.4388236317118"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import max_error\n",
    "max_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.42135995375807"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31340.27185677736"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.542462209216258"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.782038379723854"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946175672765682"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.8.2\n",
      "IPython 7.13.0\n",
      "\n",
      "subprocess unknown\n",
      "pandas 1.0.3\n",
      "numpy 1.18.2\n",
      "os unknown\n",
      "train_test_split not installed\n",
      "preprocessing not installed\n",
      "MLPRegressor not installed\n",
      "watermark 2.0.2\n",
      "mean_squared_error not installed\n",
      "r2_score not installed\n",
      "MinMaxScaler not installed\n",
      "StandardScaler not installed\n",
      "warnings unknown\n",
      "cross_val_score not installed\n",
      "DecisionTreeRegressor not installed\n",
      "explained_variance_score not installed\n",
      "max_error not installed\n",
      "mean_absolute_error not installed\n",
      "mean_squared_log_error not installed\n",
      "median_absolute_error not installed\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.3.0-59-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      " \n",
      "last updated: Thu Jun 18 2020 18:35:48 EEST\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# versiuni de pachete folosite\n",
    "%watermark -v -m -p subprocess,pandas,numpy,os,train_test_split,preprocessing,MLPRegressor,watermark,mean_squared_error,r2_score,MinMaxScaler,StandardScaler,warnings,cross_val_score,DecisionTreeRegressor,explained_variance_score,max_error,mean_absolute_error,mean_squared_log_error,median_absolute_error\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = data.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,10,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(data.columns.values)\n",
    "ax.set_yticklabels(data.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['Date'], data['Death'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "X1 = np.arange(-5, 5, 0.25)\n",
    "Y1 = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X1, Y1)\n",
    "X,Y\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "Z1=1/(1+np.exp(0.2*X+2*Y)) # two inputs, one output neuron (soft threshold)\n",
    "Z2=1/(1+np.exp(-0.2*X-2*Y+1)) # oposing face soft threshold\n",
    "surf = ax.plot_surface(X, Y, Z1, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "ax.set_title('Perceptron - soft threshold separation')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z2, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "ax.set_title(' opossite facing soft threshold separation')\n",
    "#surf = ax.plot_surface(X, Y, 1/(1+np.exp(Z1+Z2)), cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
